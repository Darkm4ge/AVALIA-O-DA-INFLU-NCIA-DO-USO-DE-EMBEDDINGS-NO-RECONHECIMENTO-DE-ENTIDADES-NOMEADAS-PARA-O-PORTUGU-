{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_wSlmVnjBfP"
      },
      "source": [
        "# FlairNLP\n",
        "\n",
        "Baseado nos tutoriais do flairNLP\n",
        "https://github.com/flairNLP/flair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7cv6MyYj9g4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install flair transformers seqeval git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEAuBQUjA0bl"
      },
      "source": [
        "## Teste 1.1 NER Flair Classic Word Embeddings com Corpus Multi_Wikiner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecLSL6v1A0bq"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E0IZf4sA0bq"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "\n",
        "## Corpus\n",
        "from flair.datasets import NER_MULTI_WIKINER\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import WordEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb2KbJ6LA0br"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZehCu-YA0br",
        "outputId": "7ce302f8-dc55-49f1-874c-ebeaf540568d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-22 22:57:47,053 https://raw.githubusercontent.com/dice-group/FOX/master/input/Wikiner/aij-wikiner-en-wp3.bz2 not found in cache, downloading to /tmp/tmpsb20m97a\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6208404/6208404 [00:00<00:00, 46017275.49B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-22 22:57:47,246 copying /tmp/tmpsb20m97a to cache at /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.bz2\n",
            "2022-11-22 22:57:47,255 removing temp file /tmp/tmpsb20m97a\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-22 22:57:50,908 Read data for language en\n",
            "2022-11-22 22:57:50,910 Reading data from /root/.flair/datasets/ner_multi_wikiner/en\n",
            "2022-11-22 22:57:50,912 Train: /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.train\n",
            "2022-11-22 22:57:50,913 Dev: None\n",
            "2022-11-22 22:57:50,915 Test: None\n",
            "MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en\n"
          ]
        }
      ],
      "source": [
        "## Corpus\n",
        "# 1. get the corpus\n",
        "corpus = NER_MULTI_WIKINER()\n",
        "print(corpus)\n",
        "\n",
        "## Tarefa\n",
        "# 2. what label do we want to predict?\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79eqxwH-A0br",
        "outputId": "aa5d320e-a352-454a-98f7-d174b10c0f35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-22 22:58:52,312 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "115144it [01:02, 1828.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-22 22:59:55,324 Dictionary created for label 'ner' with 5 values: PER (seen 77966 times), LOC (seen 69767 times), MISC (seen 59730 times), ORG (seen 40027 times)\n",
            "Dictionary with 5 tags: <unk>, PER, LOC, MISC, ORG\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# 3. make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa8JGdIZA0br"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R0JQ7PJA0br",
        "outputId": "fe11b63c-304f-4364-d89e-72deb388c47f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-22 23:13:44,652 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpb_lfsvcm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 710528528/710528528 [01:03<00:00, 11150720.66B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-22 23:14:49,198 copying /tmp/tmpb_lfsvcm to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M.vectors.npy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-22 23:14:51,049 removing temp file /tmp/tmpb_lfsvcm\n",
            "2022-11-22 23:14:52,470 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmp4ul8g0_x\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23541010/23541010 [00:03<00:00, 6289157.24B/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-22 23:14:57,059 copying /tmp/tmp4ul8g0_x to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-22 23:14:57,084 removing temp file /tmp/tmp4ul8g0_x\n"
          ]
        }
      ],
      "source": [
        "## Embeddings\n",
        "# Initialize embedding\n",
        "embeddings = WordEmbeddings('pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Pwv28MA0br"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecCdj_i-A0br",
        "outputId": "5c8f59e0-5c6a-4528-e0c5-58cb32f171da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-22 23:29:56,488 SequenceTagger predicts: Dictionary with 17 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "# 5. initialize sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1808-0DLA0br",
        "outputId": "485e85d6-ce85-4756-af4b-ca2926757f9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-22 23:30:07,867 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-22 23:30:07,869 Model: \"SequenceTagger(\n",
            "  (embeddings): WordEmbeddings(\n",
            "    'pt'\n",
            "    (embedding): Embedding(592108, 300)\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=300, out_features=300, bias=True)\n",
            "  (rnn): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=19, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-11-22 23:30:07,871 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-22 23:30:07,873 Corpus: \"MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en\"\n",
            "2022-11-22 23:30:07,874 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-22 23:30:07,876 Parameters:\n",
            "2022-11-22 23:30:07,879  - learning_rate: \"0.100000\"\n",
            "2022-11-22 23:30:07,882  - mini_batch_size: \"32\"\n",
            "2022-11-22 23:30:07,884  - patience: \"3\"\n",
            "2022-11-22 23:30:07,886  - anneal_factor: \"0.5\"\n",
            "2022-11-22 23:30:07,888  - max_epochs: \"10\"\n",
            "2022-11-22 23:30:07,890  - shuffle: \"True\"\n",
            "2022-11-22 23:30:07,892  - train_with_dev: \"False\"\n",
            "2022-11-22 23:30:07,894  - batch_growth_annealing: \"False\"\n",
            "2022-11-22 23:30:07,896 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-22 23:30:07,897 Model training base path: \"resources/taggers/sota-ner-flair\"\n",
            "2022-11-22 23:30:07,899 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-22 23:30:07,900 Device: cuda:0\n",
            "2022-11-22 23:30:07,901 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-22 23:30:07,902 Embeddings storage mode: cpu\n",
            "2022-11-22 23:30:07,904 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-22 23:30:49,750 epoch 1 - iter 359/3599 - loss 0.45141198 - samples/sec: 390.34 - lr: 0.100000\n",
            "2022-11-22 23:31:29,761 epoch 1 - iter 718/3599 - loss 0.36210393 - samples/sec: 406.60 - lr: 0.100000\n",
            "2022-11-22 23:32:09,601 epoch 1 - iter 1077/3599 - loss 0.32094341 - samples/sec: 403.13 - lr: 0.100000\n",
            "2022-11-22 23:32:50,466 epoch 1 - iter 1436/3599 - loss 0.29693081 - samples/sec: 392.37 - lr: 0.100000\n"
          ]
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# 6. initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 7. start training\n",
        "trainer.train('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              #embeddings_storage_mode='gpu',\n",
        "              max_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3krh2xB7vtX"
      },
      "source": [
        "## Teste 1.2 NER Flair Staked Embeddings com Corpus Multi_Wikiner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvzF9y-17vte"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cYuGHBi7vte"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "\n",
        "## Corpus\n",
        "from flair.datasets import NER_MULTI_WIKINER\n",
        "\n",
        "## Importando os Embeddings, Flair-pt\n",
        "from flair.embeddings import FlairEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nmlv9Di7vte"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QApI0tN7vte",
        "outputId": "0471a9ce-8fcf-4d64-c7af-b162108e2f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 18:42:45,512 https://raw.githubusercontent.com/dice-group/FOX/master/input/Wikiner/aij-wikiner-en-wp3.bz2 not found in cache, downloading to /tmp/tmpmk089f03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6208404/6208404 [00:00<00:00, 69358257.97B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 18:42:45,636 copying /tmp/tmpmk089f03 to cache at /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.bz2\n",
            "2022-12-08 18:42:45,644 removing temp file /tmp/tmpmk089f03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 18:42:49,156 Read data for language en\n",
            "2022-12-08 18:42:49,158 Reading data from /root/.flair/datasets/ner_multi_wikiner/en\n",
            "2022-12-08 18:42:49,159 Train: /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.train\n",
            "2022-12-08 18:42:49,162 Dev: None\n",
            "2022-12-08 18:42:49,164 Test: None\n",
            "MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en\n"
          ]
        }
      ],
      "source": [
        "## Corpus\n",
        "# 1. get the corpus\n",
        "corpus = NER_MULTI_WIKINER()\n",
        "print(corpus)\n",
        "\n",
        "## Tarefa\n",
        "# 2. what label do we want to predict?\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK9hh3GO7vte",
        "outputId": "66ad3a02-0776-49bc-80f1-25058b2d6e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 18:42:51,977 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "115144it [00:53, 2153.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 18:43:45,517 Dictionary created for label 'ner' with 5 values: PER (seen 78167 times), LOC (seen 69480 times), MISC (seen 59599 times), ORG (seen 40034 times)\n",
            "Dictionary with 5 tags: <unk>, PER, LOC, MISC, ORG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# 3. make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oomnwDAA7vtf"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0XS0GBN7vtf",
        "outputId": "7bb571aa-f316-4084-bb8e-b729932b1d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 18:43:45,638 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-forward.pt not found in cache, downloading to /tmp/tmp0_xc8x98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 72819080/72819080 [00:02<00:00, 27963731.70B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 18:43:48,340 copying /tmp/tmp0_xc8x98 to cache at /root/.flair/embeddings/lm-pt-forward.pt\n",
            "2022-12-08 18:43:48,395 removing temp file /tmp/tmp0_xc8x98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 18:44:00,030 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-backward.pt not found in cache, downloading to /tmp/tmpfnpzbqg8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 72819080/72819080 [00:02<00:00, 35638183.05B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 18:44:02,196 copying /tmp/tmpfnpzbqg8 to cache at /root/.flair/embeddings/lm-pt-backward.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 18:44:02,249 removing temp file /tmp/tmpfnpzbqg8\n"
          ]
        }
      ],
      "source": [
        "## Empilhando os Embeddings\n",
        "from flair.embeddings import StackedEmbeddings\n",
        "\n",
        "# init Flair embeddings\n",
        "flair_embedding_forward = FlairEmbeddings('pt-forward')\n",
        "flair_embedding_backward = FlairEmbeddings('pt-backward')\n",
        "\n",
        "# create a StackedEmbedding object that combines glove and forward/backward flair embeddings\n",
        "embeddings = StackedEmbeddings([\n",
        "                                        flair_embedding_forward,\n",
        "                                        flair_embedding_backward,\n",
        "                                       ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwbeFKLl7vtf"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHXxqWJi7vtf",
        "outputId": "43ec6583-a7f7-4f9b-8115-4e3b7f1a1e51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 18:44:02,459 SequenceTagger predicts: Dictionary with 17 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "# 5. initialize sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztzddnNJSvGN",
        "outputId": "a30939c6-f86b-49d5-84fa-05e623027761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Flair_NLP/sota-ner-flair'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uARO7zxfSxh8"
      },
      "outputs": [],
      "source": [
        "## Treinando o modelo\n",
        "# 6. initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 7. start training\n",
        "trainer.train(path,\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=10,\n",
        "              checkpoint=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obKxpufr7vtf",
        "outputId": "3f406173-246a-4cb1-bd21-f96b4c4c0b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 18:44:30,434 loading file /content/drive/MyDrive/Flair_NLP/sota-ner-flair/checkpoint.pt\n",
            "2022-12-08 18:44:35,203 SequenceTagger predicts: Dictionary with 19 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, <START>, <STOP>\n",
            "2022-12-08 18:44:35,500 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 18:44:35,503 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (rnn): LSTM(4096, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=19, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-12-08 18:44:35,506 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 18:44:35,509 Corpus: \"MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en\"\n",
            "2022-12-08 18:44:35,511 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 18:44:35,513 Parameters:\n",
            "2022-12-08 18:44:35,516  - learning_rate: \"0.100000\"\n",
            "2022-12-08 18:44:35,518  - mini_batch_size: \"32\"\n",
            "2022-12-08 18:44:35,520  - patience: \"3\"\n",
            "2022-12-08 18:44:35,523  - anneal_factor: \"0.5\"\n",
            "2022-12-08 18:44:35,524  - max_epochs: \"65\"\n",
            "2022-12-08 18:44:35,527  - shuffle: \"True\"\n",
            "2022-12-08 18:44:35,528  - train_with_dev: \"False\"\n",
            "2022-12-08 18:44:35,531  - batch_growth_annealing: \"False\"\n",
            "2022-12-08 18:44:35,533 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 18:44:35,535 Model training base path: \"/content/drive/MyDrive/Flair_NLP/sota-ner-flair-resume\"\n",
            "2022-12-08 18:44:35,536 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 18:44:35,540 Device: cuda:0\n",
            "2022-12-08 18:44:35,542 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 18:44:35,544 Embeddings storage mode: cpu\n",
            "2022-12-08 18:44:35,546 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 18:47:32,566 epoch 54 - iter 359/3599 - loss 0.05059323 - samples/sec: 69.25 - lr: 0.025000\n",
            "2022-12-08 18:50:36,001 epoch 54 - iter 718/3599 - loss 0.05078475 - samples/sec: 66.41 - lr: 0.025000\n",
            "2022-12-08 18:53:37,701 epoch 54 - iter 1077/3599 - loss 0.05103959 - samples/sec: 67.76 - lr: 0.025000\n",
            "2022-12-08 18:56:39,792 epoch 54 - iter 1436/3599 - loss 0.05085239 - samples/sec: 67.59 - lr: 0.025000\n",
            "2022-12-08 18:59:44,190 epoch 54 - iter 1795/3599 - loss 0.05121322 - samples/sec: 66.51 - lr: 0.025000\n",
            "2022-12-08 19:02:47,661 epoch 54 - iter 2154/3599 - loss 0.05125794 - samples/sec: 66.51 - lr: 0.025000\n",
            "2022-12-08 19:05:52,063 epoch 54 - iter 2513/3599 - loss 0.05134562 - samples/sec: 66.49 - lr: 0.025000\n",
            "2022-12-08 19:08:50,851 epoch 54 - iter 2872/3599 - loss 0.05150416 - samples/sec: 68.92 - lr: 0.025000\n",
            "2022-12-08 19:11:49,606 epoch 54 - iter 3231/3599 - loss 0.05144395 - samples/sec: 68.74 - lr: 0.025000\n",
            "2022-12-08 19:14:50,900 epoch 54 - iter 3590/3599 - loss 0.05161416 - samples/sec: 68.02 - lr: 0.025000\n",
            "2022-12-08 19:14:54,792 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 19:14:54,794 EPOCH 54 done: loss 0.0516 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [03:29<00:00,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 19:18:24,622 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 19:18:24,811 DEV : loss 0.03315554931759834 - f1-score (micro avg)  0.8839\n",
            "2022-12-08 19:18:33,623 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 19:18:34,225 saving best model\n",
            "2022-12-08 19:18:34,850 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 19:21:40,064 epoch 55 - iter 359/3599 - loss 0.05091654 - samples/sec: 66.46 - lr: 0.025000\n",
            "2022-12-08 19:24:44,254 epoch 55 - iter 718/3599 - loss 0.05152372 - samples/sec: 66.88 - lr: 0.025000\n",
            "2022-12-08 19:27:44,858 epoch 55 - iter 1077/3599 - loss 0.05127352 - samples/sec: 67.62 - lr: 0.025000\n",
            "2022-12-08 19:30:45,583 epoch 55 - iter 1436/3599 - loss 0.05167316 - samples/sec: 67.42 - lr: 0.025000\n",
            "2022-12-08 19:33:49,531 epoch 55 - iter 1795/3599 - loss 0.05134376 - samples/sec: 66.15 - lr: 0.025000\n",
            "2022-12-08 19:36:49,843 epoch 55 - iter 2154/3599 - loss 0.05155785 - samples/sec: 68.09 - lr: 0.025000\n",
            "2022-12-08 19:39:53,928 epoch 55 - iter 2513/3599 - loss 0.05167289 - samples/sec: 66.47 - lr: 0.025000\n",
            "2022-12-08 19:42:53,347 epoch 55 - iter 2872/3599 - loss 0.05178165 - samples/sec: 68.62 - lr: 0.025000\n",
            "2022-12-08 19:45:52,243 epoch 55 - iter 3231/3599 - loss 0.05158333 - samples/sec: 67.82 - lr: 0.025000\n",
            "2022-12-08 19:48:53,056 epoch 55 - iter 3590/3599 - loss 0.05156324 - samples/sec: 68.05 - lr: 0.025000\n",
            "2022-12-08 19:48:57,148 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 19:48:57,150 EPOCH 55 done: loss 0.0516 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [03:29<00:00,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 19:52:26,694 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 19:52:26,881 DEV : loss 0.03339666500687599 - f1-score (micro avg)  0.8829\n",
            "2022-12-08 19:52:36,250 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 19:52:36,817 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 19:55:40,817 epoch 56 - iter 359/3599 - loss 0.05140079 - samples/sec: 66.53 - lr: 0.025000\n",
            "2022-12-08 19:58:40,286 epoch 56 - iter 718/3599 - loss 0.05138424 - samples/sec: 68.30 - lr: 0.025000\n",
            "2022-12-08 20:01:44,432 epoch 56 - iter 1077/3599 - loss 0.05117302 - samples/sec: 66.48 - lr: 0.025000\n",
            "2022-12-08 20:04:46,483 epoch 56 - iter 1436/3599 - loss 0.05123495 - samples/sec: 67.73 - lr: 0.025000\n",
            "2022-12-08 20:07:45,015 epoch 56 - iter 1795/3599 - loss 0.05112820 - samples/sec: 69.06 - lr: 0.025000\n",
            "2022-12-08 20:10:42,780 epoch 56 - iter 2154/3599 - loss 0.05115983 - samples/sec: 69.12 - lr: 0.025000\n",
            "2022-12-08 20:13:46,344 epoch 56 - iter 2513/3599 - loss 0.05125027 - samples/sec: 66.32 - lr: 0.025000\n",
            "2022-12-08 20:16:52,082 epoch 56 - iter 2872/3599 - loss 0.05117552 - samples/sec: 66.10 - lr: 0.025000\n",
            "2022-12-08 20:19:51,791 epoch 56 - iter 3231/3599 - loss 0.05095634 - samples/sec: 68.16 - lr: 0.025000\n",
            "2022-12-08 20:22:55,264 epoch 56 - iter 3590/3599 - loss 0.05108724 - samples/sec: 66.71 - lr: 0.025000\n",
            "2022-12-08 20:22:59,020 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 20:22:59,022 EPOCH 56 done: loss 0.0511 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [03:30<00:00,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 20:26:29,568 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 20:26:29,769 DEV : loss 0.03337882459163666 - f1-score (micro avg)  0.8829\n",
            "2022-12-08 20:26:39,166 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 20:26:39,787 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 20:29:40,142 epoch 57 - iter 359/3599 - loss 0.05019054 - samples/sec: 67.60 - lr: 0.025000\n",
            "2022-12-08 20:32:40,341 epoch 57 - iter 718/3599 - loss 0.05012523 - samples/sec: 67.52 - lr: 0.025000\n",
            "2022-12-08 20:35:43,497 epoch 57 - iter 1077/3599 - loss 0.05004090 - samples/sec: 66.53 - lr: 0.025000\n",
            "2022-12-08 20:38:45,210 epoch 57 - iter 1436/3599 - loss 0.05053504 - samples/sec: 67.41 - lr: 0.025000\n",
            "2022-12-08 20:41:47,463 epoch 57 - iter 1795/3599 - loss 0.05063283 - samples/sec: 67.36 - lr: 0.025000\n",
            "2022-12-08 20:44:51,352 epoch 57 - iter 2154/3599 - loss 0.05066698 - samples/sec: 66.77 - lr: 0.025000\n",
            "2022-12-08 20:47:54,871 epoch 57 - iter 2513/3599 - loss 0.05075794 - samples/sec: 66.37 - lr: 0.025000\n",
            "2022-12-08 20:50:54,502 epoch 57 - iter 2872/3599 - loss 0.05079662 - samples/sec: 68.24 - lr: 0.025000\n",
            "2022-12-08 20:53:55,139 epoch 57 - iter 3231/3599 - loss 0.05106126 - samples/sec: 67.99 - lr: 0.025000\n",
            "2022-12-08 20:56:57,133 epoch 57 - iter 3590/3599 - loss 0.05098266 - samples/sec: 67.26 - lr: 0.025000\n",
            "2022-12-08 20:57:02,075 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 20:57:02,077 EPOCH 57 done: loss 0.0510 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [03:28<00:00,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 21:00:31,032 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 21:00:31,228 DEV : loss 0.033538468182086945 - f1-score (micro avg)  0.8816\n",
            "2022-12-08 21:00:40,093 BAD EPOCHS (no improvement): 3\n",
            "2022-12-08 21:00:40,729 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 21:03:42,198 epoch 58 - iter 359/3599 - loss 0.05024117 - samples/sec: 66.99 - lr: 0.025000\n",
            "2022-12-08 21:06:42,506 epoch 58 - iter 718/3599 - loss 0.05130312 - samples/sec: 67.56 - lr: 0.025000\n",
            "2022-12-08 21:09:45,888 epoch 58 - iter 1077/3599 - loss 0.05121155 - samples/sec: 67.04 - lr: 0.025000\n",
            "2022-12-08 21:12:46,408 epoch 58 - iter 1436/3599 - loss 0.05075006 - samples/sec: 68.16 - lr: 0.025000\n",
            "2022-12-08 21:15:48,637 epoch 58 - iter 1795/3599 - loss 0.05078508 - samples/sec: 67.67 - lr: 0.025000\n",
            "2022-12-08 21:18:46,687 epoch 58 - iter 2154/3599 - loss 0.05074026 - samples/sec: 68.66 - lr: 0.025000\n",
            "2022-12-08 21:21:51,271 epoch 58 - iter 2513/3599 - loss 0.05075213 - samples/sec: 65.92 - lr: 0.025000\n",
            "2022-12-08 21:24:53,745 epoch 58 - iter 2872/3599 - loss 0.05085364 - samples/sec: 66.89 - lr: 0.025000\n",
            "2022-12-08 21:27:55,659 epoch 58 - iter 3231/3599 - loss 0.05089834 - samples/sec: 66.63 - lr: 0.025000\n",
            "2022-12-08 21:30:56,977 epoch 58 - iter 3590/3599 - loss 0.05086019 - samples/sec: 68.02 - lr: 0.025000\n",
            "2022-12-08 21:31:00,984 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 21:31:00,986 EPOCH 58 done: loss 0.0508 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [03:28<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 21:34:29,804 Evaluating as a multi-label problem: False\n",
            "2022-12-08 21:34:29,991 DEV : loss 0.03402284160256386 - f1-score (micro avg)  0.881\n",
            "2022-12-08 21:34:39,040 Epoch    58: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2022-12-08 21:34:39,042 BAD EPOCHS (no improvement): 4\n",
            "2022-12-08 21:34:39,630 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 21:37:42,970 epoch 59 - iter 359/3599 - loss 0.04994975 - samples/sec: 66.45 - lr: 0.012500\n",
            "2022-12-08 21:40:43,584 epoch 59 - iter 718/3599 - loss 0.05037436 - samples/sec: 68.29 - lr: 0.012500\n",
            "2022-12-08 21:43:46,846 epoch 59 - iter 1077/3599 - loss 0.05022167 - samples/sec: 66.28 - lr: 0.012500\n",
            "2022-12-08 21:46:46,396 epoch 59 - iter 1436/3599 - loss 0.04993305 - samples/sec: 68.23 - lr: 0.012500\n",
            "2022-12-08 21:49:48,431 epoch 59 - iter 1795/3599 - loss 0.04967358 - samples/sec: 67.22 - lr: 0.012500\n",
            "2022-12-08 21:52:50,721 epoch 59 - iter 2154/3599 - loss 0.04997911 - samples/sec: 67.17 - lr: 0.012500\n",
            "2022-12-08 21:55:51,806 epoch 59 - iter 2513/3599 - loss 0.04977377 - samples/sec: 67.11 - lr: 0.012500\n",
            "2022-12-08 21:58:50,862 epoch 59 - iter 2872/3599 - loss 0.04975028 - samples/sec: 68.25 - lr: 0.012500\n",
            "2022-12-08 22:01:53,013 epoch 59 - iter 3231/3599 - loss 0.04975398 - samples/sec: 66.55 - lr: 0.012500\n",
            "2022-12-08 22:04:55,484 epoch 59 - iter 3590/3599 - loss 0.04975568 - samples/sec: 67.24 - lr: 0.012500\n",
            "2022-12-08 22:05:00,140 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 22:05:00,142 EPOCH 59 done: loss 0.0497 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [03:29<00:00,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 22:08:30,004 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 22:08:30,191 DEV : loss 0.03346940129995346 - f1-score (micro avg)  0.8819\n",
            "2022-12-08 22:08:39,023 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 22:08:39,642 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 22:11:40,923 epoch 60 - iter 359/3599 - loss 0.04842534 - samples/sec: 67.38 - lr: 0.012500\n",
            "2022-12-08 22:14:42,488 epoch 60 - iter 718/3599 - loss 0.04875447 - samples/sec: 67.28 - lr: 0.012500\n",
            "2022-12-08 22:17:43,196 epoch 60 - iter 1077/3599 - loss 0.04922383 - samples/sec: 68.13 - lr: 0.012500\n",
            "2022-12-08 22:20:46,339 epoch 60 - iter 1436/3599 - loss 0.04905793 - samples/sec: 67.46 - lr: 0.012500\n",
            "2022-12-08 22:23:49,618 epoch 60 - iter 1795/3599 - loss 0.04925022 - samples/sec: 66.98 - lr: 0.012500\n",
            "2022-12-08 22:26:49,781 epoch 60 - iter 2154/3599 - loss 0.04936198 - samples/sec: 67.65 - lr: 0.012500\n",
            "2022-12-08 22:29:52,125 epoch 60 - iter 2513/3599 - loss 0.04939714 - samples/sec: 66.97 - lr: 0.012500\n",
            "2022-12-08 22:32:51,488 epoch 60 - iter 2872/3599 - loss 0.04941468 - samples/sec: 68.98 - lr: 0.012500\n",
            "2022-12-08 22:35:53,989 epoch 60 - iter 3231/3599 - loss 0.04940286 - samples/sec: 67.37 - lr: 0.012500\n",
            "2022-12-08 22:38:57,356 epoch 60 - iter 3590/3599 - loss 0.04928581 - samples/sec: 66.29 - lr: 0.012500\n",
            "2022-12-08 22:39:01,827 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 22:39:01,829 EPOCH 60 done: loss 0.0493 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [03:29<00:00,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 22:42:31,653 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 22:42:31,847 DEV : loss 0.033621639013290405 - f1-score (micro avg)  0.8815\n",
            "2022-12-08 22:42:40,664 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 22:42:41,242 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 22:45:44,299 epoch 61 - iter 359/3599 - loss 0.04852537 - samples/sec: 66.85 - lr: 0.012500\n",
            "2022-12-08 22:48:45,879 epoch 61 - iter 718/3599 - loss 0.04963100 - samples/sec: 66.95 - lr: 0.012500\n",
            "2022-12-08 22:51:45,439 epoch 61 - iter 1077/3599 - loss 0.04954080 - samples/sec: 68.24 - lr: 0.012500\n",
            "2022-12-08 22:54:46,994 epoch 61 - iter 1436/3599 - loss 0.04956612 - samples/sec: 66.93 - lr: 0.012500\n",
            "2022-12-08 22:57:48,761 epoch 61 - iter 1795/3599 - loss 0.04936398 - samples/sec: 67.34 - lr: 0.012500\n",
            "2022-12-08 23:00:49,028 epoch 61 - iter 2154/3599 - loss 0.04937412 - samples/sec: 67.93 - lr: 0.012500\n",
            "2022-12-08 23:03:50,939 epoch 61 - iter 2513/3599 - loss 0.04931846 - samples/sec: 66.81 - lr: 0.012500\n",
            "2022-12-08 23:06:52,285 epoch 61 - iter 2872/3599 - loss 0.04935825 - samples/sec: 67.03 - lr: 0.012500\n",
            "2022-12-08 23:09:55,249 epoch 61 - iter 3231/3599 - loss 0.04934709 - samples/sec: 66.94 - lr: 0.012500\n",
            "2022-12-08 23:12:56,933 epoch 61 - iter 3590/3599 - loss 0.04919065 - samples/sec: 66.70 - lr: 0.012500\n",
            "2022-12-08 23:13:01,014 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 23:13:01,016 EPOCH 61 done: loss 0.0492 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [03:28<00:00,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 23:16:30,045 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 23:16:30,231 DEV : loss 0.03359127417206764 - f1-score (micro avg)  0.8819\n",
            "2022-12-08 23:16:39,043 BAD EPOCHS (no improvement): 3\n",
            "2022-12-08 23:16:39,614 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 23:19:43,643 epoch 62 - iter 359/3599 - loss 0.04923401 - samples/sec: 66.94 - lr: 0.012500\n",
            "2022-12-08 23:22:45,534 epoch 62 - iter 718/3599 - loss 0.04907112 - samples/sec: 67.65 - lr: 0.012500\n",
            "2022-12-08 23:25:44,062 epoch 62 - iter 1077/3599 - loss 0.04865779 - samples/sec: 68.28 - lr: 0.012500\n",
            "2022-12-08 23:28:48,894 epoch 62 - iter 1436/3599 - loss 0.04886075 - samples/sec: 65.81 - lr: 0.012500\n",
            "2022-12-08 23:31:50,344 epoch 62 - iter 1795/3599 - loss 0.04888479 - samples/sec: 67.32 - lr: 0.012500\n",
            "2022-12-08 23:34:48,539 epoch 62 - iter 2154/3599 - loss 0.04895920 - samples/sec: 68.78 - lr: 0.012500\n",
            "2022-12-08 23:37:49,990 epoch 62 - iter 2513/3599 - loss 0.04883737 - samples/sec: 67.60 - lr: 0.012500\n",
            "2022-12-08 23:40:51,084 epoch 62 - iter 2872/3599 - loss 0.04866263 - samples/sec: 67.62 - lr: 0.012500\n",
            "2022-12-08 23:43:47,888 epoch 62 - iter 3231/3599 - loss 0.04879912 - samples/sec: 69.16 - lr: 0.012500\n",
            "2022-12-08 23:46:51,307 epoch 62 - iter 3590/3599 - loss 0.04893142 - samples/sec: 67.02 - lr: 0.012500\n",
            "2022-12-08 23:46:55,176 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 23:46:55,178 EPOCH 62 done: loss 0.0489 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [03:30<00:00,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 23:50:25,615 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 23:50:25,797 DEV : loss 0.03345775976777077 - f1-score (micro avg)  0.8816\n",
            "2022-12-08 23:50:35,250 Epoch    62: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2022-12-08 23:50:35,253 BAD EPOCHS (no improvement): 4\n",
            "2022-12-08 23:50:35,845 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 23:53:41,412 epoch 63 - iter 359/3599 - loss 0.04775655 - samples/sec: 66.27 - lr: 0.006250\n",
            "2022-12-08 23:56:42,428 epoch 63 - iter 718/3599 - loss 0.04810538 - samples/sec: 67.80 - lr: 0.006250\n",
            "2022-12-08 23:59:43,837 epoch 63 - iter 1077/3599 - loss 0.04843930 - samples/sec: 67.35 - lr: 0.006250\n",
            "2022-12-09 00:02:51,939 epoch 63 - iter 1436/3599 - loss 0.04834537 - samples/sec: 65.39 - lr: 0.006250\n",
            "2022-12-09 00:05:55,777 epoch 63 - iter 1795/3599 - loss 0.04824463 - samples/sec: 66.53 - lr: 0.006250\n",
            "2022-12-09 00:08:51,736 epoch 63 - iter 2154/3599 - loss 0.04829624 - samples/sec: 68.99 - lr: 0.006250\n",
            "2022-12-09 00:11:53,036 epoch 63 - iter 2513/3599 - loss 0.04846631 - samples/sec: 68.00 - lr: 0.006250\n",
            "2022-12-09 00:14:53,371 epoch 63 - iter 2872/3599 - loss 0.04852250 - samples/sec: 68.23 - lr: 0.006250\n",
            "2022-12-09 00:17:54,687 epoch 63 - iter 3231/3599 - loss 0.04851350 - samples/sec: 67.17 - lr: 0.006250\n",
            "2022-12-09 00:20:54,930 epoch 63 - iter 3590/3599 - loss 0.04852305 - samples/sec: 67.29 - lr: 0.006250\n",
            "2022-12-09 00:20:58,814 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 00:20:58,816 EPOCH 63 done: loss 0.0485 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [03:30<00:00,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-09 00:24:29,356 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-09 00:24:29,548 DEV : loss 0.033426813781261444 - f1-score (micro avg)  0.883\n",
            "2022-12-09 00:24:39,027 BAD EPOCHS (no improvement): 1\n",
            "2022-12-09 00:24:39,624 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 00:27:42,742 epoch 64 - iter 359/3599 - loss 0.04773550 - samples/sec: 66.43 - lr: 0.006250\n",
            "2022-12-09 00:30:44,094 epoch 64 - iter 718/3599 - loss 0.04771644 - samples/sec: 67.07 - lr: 0.006250\n",
            "2022-12-09 00:33:45,243 epoch 64 - iter 1077/3599 - loss 0.04836028 - samples/sec: 67.78 - lr: 0.006250\n",
            "2022-12-09 00:36:46,955 epoch 64 - iter 1436/3599 - loss 0.04883840 - samples/sec: 67.93 - lr: 0.006250\n",
            "2022-12-09 00:39:47,662 epoch 64 - iter 1795/3599 - loss 0.04874391 - samples/sec: 67.46 - lr: 0.006250\n",
            "2022-12-09 00:42:52,215 epoch 64 - iter 2154/3599 - loss 0.04862664 - samples/sec: 66.46 - lr: 0.006250\n",
            "2022-12-09 00:45:54,607 epoch 64 - iter 2513/3599 - loss 0.04857048 - samples/sec: 66.98 - lr: 0.006250\n",
            "2022-12-09 00:48:55,202 epoch 64 - iter 2872/3599 - loss 0.04856956 - samples/sec: 67.35 - lr: 0.006250\n",
            "2022-12-09 00:51:59,631 epoch 64 - iter 3231/3599 - loss 0.04857408 - samples/sec: 66.70 - lr: 0.006250\n",
            "2022-12-09 00:54:59,465 epoch 64 - iter 3590/3599 - loss 0.04847080 - samples/sec: 68.50 - lr: 0.006250\n",
            "2022-12-09 00:55:03,576 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 00:55:03,578 EPOCH 64 done: loss 0.0485 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [03:30<00:00,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-09 00:58:33,952 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-09 00:58:34,147 DEV : loss 0.033211324363946915 - f1-score (micro avg)  0.8832\n",
            "2022-12-09 00:58:43,575 BAD EPOCHS (no improvement): 2\n",
            "2022-12-09 00:58:44,162 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 01:01:46,045 epoch 65 - iter 359/3599 - loss 0.04769880 - samples/sec: 67.39 - lr: 0.006250\n",
            "2022-12-09 01:04:48,818 epoch 65 - iter 718/3599 - loss 0.04759332 - samples/sec: 67.16 - lr: 0.006250\n",
            "2022-12-09 01:07:49,075 epoch 65 - iter 1077/3599 - loss 0.04760115 - samples/sec: 68.99 - lr: 0.006250\n",
            "2022-12-09 01:10:52,657 epoch 65 - iter 1436/3599 - loss 0.04775375 - samples/sec: 66.85 - lr: 0.006250\n",
            "2022-12-09 01:13:54,009 epoch 65 - iter 1795/3599 - loss 0.04783859 - samples/sec: 67.70 - lr: 0.006250\n",
            "2022-12-09 01:16:54,101 epoch 65 - iter 2154/3599 - loss 0.04777268 - samples/sec: 68.03 - lr: 0.006250\n",
            "2022-12-09 01:19:53,415 epoch 65 - iter 2513/3599 - loss 0.04795795 - samples/sec: 68.19 - lr: 0.006250\n",
            "2022-12-09 01:22:56,418 epoch 65 - iter 2872/3599 - loss 0.04801333 - samples/sec: 67.38 - lr: 0.006250\n",
            "2022-12-09 01:25:56,798 epoch 65 - iter 3231/3599 - loss 0.04809705 - samples/sec: 67.60 - lr: 0.006250\n",
            "2022-12-09 01:28:59,727 epoch 65 - iter 3590/3599 - loss 0.04811009 - samples/sec: 66.44 - lr: 0.006250\n",
            "2022-12-09 01:29:04,010 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 01:29:04,012 EPOCH 65 done: loss 0.0481 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [03:29<00:00,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-09 01:32:34,000 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-09 01:32:34,190 DEV : loss 0.033215440809726715 - f1-score (micro avg)  0.8829\n",
            "2022-12-09 01:32:43,869 BAD EPOCHS (no improvement): 3\n",
            "2022-12-09 01:32:45,120 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 01:32:45,124 loading file /content/drive/MyDrive/Flair_NLP/sota-ner-flair-resume/best-model.pt\n",
            "2022-12-09 01:32:45,921 SequenceTagger predicts: Dictionary with 19 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, <START>, <STOP>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 445/445 [03:43<00:00,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-09 01:36:29,965 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-09 01:36:30,179 0.8836\t0.879\t0.8813\t0.8407\n",
            "2022-12-09 01:36:30,182 \n",
            "Results:\n",
            "- F-score (micro) 0.8813\n",
            "- F-score (macro) 0.8725\n",
            "- Accuracy 0.8407\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         PER     0.9304    0.9554    0.9428      9463\n",
            "         LOC     0.8647    0.9072    0.8854      8736\n",
            "        MISC     0.8534    0.7933    0.8222      7455\n",
            "         ORG     0.8681    0.8128    0.8395      4995\n",
            "\n",
            "   micro avg     0.8836    0.8790    0.8813     30649\n",
            "   macro avg     0.8792    0.8672    0.8725     30649\n",
            "weighted avg     0.8828    0.8790    0.8803     30649\n",
            "\n",
            "2022-12-09 01:36:30,184 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 01:36:30,185 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 445/445 [03:42<00:00,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-09 01:40:13,028 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-09 01:40:13,239 /root/.flair/datasets/ner_multi_wikiner/en\n",
            "2022-12-09 01:40:13,241 0.8836\t0.879\t0.8813\t0.8407\n"
          ]
        }
      ],
      "source": [
        "## Continuando o treinamento\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 8. continue training at later point. Load previously trained model checkpoint, then resume\n",
        "trained_model = SequenceTagger.load(path + '/checkpoint.pt')\n",
        "\n",
        "# resume training best model, but this time until new max-epochs\n",
        "trainer.resume(trained_model,\n",
        "               base_path=path + '-resume',\n",
        "               max_epochs=65,\n",
        "               checkpoint=True,\n",
        "               )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW7c_AtGp5KS"
      },
      "source": [
        "## Teste 1.3 NER Flair Staked Embeddings (Word e Flair Embeddings) com Corpus Multi_Wikiner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT07DOE1nVIj"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_eg69twjJm6"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "\n",
        "## Corpus\n",
        "from flair.datasets import NER_MULTI_WIKINER\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4koyc4JnYod"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvs0-sA2jeeu",
        "outputId": "61976c7d-b41f-4177-9f9e-9d5c04b04a94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:11:14,754 https://raw.githubusercontent.com/dice-group/FOX/master/input/Wikiner/aij-wikiner-en-wp3.bz2 not found in cache, downloading to /tmp/tmpuozd1j5w\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6208404/6208404 [00:00<00:00, 71894393.74B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:11:14,865 copying /tmp/tmpuozd1j5w to cache at /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.bz2\n",
            "2022-10-02 22:11:14,876 removing temp file /tmp/tmpuozd1j5w\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:11:18,635 Read data for language en\n",
            "2022-10-02 22:11:18,638 Reading data from /root/.flair/datasets/ner_multi_wikiner/en\n",
            "2022-10-02 22:11:18,639 Train: /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.train\n",
            "2022-10-02 22:11:18,640 Dev: None\n",
            "2022-10-02 22:11:18,642 Test: None\n",
            "MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en\n"
          ]
        }
      ],
      "source": [
        "## Corpus\n",
        "# 1. get the corpus\n",
        "corpus = NER_MULTI_WIKINER()\n",
        "print(corpus)\n",
        "\n",
        "## Tarefa\n",
        "# 2. what label do we want to predict?\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWEtRTZFjlPN",
        "outputId": "2042a8ed-fa76-4d8b-de37-3c19964caa79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:11:21,086 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "115144it [01:06, 1740.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:12:27,281 Dictionary created for label 'ner' with 5 values: PER (seen 77888 times), LOC (seen 69606 times), MISC (seen 59622 times), ORG (seen 40265 times)\n",
            "Dictionary with 5 tags: <unk>, PER, LOC, MISC, ORG\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# 3. make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE4G2c3MncbG"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNFsG2dAkEJA",
        "outputId": "093b5eb1-dee5-4f29-913c-88f406064e5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:12:29,279 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmp13t7_jmf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 710528528/710528528 [00:53<00:00, 13356902.66B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:13:23,170 copying /tmp/tmp13t7_jmf to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M.vectors.npy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:13:25,149 removing temp file /tmp/tmp13t7_jmf\n",
            "2022-10-02 22:13:27,229 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmpeeyyxw91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23541010/23541010 [00:03<00:00, 7440299.40B/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:13:31,119 copying /tmp/tmpeeyyxw91 to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M\n",
            "2022-10-02 22:13:31,146 removing temp file /tmp/tmpeeyyxw91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:13:34,403 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-forward.pt not found in cache, downloading to /tmp/tmpfxpw_axy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:06<00:00, 10630538.32B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:13:42,027 copying /tmp/tmpfxpw_axy to cache at /root/.flair/embeddings/lm-pt-forward.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:13:42,098 removing temp file /tmp/tmpfxpw_axy\n",
            "2022-10-02 22:13:51,818 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-backward.pt not found in cache, downloading to /tmp/tmp_g0i_uyv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:06<00:00, 10960555.84B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:13:59,233 copying /tmp/tmp_g0i_uyv to cache at /root/.flair/embeddings/lm-pt-backward.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:13:59,305 removing temp file /tmp/tmp_g0i_uyv\n"
          ]
        }
      ],
      "source": [
        "## Stacked Embeddings\n",
        "# Initialize embedding stack with \n",
        "embedding_types = [\n",
        "    WordEmbeddings('pt'),\n",
        "    FlairEmbeddings('pt-forward'),\n",
        "    FlairEmbeddings('pt-backward')\n",
        "]\n",
        "\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmAx0fh0nhhJ"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKqPbwHoqYkc",
        "outputId": "3bbba1fd-2dc1-45c4-f05a-8c84bbbb3588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:13:59,536 SequenceTagger predicts: Dictionary with 17 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "# 5. initialize sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvT68IlfeMSq",
        "outputId": "7d56ac4a-58ae-4a6b-b6c8-a4c47efb8c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Flair_NLP/sota-ner-flair'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bDfp3zCuIjt"
      },
      "outputs": [],
      "source": [
        "## Treinando o modelo\n",
        "# 6. initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 7. start training\n",
        "trainer.train(path,\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=1,\n",
        "              checkpoint=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GijkPYmdf87i",
        "outputId": "f4d99872-a842-4b5e-944f-c07dedfb3900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 22:32:12,860 loading file /content/drive/MyDrive/Flair_NLP/sota-ner-flair/checkpoint.pt\n",
            "2022-10-02 22:32:26,130 SequenceTagger predicts: Dictionary with 19 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, <START>, <STOP>\n",
            "2022-10-02 22:32:26,462 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-02 22:32:26,465 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'pt'\n",
            "      (embedding): Embedding(592108, 300)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4396, out_features=4396, bias=True)\n",
            "  (rnn): LSTM(4396, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=19, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-10-02 22:32:26,467 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-02 22:32:26,471 Corpus: \"MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en\"\n",
            "2022-10-02 22:32:26,474 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-02 22:32:26,476 Parameters:\n",
            "2022-10-02 22:32:26,481  - learning_rate: \"0.100000\"\n",
            "2022-10-02 22:32:26,483  - mini_batch_size: \"32\"\n",
            "2022-10-02 22:32:26,484  - patience: \"3\"\n",
            "2022-10-02 22:32:26,487  - anneal_factor: \"0.5\"\n",
            "2022-10-02 22:32:26,488  - max_epochs: \"40\"\n",
            "2022-10-02 22:32:26,490  - shuffle: \"True\"\n",
            "2022-10-02 22:32:26,492  - train_with_dev: \"False\"\n",
            "2022-10-02 22:32:26,493  - batch_growth_annealing: \"False\"\n",
            "2022-10-02 22:32:26,496 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-02 22:32:26,497 Model training base path: \"/content/drive/MyDrive/Flair_NLP/sota-ner-flair-resume\"\n",
            "2022-10-02 22:32:26,499 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-02 22:32:26,504 Device: cuda:0\n",
            "2022-10-02 22:32:26,506 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-02 22:32:26,508 Embeddings storage mode: cpu\n",
            "2022-10-02 22:32:26,509 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-02 22:35:53,973 epoch 31 - iter 359/3599 - loss 0.05082427 - samples/sec: 58.39 - lr: 0.050000\n",
            "2022-10-02 22:39:19,165 epoch 31 - iter 718/3599 - loss 0.05137251 - samples/sec: 59.26 - lr: 0.050000\n",
            "2022-10-02 22:42:48,349 epoch 31 - iter 1077/3599 - loss 0.05203068 - samples/sec: 58.33 - lr: 0.050000\n",
            "2022-10-02 22:46:17,728 epoch 31 - iter 1436/3599 - loss 0.05159826 - samples/sec: 58.32 - lr: 0.050000\n",
            "2022-10-02 22:49:47,132 epoch 31 - iter 1795/3599 - loss 0.05137476 - samples/sec: 58.22 - lr: 0.050000\n",
            "2022-10-02 22:53:12,519 epoch 31 - iter 2154/3599 - loss 0.05147034 - samples/sec: 59.23 - lr: 0.050000\n",
            "2022-10-02 22:56:40,279 epoch 31 - iter 2513/3599 - loss 0.05159384 - samples/sec: 58.91 - lr: 0.050000\n",
            "2022-10-02 23:00:11,790 epoch 31 - iter 2872/3599 - loss 0.05160799 - samples/sec: 58.08 - lr: 0.050000\n",
            "2022-10-02 23:03:37,351 epoch 31 - iter 3231/3599 - loss 0.05154023 - samples/sec: 58.96 - lr: 0.050000\n",
            "2022-10-02 23:07:06,262 epoch 31 - iter 3590/3599 - loss 0.05159215 - samples/sec: 58.62 - lr: 0.050000\n",
            "2022-10-02 23:07:11,646 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-02 23:07:11,648 EPOCH 31 done: loss 0.0516 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:05<00:00,  1.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 23:11:16,947 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 23:11:17,129 DEV : loss 0.030893836170434952 - f1-score (micro avg)  0.8938\n",
            "2022-10-02 23:11:27,122 BAD EPOCHS (no improvement): 0\n",
            "2022-10-02 23:11:31,239 saving best model\n",
            "2022-10-02 23:11:35,755 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-02 23:15:07,131 epoch 32 - iter 359/3599 - loss 0.05245273 - samples/sec: 57.78 - lr: 0.050000\n",
            "2022-10-02 23:18:35,284 epoch 32 - iter 718/3599 - loss 0.05126390 - samples/sec: 58.76 - lr: 0.050000\n",
            "2022-10-02 23:22:06,810 epoch 32 - iter 1077/3599 - loss 0.05087804 - samples/sec: 56.89 - lr: 0.050000\n",
            "2022-10-02 23:25:33,854 epoch 32 - iter 1436/3599 - loss 0.05116237 - samples/sec: 58.84 - lr: 0.050000\n",
            "2022-10-02 23:28:59,931 epoch 32 - iter 1795/3599 - loss 0.05073585 - samples/sec: 59.40 - lr: 0.050000\n",
            "2022-10-02 23:32:25,961 epoch 32 - iter 2154/3599 - loss 0.05070094 - samples/sec: 59.27 - lr: 0.050000\n",
            "2022-10-02 23:35:56,730 epoch 32 - iter 2513/3599 - loss 0.05085431 - samples/sec: 58.78 - lr: 0.050000\n",
            "2022-10-02 23:39:29,633 epoch 32 - iter 2872/3599 - loss 0.05084864 - samples/sec: 57.52 - lr: 0.050000\n",
            "2022-10-02 23:42:55,786 epoch 32 - iter 3231/3599 - loss 0.05086551 - samples/sec: 59.67 - lr: 0.050000\n",
            "2022-10-02 23:46:23,299 epoch 32 - iter 3590/3599 - loss 0.05092821 - samples/sec: 58.96 - lr: 0.050000\n",
            "2022-10-02 23:46:28,837 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-02 23:46:28,839 EPOCH 32 done: loss 0.0509 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:05<00:00,  1.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 23:50:34,192 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-02 23:50:34,378 DEV : loss 0.03119306080043316 - f1-score (micro avg)  0.8921\n",
            "2022-10-02 23:50:44,576 BAD EPOCHS (no improvement): 1\n",
            "2022-10-02 23:50:48,656 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-02 23:54:18,527 epoch 33 - iter 359/3599 - loss 0.05053121 - samples/sec: 58.56 - lr: 0.050000\n",
            "2022-10-02 23:57:51,856 epoch 33 - iter 718/3599 - loss 0.05013061 - samples/sec: 56.88 - lr: 0.050000\n",
            "2022-10-03 00:01:19,872 epoch 33 - iter 1077/3599 - loss 0.05012656 - samples/sec: 58.15 - lr: 0.050000\n",
            "2022-10-03 00:04:49,849 epoch 33 - iter 1436/3599 - loss 0.05023257 - samples/sec: 58.37 - lr: 0.050000\n",
            "2022-10-03 00:08:20,856 epoch 33 - iter 1795/3599 - loss 0.05038790 - samples/sec: 57.56 - lr: 0.050000\n",
            "2022-10-03 00:11:49,604 epoch 33 - iter 2154/3599 - loss 0.05045264 - samples/sec: 58.99 - lr: 0.050000\n",
            "2022-10-03 00:15:18,392 epoch 33 - iter 2513/3599 - loss 0.05045401 - samples/sec: 58.69 - lr: 0.050000\n",
            "2022-10-03 00:18:43,608 epoch 33 - iter 2872/3599 - loss 0.05042200 - samples/sec: 59.74 - lr: 0.050000\n",
            "2022-10-03 00:22:14,694 epoch 33 - iter 3231/3599 - loss 0.05047321 - samples/sec: 57.56 - lr: 0.050000\n",
            "2022-10-03 00:25:43,603 epoch 33 - iter 3590/3599 - loss 0.05058130 - samples/sec: 58.09 - lr: 0.050000\n",
            "2022-10-03 00:25:48,124 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 00:25:48,127 EPOCH 33 done: loss 0.0506 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:07<00:00,  1.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 00:29:55,892 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 00:29:56,076 DEV : loss 0.03156746178865433 - f1-score (micro avg)  0.8905\n",
            "2022-10-03 00:30:06,336 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 00:30:10,414 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 00:33:42,309 epoch 34 - iter 359/3599 - loss 0.04876082 - samples/sec: 57.11 - lr: 0.050000\n",
            "2022-10-03 00:37:10,561 epoch 34 - iter 718/3599 - loss 0.04912030 - samples/sec: 58.68 - lr: 0.050000\n",
            "2022-10-03 00:40:41,687 epoch 34 - iter 1077/3599 - loss 0.04946528 - samples/sec: 57.59 - lr: 0.050000\n",
            "2022-10-03 00:44:05,470 epoch 34 - iter 1436/3599 - loss 0.04934263 - samples/sec: 59.54 - lr: 0.050000\n",
            "2022-10-03 00:47:36,398 epoch 34 - iter 1795/3599 - loss 0.04949788 - samples/sec: 58.08 - lr: 0.050000\n",
            "2022-10-03 00:51:04,685 epoch 34 - iter 2154/3599 - loss 0.04970175 - samples/sec: 59.03 - lr: 0.050000\n",
            "2022-10-03 00:54:31,788 epoch 34 - iter 2513/3599 - loss 0.04976587 - samples/sec: 58.56 - lr: 0.050000\n",
            "2022-10-03 00:57:58,616 epoch 34 - iter 2872/3599 - loss 0.04999435 - samples/sec: 59.64 - lr: 0.050000\n",
            "2022-10-03 01:01:28,147 epoch 34 - iter 3231/3599 - loss 0.05013379 - samples/sec: 58.52 - lr: 0.050000\n",
            "2022-10-03 01:04:57,792 epoch 34 - iter 3590/3599 - loss 0.05018974 - samples/sec: 58.25 - lr: 0.050000\n",
            "2022-10-03 01:05:02,889 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 01:05:02,891 EPOCH 34 done: loss 0.0502 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:08<00:00,  1.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 01:09:11,433 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 01:09:11,624 DEV : loss 0.03138367831707001 - f1-score (micro avg)  0.8915\n",
            "2022-10-03 01:09:21,957 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 01:09:25,994 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 01:12:57,807 epoch 35 - iter 359/3599 - loss 0.04887032 - samples/sec: 58.47 - lr: 0.050000\n",
            "2022-10-03 01:16:31,026 epoch 35 - iter 718/3599 - loss 0.04916607 - samples/sec: 57.48 - lr: 0.050000\n",
            "2022-10-03 01:20:01,359 epoch 35 - iter 1077/3599 - loss 0.04926210 - samples/sec: 58.09 - lr: 0.050000\n",
            "2022-10-03 01:23:34,646 epoch 35 - iter 1436/3599 - loss 0.04980183 - samples/sec: 56.85 - lr: 0.050000\n",
            "2022-10-03 01:27:00,579 epoch 35 - iter 1795/3599 - loss 0.04983806 - samples/sec: 58.81 - lr: 0.050000\n",
            "2022-10-03 01:30:27,698 epoch 35 - iter 2154/3599 - loss 0.04963649 - samples/sec: 59.26 - lr: 0.050000\n",
            "2022-10-03 01:34:01,541 epoch 35 - iter 2513/3599 - loss 0.04965254 - samples/sec: 56.93 - lr: 0.050000\n",
            "2022-10-03 01:37:23,898 epoch 35 - iter 2872/3599 - loss 0.04954661 - samples/sec: 60.17 - lr: 0.050000\n",
            "2022-10-03 01:40:53,124 epoch 35 - iter 3231/3599 - loss 0.04977579 - samples/sec: 58.30 - lr: 0.050000\n",
            "2022-10-03 01:44:18,682 epoch 35 - iter 3590/3599 - loss 0.04980866 - samples/sec: 59.76 - lr: 0.050000\n",
            "2022-10-03 01:44:23,212 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 01:44:23,215 EPOCH 35 done: loss 0.0498 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:06<00:00,  1.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 01:48:29,404 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 01:48:29,585 DEV : loss 0.031496237963438034 - f1-score (micro avg)  0.8924\n",
            "2022-10-03 01:48:40,451 Epoch    35: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2022-10-03 01:48:40,454 BAD EPOCHS (no improvement): 4\n",
            "2022-10-03 01:48:44,457 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 01:52:11,224 epoch 36 - iter 359/3599 - loss 0.04925804 - samples/sec: 59.17 - lr: 0.025000\n",
            "2022-10-03 01:55:38,764 epoch 36 - iter 718/3599 - loss 0.04946333 - samples/sec: 59.03 - lr: 0.025000\n",
            "2022-10-03 01:59:04,508 epoch 36 - iter 1077/3599 - loss 0.04882954 - samples/sec: 59.58 - lr: 0.025000\n",
            "2022-10-03 02:02:32,221 epoch 36 - iter 1436/3599 - loss 0.04837355 - samples/sec: 58.87 - lr: 0.025000\n",
            "2022-10-03 02:06:03,359 epoch 36 - iter 1795/3599 - loss 0.04814618 - samples/sec: 58.41 - lr: 0.025000\n",
            "2022-10-03 02:09:32,523 epoch 36 - iter 2154/3599 - loss 0.04807031 - samples/sec: 58.29 - lr: 0.025000\n",
            "2022-10-03 02:13:02,885 epoch 36 - iter 2513/3599 - loss 0.04820345 - samples/sec: 58.49 - lr: 0.025000\n",
            "2022-10-03 02:16:33,298 epoch 36 - iter 2872/3599 - loss 0.04812691 - samples/sec: 58.35 - lr: 0.025000\n",
            "2022-10-03 02:20:07,054 epoch 36 - iter 3231/3599 - loss 0.04812265 - samples/sec: 57.12 - lr: 0.025000\n",
            "2022-10-03 02:23:34,152 epoch 36 - iter 3590/3599 - loss 0.04815119 - samples/sec: 59.50 - lr: 0.025000\n",
            "2022-10-03 02:23:38,397 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 02:23:38,399 EPOCH 36 done: loss 0.0482 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:06<00:00,  1.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 02:27:44,698 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 02:27:44,886 DEV : loss 0.03102760948240757 - f1-score (micro avg)  0.8927\n",
            "2022-10-03 02:27:55,063 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 02:27:59,187 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 02:31:28,085 epoch 37 - iter 359/3599 - loss 0.04655174 - samples/sec: 58.22 - lr: 0.025000\n",
            "2022-10-03 02:34:58,667 epoch 37 - iter 718/3599 - loss 0.04640624 - samples/sec: 57.89 - lr: 0.025000\n",
            "2022-10-03 02:38:23,815 epoch 37 - iter 1077/3599 - loss 0.04732968 - samples/sec: 58.58 - lr: 0.025000\n",
            "2022-10-03 02:41:55,302 epoch 37 - iter 1436/3599 - loss 0.04706848 - samples/sec: 57.53 - lr: 0.025000\n",
            "2022-10-03 02:45:24,010 epoch 37 - iter 1795/3599 - loss 0.04746944 - samples/sec: 58.34 - lr: 0.025000\n",
            "2022-10-03 02:48:51,145 epoch 37 - iter 2154/3599 - loss 0.04733208 - samples/sec: 58.81 - lr: 0.025000\n",
            "2022-10-03 02:52:18,859 epoch 37 - iter 2513/3599 - loss 0.04723218 - samples/sec: 59.18 - lr: 0.025000\n",
            "2022-10-03 02:55:48,290 epoch 37 - iter 2872/3599 - loss 0.04723429 - samples/sec: 58.52 - lr: 0.025000\n",
            "2022-10-03 02:59:16,486 epoch 37 - iter 3231/3599 - loss 0.04730494 - samples/sec: 58.11 - lr: 0.025000\n",
            "2022-10-03 03:02:47,408 epoch 37 - iter 3590/3599 - loss 0.04741640 - samples/sec: 57.70 - lr: 0.025000\n",
            "2022-10-03 03:02:52,486 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 03:02:52,488 EPOCH 37 done: loss 0.0474 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:07<00:00,  1.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 03:06:59,683 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 03:06:59,865 DEV : loss 0.030757376924157143 - f1-score (micro avg)  0.8932\n",
            "2022-10-03 03:07:10,025 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 03:07:14,113 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 03:10:44,238 epoch 38 - iter 359/3599 - loss 0.04590577 - samples/sec: 58.20 - lr: 0.025000\n",
            "2022-10-03 03:14:16,081 epoch 38 - iter 718/3599 - loss 0.04696617 - samples/sec: 57.56 - lr: 0.025000\n",
            "2022-10-03 03:17:45,658 epoch 38 - iter 1077/3599 - loss 0.04728522 - samples/sec: 57.93 - lr: 0.025000\n",
            "2022-10-03 03:21:16,851 epoch 38 - iter 1436/3599 - loss 0.04705154 - samples/sec: 58.00 - lr: 0.025000\n",
            "2022-10-03 03:24:41,390 epoch 38 - iter 1795/3599 - loss 0.04708516 - samples/sec: 60.17 - lr: 0.025000\n",
            "2022-10-03 03:28:05,518 epoch 38 - iter 2154/3599 - loss 0.04718603 - samples/sec: 60.07 - lr: 0.025000\n",
            "2022-10-03 03:31:33,321 epoch 38 - iter 2513/3599 - loss 0.04711374 - samples/sec: 59.37 - lr: 0.025000\n",
            "2022-10-03 03:34:56,946 epoch 38 - iter 2872/3599 - loss 0.04707171 - samples/sec: 60.06 - lr: 0.025000\n",
            "2022-10-03 03:38:20,303 epoch 38 - iter 3231/3599 - loss 0.04707930 - samples/sec: 59.99 - lr: 0.025000\n",
            "2022-10-03 03:41:43,049 epoch 38 - iter 3590/3599 - loss 0.04698233 - samples/sec: 60.18 - lr: 0.025000\n",
            "2022-10-03 03:41:47,818 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 03:41:47,820 EPOCH 38 done: loss 0.0470 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [03:58<00:00,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 03:45:46,074 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 03:45:46,265 DEV : loss 0.030665911734104156 - f1-score (micro avg)  0.8928\n",
            "2022-10-03 03:45:56,406 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 03:46:00,459 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 03:49:24,592 epoch 39 - iter 359/3599 - loss 0.04634998 - samples/sec: 59.75 - lr: 0.025000\n",
            "2022-10-03 03:52:50,391 epoch 39 - iter 718/3599 - loss 0.04689209 - samples/sec: 59.10 - lr: 0.025000\n",
            "2022-10-03 03:56:11,898 epoch 39 - iter 1077/3599 - loss 0.04673013 - samples/sec: 60.73 - lr: 0.025000\n",
            "2022-10-03 03:59:37,150 epoch 39 - iter 1436/3599 - loss 0.04684503 - samples/sec: 59.15 - lr: 0.025000\n",
            "2022-10-03 04:03:05,487 epoch 39 - iter 1795/3599 - loss 0.04667540 - samples/sec: 59.06 - lr: 0.025000\n",
            "2022-10-03 04:06:30,026 epoch 39 - iter 2154/3599 - loss 0.04677181 - samples/sec: 59.95 - lr: 0.025000\n",
            "2022-10-03 04:09:52,357 epoch 39 - iter 2513/3599 - loss 0.04684281 - samples/sec: 60.92 - lr: 0.025000\n",
            "2022-10-03 04:13:17,167 epoch 39 - iter 2872/3599 - loss 0.04689797 - samples/sec: 59.81 - lr: 0.025000\n",
            "2022-10-03 04:16:39,685 epoch 39 - iter 3231/3599 - loss 0.04699993 - samples/sec: 60.62 - lr: 0.025000\n",
            "2022-10-03 04:19:57,196 epoch 39 - iter 3590/3599 - loss 0.04700005 - samples/sec: 62.22 - lr: 0.025000\n",
            "2022-10-03 04:20:02,087 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 04:20:02,089 EPOCH 39 done: loss 0.0470 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [03:57<00:00,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 04:23:59,218 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 04:23:59,414 DEV : loss 0.030668070539832115 - f1-score (micro avg)  0.8937\n",
            "2022-10-03 04:24:09,692 Epoch    39: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2022-10-03 04:24:09,695 BAD EPOCHS (no improvement): 4\n",
            "2022-10-03 04:24:13,716 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 04:27:36,573 epoch 40 - iter 359/3599 - loss 0.04797826 - samples/sec: 60.39 - lr: 0.012500\n",
            "2022-10-03 04:30:57,682 epoch 40 - iter 718/3599 - loss 0.04671624 - samples/sec: 60.66 - lr: 0.012500\n",
            "2022-10-03 04:34:19,675 epoch 40 - iter 1077/3599 - loss 0.04653270 - samples/sec: 60.80 - lr: 0.012500\n",
            "2022-10-03 04:37:47,390 epoch 40 - iter 1436/3599 - loss 0.04588924 - samples/sec: 58.34 - lr: 0.012500\n",
            "2022-10-03 04:41:07,524 epoch 40 - iter 1795/3599 - loss 0.04619927 - samples/sec: 60.52 - lr: 0.012500\n",
            "2022-10-03 04:44:28,032 epoch 40 - iter 2154/3599 - loss 0.04639165 - samples/sec: 61.43 - lr: 0.012500\n",
            "2022-10-03 04:47:51,072 epoch 40 - iter 2513/3599 - loss 0.04615662 - samples/sec: 60.33 - lr: 0.012500\n",
            "2022-10-03 04:51:14,866 epoch 40 - iter 2872/3599 - loss 0.04602038 - samples/sec: 60.24 - lr: 0.012500\n",
            "2022-10-03 04:54:36,830 epoch 40 - iter 3231/3599 - loss 0.04600155 - samples/sec: 61.46 - lr: 0.012500\n",
            "2022-10-03 04:57:59,826 epoch 40 - iter 3590/3599 - loss 0.04597262 - samples/sec: 60.96 - lr: 0.012500\n",
            "2022-10-03 04:58:04,569 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 04:58:04,571 EPOCH 40 done: loss 0.0460 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [03:56<00:00,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 05:02:01,296 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 05:02:01,478 DEV : loss 0.03037194348871708 - f1-score (micro avg)  0.8949\n",
            "2022-10-03 05:02:12,435 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 05:02:16,556 saving best model\n",
            "2022-10-03 05:02:25,181 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 05:02:25,260 loading file /content/drive/MyDrive/Flair_NLP/sota-ner-flair-resume/best-model.pt\n",
            "2022-10-03 05:02:27,620 SequenceTagger predicts: Dictionary with 19 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 445/445 [03:59<00:00,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 05:06:27,295 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 05:06:27,500 0.8957\t0.8933\t0.8945\t0.8535\n",
            "2022-10-03 05:06:27,502 \n",
            "Results:\n",
            "- F-score (micro) 0.8945\n",
            "- F-score (macro) 0.8849\n",
            "- Accuracy 0.8535\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         PER     0.9457    0.9628    0.9542      9859\n",
            "         LOC     0.8782    0.9166    0.8970      8677\n",
            "        MISC     0.8607    0.8184    0.8390      7452\n",
            "         ORG     0.8750    0.8256    0.8496      4868\n",
            "\n",
            "   micro avg     0.8957    0.8933    0.8945     30856\n",
            "   macro avg     0.8899    0.8808    0.8849     30856\n",
            "weighted avg     0.8950    0.8933    0.8938     30856\n",
            "\n",
            "2022-10-03 05:06:27,504 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 05:06:27,507 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 445/445 [04:00<00:00,  1.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 05:10:28,483 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 05:10:28,692 /root/.flair/datasets/ner_multi_wikiner/en\n",
            "2022-10-03 05:10:28,693 0.8957\t0.8933\t0.8945\t0.8535\n"
          ]
        }
      ],
      "source": [
        "## Continuando o treinamento\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 8. continue training at later point. Load previously trained model checkpoint, then resume\n",
        "trained_model = SequenceTagger.load(path + '/checkpoint.pt')\n",
        "\n",
        "# resume training best model, but this time until new max-epochs\n",
        "trainer.resume(trained_model,\n",
        "               base_path=path + '-resume',\n",
        "               max_epochs=40,\n",
        "               checkpoint=True,\n",
        "               )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoKhH3QqdZdS"
      },
      "source": [
        "## Teste 1.4 NER Flair Bert Embeddings com Corpus Multi_Wikiner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uFWjSmHdZdT"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdn8vyqvdZdT"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "\n",
        "## Corpus\n",
        "from flair.datasets import NER_MULTI_WIKINER\n",
        "\n",
        "## Importando os Embeddings, BERTinbaum e Flair-pt\n",
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M8CvTbxdZdT"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43sY84HrdZdT",
        "outputId": "9350ac8d-aa3c-4b14-a1c8-23594e4cc3ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 17:47:06,011 https://raw.githubusercontent.com/dice-group/FOX/master/input/Wikiner/aij-wikiner-en-wp3.bz2 not found in cache, downloading to /tmp/tmp0sselbo2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6208404/6208404 [00:00<00:00, 46143996.09B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 17:47:06,209 copying /tmp/tmp0sselbo2 to cache at /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.bz2\n",
            "2022-11-07 17:47:06,219 removing temp file /tmp/tmp0sselbo2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 17:47:09,895 Read data for language en\n",
            "2022-11-07 17:47:09,897 Reading data from /root/.flair/datasets/ner_multi_wikiner/en\n",
            "2022-11-07 17:47:09,898 Train: /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.train\n",
            "2022-11-07 17:47:09,900 Dev: None\n",
            "2022-11-07 17:47:09,901 Test: None\n",
            "MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en\n"
          ]
        }
      ],
      "source": [
        "## Corpus\n",
        "# 1. get the corpus\n",
        "corpus = NER_MULTI_WIKINER() #.downsample(0.8)\n",
        "print(corpus)\n",
        "\n",
        "## Tarefa\n",
        "# 2. what label do we want to predict?\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHqoXnmkdZdT",
        "outputId": "6a2d33db-3e0b-4b34-8ec2-c2e18ae4c45f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 17:47:12,459 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "115144it [01:03, 1809.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 17:48:16,155 Dictionary created for label 'ner' with 5 values: PER (seen 77850 times), LOC (seen 69777 times), MISC (seen 59496 times), ORG (seen 40137 times)\n",
            "Dictionary with 5 tags: <unk>, PER, LOC, MISC, ORG\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# 3. make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0yYFk_KdZdU"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-tkEpy4agYm",
        "outputId": "7141bc7a-830b-43b1-ccd8-6731d7f4fd03"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "782602b7e0da446991e13b26c6cd3e1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d0fc6eaa7b44ad8b750ff60e77fb0f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf3f60c983a94547b3d342e5d29ffa64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/210k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9d526036db9435a8e21be84f8bbb12d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aaa0c59a2e524d5892d81bd06453a351",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1c5bf61e561497b856a87b40bd3d7c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Apenas Bert\n",
        "embeddings = TransformerWordEmbeddings('neuralmind/bert-base-portuguese-cased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rAFJn8J5TbO"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrqIQBuY5TbP",
        "outputId": "b1309a2f-8099-4d9e-fdc8-411bebb5e76a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 17:48:44,553 SequenceTagger predicts: Dictionary with 17 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "# 5. initialize sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6aYFGB25TbQ",
        "outputId": "557ef827-38b5-4787-9061-5510ac0e43ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Flair_NLP/sota-ner-flair'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iybJCEXD5TbQ"
      },
      "outputs": [],
      "source": [
        "## Treinando o modelo\n",
        "# 6. initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 7. start training\n",
        "trainer.train(path,\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=15,\n",
        "              checkpoint=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0jpkXZu5TbQ",
        "outputId": "7009c5af-333b-440e-94fa-330fc543bc89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 17:49:16,772 loading file /content/drive/MyDrive/Flair_NLP/sota-ner-flair/checkpoint.pt\n",
            "2022-11-07 17:49:28,245 SequenceTagger predicts: Dictionary with 19 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, <START>, <STOP>\n",
            "2022-11-07 17:49:28,852 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 17:49:28,855 Model: \"SequenceTagger(\n",
            "  (embeddings): TransformerWordEmbeddings(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (rnn): LSTM(768, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=19, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-11-07 17:49:28,858 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 17:49:28,861 Corpus: \"MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en\"\n",
            "2022-11-07 17:49:28,866 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 17:49:28,867 Parameters:\n",
            "2022-11-07 17:49:28,869  - learning_rate: \"0.100000\"\n",
            "2022-11-07 17:49:28,871  - mini_batch_size: \"32\"\n",
            "2022-11-07 17:49:28,872  - patience: \"3\"\n",
            "2022-11-07 17:49:28,874  - anneal_factor: \"0.5\"\n",
            "2022-11-07 17:49:28,875  - max_epochs: \"40\"\n",
            "2022-11-07 17:49:28,876  - shuffle: \"True\"\n",
            "2022-11-07 17:49:28,878  - train_with_dev: \"False\"\n",
            "2022-11-07 17:49:28,880  - batch_growth_annealing: \"False\"\n",
            "2022-11-07 17:49:28,883 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 17:49:28,885 Model training base path: \"/content/drive/MyDrive/Flair_NLP/sota-ner-flair-resume\"\n",
            "2022-11-07 17:49:28,887 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 17:49:28,890 Device: cuda:0\n",
            "2022-11-07 17:49:28,892 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 17:49:28,894 Embeddings storage mode: cpu\n",
            "2022-11-07 17:49:28,895 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 17:56:02,982 epoch 34 - iter 359/3599 - loss 0.00992054 - samples/sec: 29.88 - lr: 0.006250\n",
            "2022-11-07 18:02:34,652 epoch 34 - iter 718/3599 - loss 0.00969533 - samples/sec: 30.11 - lr: 0.006250\n",
            "2022-11-07 18:09:06,916 epoch 34 - iter 1077/3599 - loss 0.00964667 - samples/sec: 30.06 - lr: 0.006250\n",
            "2022-11-07 18:15:41,772 epoch 34 - iter 1436/3599 - loss 0.00937537 - samples/sec: 29.88 - lr: 0.006250\n",
            "2022-11-07 18:22:13,668 epoch 34 - iter 1795/3599 - loss 0.00913594 - samples/sec: 30.06 - lr: 0.006250\n",
            "2022-11-07 18:28:46,704 epoch 34 - iter 2154/3599 - loss 0.00884088 - samples/sec: 30.02 - lr: 0.006250\n",
            "2022-11-07 18:35:19,929 epoch 34 - iter 2513/3599 - loss 0.00865540 - samples/sec: 30.05 - lr: 0.006250\n",
            "2022-11-07 18:41:55,507 epoch 34 - iter 2872/3599 - loss 0.00850355 - samples/sec: 29.77 - lr: 0.006250\n",
            "2022-11-07 18:48:25,099 epoch 34 - iter 3231/3599 - loss 0.00835881 - samples/sec: 30.18 - lr: 0.006250\n",
            "2022-11-07 18:54:56,187 epoch 34 - iter 3590/3599 - loss 0.00825932 - samples/sec: 30.05 - lr: 0.006250\n",
            "2022-11-07 18:55:05,272 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 18:55:05,273 EPOCH 34 done: loss 0.0083 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [03:34<00:00,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 18:58:40,252 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 18:58:40,431 DEV : loss 0.004942717030644417 - f1-score (micro avg)  0.9899\n",
            "2022-11-07 18:58:50,814 BAD EPOCHS (no improvement): 0\n",
            "2022-11-07 18:58:52,016 saving best model\n",
            "2022-11-07 18:58:53,562 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 19:03:34,789 epoch 35 - iter 359/3599 - loss 0.00575267 - samples/sec: 42.13 - lr: 0.006250\n",
            "2022-11-07 19:08:14,900 epoch 35 - iter 718/3599 - loss 0.00580104 - samples/sec: 42.58 - lr: 0.006250\n",
            "2022-11-07 19:12:55,648 epoch 35 - iter 1077/3599 - loss 0.00561060 - samples/sec: 42.32 - lr: 0.006250\n",
            "2022-11-07 19:17:34,481 epoch 35 - iter 1436/3599 - loss 0.00563158 - samples/sec: 42.74 - lr: 0.006250\n",
            "2022-11-07 19:22:18,843 epoch 35 - iter 1795/3599 - loss 0.00571494 - samples/sec: 41.65 - lr: 0.006250\n",
            "2022-11-07 19:27:03,636 epoch 35 - iter 2154/3599 - loss 0.00568379 - samples/sec: 41.82 - lr: 0.006250\n",
            "2022-11-07 19:31:47,657 epoch 35 - iter 2513/3599 - loss 0.00576511 - samples/sec: 41.79 - lr: 0.006250\n",
            "2022-11-07 19:36:23,265 epoch 35 - iter 2872/3599 - loss 0.00580156 - samples/sec: 43.21 - lr: 0.006250\n",
            "2022-11-07 19:41:04,397 epoch 35 - iter 3231/3599 - loss 0.00580702 - samples/sec: 42.28 - lr: 0.006250\n",
            "2022-11-07 19:45:48,156 epoch 35 - iter 3590/3599 - loss 0.00577142 - samples/sec: 41.91 - lr: 0.006250\n",
            "2022-11-07 19:45:54,384 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 19:45:54,386 EPOCH 35 done: loss 0.0058 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [03:00<00:00,  2.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 19:48:55,211 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 19:48:55,399 DEV : loss 0.005035409703850746 - f1-score (micro avg)  0.99\n",
            "2022-11-07 19:49:05,856 BAD EPOCHS (no improvement): 0\n",
            "2022-11-07 19:49:07,102 saving best model\n",
            "2022-11-07 19:49:08,687 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 19:53:46,684 epoch 36 - iter 359/3599 - loss 0.00443095 - samples/sec: 42.94 - lr: 0.006250\n",
            "2022-11-07 19:58:28,394 epoch 36 - iter 718/3599 - loss 0.00455827 - samples/sec: 42.36 - lr: 0.006250\n",
            "2022-11-07 20:03:08,738 epoch 36 - iter 1077/3599 - loss 0.00472461 - samples/sec: 42.51 - lr: 0.006250\n",
            "2022-11-07 20:07:54,545 epoch 36 - iter 1436/3599 - loss 0.00473504 - samples/sec: 41.62 - lr: 0.006250\n",
            "2022-11-07 20:12:37,550 epoch 36 - iter 1795/3599 - loss 0.00485336 - samples/sec: 41.99 - lr: 0.006250\n",
            "2022-11-07 20:17:22,171 epoch 36 - iter 2154/3599 - loss 0.00486744 - samples/sec: 41.73 - lr: 0.006250\n",
            "2022-11-07 20:22:04,443 epoch 36 - iter 2513/3599 - loss 0.00484755 - samples/sec: 42.30 - lr: 0.006250\n",
            "2022-11-07 20:26:44,144 epoch 36 - iter 2872/3599 - loss 0.00485266 - samples/sec: 42.54 - lr: 0.006250\n",
            "2022-11-07 20:31:23,300 epoch 36 - iter 3231/3599 - loss 0.00483424 - samples/sec: 42.78 - lr: 0.006250\n",
            "2022-11-07 20:36:04,603 epoch 36 - iter 3590/3599 - loss 0.00491178 - samples/sec: 42.36 - lr: 0.006250\n",
            "2022-11-07 20:36:10,996 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 20:36:10,998 EPOCH 36 done: loss 0.0049 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [03:13<00:00,  2.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 20:39:24,868 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 20:39:25,042 DEV : loss 0.005333692766726017 - f1-score (micro avg)  0.9898\n",
            "2022-11-07 20:39:35,455 BAD EPOCHS (no improvement): 1\n",
            "2022-11-07 20:39:36,678 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 20:44:12,121 epoch 37 - iter 359/3599 - loss 0.00364162 - samples/sec: 43.43 - lr: 0.006250\n",
            "2022-11-07 20:48:54,911 epoch 37 - iter 718/3599 - loss 0.00418868 - samples/sec: 42.00 - lr: 0.006250\n",
            "2022-11-07 20:53:33,065 epoch 37 - iter 1077/3599 - loss 0.00449623 - samples/sec: 42.73 - lr: 0.006250\n",
            "2022-11-07 20:58:09,989 epoch 37 - iter 1436/3599 - loss 0.00443504 - samples/sec: 43.13 - lr: 0.006250\n",
            "2022-11-07 21:02:49,104 epoch 37 - iter 1795/3599 - loss 0.00428571 - samples/sec: 42.73 - lr: 0.006250\n",
            "2022-11-07 21:07:29,715 epoch 37 - iter 2154/3599 - loss 0.00435909 - samples/sec: 42.49 - lr: 0.006250\n",
            "2022-11-07 21:12:08,495 epoch 37 - iter 2513/3599 - loss 0.00425953 - samples/sec: 42.79 - lr: 0.006250\n",
            "2022-11-07 21:16:47,104 epoch 37 - iter 2872/3599 - loss 0.00434775 - samples/sec: 42.67 - lr: 0.006250\n",
            "2022-11-07 21:21:29,390 epoch 37 - iter 3231/3599 - loss 0.00434011 - samples/sec: 42.21 - lr: 0.006250\n",
            "2022-11-07 21:26:15,032 epoch 37 - iter 3590/3599 - loss 0.00434581 - samples/sec: 41.74 - lr: 0.006250\n",
            "2022-11-07 21:26:21,390 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 21:26:21,392 EPOCH 37 done: loss 0.0043 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [02:57<00:00,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 21:29:18,952 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 21:29:19,133 DEV : loss 0.0059500811621546745 - f1-score (micro avg)  0.9899\n",
            "2022-11-07 21:29:29,461 BAD EPOCHS (no improvement): 2\n",
            "2022-11-07 21:29:30,684 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 21:34:03,710 epoch 38 - iter 359/3599 - loss 0.00390688 - samples/sec: 43.88 - lr: 0.006250\n",
            "2022-11-07 21:38:44,274 epoch 38 - iter 718/3599 - loss 0.00390941 - samples/sec: 42.52 - lr: 0.006250\n",
            "2022-11-07 21:43:27,315 epoch 38 - iter 1077/3599 - loss 0.00369996 - samples/sec: 42.03 - lr: 0.006250\n",
            "2022-11-07 21:48:08,042 epoch 38 - iter 1436/3599 - loss 0.00371081 - samples/sec: 42.39 - lr: 0.006250\n",
            "2022-11-07 21:52:46,845 epoch 38 - iter 1795/3599 - loss 0.00385413 - samples/sec: 42.70 - lr: 0.006250\n",
            "2022-11-07 21:57:27,537 epoch 38 - iter 2154/3599 - loss 0.00394806 - samples/sec: 42.38 - lr: 0.006250\n",
            "2022-11-07 22:02:06,093 epoch 38 - iter 2513/3599 - loss 0.00388584 - samples/sec: 42.62 - lr: 0.006250\n",
            "2022-11-07 22:06:50,070 epoch 38 - iter 2872/3599 - loss 0.00384965 - samples/sec: 41.83 - lr: 0.006250\n",
            "2022-11-07 22:11:32,425 epoch 38 - iter 3231/3599 - loss 0.00384119 - samples/sec: 42.07 - lr: 0.006250\n",
            "2022-11-07 22:16:14,529 epoch 38 - iter 3590/3599 - loss 0.00384345 - samples/sec: 42.06 - lr: 0.006250\n",
            "2022-11-07 22:16:21,110 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 22:16:21,112 EPOCH 38 done: loss 0.0039 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [02:58<00:00,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 22:19:19,853 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 22:19:20,037 DEV : loss 0.006320773623883724 - f1-score (micro avg)  0.9899\n",
            "2022-11-07 22:19:29,565 BAD EPOCHS (no improvement): 3\n",
            "2022-11-07 22:19:30,798 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 22:24:14,249 epoch 39 - iter 359/3599 - loss 0.00341819 - samples/sec: 42.26 - lr: 0.006250\n",
            "2022-11-07 22:28:51,405 epoch 39 - iter 718/3599 - loss 0.00360265 - samples/sec: 43.09 - lr: 0.006250\n",
            "2022-11-07 22:33:34,325 epoch 39 - iter 1077/3599 - loss 0.00346457 - samples/sec: 42.08 - lr: 0.006250\n",
            "2022-11-07 22:38:19,030 epoch 39 - iter 1436/3599 - loss 0.00342535 - samples/sec: 41.81 - lr: 0.006250\n",
            "2022-11-07 22:42:55,534 epoch 39 - iter 1795/3599 - loss 0.00352581 - samples/sec: 43.10 - lr: 0.006250\n",
            "2022-11-07 22:47:33,479 epoch 39 - iter 2154/3599 - loss 0.00344976 - samples/sec: 42.85 - lr: 0.006250\n",
            "2022-11-07 22:52:17,178 epoch 39 - iter 2513/3599 - loss 0.00344900 - samples/sec: 41.87 - lr: 0.006250\n",
            "2022-11-07 22:56:54,927 epoch 39 - iter 2872/3599 - loss 0.00346662 - samples/sec: 42.85 - lr: 0.006250\n",
            "2022-11-07 23:01:29,975 epoch 39 - iter 3231/3599 - loss 0.00349442 - samples/sec: 43.17 - lr: 0.006250\n",
            "2022-11-07 23:06:11,918 epoch 39 - iter 3590/3599 - loss 0.00350908 - samples/sec: 42.25 - lr: 0.006250\n",
            "2022-11-07 23:06:18,093 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 23:06:18,095 EPOCH 39 done: loss 0.0035 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [03:04<00:00,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 23:09:22,542 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 23:09:22,715 DEV : loss 0.006552606821060181 - f1-score (micro avg)  0.99\n",
            "2022-11-07 23:09:32,726 Epoch    39: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2022-11-07 23:09:32,728 BAD EPOCHS (no improvement): 4\n",
            "2022-11-07 23:09:33,944 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 23:14:09,436 epoch 40 - iter 359/3599 - loss 0.00294610 - samples/sec: 43.40 - lr: 0.003125\n",
            "2022-11-07 23:18:52,383 epoch 40 - iter 718/3599 - loss 0.00320406 - samples/sec: 41.99 - lr: 0.003125\n",
            "2022-11-07 23:23:31,838 epoch 40 - iter 1077/3599 - loss 0.00291546 - samples/sec: 42.58 - lr: 0.003125\n",
            "2022-11-07 23:28:13,332 epoch 40 - iter 1436/3599 - loss 0.00281577 - samples/sec: 42.22 - lr: 0.003125\n",
            "2022-11-07 23:32:51,493 epoch 40 - iter 1795/3599 - loss 0.00285365 - samples/sec: 42.83 - lr: 0.003125\n",
            "2022-11-07 23:37:30,295 epoch 40 - iter 2154/3599 - loss 0.00292304 - samples/sec: 42.68 - lr: 0.003125\n",
            "2022-11-07 23:42:12,815 epoch 40 - iter 2513/3599 - loss 0.00286678 - samples/sec: 42.05 - lr: 0.003125\n",
            "2022-11-07 23:46:52,436 epoch 40 - iter 2872/3599 - loss 0.00293836 - samples/sec: 42.67 - lr: 0.003125\n",
            "2022-11-07 23:51:33,888 epoch 40 - iter 3231/3599 - loss 0.00298435 - samples/sec: 42.22 - lr: 0.003125\n",
            "2022-11-07 23:56:11,195 epoch 40 - iter 3590/3599 - loss 0.00297697 - samples/sec: 42.82 - lr: 0.003125\n",
            "2022-11-07 23:56:17,497 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 23:56:17,499 EPOCH 40 done: loss 0.0030 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [03:04<00:00,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 23:59:21,752 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-07 23:59:21,919 DEV : loss 0.006868019234389067 - f1-score (micro avg)  0.9899\n",
            "2022-11-07 23:59:32,296 BAD EPOCHS (no improvement): 1\n",
            "2022-11-07 23:59:35,387 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-07 23:59:35,392 loading file /content/drive/MyDrive/Flair_NLP/sota-ner-flair-resume/best-model.pt\n",
            "2022-11-07 23:59:37,652 SequenceTagger predicts: Dictionary with 19 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 445/445 [03:07<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-08 00:02:45,682 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-08 00:02:45,884 0.9899\t0.9893\t0.9896\t0.985\n",
            "2022-11-08 00:02:45,886 \n",
            "Results:\n",
            "- F-score (micro) 0.9896\n",
            "- F-score (macro) 0.9888\n",
            "- Accuracy 0.985\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         PER     0.9966    0.9943    0.9955      9722\n",
            "         LOC     0.9879    0.9890    0.9884      8646\n",
            "        MISC     0.9870    0.9864    0.9867      7444\n",
            "         ORG     0.9845    0.9843    0.9844      4983\n",
            "\n",
            "   micro avg     0.9899    0.9893    0.9896     30795\n",
            "   macro avg     0.9890    0.9885    0.9888     30795\n",
            "weighted avg     0.9899    0.9893    0.9896     30795\n",
            "\n",
            "2022-11-08 00:02:45,889 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-08 00:02:45,891 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 445/445 [03:06<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-08 00:05:52,208 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-08 00:05:52,401 /root/.flair/datasets/ner_multi_wikiner/en\n",
            "2022-11-08 00:05:52,403 0.9899\t0.9893\t0.9896\t0.985\n"
          ]
        }
      ],
      "source": [
        "## Continuando o treinamento\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 8. continue training at later point. Load previously trained model checkpoint, then resume\n",
        "trained_model = SequenceTagger.load(path + '/checkpoint.pt')\n",
        "\n",
        "# resume training best model, but this time until new max-epochs\n",
        "trainer.resume(trained_model,\n",
        "               base_path=path + '-resume',\n",
        "               max_epochs=40,\n",
        "               checkpoint=True,\n",
        "               )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_ZS-BeDDPbJ"
      },
      "source": [
        "## Teste 1.5 NER Flair Stacked Embeddings (Bert e Flair Embeddings) com Corpus Multi_Wikiner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYPiToDIDPbT"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56tcQHKKDPbT"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "\n",
        "## Corpus\n",
        "from flair.datasets import NER_MULTI_WIKINER\n",
        "\n",
        "## Importando os Embeddings, BERTinbaum e Flair-pt\n",
        "from flair.embeddings import FlairEmbeddings, TransformerWordEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUPLWIxwDPbU"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltBzq5DbDPbU",
        "outputId": "f9028218-fd11-4709-b8a2-9e53c6457afa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 15:33:14,465 https://raw.githubusercontent.com/dice-group/FOX/master/input/Wikiner/aij-wikiner-en-wp3.bz2 not found in cache, downloading to /tmp/tmpv9g05iud\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6208404/6208404 [00:00<00:00, 20566182.55B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 15:33:14,850 copying /tmp/tmpv9g05iud to cache at /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.bz2\n",
            "2022-07-01 15:33:14,871 removing temp file /tmp/tmpv9g05iud\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 15:33:21,860 Read data for language en\n",
            "2022-07-01 15:33:21,864 Reading data from /root/.flair/datasets/ner_multi_wikiner/en\n",
            "2022-07-01 15:33:21,871 Train: /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.train\n",
            "2022-07-01 15:33:21,876 Dev: None\n",
            "2022-07-01 15:33:21,887 Test: None\n",
            "MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en\n"
          ]
        }
      ],
      "source": [
        "## Corpus\n",
        "# 1. get the corpus\n",
        "corpus = NER_MULTI_WIKINER()#.downsample(0.8)\n",
        "print(corpus)\n",
        "\n",
        "## Tarefa\n",
        "# 2. what label do we want to predict?\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sukn-4MmDPbU",
        "outputId": "e82048a1-98f4-425c-c984-1c1d7e400c70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 15:33:29,053 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "115144it [01:31, 1253.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 15:35:00,950 Dictionary created for label 'ner' with 5 values: PER (seen 77822 times), LOC (seen 69649 times), MISC (seen 59687 times), ORG (seen 40211 times)\n",
            "Dictionary with 5 tags: <unk>, PER, LOC, MISC, ORG\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# 3. make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwYHKBgMDPbU"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "mvgM2PwnDPbU",
        "outputId": "d4e321d0-d87f-4fff-a39b-65522d4f2a42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 15:35:01,826 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-forward.pt not found in cache, downloading to /tmp/tmp_mxmsak_\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:04<00:00, 14676906.07B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 15:35:07,348 copying /tmp/tmp_mxmsak_ to cache at /root/.flair/embeddings/lm-pt-forward.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 15:35:07,488 removing temp file /tmp/tmp_mxmsak_\n",
            "2022-07-01 15:35:23,841 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-backward.pt not found in cache, downloading to /tmp/tmpvha3yd93\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:04<00:00, 14851720.20B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 15:35:29,276 copying /tmp/tmpvha3yd93 to cache at /root/.flair/embeddings/lm-pt-backward.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 15:35:29,411 removing temp file /tmp/tmpvha3yd93\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "025ed27f85164636b70500675d128bff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d490e7610e124832b6ffeb89c3478ad7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7109933efb0e47308129b5650187ba27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6fbe0f7351a4a23b33eeb8d68a3de84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8dee82853d3411384d72b4515593c4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0177a32fbed41d2b8bf9fb3ed41faf0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# init Flair embeddings\n",
        "flair_embedding_forward = FlairEmbeddings('pt-forward')\n",
        "flair_embedding_backward = FlairEmbeddings('pt-backward')\n",
        "\n",
        "# init pt BERT\n",
        "bert_embedding = TransformerWordEmbeddings('neuralmind/bert-base-portuguese-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U6je6h2DPbU"
      },
      "outputs": [],
      "source": [
        "## Empilhando os Embeddings\n",
        "from flair.embeddings import StackedEmbeddings\n",
        "\n",
        "# create a StackedEmbedding object that combines Bert and forward/backward flair embeddings\n",
        "embeddings = StackedEmbeddings([\n",
        "                                        bert_embedding,\n",
        "                                        flair_embedding_forward,\n",
        "                                        flair_embedding_backward,\n",
        "                                       ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDFAQblGDPbU"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9UX5mjrDPbU",
        "outputId": "0ac08c65-55d2-4d22-e22d-e2027f668b70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 15:35:48,782 SequenceTagger predicts: Dictionary with 17 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "# 5. initialize sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB158BbADPbU",
        "outputId": "3975933a-0f5f-495d-c7ab-e8f4fc9c68d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 15:35:49,123 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 15:35:49,129 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): TransformerWordEmbeddings(\n",
            "      (model): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4864, out_features=4864, bias=True)\n",
            "  (rnn): LSTM(4864, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=19, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-07-01 15:35:49,132 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 15:35:49,134 Corpus: \"MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en\"\n",
            "2022-07-01 15:35:49,141 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 15:35:49,144 Parameters:\n",
            "2022-07-01 15:35:49,150  - learning_rate: \"0.100000\"\n",
            "2022-07-01 15:35:49,154  - mini_batch_size: \"32\"\n",
            "2022-07-01 15:35:49,155  - patience: \"3\"\n",
            "2022-07-01 15:35:49,159  - anneal_factor: \"0.5\"\n",
            "2022-07-01 15:35:49,161  - max_epochs: \"15\"\n",
            "2022-07-01 15:35:49,172  - shuffle: \"True\"\n",
            "2022-07-01 15:35:49,173  - train_with_dev: \"False\"\n",
            "2022-07-01 15:35:49,175  - batch_growth_annealing: \"False\"\n",
            "2022-07-01 15:35:49,177 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 15:35:49,179 Model training base path: \"resources/taggers/sota-ner-flair\"\n",
            "2022-07-01 15:35:49,180 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 15:35:49,182 Device: cuda:0\n",
            "2022-07-01 15:35:49,184 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 15:35:49,186 Embeddings storage mode: cpu\n",
            "2022-07-01 15:35:49,187 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 15:42:02,200 epoch 1 - iter 359/3599 - loss 0.40167966 - samples/sec: 31.93 - lr: 0.100000\n",
            "2022-07-01 15:48:09,752 epoch 1 - iter 718/3599 - loss 0.31609542 - samples/sec: 32.33 - lr: 0.100000\n",
            "2022-07-01 15:54:16,996 epoch 1 - iter 1077/3599 - loss 0.27587112 - samples/sec: 32.47 - lr: 0.100000\n",
            "2022-07-01 16:00:30,691 epoch 1 - iter 1436/3599 - loss 0.24834229 - samples/sec: 31.80 - lr: 0.100000\n",
            "2022-07-01 16:06:39,478 epoch 1 - iter 1795/3599 - loss 0.22713805 - samples/sec: 32.33 - lr: 0.100000\n",
            "2022-07-01 16:12:53,365 epoch 1 - iter 2154/3599 - loss 0.21118671 - samples/sec: 31.88 - lr: 0.100000\n",
            "2022-07-01 16:18:55,045 epoch 1 - iter 2513/3599 - loss 0.19847788 - samples/sec: 32.83 - lr: 0.100000\n",
            "2022-07-01 16:24:55,217 epoch 1 - iter 2872/3599 - loss 0.18742488 - samples/sec: 33.06 - lr: 0.100000\n",
            "2022-07-01 16:31:06,181 epoch 1 - iter 3231/3599 - loss 0.17833925 - samples/sec: 32.07 - lr: 0.100000\n",
            "2022-07-01 16:37:14,957 epoch 1 - iter 3590/3599 - loss 0.17113372 - samples/sec: 32.17 - lr: 0.100000\n",
            "2022-07-01 16:37:23,359 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 16:37:23,365 EPOCH 1 done: loss 0.1709 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:51<00:00,  1.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 16:42:14,536 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 16:42:14,777 DEV : loss 0.11693257838487625 - f1-score (micro avg)  0.7167\n",
            "2022-07-01 16:42:27,331 BAD EPOCHS (no improvement): 0\n",
            "2022-07-01 16:42:27,333 saving best model\n",
            "2022-07-01 16:42:29,857 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 16:48:34,228 epoch 2 - iter 359/3599 - loss 0.09556453 - samples/sec: 32.83 - lr: 0.100000\n",
            "2022-07-01 16:54:32,841 epoch 2 - iter 718/3599 - loss 0.09331032 - samples/sec: 33.30 - lr: 0.100000\n",
            "2022-07-01 17:00:26,463 epoch 2 - iter 1077/3599 - loss 0.09147748 - samples/sec: 33.68 - lr: 0.100000\n",
            "2022-07-01 17:06:22,043 epoch 2 - iter 1436/3599 - loss 0.08973761 - samples/sec: 33.56 - lr: 0.100000\n",
            "2022-07-01 17:12:13,372 epoch 2 - iter 1795/3599 - loss 0.08797676 - samples/sec: 33.82 - lr: 0.100000\n",
            "2022-07-01 17:18:07,022 epoch 2 - iter 2154/3599 - loss 0.08670916 - samples/sec: 33.69 - lr: 0.100000\n",
            "2022-07-01 17:24:04,531 epoch 2 - iter 2513/3599 - loss 0.08538644 - samples/sec: 33.30 - lr: 0.100000\n",
            "2022-07-01 17:30:00,581 epoch 2 - iter 2872/3599 - loss 0.08428289 - samples/sec: 33.55 - lr: 0.100000\n",
            "2022-07-01 17:36:03,377 epoch 2 - iter 3231/3599 - loss 0.08325992 - samples/sec: 32.90 - lr: 0.100000\n",
            "2022-07-01 17:42:07,818 epoch 2 - iter 3590/3599 - loss 0.08232464 - samples/sec: 32.72 - lr: 0.100000\n",
            "2022-07-01 17:42:16,612 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 17:42:16,619 EPOCH 2 done: loss 0.0823 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:45<00:00,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 17:47:02,146 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 17:47:02,360 DEV : loss 0.06909181922674179 - f1-score (micro avg)  0.7998\n",
            "2022-07-01 17:47:14,056 BAD EPOCHS (no improvement): 0\n",
            "2022-07-01 17:47:14,058 saving best model\n",
            "2022-07-01 17:47:16,562 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 17:53:17,837 epoch 3 - iter 359/3599 - loss 0.06568131 - samples/sec: 33.08 - lr: 0.100000\n",
            "2022-07-01 17:59:16,674 epoch 3 - iter 718/3599 - loss 0.09205529 - samples/sec: 33.11 - lr: 0.100000\n",
            "2022-07-01 18:05:16,222 epoch 3 - iter 1077/3599 - loss 0.13022415 - samples/sec: 33.22 - lr: 0.100000\n",
            "2022-07-01 18:11:15,889 epoch 3 - iter 1436/3599 - loss 0.14024553 - samples/sec: 33.06 - lr: 0.100000\n",
            "2022-07-01 18:17:11,810 epoch 3 - iter 1795/3599 - loss 0.14418021 - samples/sec: 33.48 - lr: 0.100000\n",
            "2022-07-01 18:23:10,882 epoch 3 - iter 2154/3599 - loss 0.14465574 - samples/sec: 33.31 - lr: 0.100000\n",
            "2022-07-01 18:29:11,258 epoch 3 - iter 2513/3599 - loss 0.14421982 - samples/sec: 32.99 - lr: 0.100000\n",
            "2022-07-01 18:35:11,058 epoch 3 - iter 2872/3599 - loss 0.14307452 - samples/sec: 32.96 - lr: 0.100000\n",
            "2022-07-01 18:41:18,542 epoch 3 - iter 3231/3599 - loss 0.14194748 - samples/sec: 32.51 - lr: 0.100000\n",
            "2022-07-01 18:47:22,260 epoch 3 - iter 3590/3599 - loss 0.14035958 - samples/sec: 32.76 - lr: 0.100000\n",
            "2022-07-01 18:47:29,800 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 18:47:29,802 EPOCH 3 done: loss 0.1403 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:52<00:00,  1.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 18:52:22,016 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 18:52:22,231 DEV : loss 0.10298652946949005 - f1-score (micro avg)  0.6603\n",
            "2022-07-01 18:52:35,402 BAD EPOCHS (no improvement): 1\n",
            "2022-07-01 18:52:35,404 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 18:58:39,651 epoch 4 - iter 359/3599 - loss 0.12003489 - samples/sec: 32.77 - lr: 0.100000\n",
            "2022-07-01 19:04:39,383 epoch 4 - iter 718/3599 - loss 0.12011036 - samples/sec: 33.13 - lr: 0.100000\n",
            "2022-07-01 19:10:40,131 epoch 4 - iter 1077/3599 - loss 0.11938079 - samples/sec: 33.05 - lr: 0.100000\n",
            "2022-07-01 19:16:43,954 epoch 4 - iter 1436/3599 - loss 0.11908464 - samples/sec: 32.64 - lr: 0.100000\n",
            "2022-07-01 19:22:54,429 epoch 4 - iter 1795/3599 - loss 0.11830520 - samples/sec: 32.23 - lr: 0.100000\n",
            "2022-07-01 19:29:04,915 epoch 4 - iter 2154/3599 - loss 0.11768963 - samples/sec: 32.17 - lr: 0.100000\n",
            "2022-07-01 19:35:09,579 epoch 4 - iter 2513/3599 - loss 0.11714608 - samples/sec: 32.70 - lr: 0.100000\n",
            "2022-07-01 19:41:17,463 epoch 4 - iter 2872/3599 - loss 0.11630851 - samples/sec: 32.51 - lr: 0.100000\n",
            "2022-07-01 19:47:21,613 epoch 4 - iter 3231/3599 - loss 0.11555506 - samples/sec: 32.84 - lr: 0.100000\n",
            "2022-07-01 19:53:24,439 epoch 4 - iter 3590/3599 - loss 0.11490172 - samples/sec: 32.95 - lr: 0.100000\n",
            "2022-07-01 19:53:32,489 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 19:53:32,491 EPOCH 4 done: loss 0.1149 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:50<00:00,  1.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 19:58:22,701 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 19:58:22,916 DEV : loss 0.08952836692333221 - f1-score (micro avg)  0.6992\n",
            "2022-07-01 19:58:35,424 BAD EPOCHS (no improvement): 2\n",
            "2022-07-01 19:58:35,427 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 20:04:41,365 epoch 5 - iter 359/3599 - loss 0.10732584 - samples/sec: 32.77 - lr: 0.100000\n",
            "2022-07-01 20:10:46,272 epoch 5 - iter 718/3599 - loss 0.10730552 - samples/sec: 32.54 - lr: 0.100000\n",
            "2022-07-01 20:16:50,797 epoch 5 - iter 1077/3599 - loss 0.10728749 - samples/sec: 32.65 - lr: 0.100000\n",
            "2022-07-01 20:22:55,819 epoch 5 - iter 1436/3599 - loss 0.10658081 - samples/sec: 32.69 - lr: 0.100000\n",
            "2022-07-01 20:29:03,784 epoch 5 - iter 1795/3599 - loss 0.10651169 - samples/sec: 32.31 - lr: 0.100000\n",
            "2022-07-01 20:35:07,405 epoch 5 - iter 2154/3599 - loss 0.10645910 - samples/sec: 32.84 - lr: 0.100000\n",
            "2022-07-01 20:41:09,512 epoch 5 - iter 2513/3599 - loss 0.10613090 - samples/sec: 32.92 - lr: 0.100000\n",
            "2022-07-01 20:47:11,777 epoch 5 - iter 2872/3599 - loss 0.10570948 - samples/sec: 32.92 - lr: 0.100000\n",
            "2022-07-01 20:53:16,799 epoch 5 - iter 3231/3599 - loss 0.10532559 - samples/sec: 32.58 - lr: 0.100000\n",
            "2022-07-01 20:59:23,809 epoch 5 - iter 3590/3599 - loss 0.10488735 - samples/sec: 32.38 - lr: 0.100000\n",
            "2022-07-01 20:59:32,644 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 20:59:32,647 EPOCH 5 done: loss 0.1049 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:53<00:00,  1.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 21:04:26,258 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 21:04:26,507 DEV : loss 0.08369728922843933 - f1-score (micro avg)  0.7163\n",
            "2022-07-01 21:04:39,586 BAD EPOCHS (no improvement): 3\n",
            "2022-07-01 21:04:39,589 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 21:10:51,321 epoch 6 - iter 359/3599 - loss 0.10283127 - samples/sec: 32.13 - lr: 0.100000\n",
            "2022-07-01 21:17:00,091 epoch 6 - iter 718/3599 - loss 0.10228193 - samples/sec: 32.33 - lr: 0.100000\n",
            "2022-07-01 21:23:06,579 epoch 6 - iter 1077/3599 - loss 0.10135422 - samples/sec: 32.58 - lr: 0.100000\n",
            "2022-07-01 21:29:14,847 epoch 6 - iter 1436/3599 - loss 0.10040099 - samples/sec: 32.20 - lr: 0.100000\n",
            "2022-07-01 21:35:24,480 epoch 6 - iter 1795/3599 - loss 0.10034860 - samples/sec: 32.21 - lr: 0.100000\n",
            "2022-07-01 21:41:29,847 epoch 6 - iter 2154/3599 - loss 0.10012187 - samples/sec: 32.68 - lr: 0.100000\n",
            "2022-07-01 21:47:34,660 epoch 6 - iter 2513/3599 - loss 0.09997741 - samples/sec: 32.78 - lr: 0.100000\n",
            "2022-07-01 21:53:42,917 epoch 6 - iter 2872/3599 - loss 0.09976310 - samples/sec: 32.44 - lr: 0.100000\n",
            "2022-07-01 21:59:52,989 epoch 6 - iter 3231/3599 - loss 0.09958540 - samples/sec: 32.24 - lr: 0.100000\n",
            "2022-07-01 22:05:55,322 epoch 6 - iter 3590/3599 - loss 0.09935596 - samples/sec: 32.98 - lr: 0.100000\n",
            "2022-07-01 22:06:04,467 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 22:06:04,469 EPOCH 6 done: loss 0.0994 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:50<00:00,  1.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 22:10:55,341 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 22:10:55,572 DEV : loss 0.07869435101747513 - f1-score (micro avg)  0.7307\n",
            "2022-07-01 22:11:08,425 Epoch     6: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2022-07-01 22:11:08,427 BAD EPOCHS (no improvement): 4\n",
            "2022-07-01 22:11:08,434 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 22:17:15,410 epoch 7 - iter 359/3599 - loss 0.09070431 - samples/sec: 32.61 - lr: 0.050000\n",
            "2022-07-01 22:23:16,347 epoch 7 - iter 718/3599 - loss 0.09033197 - samples/sec: 33.13 - lr: 0.050000\n",
            "2022-07-01 22:29:20,249 epoch 7 - iter 1077/3599 - loss 0.09041354 - samples/sec: 32.86 - lr: 0.050000\n",
            "2022-07-01 22:35:35,142 epoch 7 - iter 1436/3599 - loss 0.09016201 - samples/sec: 31.80 - lr: 0.050000\n",
            "2022-07-01 22:41:43,082 epoch 7 - iter 1795/3599 - loss 0.08961226 - samples/sec: 32.31 - lr: 0.050000\n",
            "2022-07-01 22:47:51,736 epoch 7 - iter 2154/3599 - loss 0.08961064 - samples/sec: 32.49 - lr: 0.050000\n",
            "2022-07-01 22:54:05,513 epoch 7 - iter 2513/3599 - loss 0.08969776 - samples/sec: 31.90 - lr: 0.050000\n",
            "2022-07-01 23:00:09,948 epoch 7 - iter 2872/3599 - loss 0.08974500 - samples/sec: 32.73 - lr: 0.050000\n",
            "2022-07-01 23:06:18,085 epoch 7 - iter 3231/3599 - loss 0.08963548 - samples/sec: 32.28 - lr: 0.050000\n",
            "2022-07-01 23:12:24,048 epoch 7 - iter 3590/3599 - loss 0.08946628 - samples/sec: 32.51 - lr: 0.050000\n",
            "2022-07-01 23:12:33,024 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 23:12:33,027 EPOCH 7 done: loss 0.0895 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:52<00:00,  1.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 23:17:25,175 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-01 23:17:25,421 DEV : loss 0.07306062430143356 - f1-score (micro avg)  0.7539\n",
            "2022-07-01 23:17:38,445 BAD EPOCHS (no improvement): 1\n",
            "2022-07-01 23:17:38,448 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-01 23:23:49,197 epoch 8 - iter 359/3599 - loss 0.08768483 - samples/sec: 32.17 - lr: 0.050000\n",
            "2022-07-01 23:29:58,275 epoch 8 - iter 718/3599 - loss 0.08681808 - samples/sec: 32.34 - lr: 0.050000\n",
            "2022-07-01 23:36:03,625 epoch 8 - iter 1077/3599 - loss 0.08732504 - samples/sec: 32.53 - lr: 0.050000\n",
            "2022-07-01 23:42:05,042 epoch 8 - iter 1436/3599 - loss 0.08685248 - samples/sec: 32.95 - lr: 0.050000\n",
            "2022-07-01 23:48:07,040 epoch 8 - iter 1795/3599 - loss 0.08690577 - samples/sec: 32.80 - lr: 0.050000\n",
            "2022-07-01 23:54:13,884 epoch 8 - iter 2154/3599 - loss 0.08682757 - samples/sec: 32.34 - lr: 0.050000\n",
            "2022-07-02 00:00:16,706 epoch 8 - iter 2513/3599 - loss 0.08643209 - samples/sec: 32.81 - lr: 0.050000\n",
            "2022-07-02 00:06:16,512 epoch 8 - iter 2872/3599 - loss 0.08643070 - samples/sec: 32.99 - lr: 0.050000\n",
            "2022-07-02 00:12:11,202 epoch 8 - iter 3231/3599 - loss 0.08643374 - samples/sec: 33.73 - lr: 0.050000\n",
            "2022-07-02 00:18:08,093 epoch 8 - iter 3590/3599 - loss 0.08637451 - samples/sec: 33.37 - lr: 0.050000\n",
            "2022-07-02 00:18:17,662 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 00:18:17,665 EPOCH 8 done: loss 0.0864 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:42<00:00,  1.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 00:22:59,839 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 00:23:00,051 DEV : loss 0.07063516229391098 - f1-score (micro avg)  0.761\n",
            "2022-07-02 00:23:12,386 BAD EPOCHS (no improvement): 2\n",
            "2022-07-02 00:23:12,390 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 00:29:21,296 epoch 9 - iter 359/3599 - loss 0.08486921 - samples/sec: 32.26 - lr: 0.050000\n",
            "2022-07-02 00:35:20,862 epoch 9 - iter 718/3599 - loss 0.08418002 - samples/sec: 33.15 - lr: 0.050000\n",
            "2022-07-02 00:41:23,592 epoch 9 - iter 1077/3599 - loss 0.08432180 - samples/sec: 32.66 - lr: 0.050000\n",
            "2022-07-02 00:47:24,064 epoch 9 - iter 1436/3599 - loss 0.08443199 - samples/sec: 33.07 - lr: 0.050000\n",
            "2022-07-02 00:53:27,862 epoch 9 - iter 1795/3599 - loss 0.08435560 - samples/sec: 32.79 - lr: 0.050000\n",
            "2022-07-02 00:59:28,708 epoch 9 - iter 2154/3599 - loss 0.08439114 - samples/sec: 33.03 - lr: 0.050000\n",
            "2022-07-02 01:05:37,114 epoch 9 - iter 2513/3599 - loss 0.08414368 - samples/sec: 32.38 - lr: 0.050000\n",
            "2022-07-02 01:11:39,424 epoch 9 - iter 2872/3599 - loss 0.08400818 - samples/sec: 32.83 - lr: 0.050000\n",
            "2022-07-02 01:17:42,830 epoch 9 - iter 3231/3599 - loss 0.08401307 - samples/sec: 32.85 - lr: 0.050000\n",
            "2022-07-02 01:23:43,238 epoch 9 - iter 3590/3599 - loss 0.08408326 - samples/sec: 33.10 - lr: 0.050000\n",
            "2022-07-02 01:23:51,582 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 01:23:51,585 EPOCH 9 done: loss 0.0841 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:47<00:00,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 01:28:38,793 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 01:28:39,011 DEV : loss 0.07018689066171646 - f1-score (micro avg)  0.7641\n",
            "2022-07-02 01:28:51,526 BAD EPOCHS (no improvement): 3\n",
            "2022-07-02 01:28:51,529 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 01:34:57,281 epoch 10 - iter 359/3599 - loss 0.08244061 - samples/sec: 32.57 - lr: 0.050000\n",
            "2022-07-02 01:41:02,945 epoch 10 - iter 718/3599 - loss 0.08281511 - samples/sec: 32.54 - lr: 0.050000\n",
            "2022-07-02 01:47:00,517 epoch 10 - iter 1077/3599 - loss 0.08244422 - samples/sec: 33.39 - lr: 0.050000\n",
            "2022-07-02 01:52:54,745 epoch 10 - iter 1436/3599 - loss 0.08214957 - samples/sec: 33.52 - lr: 0.050000\n",
            "2022-07-02 01:58:52,491 epoch 10 - iter 1795/3599 - loss 0.08196482 - samples/sec: 33.41 - lr: 0.050000\n",
            "2022-07-02 02:04:47,569 epoch 10 - iter 2154/3599 - loss 0.08223575 - samples/sec: 33.44 - lr: 0.050000\n",
            "2022-07-02 02:10:39,058 epoch 10 - iter 2513/3599 - loss 0.08225816 - samples/sec: 33.95 - lr: 0.050000\n",
            "2022-07-02 02:16:39,061 epoch 10 - iter 2872/3599 - loss 0.08239524 - samples/sec: 33.06 - lr: 0.050000\n",
            "2022-07-02 02:22:33,620 epoch 10 - iter 3231/3599 - loss 0.08231412 - samples/sec: 33.66 - lr: 0.050000\n",
            "2022-07-02 02:28:30,093 epoch 10 - iter 3590/3599 - loss 0.08234593 - samples/sec: 33.50 - lr: 0.050000\n",
            "2022-07-02 02:28:37,685 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 02:28:37,686 EPOCH 10 done: loss 0.0823 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:40<00:00,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 02:33:18,290 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 02:33:18,487 DEV : loss 0.06740263104438782 - f1-score (micro avg)  0.7739\n",
            "2022-07-02 02:33:30,168 Epoch    10: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2022-07-02 02:33:30,170 BAD EPOCHS (no improvement): 4\n",
            "2022-07-02 02:33:30,175 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 02:39:26,837 epoch 11 - iter 359/3599 - loss 0.07959373 - samples/sec: 33.45 - lr: 0.025000\n",
            "2022-07-02 02:45:30,358 epoch 11 - iter 718/3599 - loss 0.07924346 - samples/sec: 32.89 - lr: 0.025000\n",
            "2022-07-02 02:51:28,123 epoch 11 - iter 1077/3599 - loss 0.07915909 - samples/sec: 33.33 - lr: 0.025000\n",
            "2022-07-02 02:57:30,238 epoch 11 - iter 1436/3599 - loss 0.07904611 - samples/sec: 32.80 - lr: 0.025000\n",
            "2022-07-02 03:03:24,032 epoch 11 - iter 1795/3599 - loss 0.07899562 - samples/sec: 33.77 - lr: 0.025000\n",
            "2022-07-02 03:09:22,506 epoch 11 - iter 2154/3599 - loss 0.07893601 - samples/sec: 33.12 - lr: 0.025000\n",
            "2022-07-02 03:15:32,234 epoch 11 - iter 2513/3599 - loss 0.07891471 - samples/sec: 32.28 - lr: 0.025000\n",
            "2022-07-02 03:21:32,944 epoch 11 - iter 2872/3599 - loss 0.07887299 - samples/sec: 33.00 - lr: 0.025000\n",
            "2022-07-02 03:27:29,608 epoch 11 - iter 3231/3599 - loss 0.07884461 - samples/sec: 33.43 - lr: 0.025000\n",
            "2022-07-02 03:33:28,581 epoch 11 - iter 3590/3599 - loss 0.07863532 - samples/sec: 33.18 - lr: 0.025000\n",
            "2022-07-02 03:33:36,699 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 03:33:36,704 EPOCH 11 done: loss 0.0786 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:42<00:00,  1.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 03:38:19,400 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 03:38:19,621 DEV : loss 0.06482449173927307 - f1-score (micro avg)  0.7813\n",
            "2022-07-02 03:38:32,008 BAD EPOCHS (no improvement): 1\n",
            "2022-07-02 03:38:32,010 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 03:45:04,664 epoch 12 - iter 359/3599 - loss 0.07767665 - samples/sec: 30.25 - lr: 0.025000\n",
            "2022-07-02 03:50:57,121 epoch 12 - iter 718/3599 - loss 0.07733437 - samples/sec: 33.64 - lr: 0.025000\n",
            "2022-07-02 03:56:51,905 epoch 12 - iter 1077/3599 - loss 0.07779137 - samples/sec: 33.44 - lr: 0.025000\n",
            "2022-07-02 04:02:46,456 epoch 12 - iter 1436/3599 - loss 0.07757103 - samples/sec: 33.50 - lr: 0.025000\n",
            "2022-07-02 04:08:39,253 epoch 12 - iter 1795/3599 - loss 0.07747800 - samples/sec: 33.82 - lr: 0.025000\n",
            "2022-07-02 04:14:34,678 epoch 12 - iter 2154/3599 - loss 0.07752183 - samples/sec: 33.41 - lr: 0.025000\n",
            "2022-07-02 04:20:30,394 epoch 12 - iter 2513/3599 - loss 0.07744192 - samples/sec: 33.42 - lr: 0.025000\n",
            "2022-07-02 04:26:24,677 epoch 12 - iter 2872/3599 - loss 0.07757757 - samples/sec: 33.56 - lr: 0.025000\n",
            "2022-07-02 04:32:16,299 epoch 12 - iter 3231/3599 - loss 0.07740242 - samples/sec: 33.85 - lr: 0.025000\n",
            "2022-07-02 04:38:09,216 epoch 12 - iter 3590/3599 - loss 0.07718368 - samples/sec: 33.69 - lr: 0.025000\n",
            "2022-07-02 04:38:17,132 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 04:38:17,133 EPOCH 12 done: loss 0.0772 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:41<00:00,  1.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 04:42:58,756 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 04:42:58,966 DEV : loss 0.06458857655525208 - f1-score (micro avg)  0.7793\n",
            "2022-07-02 04:43:11,460 BAD EPOCHS (no improvement): 2\n",
            "2022-07-02 04:43:11,463 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 04:49:07,454 epoch 13 - iter 359/3599 - loss 0.07602494 - samples/sec: 33.45 - lr: 0.025000\n",
            "2022-07-02 04:55:03,460 epoch 13 - iter 718/3599 - loss 0.07613125 - samples/sec: 33.51 - lr: 0.025000\n",
            "2022-07-02 05:00:54,780 epoch 13 - iter 1077/3599 - loss 0.07602427 - samples/sec: 33.93 - lr: 0.025000\n",
            "2022-07-02 05:06:52,595 epoch 13 - iter 1436/3599 - loss 0.07611535 - samples/sec: 33.46 - lr: 0.025000\n",
            "2022-07-02 05:12:50,398 epoch 13 - iter 1795/3599 - loss 0.07598614 - samples/sec: 33.38 - lr: 0.025000\n",
            "2022-07-02 05:18:48,892 epoch 13 - iter 2154/3599 - loss 0.07621668 - samples/sec: 33.19 - lr: 0.025000\n",
            "2022-07-02 05:24:38,299 epoch 13 - iter 2513/3599 - loss 0.07637151 - samples/sec: 34.16 - lr: 0.025000\n",
            "2022-07-02 05:30:32,049 epoch 13 - iter 2872/3599 - loss 0.07615068 - samples/sec: 33.62 - lr: 0.025000\n",
            "2022-07-02 05:36:26,454 epoch 13 - iter 3231/3599 - loss 0.07625392 - samples/sec: 33.30 - lr: 0.025000\n",
            "2022-07-02 05:42:22,458 epoch 13 - iter 3590/3599 - loss 0.07616746 - samples/sec: 33.41 - lr: 0.025000\n",
            "2022-07-02 05:42:31,024 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 05:42:31,026 EPOCH 13 done: loss 0.0761 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:42<00:00,  1.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 05:47:13,641 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 05:47:13,854 DEV : loss 0.0635419487953186 - f1-score (micro avg)  0.7825\n",
            "2022-07-02 05:47:25,872 BAD EPOCHS (no improvement): 3\n",
            "2022-07-02 05:47:25,874 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 05:53:26,543 epoch 14 - iter 359/3599 - loss 0.07470981 - samples/sec: 32.84 - lr: 0.025000\n",
            "2022-07-02 05:59:29,681 epoch 14 - iter 718/3599 - loss 0.07444120 - samples/sec: 32.85 - lr: 0.025000\n",
            "2022-07-02 06:05:35,828 epoch 14 - iter 1077/3599 - loss 0.07487054 - samples/sec: 32.54 - lr: 0.025000\n",
            "2022-07-02 06:11:37,712 epoch 14 - iter 1436/3599 - loss 0.07440439 - samples/sec: 32.91 - lr: 0.025000\n",
            "2022-07-02 06:17:40,063 epoch 14 - iter 1795/3599 - loss 0.07466584 - samples/sec: 32.94 - lr: 0.025000\n",
            "2022-07-02 06:23:48,626 epoch 14 - iter 2154/3599 - loss 0.07462583 - samples/sec: 32.42 - lr: 0.025000\n",
            "2022-07-02 06:29:51,625 epoch 14 - iter 2513/3599 - loss 0.07474047 - samples/sec: 33.00 - lr: 0.025000\n",
            "2022-07-02 06:35:55,160 epoch 14 - iter 2872/3599 - loss 0.07495098 - samples/sec: 32.91 - lr: 0.025000\n",
            "2022-07-02 06:42:02,147 epoch 14 - iter 3231/3599 - loss 0.07507078 - samples/sec: 32.52 - lr: 0.025000\n",
            "2022-07-02 06:48:15,985 epoch 14 - iter 3590/3599 - loss 0.07501951 - samples/sec: 31.89 - lr: 0.025000\n",
            "2022-07-02 06:48:24,226 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 06:48:24,232 EPOCH 14 done: loss 0.0750 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:54<00:00,  1.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 06:53:18,387 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 06:53:18,648 DEV : loss 0.06309645622968674 - f1-score (micro avg)  0.7888\n",
            "2022-07-02 06:53:31,832 Epoch    14: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2022-07-02 06:53:31,836 BAD EPOCHS (no improvement): 4\n",
            "2022-07-02 06:53:31,842 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 07:00:38,971 epoch 15 - iter 359/3599 - loss 0.07310102 - samples/sec: 27.91 - lr: 0.012500\n",
            "2022-07-02 07:07:52,480 epoch 15 - iter 718/3599 - loss 0.07385449 - samples/sec: 27.38 - lr: 0.012500\n",
            "2022-07-02 07:15:03,086 epoch 15 - iter 1077/3599 - loss 0.07380811 - samples/sec: 27.51 - lr: 0.012500\n",
            "2022-07-02 07:22:16,770 epoch 15 - iter 1436/3599 - loss 0.07367942 - samples/sec: 27.25 - lr: 0.012500\n",
            "2022-07-02 07:29:24,911 epoch 15 - iter 1795/3599 - loss 0.07361567 - samples/sec: 27.67 - lr: 0.012500\n",
            "2022-07-02 07:36:31,626 epoch 15 - iter 2154/3599 - loss 0.07353147 - samples/sec: 27.88 - lr: 0.012500\n",
            "2022-07-02 07:43:18,713 epoch 15 - iter 2513/3599 - loss 0.07320054 - samples/sec: 29.16 - lr: 0.012500\n",
            "2022-07-02 07:49:24,746 epoch 15 - iter 2872/3599 - loss 0.07315937 - samples/sec: 32.67 - lr: 0.012500\n",
            "2022-07-02 07:55:35,481 epoch 15 - iter 3231/3599 - loss 0.07331015 - samples/sec: 32.22 - lr: 0.012500\n",
            "2022-07-02 08:01:40,405 epoch 15 - iter 3590/3599 - loss 0.07335635 - samples/sec: 32.60 - lr: 0.012500\n",
            "2022-07-02 08:01:48,395 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 08:01:48,402 EPOCH 15 done: loss 0.0734 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [04:56<00:00,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 08:06:45,207 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 08:06:45,452 DEV : loss 0.0615210086107254 - f1-score (micro avg)  0.7923\n",
            "2022-07-02 08:06:58,291 BAD EPOCHS (no improvement): 1\n",
            "2022-07-02 08:07:00,778 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 08:07:00,785 loading file resources/taggers/sota-ner-flair/best-model.pt\n",
            "2022-07-02 08:07:04,177 SequenceTagger predicts: Dictionary with 19 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 445/445 [04:52<00:00,  1.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 08:11:57,590 Evaluating as a multi-label problem: False\n",
            "2022-07-02 08:11:57,851 0.7992\t0.7982\t0.7987\t0.7457\n",
            "2022-07-02 08:11:57,854 \n",
            "Results:\n",
            "- F-score (micro) 0.7987\n",
            "- F-score (macro) 0.7821\n",
            "- Accuracy 0.7457\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         PER     0.9169    0.8820    0.8991      9659\n",
            "         LOC     0.8160    0.8273    0.8216      8664\n",
            "        MISC     0.7836    0.6477    0.7092      7158\n",
            "         ORG     0.6193    0.8013    0.6987      4933\n",
            "\n",
            "   micro avg     0.7992    0.7982    0.7987     30414\n",
            "   macro avg     0.7840    0.7896    0.7821     30414\n",
            "weighted avg     0.8085    0.7982    0.7998     30414\n",
            "\n",
            "2022-07-02 08:11:57,866 ----------------------------------------------------------------------------------------------------\n",
            "2022-07-02 08:11:57,868 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 445/445 [04:51<00:00,  1.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-02 08:16:49,682 Evaluating as a multi-label problem: False\n",
            "2022-07-02 08:16:49,938 /root/.flair/datasets/ner_multi_wikiner/en\n",
            "2022-07-02 08:16:49,940 0.7992\t0.7982\t0.7987\t0.7457\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.11693257838487625,\n",
              "  0.06909181922674179,\n",
              "  0.10298652946949005,\n",
              "  0.08952836692333221,\n",
              "  0.08369728922843933,\n",
              "  0.07869435101747513,\n",
              "  0.07306062430143356,\n",
              "  0.07063516229391098,\n",
              "  0.07018689066171646,\n",
              "  0.06740263104438782,\n",
              "  0.06482449173927307,\n",
              "  0.06458857655525208,\n",
              "  0.0635419487953186,\n",
              "  0.06309645622968674,\n",
              "  0.0615210086107254],\n",
              " 'dev_score_history': [0.7167326858031725,\n",
              "  0.7998119621031317,\n",
              "  0.660317231694363,\n",
              "  0.6992211555877559,\n",
              "  0.7163185093529368,\n",
              "  0.7307239499375126,\n",
              "  0.753884422654025,\n",
              "  0.7610328638497652,\n",
              "  0.7641248803741355,\n",
              "  0.7739174401386832,\n",
              "  0.7813398426905342,\n",
              "  0.779318950395139,\n",
              "  0.7825426944971536,\n",
              "  0.788813259429108,\n",
              "  0.7923239551146528],\n",
              " 'test_score': 0.798710271764164,\n",
              " 'train_loss_history': [0.17091064553016125,\n",
              "  0.08230704638068084,\n",
              "  0.14033509731334098,\n",
              "  0.11488241981765618,\n",
              "  0.10486285302191621,\n",
              "  0.09935295508629954,\n",
              "  0.08950161790416439,\n",
              "  0.0863801463772986,\n",
              "  0.08407901529583602,\n",
              "  0.08232809602399596,\n",
              "  0.07864175314831473,\n",
              "  0.07716508056691776,\n",
              "  0.07614582494477523,\n",
              "  0.07501418293797096,\n",
              "  0.07335135084586317]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# 6. initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "\n",
        "# 7. start training\n",
        "trainer.train('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FEh-XFYJwPz"
      },
      "source": [
        "## Teste 1.6 NER Flair Stacked Embeddings (Word, Bert e Flair Embeddings) com Corpus Multi_Wikiner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGiL58J7JwP6"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zprDZYcIJwP6"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "## Corpus\n",
        "from flair.datasets import NER_MULTI_WIKINER\n",
        "\n",
        "## Importando os Embeddings, BERTinbaum e Flair-pt\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, TransformerWordEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMgco6pAJwP7"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GVCjDJxJwP7",
        "outputId": "b6dbbcb9-3860-48d6-bbba-e24b77acf20f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:27:07,215 https://raw.githubusercontent.com/dice-group/FOX/master/input/Wikiner/aij-wikiner-en-wp3.bz2 not found in cache, downloading to /tmp/tmpwy_zn2h1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6208404/6208404 [00:00<00:00, 58260620.13B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:27:07,366 copying /tmp/tmpwy_zn2h1 to cache at /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.bz2\n",
            "2022-08-24 19:27:07,377 removing temp file /tmp/tmpwy_zn2h1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:27:11,250 Read data for language en\n",
            "2022-08-24 19:27:11,253 Reading data from /root/.flair/datasets/ner_multi_wikiner/en\n",
            "2022-08-24 19:27:11,253 Train: /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.train\n",
            "2022-08-24 19:27:11,255 Dev: None\n",
            "2022-08-24 19:27:11,256 Test: None\n",
            "MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en\n"
          ]
        }
      ],
      "source": [
        "## Corpus\n",
        "corpus = NER_MULTI_WIKINER()\n",
        "print(corpus)\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IsOJDkAJwP7",
        "outputId": "4de582e8-640a-44b6-b8f8-4de09a9ffb6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:29:39,710 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "115144it [01:00, 1888.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:30:40,684 Dictionary created for label 'ner' with 5 values: PER (seen 77811 times), LOC (seen 69560 times), MISC (seen 59532 times), ORG (seen 40285 times)\n",
            "Dictionary with 5 tags: <unk>, PER, LOC, MISC, ORG\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf4gF5CvJwP7"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "-dgPuI8zJwP7",
        "outputId": "1381ebcd-f339-44ae-8549-58f8bf21d3f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:27:14,657 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpzvhwdpvh\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 710528528/710528528 [00:41<00:00, 17202692.27B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:27:56,486 copying /tmp/tmpzvhwdpvh to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M.vectors.npy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:27:58,079 removing temp file /tmp/tmpzvhwdpvh\n",
            "2022-08-24 19:27:58,811 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmpbl1gym29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23541010/23541010 [00:02<00:00, 10144657.30B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:28:01,740 copying /tmp/tmpbl1gym29 to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M\n",
            "2022-08-24 19:28:01,769 removing temp file /tmp/tmpbl1gym29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:28:04,941 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-forward.pt not found in cache, downloading to /tmp/tmp9ybveelw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:05<00:00, 13998317.62B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:28:10,694 copying /tmp/tmp9ybveelw to cache at /root/.flair/embeddings/lm-pt-forward.pt\n",
            "2022-08-24 19:28:10,763 removing temp file /tmp/tmp9ybveelw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:28:21,895 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-backward.pt not found in cache, downloading to /tmp/tmpcqfjc3mt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:05<00:00, 14032318.08B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:28:27,656 copying /tmp/tmpcqfjc3mt to cache at /root/.flair/embeddings/lm-pt-backward.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:28:27,726 removing temp file /tmp/tmpcqfjc3mt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3ec48af97d24c7abd18ec0e86f15556",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f69dfe3dc9f49588b1c825044ca1f59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c7677b2fb9e4c12bde092195cdf0dea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a92321211f74c4d996f059f6baabc30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ea97ed422c64615a225684d56d4276a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18596e77f80b4a77a65a21242dd50643",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/418M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# init Word Embeddings\n",
        "word_embedding = WordEmbeddings('pt')\n",
        "\n",
        "# init Flair embeddings\n",
        "flair_embedding_forward = FlairEmbeddings('pt-forward')\n",
        "flair_embedding_backward = FlairEmbeddings('pt-backward')\n",
        "\n",
        "# init pt BERT\n",
        "bert_embedding = TransformerWordEmbeddings('neuralmind/bert-base-portuguese-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxChTJtPJwP7"
      },
      "outputs": [],
      "source": [
        "## Empilhando os Embeddings\n",
        "from flair.embeddings import StackedEmbeddings\n",
        "\n",
        "# create a StackedEmbedding object that combines Bert and forward/backward flair embeddings\n",
        "embeddings = StackedEmbeddings([\n",
        "                                        word_embedding,\n",
        "                                        flair_embedding_forward,\n",
        "                                        flair_embedding_backward,\n",
        "                                        bert_embedding\n",
        "                                       ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mofnzuW1JwP7"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EswZBAl8JwP7",
        "outputId": "549e225d-fe05-4407-96b2-9cbb83e44feb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:30:52,930 SequenceTagger predicts: Dictionary with 17 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "# 5. initialize sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP3GmXZ6JwP7",
        "outputId": "571d9d5a-69f7-4d43-dfd5-159a96322c5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 19:30:57,670 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-24 19:30:57,673 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'pt'\n",
            "      (embedding): Embedding(592108, 300)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_3): TransformerWordEmbeddings(\n",
            "      (model): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=5164, out_features=5164, bias=True)\n",
            "  (rnn): LSTM(5164, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=19, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-08-24 19:30:57,675 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-24 19:30:57,677 Corpus: \"MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en\"\n",
            "2022-08-24 19:30:57,678 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-24 19:30:57,679 Parameters:\n",
            "2022-08-24 19:30:57,680  - learning_rate: \"0.100000\"\n",
            "2022-08-24 19:30:57,682  - mini_batch_size: \"32\"\n",
            "2022-08-24 19:30:57,684  - patience: \"3\"\n",
            "2022-08-24 19:30:57,686  - anneal_factor: \"0.5\"\n",
            "2022-08-24 19:30:57,687  - max_epochs: \"100\"\n",
            "2022-08-24 19:30:57,688  - shuffle: \"True\"\n",
            "2022-08-24 19:30:57,690  - train_with_dev: \"False\"\n",
            "2022-08-24 19:30:57,692  - batch_growth_annealing: \"False\"\n",
            "2022-08-24 19:30:57,693 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-24 19:30:57,694 Model training base path: \"resources/taggers/sota-ner-flair\"\n",
            "2022-08-24 19:30:57,696 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-24 19:30:57,697 Device: cuda:0\n",
            "2022-08-24 19:30:57,698 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-24 19:30:57,700 Embeddings storage mode: cpu\n",
            "2022-08-24 19:30:57,701 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-24 19:36:53,940 epoch 1 - iter 359/3599 - loss 0.33686799 - samples/sec: 33.34 - lr: 0.100000\n",
            "2022-08-24 19:43:01,763 epoch 1 - iter 718/3599 - loss 0.26128799 - samples/sec: 32.43 - lr: 0.100000\n",
            "2022-08-24 19:47:31,151 epoch 1 - iter 1077/3599 - loss 0.22617139 - samples/sec: 44.88 - lr: 0.100000\n",
            "2022-08-24 19:52:12,147 epoch 1 - iter 1436/3599 - loss 0.20346495 - samples/sec: 42.76 - lr: 0.100000\n",
            "2022-08-24 19:58:23,510 epoch 1 - iter 1795/3599 - loss 0.18614137 - samples/sec: 31.98 - lr: 0.100000\n",
            "2022-08-24 20:04:39,172 epoch 1 - iter 2154/3599 - loss 0.18696923 - samples/sec: 31.58 - lr: 0.100000\n",
            "2022-08-24 20:10:32,276 epoch 1 - iter 2513/3599 - loss 0.18514482 - samples/sec: 33.45 - lr: 0.100000\n",
            "2022-08-24 20:14:59,714 epoch 1 - iter 2872/3599 - loss 0.17870301 - samples/sec: 44.79 - lr: 0.100000\n",
            "2022-08-24 20:20:46,963 epoch 1 - iter 3231/3599 - loss 0.17266698 - samples/sec: 34.34 - lr: 0.100000\n",
            "2022-08-24 20:26:54,587 epoch 1 - iter 3590/3599 - loss 0.16700182 - samples/sec: 32.32 - lr: 0.100000\n",
            "2022-08-24 20:27:03,260 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-24 20:27:03,262 EPOCH 1 done: loss 0.1669 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [03:53<00:00,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 20:30:57,224 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-24 20:30:57,454 DEV : loss 0.10826125741004944 - f1-score (micro avg)  0.6756\n",
            "2022-08-24 20:31:08,004 BAD EPOCHS (no improvement): 0\n",
            "2022-08-24 20:31:08,007 saving best model\n",
            "2022-08-24 20:31:14,575 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-24 20:35:49,055 epoch 2 - iter 359/3599 - loss 0.11260556 - samples/sec: 43.91 - lr: 0.100000\n",
            "2022-08-24 20:40:25,653 epoch 2 - iter 718/3599 - loss 0.10887721 - samples/sec: 43.41 - lr: 0.100000\n",
            "2022-08-24 20:44:56,801 epoch 2 - iter 1077/3599 - loss 0.10738208 - samples/sec: 44.12 - lr: 0.100000\n",
            "2022-08-24 20:49:27,230 epoch 2 - iter 1436/3599 - loss 0.10516771 - samples/sec: 44.52 - lr: 0.100000\n",
            "2022-08-24 20:53:59,964 epoch 2 - iter 1795/3599 - loss 0.10313117 - samples/sec: 44.45 - lr: 0.100000\n",
            "2022-08-24 20:58:29,744 epoch 2 - iter 2154/3599 - loss 0.10185777 - samples/sec: 44.64 - lr: 0.100000\n",
            "2022-08-24 21:03:01,249 epoch 2 - iter 2513/3599 - loss 0.10009149 - samples/sec: 44.20 - lr: 0.100000\n"
          ]
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# 6. initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "\n",
        "# 7. start training\n",
        "trainer.train('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kCAsXVDL2cl"
      },
      "source": [
        "## Teste 2.1 NER Flair Classic Word Embeddings com Corpus Lener_br\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C87p0ahbL2cr"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPzFZZOmL2cr"
      },
      "outputs": [],
      "source": [
        "## Importes\n",
        "## datasets\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import WordEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U763QiM7L2cs"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN3jQEBML2cs",
        "outputId": "e95dcfe3-2e66-434d-a923-b70d14438fe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl-WBwPjL2cs",
        "outputId": "015d1393-d896-42dd-ae9c-c20bb199f471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:01:51,273 Reading data from /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig\n",
            "2022-12-12 00:01:51,275 Train: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig/train.txt\n",
            "2022-12-12 00:01:51,279 Dev: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig/dev.txt\n",
            "2022-12-12 00:01:51,280 Test: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig/test.txt\n"
          ]
        }
      ],
      "source": [
        "## carregando um corpus e definindo as colunas\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9k2l7IJL2cs",
        "outputId": "a5c8de00-78c3-4536-a2a1-fa074bc02b31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:02:01,521 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7827it [00:00, 47659.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:02:01,722 Dictionary created for label 'ner' with 7 values: ORGANIZACAO (seen 2400 times), LEGISLACAO (seen 1920 times), PESSOA (seen 1525 times), TEMPO (seen 1334 times), JURISPRUDENCIA (seen 1104 times), LOCAL (seen 611 times)\n",
            "Dictionary with 7 tags: <unk>, ORGANIZACAO, LEGISLACAO, PESSOA, TEMPO, JURISPRUDENCIA, LOCAL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrNaYl5VL2cs"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSCJO9fEL2cs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4742bca-cec0-43f5-f796-710401ddc411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:02:02,756 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpxn5w9s_0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 710528528/710528528 [00:53<00:00, 13373490.70B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:02:56,534 copying /tmp/tmpxn5w9s_0 to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M.vectors.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:02:58,505 removing temp file /tmp/tmpxn5w9s_0\n",
            "2022-12-12 00:02:59,556 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmpzhe_duta\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23541010/23541010 [00:03<00:00, 7598937.33B/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:03:03,311 copying /tmp/tmpzhe_duta to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M\n",
            "2022-12-12 00:03:03,330 removing temp file /tmp/tmpzhe_duta\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Embeddings\n",
        "# Initialize embedding\n",
        "embeddings = WordEmbeddings('pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xph3wVUvL2cs"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53iwI84iL2cs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b86abb9-2854-4c13-c187-08cf2e800537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:03:06,066 SequenceTagger predicts: Dictionary with 25 tags: O, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-LEGISLACAO, B-LEGISLACAO, E-LEGISLACAO, I-LEGISLACAO, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-TEMPO, B-TEMPO, E-TEMPO, I-TEMPO, S-JURISPRUDENCIA, B-JURISPRUDENCIA, E-JURISPRUDENCIA, I-JURISPRUDENCIA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhMzkvGsL2ct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c5e7800-2dec-41ef-af83-3e79014ede47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:03:14,172 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:03:14,175 Model: \"SequenceTagger(\n",
            "  (embeddings): WordEmbeddings(\n",
            "    'pt'\n",
            "    (embedding): Embedding(592108, 300)\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=300, out_features=300, bias=True)\n",
            "  (rnn): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=27, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-12-12 00:03:14,177 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:03:14,179 Corpus: \"Corpus: 7827 train + 1176 dev + 1389 test sentences\"\n",
            "2022-12-12 00:03:14,181 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:03:14,182 Parameters:\n",
            "2022-12-12 00:03:14,185  - learning_rate: \"0.100000\"\n",
            "2022-12-12 00:03:14,186  - mini_batch_size: \"32\"\n",
            "2022-12-12 00:03:14,187  - patience: \"3\"\n",
            "2022-12-12 00:03:14,190  - anneal_factor: \"0.5\"\n",
            "2022-12-12 00:03:14,191  - max_epochs: \"150\"\n",
            "2022-12-12 00:03:14,194  - shuffle: \"True\"\n",
            "2022-12-12 00:03:14,195  - train_with_dev: \"False\"\n",
            "2022-12-12 00:03:14,197  - batch_growth_annealing: \"False\"\n",
            "2022-12-12 00:03:14,198 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:03:14,199 Model training base path: \"resources/taggers/sota-ner-flair\"\n",
            "2022-12-12 00:03:14,202 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:03:14,204 Device: cuda:0\n",
            "2022-12-12 00:03:14,205 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:03:14,208 Embeddings storage mode: cpu\n",
            "2022-12-12 00:03:14,210 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:03:20,111 epoch 1 - iter 24/245 - loss 1.31429378 - samples/sec: 130.22 - lr: 0.100000\n",
            "2022-12-12 00:03:23,762 epoch 1 - iter 48/245 - loss 1.03530880 - samples/sec: 210.60 - lr: 0.100000\n",
            "2022-12-12 00:03:27,144 epoch 1 - iter 72/245 - loss 0.87960436 - samples/sec: 227.35 - lr: 0.100000\n",
            "2022-12-12 00:03:30,784 epoch 1 - iter 96/245 - loss 0.75163027 - samples/sec: 211.22 - lr: 0.100000\n",
            "2022-12-12 00:03:33,291 epoch 1 - iter 120/245 - loss 0.68946309 - samples/sec: 306.86 - lr: 0.100000\n",
            "2022-12-12 00:03:36,119 epoch 1 - iter 144/245 - loss 0.66825419 - samples/sec: 271.95 - lr: 0.100000\n",
            "2022-12-12 00:03:39,350 epoch 1 - iter 168/245 - loss 0.60738740 - samples/sec: 237.93 - lr: 0.100000\n",
            "2022-12-12 00:03:43,624 epoch 1 - iter 192/245 - loss 0.57515420 - samples/sec: 179.86 - lr: 0.100000\n",
            "2022-12-12 00:03:48,058 epoch 1 - iter 216/245 - loss 0.54536587 - samples/sec: 173.35 - lr: 0.100000\n",
            "2022-12-12 00:03:52,394 epoch 1 - iter 240/245 - loss 0.50894978 - samples/sec: 177.28 - lr: 0.100000\n",
            "2022-12-12 00:03:52,933 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:03:52,935 EPOCH 1 done: loss 0.5048 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:04:01,106 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:04:01,127 DEV : loss 0.2923157811164856 - f1-score (micro avg)  0.3266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:04:01,213 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:04:01,215 saving best model\n",
            "2022-12-12 00:04:03,843 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:04:07,577 epoch 2 - iter 24/245 - loss 0.26401509 - samples/sec: 205.98 - lr: 0.100000\n",
            "2022-12-12 00:04:11,315 epoch 2 - iter 48/245 - loss 0.24095730 - samples/sec: 205.71 - lr: 0.100000\n",
            "2022-12-12 00:04:14,920 epoch 2 - iter 72/245 - loss 0.23139441 - samples/sec: 213.26 - lr: 0.100000\n",
            "2022-12-12 00:04:18,608 epoch 2 - iter 96/245 - loss 0.22623612 - samples/sec: 208.51 - lr: 0.100000\n",
            "2022-12-12 00:04:22,780 epoch 2 - iter 120/245 - loss 0.22045064 - samples/sec: 184.26 - lr: 0.100000\n",
            "2022-12-12 00:04:25,881 epoch 2 - iter 144/245 - loss 0.21562629 - samples/sec: 247.96 - lr: 0.100000\n",
            "2022-12-12 00:04:30,512 epoch 2 - iter 168/245 - loss 0.21055466 - samples/sec: 166.00 - lr: 0.100000\n",
            "2022-12-12 00:04:33,397 epoch 2 - iter 192/245 - loss 0.20625175 - samples/sec: 266.54 - lr: 0.100000\n",
            "2022-12-12 00:04:36,773 epoch 2 - iter 216/245 - loss 0.19934086 - samples/sec: 227.78 - lr: 0.100000\n",
            "2022-12-12 00:04:41,690 epoch 2 - iter 240/245 - loss 0.19654691 - samples/sec: 156.33 - lr: 0.100000\n",
            "2022-12-12 00:04:42,363 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:04:42,364 EPOCH 2 done: loss 0.1959 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:04:49,626 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:04:49,649 DEV : loss 0.15578848123550415 - f1-score (micro avg)  0.4512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:04:49,732 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:04:49,735 saving best model\n",
            "2022-12-12 00:04:52,557 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:04:56,147 epoch 3 - iter 24/245 - loss 0.15902660 - samples/sec: 215.66 - lr: 0.100000\n",
            "2022-12-12 00:05:00,502 epoch 3 - iter 48/245 - loss 0.15090710 - samples/sec: 176.54 - lr: 0.100000\n",
            "2022-12-12 00:05:04,123 epoch 3 - iter 72/245 - loss 0.14509615 - samples/sec: 212.31 - lr: 0.100000\n",
            "2022-12-12 00:05:08,384 epoch 3 - iter 96/245 - loss 0.14392058 - samples/sec: 180.43 - lr: 0.100000\n",
            "2022-12-12 00:05:13,036 epoch 3 - iter 120/245 - loss 0.14231136 - samples/sec: 165.24 - lr: 0.100000\n",
            "2022-12-12 00:05:16,646 epoch 3 - iter 144/245 - loss 0.13823325 - samples/sec: 212.97 - lr: 0.100000\n",
            "2022-12-12 00:05:19,540 epoch 3 - iter 168/245 - loss 0.13671142 - samples/sec: 265.75 - lr: 0.100000\n",
            "2022-12-12 00:05:23,708 epoch 3 - iter 192/245 - loss 0.13551729 - samples/sec: 184.43 - lr: 0.100000\n",
            "2022-12-12 00:05:26,968 epoch 3 - iter 216/245 - loss 0.13174102 - samples/sec: 235.82 - lr: 0.100000\n",
            "2022-12-12 00:05:30,503 epoch 3 - iter 240/245 - loss 0.12840932 - samples/sec: 217.55 - lr: 0.100000\n",
            "2022-12-12 00:05:31,161 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:05:31,163 EPOCH 3 done: loss 0.1275 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:05:39,232 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:05:39,253 DEV : loss 0.11385537683963776 - f1-score (micro avg)  0.5675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:05:39,338 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:05:39,340 saving best model\n",
            "2022-12-12 00:05:42,035 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:05:46,475 epoch 4 - iter 24/245 - loss 0.11153287 - samples/sec: 173.85 - lr: 0.100000\n",
            "2022-12-12 00:05:51,317 epoch 4 - iter 48/245 - loss 0.10553651 - samples/sec: 158.77 - lr: 0.100000\n",
            "2022-12-12 00:05:55,404 epoch 4 - iter 72/245 - loss 0.10524185 - samples/sec: 188.14 - lr: 0.100000\n",
            "2022-12-12 00:05:59,425 epoch 4 - iter 96/245 - loss 0.10660237 - samples/sec: 191.18 - lr: 0.100000\n",
            "2022-12-12 00:06:03,022 epoch 4 - iter 120/245 - loss 0.10432074 - samples/sec: 213.74 - lr: 0.100000\n",
            "2022-12-12 00:06:06,037 epoch 4 - iter 144/245 - loss 0.10346559 - samples/sec: 255.09 - lr: 0.100000\n",
            "2022-12-12 00:06:09,294 epoch 4 - iter 168/245 - loss 0.10365828 - samples/sec: 236.05 - lr: 0.100000\n",
            "2022-12-12 00:06:12,072 epoch 4 - iter 192/245 - loss 0.10214064 - samples/sec: 276.85 - lr: 0.100000\n",
            "2022-12-12 00:06:15,895 epoch 4 - iter 216/245 - loss 0.10112016 - samples/sec: 201.12 - lr: 0.100000\n",
            "2022-12-12 00:06:19,295 epoch 4 - iter 240/245 - loss 0.10167011 - samples/sec: 226.15 - lr: 0.100000\n",
            "2022-12-12 00:06:19,899 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:06:19,901 EPOCH 4 done: loss 0.1009 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:06:27,936 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:06:27,963 DEV : loss 0.09648843109607697 - f1-score (micro avg)  0.5993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:06:28,050 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:06:28,053 saving best model\n",
            "2022-12-12 00:06:30,920 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:06:36,185 epoch 5 - iter 24/245 - loss 0.09842539 - samples/sec: 146.48 - lr: 0.100000\n",
            "2022-12-12 00:06:40,964 epoch 5 - iter 48/245 - loss 0.08962839 - samples/sec: 160.83 - lr: 0.100000\n",
            "2022-12-12 00:06:44,110 epoch 5 - iter 72/245 - loss 0.09298976 - samples/sec: 244.43 - lr: 0.100000\n",
            "2022-12-12 00:06:48,083 epoch 5 - iter 96/245 - loss 0.09191562 - samples/sec: 193.51 - lr: 0.100000\n",
            "2022-12-12 00:06:51,459 epoch 5 - iter 120/245 - loss 0.09046449 - samples/sec: 227.75 - lr: 0.100000\n",
            "2022-12-12 00:06:54,442 epoch 5 - iter 144/245 - loss 0.08996636 - samples/sec: 257.82 - lr: 0.100000\n",
            "2022-12-12 00:06:57,374 epoch 5 - iter 168/245 - loss 0.08836427 - samples/sec: 262.15 - lr: 0.100000\n",
            "2022-12-12 00:07:01,328 epoch 5 - iter 192/245 - loss 0.08808060 - samples/sec: 194.48 - lr: 0.100000\n",
            "2022-12-12 00:07:04,859 epoch 5 - iter 216/245 - loss 0.08828690 - samples/sec: 217.78 - lr: 0.100000\n",
            "2022-12-12 00:07:08,519 epoch 5 - iter 240/245 - loss 0.08716035 - samples/sec: 210.09 - lr: 0.100000\n",
            "2022-12-12 00:07:09,068 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:07:09,070 EPOCH 5 done: loss 0.0870 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:07:16,447 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:07:16,470 DEV : loss 0.08739913254976273 - f1-score (micro avg)  0.6363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:07:16,556 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:07:16,559 saving best model\n",
            "2022-12-12 00:07:19,237 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:07:23,005 epoch 6 - iter 24/245 - loss 0.08610648 - samples/sec: 204.96 - lr: 0.100000\n",
            "2022-12-12 00:07:27,228 epoch 6 - iter 48/245 - loss 0.08246356 - samples/sec: 182.06 - lr: 0.100000\n",
            "2022-12-12 00:07:30,766 epoch 6 - iter 72/245 - loss 0.07920964 - samples/sec: 217.29 - lr: 0.100000\n",
            "2022-12-12 00:07:35,217 epoch 6 - iter 96/245 - loss 0.07788415 - samples/sec: 172.72 - lr: 0.100000\n",
            "2022-12-12 00:07:38,327 epoch 6 - iter 120/245 - loss 0.07777157 - samples/sec: 247.22 - lr: 0.100000\n",
            "2022-12-12 00:07:42,179 epoch 6 - iter 144/245 - loss 0.07708356 - samples/sec: 199.59 - lr: 0.100000\n",
            "2022-12-12 00:07:45,215 epoch 6 - iter 168/245 - loss 0.07734724 - samples/sec: 253.32 - lr: 0.100000\n",
            "2022-12-12 00:07:49,862 epoch 6 - iter 192/245 - loss 0.07753427 - samples/sec: 165.42 - lr: 0.100000\n",
            "2022-12-12 00:07:52,957 epoch 6 - iter 216/245 - loss 0.07712939 - samples/sec: 248.50 - lr: 0.100000\n",
            "2022-12-12 00:07:57,089 epoch 6 - iter 240/245 - loss 0.07729204 - samples/sec: 186.01 - lr: 0.100000\n",
            "2022-12-12 00:07:57,785 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:07:57,787 EPOCH 6 done: loss 0.0772 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:08:06,057 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:08:06,077 DEV : loss 0.08484203368425369 - f1-score (micro avg)  0.6697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:08:06,160 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:08:06,162 saving best model\n",
            "2022-12-12 00:08:08,904 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:08:12,408 epoch 7 - iter 24/245 - loss 0.06820545 - samples/sec: 220.49 - lr: 0.100000\n",
            "2022-12-12 00:08:16,281 epoch 7 - iter 48/245 - loss 0.06997260 - samples/sec: 198.53 - lr: 0.100000\n",
            "2022-12-12 00:08:19,718 epoch 7 - iter 72/245 - loss 0.06759878 - samples/sec: 223.68 - lr: 0.100000\n",
            "2022-12-12 00:08:23,537 epoch 7 - iter 96/245 - loss 0.06902120 - samples/sec: 201.34 - lr: 0.100000\n",
            "2022-12-12 00:08:27,372 epoch 7 - iter 120/245 - loss 0.07283041 - samples/sec: 200.48 - lr: 0.100000\n",
            "2022-12-12 00:08:31,420 epoch 7 - iter 144/245 - loss 0.07190493 - samples/sec: 189.91 - lr: 0.100000\n",
            "2022-12-12 00:08:34,750 epoch 7 - iter 168/245 - loss 0.07191624 - samples/sec: 230.88 - lr: 0.100000\n",
            "2022-12-12 00:08:38,812 epoch 7 - iter 192/245 - loss 0.07232403 - samples/sec: 189.24 - lr: 0.100000\n",
            "2022-12-12 00:08:43,402 epoch 7 - iter 216/245 - loss 0.07222374 - samples/sec: 167.47 - lr: 0.100000\n",
            "2022-12-12 00:08:47,284 epoch 7 - iter 240/245 - loss 0.07146206 - samples/sec: 198.06 - lr: 0.100000\n",
            "2022-12-12 00:08:47,824 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:08:47,826 EPOCH 7 done: loss 0.0715 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:08:55,060 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:08:55,080 DEV : loss 0.08396030217409134 - f1-score (micro avg)  0.6781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:08:55,164 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:08:55,166 saving best model\n",
            "2022-12-12 00:08:57,887 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:09:01,150 epoch 8 - iter 24/245 - loss 0.07088550 - samples/sec: 236.64 - lr: 0.100000\n",
            "2022-12-12 00:09:05,236 epoch 8 - iter 48/245 - loss 0.06677235 - samples/sec: 188.16 - lr: 0.100000\n",
            "2022-12-12 00:09:09,372 epoch 8 - iter 72/245 - loss 0.06364550 - samples/sec: 185.87 - lr: 0.100000\n",
            "2022-12-12 00:09:13,819 epoch 8 - iter 96/245 - loss 0.06406538 - samples/sec: 172.86 - lr: 0.100000\n",
            "2022-12-12 00:09:17,073 epoch 8 - iter 120/245 - loss 0.06413275 - samples/sec: 236.30 - lr: 0.100000\n",
            "2022-12-12 00:09:21,464 epoch 8 - iter 144/245 - loss 0.06318637 - samples/sec: 175.07 - lr: 0.100000\n",
            "2022-12-12 00:09:25,492 epoch 8 - iter 168/245 - loss 0.06405435 - samples/sec: 190.87 - lr: 0.100000\n",
            "2022-12-12 00:09:28,875 epoch 8 - iter 192/245 - loss 0.06513528 - samples/sec: 227.28 - lr: 0.100000\n",
            "2022-12-12 00:09:32,473 epoch 8 - iter 216/245 - loss 0.06550220 - samples/sec: 213.71 - lr: 0.100000\n",
            "2022-12-12 00:09:35,872 epoch 8 - iter 240/245 - loss 0.06479585 - samples/sec: 226.18 - lr: 0.100000\n",
            "2022-12-12 00:09:36,392 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:09:36,393 EPOCH 8 done: loss 0.0651 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:09:44,385 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:09:44,406 DEV : loss 0.0750160664319992 - f1-score (micro avg)  0.7149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:09:44,493 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:09:44,495 saving best model\n",
            "2022-12-12 00:09:47,284 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:09:51,400 epoch 9 - iter 24/245 - loss 0.06027273 - samples/sec: 187.70 - lr: 0.100000\n",
            "2022-12-12 00:09:55,108 epoch 9 - iter 48/245 - loss 0.06026652 - samples/sec: 207.36 - lr: 0.100000\n",
            "2022-12-12 00:09:58,337 epoch 9 - iter 72/245 - loss 0.05974409 - samples/sec: 238.14 - lr: 0.100000\n",
            "2022-12-12 00:10:02,219 epoch 9 - iter 96/245 - loss 0.06023450 - samples/sec: 198.07 - lr: 0.100000\n",
            "2022-12-12 00:10:05,453 epoch 9 - iter 120/245 - loss 0.06163003 - samples/sec: 237.70 - lr: 0.100000\n",
            "2022-12-12 00:10:10,414 epoch 9 - iter 144/245 - loss 0.06431734 - samples/sec: 154.97 - lr: 0.100000\n",
            "2022-12-12 00:10:14,539 epoch 9 - iter 168/245 - loss 0.06415749 - samples/sec: 186.34 - lr: 0.100000\n",
            "2022-12-12 00:10:17,825 epoch 9 - iter 192/245 - loss 0.06332840 - samples/sec: 233.99 - lr: 0.100000\n",
            "2022-12-12 00:10:21,965 epoch 9 - iter 216/245 - loss 0.06348707 - samples/sec: 185.68 - lr: 0.100000\n",
            "2022-12-12 00:10:25,092 epoch 9 - iter 240/245 - loss 0.06260107 - samples/sec: 245.95 - lr: 0.100000\n",
            "2022-12-12 00:10:25,885 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:10:25,887 EPOCH 9 done: loss 0.0626 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:10:33,251 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:10:33,274 DEV : loss 0.07586988061666489 - f1-score (micro avg)  0.7015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:10:33,361 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 00:10:33,364 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:10:36,517 epoch 10 - iter 24/245 - loss 0.05059169 - samples/sec: 244.05 - lr: 0.100000\n",
            "2022-12-12 00:10:39,892 epoch 10 - iter 48/245 - loss 0.05400193 - samples/sec: 227.85 - lr: 0.100000\n",
            "2022-12-12 00:10:43,450 epoch 10 - iter 72/245 - loss 0.05778809 - samples/sec: 216.11 - lr: 0.100000\n",
            "2022-12-12 00:10:47,192 epoch 10 - iter 96/245 - loss 0.05886440 - samples/sec: 205.53 - lr: 0.100000\n",
            "2022-12-12 00:10:51,139 epoch 10 - iter 120/245 - loss 0.05718147 - samples/sec: 194.80 - lr: 0.100000\n",
            "2022-12-12 00:10:55,256 epoch 10 - iter 144/245 - loss 0.06050747 - samples/sec: 186.71 - lr: 0.100000\n",
            "2022-12-12 00:11:00,465 epoch 10 - iter 168/245 - loss 0.05913320 - samples/sec: 147.57 - lr: 0.100000\n",
            "2022-12-12 00:11:04,330 epoch 10 - iter 192/245 - loss 0.05906193 - samples/sec: 198.85 - lr: 0.100000\n",
            "2022-12-12 00:11:08,850 epoch 10 - iter 216/245 - loss 0.05843010 - samples/sec: 170.09 - lr: 0.100000\n",
            "2022-12-12 00:11:12,001 epoch 10 - iter 240/245 - loss 0.05779645 - samples/sec: 244.06 - lr: 0.100000\n",
            "2022-12-12 00:11:12,538 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:11:12,540 EPOCH 10 done: loss 0.0578 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:11:19,900 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:11:19,921 DEV : loss 0.0714409276843071 - f1-score (micro avg)  0.7322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:11:20,006 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:11:20,008 saving best model\n",
            "2022-12-12 00:11:22,882 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:11:26,425 epoch 11 - iter 24/245 - loss 0.04951035 - samples/sec: 217.16 - lr: 0.100000\n",
            "2022-12-12 00:11:29,933 epoch 11 - iter 48/245 - loss 0.05543702 - samples/sec: 219.17 - lr: 0.100000\n",
            "2022-12-12 00:11:33,674 epoch 11 - iter 72/245 - loss 0.05252121 - samples/sec: 205.49 - lr: 0.100000\n",
            "2022-12-12 00:11:37,159 epoch 11 - iter 96/245 - loss 0.05369661 - samples/sec: 220.65 - lr: 0.100000\n",
            "2022-12-12 00:11:40,053 epoch 11 - iter 120/245 - loss 0.05412239 - samples/sec: 265.72 - lr: 0.100000\n",
            "2022-12-12 00:11:43,767 epoch 11 - iter 144/245 - loss 0.05243791 - samples/sec: 206.98 - lr: 0.100000\n",
            "2022-12-12 00:11:48,419 epoch 11 - iter 168/245 - loss 0.05275741 - samples/sec: 165.25 - lr: 0.100000\n",
            "2022-12-12 00:11:52,978 epoch 11 - iter 192/245 - loss 0.05357039 - samples/sec: 168.59 - lr: 0.100000\n",
            "2022-12-12 00:11:57,854 epoch 11 - iter 216/245 - loss 0.05407079 - samples/sec: 157.65 - lr: 0.100000\n",
            "2022-12-12 00:12:00,851 epoch 11 - iter 240/245 - loss 0.05382281 - samples/sec: 256.59 - lr: 0.100000\n",
            "2022-12-12 00:12:01,404 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:12:01,406 EPOCH 11 done: loss 0.0538 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:12:09,541 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:12:09,562 DEV : loss 0.06436680257320404 - f1-score (micro avg)  0.7623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:12:09,645 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:12:09,647 saving best model\n",
            "2022-12-12 00:12:12,490 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:12:15,536 epoch 12 - iter 24/245 - loss 0.05081558 - samples/sec: 252.88 - lr: 0.100000\n",
            "2022-12-12 00:12:19,518 epoch 12 - iter 48/245 - loss 0.04639467 - samples/sec: 193.07 - lr: 0.100000\n",
            "2022-12-12 00:12:23,739 epoch 12 - iter 72/245 - loss 0.04612579 - samples/sec: 182.12 - lr: 0.100000\n",
            "2022-12-12 00:12:28,754 epoch 12 - iter 96/245 - loss 0.05033583 - samples/sec: 153.26 - lr: 0.100000\n",
            "2022-12-12 00:12:31,699 epoch 12 - iter 120/245 - loss 0.05151383 - samples/sec: 261.09 - lr: 0.100000\n",
            "2022-12-12 00:12:35,300 epoch 12 - iter 144/245 - loss 0.05139241 - samples/sec: 213.55 - lr: 0.100000\n",
            "2022-12-12 00:12:39,366 epoch 12 - iter 168/245 - loss 0.05280428 - samples/sec: 189.10 - lr: 0.100000\n",
            "2022-12-12 00:12:42,916 epoch 12 - iter 192/245 - loss 0.05322270 - samples/sec: 216.57 - lr: 0.100000\n",
            "2022-12-12 00:12:46,318 epoch 12 - iter 216/245 - loss 0.05360121 - samples/sec: 226.02 - lr: 0.100000\n",
            "2022-12-12 00:12:50,312 epoch 12 - iter 240/245 - loss 0.05286224 - samples/sec: 192.49 - lr: 0.100000\n",
            "2022-12-12 00:12:50,999 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:12:51,001 EPOCH 12 done: loss 0.0529 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:12:58,325 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:12:58,347 DEV : loss 0.06989233940839767 - f1-score (micro avg)  0.7377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:12:58,444 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 00:12:58,446 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:13:02,709 epoch 13 - iter 24/245 - loss 0.05501558 - samples/sec: 180.39 - lr: 0.100000\n",
            "2022-12-12 00:13:05,744 epoch 13 - iter 48/245 - loss 0.05742985 - samples/sec: 253.36 - lr: 0.100000\n",
            "2022-12-12 00:13:08,919 epoch 13 - iter 72/245 - loss 0.05441051 - samples/sec: 242.15 - lr: 0.100000\n",
            "2022-12-12 00:13:12,688 epoch 13 - iter 96/245 - loss 0.05155758 - samples/sec: 203.95 - lr: 0.100000\n",
            "2022-12-12 00:13:15,953 epoch 13 - iter 120/245 - loss 0.05040607 - samples/sec: 235.53 - lr: 0.100000\n",
            "2022-12-12 00:13:20,044 epoch 13 - iter 144/245 - loss 0.05013262 - samples/sec: 187.93 - lr: 0.100000\n",
            "2022-12-12 00:13:23,757 epoch 13 - iter 168/245 - loss 0.04962759 - samples/sec: 207.10 - lr: 0.100000\n",
            "2022-12-12 00:13:28,452 epoch 13 - iter 192/245 - loss 0.04950799 - samples/sec: 163.70 - lr: 0.100000\n",
            "2022-12-12 00:13:33,104 epoch 13 - iter 216/245 - loss 0.04972179 - samples/sec: 165.23 - lr: 0.100000\n",
            "2022-12-12 00:13:36,672 epoch 13 - iter 240/245 - loss 0.04947844 - samples/sec: 215.54 - lr: 0.100000\n",
            "2022-12-12 00:13:37,274 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:13:37,275 EPOCH 13 done: loss 0.0496 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:13:45,302 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:13:45,322 DEV : loss 0.0637994259595871 - f1-score (micro avg)  0.7336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:13:45,406 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 00:13:45,407 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:13:49,338 epoch 14 - iter 24/245 - loss 0.05102853 - samples/sec: 195.64 - lr: 0.100000\n",
            "2022-12-12 00:13:53,874 epoch 14 - iter 48/245 - loss 0.04761547 - samples/sec: 169.46 - lr: 0.100000\n",
            "2022-12-12 00:13:57,333 epoch 14 - iter 72/245 - loss 0.04798379 - samples/sec: 222.26 - lr: 0.100000\n",
            "2022-12-12 00:14:00,692 epoch 14 - iter 96/245 - loss 0.04870307 - samples/sec: 228.97 - lr: 0.100000\n",
            "2022-12-12 00:14:04,417 epoch 14 - iter 120/245 - loss 0.04901188 - samples/sec: 206.41 - lr: 0.100000\n",
            "2022-12-12 00:14:07,517 epoch 14 - iter 144/245 - loss 0.04770171 - samples/sec: 248.07 - lr: 0.100000\n",
            "2022-12-12 00:14:11,042 epoch 14 - iter 168/245 - loss 0.04795038 - samples/sec: 218.17 - lr: 0.100000\n",
            "2022-12-12 00:14:14,632 epoch 14 - iter 192/245 - loss 0.04828727 - samples/sec: 214.20 - lr: 0.100000\n",
            "2022-12-12 00:14:18,240 epoch 14 - iter 216/245 - loss 0.04822152 - samples/sec: 213.08 - lr: 0.100000\n",
            "2022-12-12 00:14:23,168 epoch 14 - iter 240/245 - loss 0.04790802 - samples/sec: 155.99 - lr: 0.100000\n",
            "2022-12-12 00:14:23,767 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:14:23,769 EPOCH 14 done: loss 0.0480 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:14:31,062 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:14:31,082 DEV : loss 0.06944262236356735 - f1-score (micro avg)  0.7472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:14:31,164 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 00:14:31,166 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:14:35,317 epoch 15 - iter 24/245 - loss 0.05003095 - samples/sec: 185.21 - lr: 0.100000\n",
            "2022-12-12 00:14:39,046 epoch 15 - iter 48/245 - loss 0.04653491 - samples/sec: 206.17 - lr: 0.100000\n",
            "2022-12-12 00:14:42,525 epoch 15 - iter 72/245 - loss 0.04720241 - samples/sec: 220.97 - lr: 0.100000\n",
            "2022-12-12 00:14:46,276 epoch 15 - iter 96/245 - loss 0.04636203 - samples/sec: 204.98 - lr: 0.100000\n",
            "2022-12-12 00:14:50,370 epoch 15 - iter 120/245 - loss 0.04724298 - samples/sec: 187.80 - lr: 0.100000\n",
            "2022-12-12 00:14:54,117 epoch 15 - iter 144/245 - loss 0.04738967 - samples/sec: 205.18 - lr: 0.100000\n",
            "2022-12-12 00:14:57,395 epoch 15 - iter 168/245 - loss 0.04731568 - samples/sec: 234.61 - lr: 0.100000\n",
            "2022-12-12 00:15:01,566 epoch 15 - iter 192/245 - loss 0.04718094 - samples/sec: 184.31 - lr: 0.100000\n",
            "2022-12-12 00:15:05,060 epoch 15 - iter 216/245 - loss 0.04737644 - samples/sec: 220.04 - lr: 0.100000\n",
            "2022-12-12 00:15:08,234 epoch 15 - iter 240/245 - loss 0.04692633 - samples/sec: 242.31 - lr: 0.100000\n",
            "2022-12-12 00:15:09,198 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:15:09,200 EPOCH 15 done: loss 0.0470 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:15:17,178 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:15:17,198 DEV : loss 0.075251005589962 - f1-score (micro avg)  0.7271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:15:17,280 Epoch    15: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2022-12-12 00:15:17,281 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 00:15:17,286 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:15:20,419 epoch 16 - iter 24/245 - loss 0.03592490 - samples/sec: 245.47 - lr: 0.050000\n",
            "2022-12-12 00:15:23,900 epoch 16 - iter 48/245 - loss 0.03698879 - samples/sec: 220.89 - lr: 0.050000\n",
            "2022-12-12 00:15:28,288 epoch 16 - iter 72/245 - loss 0.03669612 - samples/sec: 175.16 - lr: 0.050000\n",
            "2022-12-12 00:15:31,390 epoch 16 - iter 96/245 - loss 0.03703881 - samples/sec: 247.96 - lr: 0.050000\n",
            "2022-12-12 00:15:35,365 epoch 16 - iter 120/245 - loss 0.03755946 - samples/sec: 193.37 - lr: 0.050000\n",
            "2022-12-12 00:15:38,679 epoch 16 - iter 144/245 - loss 0.03805249 - samples/sec: 232.07 - lr: 0.050000\n",
            "2022-12-12 00:15:42,353 epoch 16 - iter 168/245 - loss 0.03926307 - samples/sec: 209.27 - lr: 0.050000\n",
            "2022-12-12 00:15:46,636 epoch 16 - iter 192/245 - loss 0.03885429 - samples/sec: 179.50 - lr: 0.050000\n",
            "2022-12-12 00:15:51,587 epoch 16 - iter 216/245 - loss 0.03951558 - samples/sec: 155.25 - lr: 0.050000\n",
            "2022-12-12 00:15:54,468 epoch 16 - iter 240/245 - loss 0.03995792 - samples/sec: 266.90 - lr: 0.050000\n",
            "2022-12-12 00:15:55,638 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:15:55,639 EPOCH 16 done: loss 0.0398 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:16:03,796 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:16:03,819 DEV : loss 0.06169668585062027 - f1-score (micro avg)  0.7724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:16:03,906 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:16:03,908 saving best model\n",
            "2022-12-12 00:16:06,615 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:16:10,188 epoch 17 - iter 24/245 - loss 0.04317580 - samples/sec: 215.34 - lr: 0.050000\n",
            "2022-12-12 00:16:13,761 epoch 17 - iter 48/245 - loss 0.04020211 - samples/sec: 215.14 - lr: 0.050000\n",
            "2022-12-12 00:16:18,305 epoch 17 - iter 72/245 - loss 0.04017417 - samples/sec: 169.17 - lr: 0.050000\n",
            "2022-12-12 00:16:22,441 epoch 17 - iter 96/245 - loss 0.03800439 - samples/sec: 185.90 - lr: 0.050000\n",
            "2022-12-12 00:16:25,589 epoch 17 - iter 120/245 - loss 0.03761091 - samples/sec: 244.28 - lr: 0.050000\n",
            "2022-12-12 00:16:28,958 epoch 17 - iter 144/245 - loss 0.03804841 - samples/sec: 228.22 - lr: 0.050000\n",
            "2022-12-12 00:16:32,522 epoch 17 - iter 168/245 - loss 0.03836792 - samples/sec: 215.74 - lr: 0.050000\n",
            "2022-12-12 00:16:35,912 epoch 17 - iter 192/245 - loss 0.03863941 - samples/sec: 226.81 - lr: 0.050000\n",
            "2022-12-12 00:16:40,472 epoch 17 - iter 216/245 - loss 0.03912518 - samples/sec: 168.55 - lr: 0.050000\n",
            "2022-12-12 00:16:44,251 epoch 17 - iter 240/245 - loss 0.03864425 - samples/sec: 203.43 - lr: 0.050000\n",
            "2022-12-12 00:16:45,097 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:16:45,099 EPOCH 17 done: loss 0.0390 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:16:52,475 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:16:52,499 DEV : loss 0.05496588721871376 - f1-score (micro avg)  0.7981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:16:52,587 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:16:52,589 saving best model\n",
            "2022-12-12 00:16:55,338 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:16:59,288 epoch 18 - iter 24/245 - loss 0.04294363 - samples/sec: 195.61 - lr: 0.050000\n",
            "2022-12-12 00:17:02,716 epoch 18 - iter 48/245 - loss 0.04090553 - samples/sec: 224.31 - lr: 0.050000\n",
            "2022-12-12 00:17:08,282 epoch 18 - iter 72/245 - loss 0.03837357 - samples/sec: 138.10 - lr: 0.050000\n",
            "2022-12-12 00:17:11,341 epoch 18 - iter 96/245 - loss 0.03797434 - samples/sec: 251.37 - lr: 0.050000\n",
            "2022-12-12 00:17:15,249 epoch 18 - iter 120/245 - loss 0.03818410 - samples/sec: 196.70 - lr: 0.050000\n",
            "2022-12-12 00:17:18,933 epoch 18 - iter 144/245 - loss 0.03748600 - samples/sec: 208.73 - lr: 0.050000\n",
            "2022-12-12 00:17:22,150 epoch 18 - iter 168/245 - loss 0.03723495 - samples/sec: 239.03 - lr: 0.050000\n",
            "2022-12-12 00:17:25,378 epoch 18 - iter 192/245 - loss 0.03744052 - samples/sec: 238.13 - lr: 0.050000\n",
            "2022-12-12 00:17:29,630 epoch 18 - iter 216/245 - loss 0.03742905 - samples/sec: 180.82 - lr: 0.050000\n",
            "2022-12-12 00:17:33,195 epoch 18 - iter 240/245 - loss 0.03751933 - samples/sec: 215.67 - lr: 0.050000\n",
            "2022-12-12 00:17:33,681 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:17:33,683 EPOCH 18 done: loss 0.0374 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:17:41,753 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:17:41,775 DEV : loss 0.05796543508768082 - f1-score (micro avg)  0.7874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:17:41,865 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 00:17:41,868 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:17:45,497 epoch 19 - iter 24/245 - loss 0.03614377 - samples/sec: 212.10 - lr: 0.050000\n",
            "2022-12-12 00:17:49,167 epoch 19 - iter 48/245 - loss 0.03512100 - samples/sec: 209.53 - lr: 0.050000\n",
            "2022-12-12 00:17:53,374 epoch 19 - iter 72/245 - loss 0.03422527 - samples/sec: 182.71 - lr: 0.050000\n",
            "2022-12-12 00:17:56,954 epoch 19 - iter 96/245 - loss 0.03368849 - samples/sec: 214.81 - lr: 0.050000\n",
            "2022-12-12 00:18:01,248 epoch 19 - iter 120/245 - loss 0.03495017 - samples/sec: 178.99 - lr: 0.050000\n",
            "2022-12-12 00:18:03,847 epoch 19 - iter 144/245 - loss 0.03527527 - samples/sec: 295.98 - lr: 0.050000\n",
            "2022-12-12 00:18:08,695 epoch 19 - iter 168/245 - loss 0.03620585 - samples/sec: 158.54 - lr: 0.050000\n",
            "2022-12-12 00:18:12,382 epoch 19 - iter 192/245 - loss 0.03559307 - samples/sec: 208.51 - lr: 0.050000\n",
            "2022-12-12 00:18:15,521 epoch 19 - iter 216/245 - loss 0.03615529 - samples/sec: 245.01 - lr: 0.050000\n",
            "2022-12-12 00:18:19,600 epoch 19 - iter 240/245 - loss 0.03633015 - samples/sec: 188.47 - lr: 0.050000\n",
            "2022-12-12 00:18:20,515 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:18:20,517 EPOCH 19 done: loss 0.0361 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:18:27,901 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:18:27,922 DEV : loss 0.058128539472818375 - f1-score (micro avg)  0.7912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:18:28,007 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 00:18:28,010 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:18:31,817 epoch 20 - iter 24/245 - loss 0.03813562 - samples/sec: 202.02 - lr: 0.050000\n",
            "2022-12-12 00:18:37,863 epoch 20 - iter 48/245 - loss 0.03679526 - samples/sec: 127.10 - lr: 0.050000\n",
            "2022-12-12 00:18:41,554 epoch 20 - iter 72/245 - loss 0.03644457 - samples/sec: 208.35 - lr: 0.050000\n",
            "2022-12-12 00:18:44,802 epoch 20 - iter 96/245 - loss 0.03773249 - samples/sec: 236.68 - lr: 0.050000\n",
            "2022-12-12 00:18:47,997 epoch 20 - iter 120/245 - loss 0.03697183 - samples/sec: 240.73 - lr: 0.050000\n",
            "2022-12-12 00:18:51,452 epoch 20 - iter 144/245 - loss 0.03659627 - samples/sec: 222.54 - lr: 0.050000\n",
            "2022-12-12 00:18:54,856 epoch 20 - iter 168/245 - loss 0.03615226 - samples/sec: 225.91 - lr: 0.050000\n",
            "2022-12-12 00:18:58,040 epoch 20 - iter 192/245 - loss 0.03558518 - samples/sec: 241.49 - lr: 0.050000\n",
            "2022-12-12 00:19:01,679 epoch 20 - iter 216/245 - loss 0.03561232 - samples/sec: 211.31 - lr: 0.050000\n",
            "2022-12-12 00:19:05,243 epoch 20 - iter 240/245 - loss 0.03543068 - samples/sec: 215.76 - lr: 0.050000\n",
            "2022-12-12 00:19:05,790 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:19:05,792 EPOCH 20 done: loss 0.0354 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:19:13,881 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:19:13,903 DEV : loss 0.05565234646201134 - f1-score (micro avg)  0.7877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:19:13,993 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 00:19:13,996 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:19:17,321 epoch 21 - iter 24/245 - loss 0.03648111 - samples/sec: 231.43 - lr: 0.050000\n",
            "2022-12-12 00:19:20,321 epoch 21 - iter 48/245 - loss 0.03576872 - samples/sec: 256.27 - lr: 0.050000\n",
            "2022-12-12 00:19:23,200 epoch 21 - iter 72/245 - loss 0.03668871 - samples/sec: 267.13 - lr: 0.050000\n",
            "2022-12-12 00:19:28,705 epoch 21 - iter 96/245 - loss 0.03603880 - samples/sec: 139.62 - lr: 0.050000\n",
            "2022-12-12 00:19:31,670 epoch 21 - iter 120/245 - loss 0.03539313 - samples/sec: 259.28 - lr: 0.050000\n",
            "2022-12-12 00:19:35,026 epoch 21 - iter 144/245 - loss 0.03560013 - samples/sec: 229.14 - lr: 0.050000\n",
            "2022-12-12 00:19:39,503 epoch 21 - iter 168/245 - loss 0.03500558 - samples/sec: 171.68 - lr: 0.050000\n",
            "2022-12-12 00:19:43,229 epoch 21 - iter 192/245 - loss 0.03490618 - samples/sec: 206.34 - lr: 0.050000\n",
            "2022-12-12 00:19:47,071 epoch 21 - iter 216/245 - loss 0.03510189 - samples/sec: 200.11 - lr: 0.050000\n",
            "2022-12-12 00:19:51,425 epoch 21 - iter 240/245 - loss 0.03474712 - samples/sec: 176.56 - lr: 0.050000\n",
            "2022-12-12 00:19:51,935 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:19:51,937 EPOCH 21 done: loss 0.0348 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:19:59,294 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:19:59,315 DEV : loss 0.05434331297874451 - f1-score (micro avg)  0.7924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:19:59,399 Epoch    21: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2022-12-12 00:19:59,401 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 00:19:59,405 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:20:03,767 epoch 22 - iter 24/245 - loss 0.02951122 - samples/sec: 176.29 - lr: 0.025000\n",
            "2022-12-12 00:20:07,912 epoch 22 - iter 48/245 - loss 0.03023044 - samples/sec: 185.46 - lr: 0.025000\n",
            "2022-12-12 00:20:13,525 epoch 22 - iter 72/245 - loss 0.03334559 - samples/sec: 136.92 - lr: 0.025000\n",
            "2022-12-12 00:20:17,256 epoch 22 - iter 96/245 - loss 0.03223842 - samples/sec: 206.05 - lr: 0.025000\n",
            "2022-12-12 00:20:20,553 epoch 22 - iter 120/245 - loss 0.03152971 - samples/sec: 233.29 - lr: 0.025000\n",
            "2022-12-12 00:20:24,072 epoch 22 - iter 144/245 - loss 0.03137732 - samples/sec: 218.55 - lr: 0.025000\n",
            "2022-12-12 00:20:27,465 epoch 22 - iter 168/245 - loss 0.03190462 - samples/sec: 226.60 - lr: 0.025000\n",
            "2022-12-12 00:20:30,460 epoch 22 - iter 192/245 - loss 0.03216998 - samples/sec: 256.74 - lr: 0.025000\n",
            "2022-12-12 00:20:33,427 epoch 22 - iter 216/245 - loss 0.03191814 - samples/sec: 259.24 - lr: 0.025000\n",
            "2022-12-12 00:20:37,715 epoch 22 - iter 240/245 - loss 0.03155608 - samples/sec: 179.28 - lr: 0.025000\n",
            "2022-12-12 00:20:38,489 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:20:38,490 EPOCH 22 done: loss 0.0315 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:20:45,822 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:20:45,842 DEV : loss 0.05765221640467644 - f1-score (micro avg)  0.7894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:20:45,925 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 00:20:45,927 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:20:49,383 epoch 23 - iter 24/245 - loss 0.03350781 - samples/sec: 222.56 - lr: 0.025000\n",
            "2022-12-12 00:20:54,494 epoch 23 - iter 48/245 - loss 0.03703544 - samples/sec: 150.38 - lr: 0.025000\n",
            "2022-12-12 00:20:57,443 epoch 23 - iter 72/245 - loss 0.03414646 - samples/sec: 260.81 - lr: 0.025000\n",
            "2022-12-12 00:21:00,600 epoch 23 - iter 96/245 - loss 0.03261156 - samples/sec: 243.54 - lr: 0.025000\n",
            "2022-12-12 00:21:04,283 epoch 23 - iter 120/245 - loss 0.03175288 - samples/sec: 208.74 - lr: 0.025000\n",
            "2022-12-12 00:21:08,424 epoch 23 - iter 144/245 - loss 0.03250808 - samples/sec: 185.67 - lr: 0.025000\n",
            "2022-12-12 00:21:13,620 epoch 23 - iter 168/245 - loss 0.03235882 - samples/sec: 147.94 - lr: 0.025000\n",
            "2022-12-12 00:21:16,459 epoch 23 - iter 192/245 - loss 0.03204140 - samples/sec: 270.91 - lr: 0.025000\n",
            "2022-12-12 00:21:19,884 epoch 23 - iter 216/245 - loss 0.03150372 - samples/sec: 224.49 - lr: 0.025000\n",
            "2022-12-12 00:21:23,397 epoch 23 - iter 240/245 - loss 0.03136398 - samples/sec: 218.89 - lr: 0.025000\n",
            "2022-12-12 00:21:24,215 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:21:24,217 EPOCH 23 done: loss 0.0312 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:21:32,260 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:21:32,281 DEV : loss 0.05738389119505882 - f1-score (micro avg)  0.7911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:21:32,366 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 00:21:32,368 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:21:35,772 epoch 24 - iter 24/245 - loss 0.02879268 - samples/sec: 225.97 - lr: 0.025000\n",
            "2022-12-12 00:21:39,855 epoch 24 - iter 48/245 - loss 0.03036666 - samples/sec: 188.25 - lr: 0.025000\n",
            "2022-12-12 00:21:43,456 epoch 24 - iter 72/245 - loss 0.03021611 - samples/sec: 213.49 - lr: 0.025000\n",
            "2022-12-12 00:21:47,813 epoch 24 - iter 96/245 - loss 0.02964171 - samples/sec: 176.43 - lr: 0.025000\n",
            "2022-12-12 00:21:51,353 epoch 24 - iter 120/245 - loss 0.02934928 - samples/sec: 217.24 - lr: 0.025000\n",
            "2022-12-12 00:21:54,260 epoch 24 - iter 144/245 - loss 0.02889815 - samples/sec: 264.58 - lr: 0.025000\n",
            "2022-12-12 00:21:57,360 epoch 24 - iter 168/245 - loss 0.02964090 - samples/sec: 248.04 - lr: 0.025000\n",
            "2022-12-12 00:22:02,132 epoch 24 - iter 192/245 - loss 0.03042136 - samples/sec: 161.08 - lr: 0.025000\n",
            "2022-12-12 00:22:06,220 epoch 24 - iter 216/245 - loss 0.03029190 - samples/sec: 188.06 - lr: 0.025000\n",
            "2022-12-12 00:22:10,057 epoch 24 - iter 240/245 - loss 0.03102011 - samples/sec: 200.34 - lr: 0.025000\n",
            "2022-12-12 00:22:10,674 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:22:10,676 EPOCH 24 done: loss 0.0310 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:22:18,030 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:22:18,051 DEV : loss 0.055567171424627304 - f1-score (micro avg)  0.7792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:22:18,135 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 00:22:18,137 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:22:21,690 epoch 25 - iter 24/245 - loss 0.03248474 - samples/sec: 216.44 - lr: 0.025000\n",
            "2022-12-12 00:22:25,424 epoch 25 - iter 48/245 - loss 0.02903011 - samples/sec: 205.91 - lr: 0.025000\n",
            "2022-12-12 00:22:29,098 epoch 25 - iter 72/245 - loss 0.03029577 - samples/sec: 209.25 - lr: 0.025000\n",
            "2022-12-12 00:22:32,453 epoch 25 - iter 96/245 - loss 0.02966817 - samples/sec: 229.17 - lr: 0.025000\n",
            "2022-12-12 00:22:36,011 epoch 25 - iter 120/245 - loss 0.02929285 - samples/sec: 216.11 - lr: 0.025000\n",
            "2022-12-12 00:22:39,047 epoch 25 - iter 144/245 - loss 0.02956586 - samples/sec: 253.33 - lr: 0.025000\n",
            "2022-12-12 00:22:42,349 epoch 25 - iter 168/245 - loss 0.02943033 - samples/sec: 232.86 - lr: 0.025000\n",
            "2022-12-12 00:22:47,140 epoch 25 - iter 192/245 - loss 0.03062265 - samples/sec: 160.45 - lr: 0.025000\n",
            "2022-12-12 00:22:51,063 epoch 25 - iter 216/245 - loss 0.03051490 - samples/sec: 196.00 - lr: 0.025000\n",
            "2022-12-12 00:22:55,147 epoch 25 - iter 240/245 - loss 0.03084289 - samples/sec: 188.21 - lr: 0.025000\n",
            "2022-12-12 00:22:56,149 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:22:56,151 EPOCH 25 done: loss 0.0308 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:23:04,092 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:23:04,113 DEV : loss 0.05524937063455582 - f1-score (micro avg)  0.792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:23:04,198 Epoch    25: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2022-12-12 00:23:04,198 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 00:23:04,200 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:23:08,440 epoch 26 - iter 24/245 - loss 0.02685290 - samples/sec: 181.41 - lr: 0.012500\n",
            "2022-12-12 00:23:12,737 epoch 26 - iter 48/245 - loss 0.03149097 - samples/sec: 178.93 - lr: 0.012500\n",
            "2022-12-12 00:23:16,667 epoch 26 - iter 72/245 - loss 0.03166157 - samples/sec: 195.63 - lr: 0.012500\n",
            "2022-12-12 00:23:19,710 epoch 26 - iter 96/245 - loss 0.03117864 - samples/sec: 252.65 - lr: 0.012500\n",
            "2022-12-12 00:23:24,523 epoch 26 - iter 120/245 - loss 0.03117928 - samples/sec: 159.72 - lr: 0.012500\n",
            "2022-12-12 00:23:28,308 epoch 26 - iter 144/245 - loss 0.03076256 - samples/sec: 203.09 - lr: 0.012500\n",
            "2022-12-12 00:23:31,887 epoch 26 - iter 168/245 - loss 0.03015995 - samples/sec: 214.87 - lr: 0.012500\n",
            "2022-12-12 00:23:34,573 epoch 26 - iter 192/245 - loss 0.02997391 - samples/sec: 286.34 - lr: 0.012500\n",
            "2022-12-12 00:23:38,025 epoch 26 - iter 216/245 - loss 0.02969949 - samples/sec: 222.71 - lr: 0.012500\n",
            "2022-12-12 00:23:41,435 epoch 26 - iter 240/245 - loss 0.02979783 - samples/sec: 225.52 - lr: 0.012500\n",
            "2022-12-12 00:23:42,567 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:23:42,568 EPOCH 26 done: loss 0.0298 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:23:49,862 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:23:49,883 DEV : loss 0.05366700515151024 - f1-score (micro avg)  0.7997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:23:49,966 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:23:49,968 saving best model\n",
            "2022-12-12 00:23:52,775 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:23:56,274 epoch 27 - iter 24/245 - loss 0.02979833 - samples/sec: 219.88 - lr: 0.012500\n",
            "2022-12-12 00:23:59,575 epoch 27 - iter 48/245 - loss 0.02764379 - samples/sec: 232.90 - lr: 0.012500\n",
            "2022-12-12 00:24:02,810 epoch 27 - iter 72/245 - loss 0.02808562 - samples/sec: 237.78 - lr: 0.012500\n",
            "2022-12-12 00:24:06,077 epoch 27 - iter 96/245 - loss 0.02759860 - samples/sec: 235.39 - lr: 0.012500\n",
            "2022-12-12 00:24:10,789 epoch 27 - iter 120/245 - loss 0.02778734 - samples/sec: 163.14 - lr: 0.012500\n",
            "2022-12-12 00:24:15,309 epoch 27 - iter 144/245 - loss 0.02916735 - samples/sec: 170.07 - lr: 0.012500\n",
            "2022-12-12 00:24:20,572 epoch 27 - iter 168/245 - loss 0.02887917 - samples/sec: 146.03 - lr: 0.012500\n",
            "2022-12-12 00:24:24,200 epoch 27 - iter 192/245 - loss 0.02884586 - samples/sec: 211.90 - lr: 0.012500\n",
            "2022-12-12 00:24:27,655 epoch 27 - iter 216/245 - loss 0.02888007 - samples/sec: 222.55 - lr: 0.012500\n",
            "2022-12-12 00:24:31,564 epoch 27 - iter 240/245 - loss 0.02920564 - samples/sec: 196.65 - lr: 0.012500\n",
            "2022-12-12 00:24:32,097 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:24:32,099 EPOCH 27 done: loss 0.0292 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:24:39,552 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:24:39,574 DEV : loss 0.05467750132083893 - f1-score (micro avg)  0.7953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:24:39,658 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 00:24:39,660 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:24:43,205 epoch 28 - iter 24/245 - loss 0.02774837 - samples/sec: 216.95 - lr: 0.012500\n",
            "2022-12-12 00:24:46,299 epoch 28 - iter 48/245 - loss 0.02861203 - samples/sec: 248.54 - lr: 0.012500\n",
            "2022-12-12 00:24:50,166 epoch 28 - iter 72/245 - loss 0.02785741 - samples/sec: 198.81 - lr: 0.012500\n",
            "2022-12-12 00:24:54,033 epoch 28 - iter 96/245 - loss 0.02745632 - samples/sec: 198.80 - lr: 0.012500\n",
            "2022-12-12 00:24:57,790 epoch 28 - iter 120/245 - loss 0.02808065 - samples/sec: 204.68 - lr: 0.012500\n",
            "2022-12-12 00:25:00,618 epoch 28 - iter 144/245 - loss 0.02800248 - samples/sec: 271.94 - lr: 0.012500\n",
            "2022-12-12 00:25:05,213 epoch 28 - iter 168/245 - loss 0.02854134 - samples/sec: 167.26 - lr: 0.012500\n",
            "2022-12-12 00:25:08,380 epoch 28 - iter 192/245 - loss 0.02913000 - samples/sec: 242.79 - lr: 0.012500\n",
            "2022-12-12 00:25:12,917 epoch 28 - iter 216/245 - loss 0.02894085 - samples/sec: 169.42 - lr: 0.012500\n",
            "2022-12-12 00:25:17,413 epoch 28 - iter 240/245 - loss 0.02876312 - samples/sec: 170.97 - lr: 0.012500\n",
            "2022-12-12 00:25:17,944 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:25:17,946 EPOCH 28 done: loss 0.0287 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:25:26,025 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:25:26,047 DEV : loss 0.053843773901462555 - f1-score (micro avg)  0.7968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:25:26,134 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 00:25:26,137 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:25:29,275 epoch 29 - iter 24/245 - loss 0.03509223 - samples/sec: 245.17 - lr: 0.012500\n",
            "2022-12-12 00:25:34,027 epoch 29 - iter 48/245 - loss 0.03284114 - samples/sec: 161.76 - lr: 0.012500\n",
            "2022-12-12 00:25:38,630 epoch 29 - iter 72/245 - loss 0.03225266 - samples/sec: 167.00 - lr: 0.012500\n",
            "2022-12-12 00:25:41,520 epoch 29 - iter 96/245 - loss 0.03089442 - samples/sec: 266.09 - lr: 0.012500\n",
            "2022-12-12 00:25:45,109 epoch 29 - iter 120/245 - loss 0.03050364 - samples/sec: 214.20 - lr: 0.012500\n",
            "2022-12-12 00:25:48,710 epoch 29 - iter 144/245 - loss 0.02975153 - samples/sec: 213.52 - lr: 0.012500\n",
            "2022-12-12 00:25:51,774 epoch 29 - iter 168/245 - loss 0.02921907 - samples/sec: 251.02 - lr: 0.012500\n",
            "2022-12-12 00:25:55,369 epoch 29 - iter 192/245 - loss 0.02952837 - samples/sec: 213.88 - lr: 0.012500\n",
            "2022-12-12 00:25:58,608 epoch 29 - iter 216/245 - loss 0.02916747 - samples/sec: 237.39 - lr: 0.012500\n",
            "2022-12-12 00:26:03,798 epoch 29 - iter 240/245 - loss 0.02874932 - samples/sec: 148.10 - lr: 0.012500\n",
            "2022-12-12 00:26:04,419 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:26:04,422 EPOCH 29 done: loss 0.0287 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:26:11,867 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:26:11,889 DEV : loss 0.053881824016571045 - f1-score (micro avg)  0.796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:26:11,977 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 00:26:11,979 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:26:16,559 epoch 30 - iter 24/245 - loss 0.02871823 - samples/sec: 167.92 - lr: 0.012500\n",
            "2022-12-12 00:26:20,070 epoch 30 - iter 48/245 - loss 0.02718697 - samples/sec: 219.04 - lr: 0.012500\n",
            "2022-12-12 00:26:23,471 epoch 30 - iter 72/245 - loss 0.02944228 - samples/sec: 226.03 - lr: 0.012500\n",
            "2022-12-12 00:26:26,984 epoch 30 - iter 96/245 - loss 0.02875363 - samples/sec: 218.87 - lr: 0.012500\n",
            "2022-12-12 00:26:30,775 epoch 30 - iter 120/245 - loss 0.02813593 - samples/sec: 202.81 - lr: 0.012500\n",
            "2022-12-12 00:26:35,741 epoch 30 - iter 144/245 - loss 0.02903299 - samples/sec: 154.77 - lr: 0.012500\n",
            "2022-12-12 00:26:39,124 epoch 30 - iter 168/245 - loss 0.02982778 - samples/sec: 227.31 - lr: 0.012500\n",
            "2022-12-12 00:26:42,373 epoch 30 - iter 192/245 - loss 0.02946697 - samples/sec: 236.66 - lr: 0.012500\n",
            "2022-12-12 00:26:46,532 epoch 30 - iter 216/245 - loss 0.02883915 - samples/sec: 184.83 - lr: 0.012500\n",
            "2022-12-12 00:26:50,477 epoch 30 - iter 240/245 - loss 0.02831370 - samples/sec: 194.87 - lr: 0.012500\n",
            "2022-12-12 00:26:51,193 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:26:51,195 EPOCH 30 done: loss 0.0282 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:26:59,242 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:26:59,263 DEV : loss 0.053141385316848755 - f1-score (micro avg)  0.7991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:26:59,347 Epoch    30: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2022-12-12 00:26:59,349 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 00:26:59,352 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:27:02,527 epoch 31 - iter 24/245 - loss 0.02859614 - samples/sec: 242.23 - lr: 0.006250\n",
            "2022-12-12 00:27:05,693 epoch 31 - iter 48/245 - loss 0.02819758 - samples/sec: 242.88 - lr: 0.006250\n",
            "2022-12-12 00:27:10,228 epoch 31 - iter 72/245 - loss 0.02694984 - samples/sec: 169.50 - lr: 0.006250\n",
            "2022-12-12 00:27:14,747 epoch 31 - iter 96/245 - loss 0.02701232 - samples/sec: 170.10 - lr: 0.006250\n",
            "2022-12-12 00:27:18,493 epoch 31 - iter 120/245 - loss 0.02739739 - samples/sec: 205.24 - lr: 0.006250\n",
            "2022-12-12 00:27:22,317 epoch 31 - iter 144/245 - loss 0.02671338 - samples/sec: 201.06 - lr: 0.006250\n",
            "2022-12-12 00:27:25,497 epoch 31 - iter 168/245 - loss 0.02627026 - samples/sec: 241.84 - lr: 0.006250\n",
            "2022-12-12 00:27:28,805 epoch 31 - iter 192/245 - loss 0.02662331 - samples/sec: 232.45 - lr: 0.006250\n",
            "2022-12-12 00:27:32,841 epoch 31 - iter 216/245 - loss 0.02717441 - samples/sec: 190.50 - lr: 0.006250\n",
            "2022-12-12 00:27:36,704 epoch 31 - iter 240/245 - loss 0.02812759 - samples/sec: 199.02 - lr: 0.006250\n",
            "2022-12-12 00:27:37,611 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:27:37,613 EPOCH 31 done: loss 0.0282 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:27:45,031 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:27:45,052 DEV : loss 0.05262794718146324 - f1-score (micro avg)  0.8013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:27:45,135 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:27:45,137 saving best model\n",
            "2022-12-12 00:27:47,895 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:27:51,190 epoch 32 - iter 24/245 - loss 0.02656297 - samples/sec: 234.92 - lr: 0.006250\n",
            "2022-12-12 00:27:55,150 epoch 32 - iter 48/245 - loss 0.02729281 - samples/sec: 194.16 - lr: 0.006250\n",
            "2022-12-12 00:27:58,177 epoch 32 - iter 72/245 - loss 0.02665917 - samples/sec: 254.04 - lr: 0.006250\n",
            "2022-12-12 00:28:01,725 epoch 32 - iter 96/245 - loss 0.02670544 - samples/sec: 216.70 - lr: 0.006250\n",
            "2022-12-12 00:28:05,232 epoch 32 - iter 120/245 - loss 0.02667180 - samples/sec: 219.31 - lr: 0.006250\n",
            "2022-12-12 00:28:09,391 epoch 32 - iter 144/245 - loss 0.02701764 - samples/sec: 184.84 - lr: 0.006250\n",
            "2022-12-12 00:28:15,228 epoch 32 - iter 168/245 - loss 0.02696302 - samples/sec: 131.64 - lr: 0.006250\n",
            "2022-12-12 00:28:18,178 epoch 32 - iter 192/245 - loss 0.02692918 - samples/sec: 260.65 - lr: 0.006250\n",
            "2022-12-12 00:28:21,628 epoch 32 - iter 216/245 - loss 0.02663868 - samples/sec: 222.88 - lr: 0.006250\n",
            "2022-12-12 00:28:26,330 epoch 32 - iter 240/245 - loss 0.02724220 - samples/sec: 163.48 - lr: 0.006250\n",
            "2022-12-12 00:28:26,934 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:28:26,936 EPOCH 32 done: loss 0.0273 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:28:34,274 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:28:34,296 DEV : loss 0.053773507475852966 - f1-score (micro avg)  0.8029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:28:34,380 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:28:34,382 saving best model\n",
            "2022-12-12 00:28:37,127 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:28:40,692 epoch 33 - iter 24/245 - loss 0.02607784 - samples/sec: 216.94 - lr: 0.006250\n",
            "2022-12-12 00:28:44,145 epoch 33 - iter 48/245 - loss 0.02688184 - samples/sec: 222.69 - lr: 0.006250\n",
            "2022-12-12 00:28:47,998 epoch 33 - iter 72/245 - loss 0.02729285 - samples/sec: 199.51 - lr: 0.006250\n",
            "2022-12-12 00:28:53,101 epoch 33 - iter 96/245 - loss 0.02692850 - samples/sec: 150.63 - lr: 0.006250\n",
            "2022-12-12 00:28:56,203 epoch 33 - iter 120/245 - loss 0.02674202 - samples/sec: 247.86 - lr: 0.006250\n",
            "2022-12-12 00:28:59,920 epoch 33 - iter 144/245 - loss 0.02632017 - samples/sec: 206.87 - lr: 0.006250\n",
            "2022-12-12 00:29:03,681 epoch 33 - iter 168/245 - loss 0.02798797 - samples/sec: 204.41 - lr: 0.006250\n",
            "2022-12-12 00:29:08,362 epoch 33 - iter 192/245 - loss 0.02813245 - samples/sec: 164.24 - lr: 0.006250\n",
            "2022-12-12 00:29:11,698 epoch 33 - iter 216/245 - loss 0.02808815 - samples/sec: 230.50 - lr: 0.006250\n",
            "2022-12-12 00:29:15,040 epoch 33 - iter 240/245 - loss 0.02807778 - samples/sec: 230.06 - lr: 0.006250\n",
            "2022-12-12 00:29:15,786 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:29:15,787 EPOCH 33 done: loss 0.0279 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:29:23,778 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:29:23,799 DEV : loss 0.053234782069921494 - f1-score (micro avg)  0.8001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:29:23,882 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 00:29:23,884 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:29:27,163 epoch 34 - iter 24/245 - loss 0.02862711 - samples/sec: 234.59 - lr: 0.006250\n",
            "2022-12-12 00:29:30,480 epoch 34 - iter 48/245 - loss 0.02977449 - samples/sec: 231.83 - lr: 0.006250\n",
            "2022-12-12 00:29:33,504 epoch 34 - iter 72/245 - loss 0.02967465 - samples/sec: 254.32 - lr: 0.006250\n",
            "2022-12-12 00:29:36,775 epoch 34 - iter 96/245 - loss 0.02824383 - samples/sec: 235.06 - lr: 0.006250\n",
            "2022-12-12 00:29:40,120 epoch 34 - iter 120/245 - loss 0.02770536 - samples/sec: 229.88 - lr: 0.006250\n",
            "2022-12-12 00:29:43,391 epoch 34 - iter 144/245 - loss 0.02642784 - samples/sec: 235.10 - lr: 0.006250\n",
            "2022-12-12 00:29:50,571 epoch 34 - iter 168/245 - loss 0.02724332 - samples/sec: 107.03 - lr: 0.006250\n",
            "2022-12-12 00:29:54,511 epoch 34 - iter 192/245 - loss 0.02692574 - samples/sec: 195.15 - lr: 0.006250\n",
            "2022-12-12 00:29:57,764 epoch 34 - iter 216/245 - loss 0.02740939 - samples/sec: 236.39 - lr: 0.006250\n",
            "2022-12-12 00:30:01,399 epoch 34 - iter 240/245 - loss 0.02731985 - samples/sec: 211.53 - lr: 0.006250\n",
            "2022-12-12 00:30:01,931 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:30:01,933 EPOCH 34 done: loss 0.0273 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:30:09,205 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:30:09,225 DEV : loss 0.054175663739442825 - f1-score (micro avg)  0.8038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:30:09,309 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 00:30:09,311 saving best model\n",
            "2022-12-12 00:30:12,109 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:30:15,794 epoch 35 - iter 24/245 - loss 0.02540975 - samples/sec: 209.79 - lr: 0.006250\n",
            "2022-12-12 00:30:19,473 epoch 35 - iter 48/245 - loss 0.02838032 - samples/sec: 208.95 - lr: 0.006250\n",
            "2022-12-12 00:30:24,446 epoch 35 - iter 72/245 - loss 0.02938859 - samples/sec: 154.58 - lr: 0.006250\n",
            "2022-12-12 00:30:27,976 epoch 35 - iter 96/245 - loss 0.02937099 - samples/sec: 217.83 - lr: 0.006250\n",
            "2022-12-12 00:30:31,224 epoch 35 - iter 120/245 - loss 0.02902425 - samples/sec: 236.76 - lr: 0.006250\n",
            "2022-12-12 00:30:35,046 epoch 35 - iter 144/245 - loss 0.02847592 - samples/sec: 201.12 - lr: 0.006250\n",
            "2022-12-12 00:30:38,506 epoch 35 - iter 168/245 - loss 0.02830928 - samples/sec: 222.20 - lr: 0.006250\n",
            "2022-12-12 00:30:42,663 epoch 35 - iter 192/245 - loss 0.02813065 - samples/sec: 184.91 - lr: 0.006250\n",
            "2022-12-12 00:30:45,481 epoch 35 - iter 216/245 - loss 0.02764343 - samples/sec: 272.93 - lr: 0.006250\n",
            "2022-12-12 00:30:49,570 epoch 35 - iter 240/245 - loss 0.02731550 - samples/sec: 188.04 - lr: 0.006250\n",
            "2022-12-12 00:30:50,063 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:30:50,065 EPOCH 35 done: loss 0.0273 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:30:58,131 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:30:58,152 DEV : loss 0.05312367528676987 - f1-score (micro avg)  0.8032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:30:58,235 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 00:30:58,237 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:31:01,636 epoch 36 - iter 24/245 - loss 0.03470156 - samples/sec: 226.32 - lr: 0.006250\n",
            "2022-12-12 00:31:05,323 epoch 36 - iter 48/245 - loss 0.03025361 - samples/sec: 208.56 - lr: 0.006250\n",
            "2022-12-12 00:31:09,548 epoch 36 - iter 72/245 - loss 0.02739179 - samples/sec: 181.93 - lr: 0.006250\n",
            "2022-12-12 00:31:13,194 epoch 36 - iter 96/245 - loss 0.02651195 - samples/sec: 210.88 - lr: 0.006250\n",
            "2022-12-12 00:31:17,555 epoch 36 - iter 120/245 - loss 0.02670512 - samples/sec: 176.26 - lr: 0.006250\n",
            "2022-12-12 00:31:20,983 epoch 36 - iter 144/245 - loss 0.02671356 - samples/sec: 224.34 - lr: 0.006250\n",
            "2022-12-12 00:31:25,123 epoch 36 - iter 168/245 - loss 0.02680747 - samples/sec: 185.67 - lr: 0.006250\n",
            "2022-12-12 00:31:28,360 epoch 36 - iter 192/245 - loss 0.02628512 - samples/sec: 237.54 - lr: 0.006250\n",
            "2022-12-12 00:31:31,216 epoch 36 - iter 216/245 - loss 0.02627489 - samples/sec: 269.21 - lr: 0.006250\n",
            "2022-12-12 00:31:36,654 epoch 36 - iter 240/245 - loss 0.02597967 - samples/sec: 141.35 - lr: 0.006250\n",
            "2022-12-12 00:31:37,194 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:31:37,197 EPOCH 36 done: loss 0.0259 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:31:44,583 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:31:44,605 DEV : loss 0.05461762845516205 - f1-score (micro avg)  0.8012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:31:44,691 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 00:31:44,693 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:31:49,155 epoch 37 - iter 24/245 - loss 0.02795666 - samples/sec: 172.33 - lr: 0.006250\n",
            "2022-12-12 00:31:53,278 epoch 37 - iter 48/245 - loss 0.02583506 - samples/sec: 186.47 - lr: 0.006250\n",
            "2022-12-12 00:31:58,064 epoch 37 - iter 72/245 - loss 0.02509968 - samples/sec: 160.63 - lr: 0.006250\n",
            "2022-12-12 00:32:01,404 epoch 37 - iter 96/245 - loss 0.02526318 - samples/sec: 230.21 - lr: 0.006250\n",
            "2022-12-12 00:32:04,324 epoch 37 - iter 120/245 - loss 0.02595263 - samples/sec: 263.37 - lr: 0.006250\n",
            "2022-12-12 00:32:07,238 epoch 37 - iter 144/245 - loss 0.02639000 - samples/sec: 263.88 - lr: 0.006250\n",
            "2022-12-12 00:32:10,557 epoch 37 - iter 168/245 - loss 0.02663034 - samples/sec: 231.70 - lr: 0.006250\n",
            "2022-12-12 00:32:13,578 epoch 37 - iter 192/245 - loss 0.02649797 - samples/sec: 254.54 - lr: 0.006250\n",
            "2022-12-12 00:32:18,354 epoch 37 - iter 216/245 - loss 0.02671098 - samples/sec: 160.91 - lr: 0.006250\n",
            "2022-12-12 00:32:22,580 epoch 37 - iter 240/245 - loss 0.02709355 - samples/sec: 181.91 - lr: 0.006250\n",
            "2022-12-12 00:32:23,924 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:32:23,926 EPOCH 37 done: loss 0.0272 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:32:31,324 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:32:31,346 DEV : loss 0.05320560187101364 - f1-score (micro avg)  0.8007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:32:31,435 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 00:32:31,437 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:32:35,096 epoch 38 - iter 24/245 - loss 0.03075486 - samples/sec: 210.21 - lr: 0.006250\n",
            "2022-12-12 00:32:38,354 epoch 38 - iter 48/245 - loss 0.02809421 - samples/sec: 236.07 - lr: 0.006250\n",
            "2022-12-12 00:32:42,117 epoch 38 - iter 72/245 - loss 0.02697999 - samples/sec: 204.27 - lr: 0.006250\n",
            "2022-12-12 00:32:45,152 epoch 38 - iter 96/245 - loss 0.02573055 - samples/sec: 253.45 - lr: 0.006250\n",
            "2022-12-12 00:32:49,317 epoch 38 - iter 120/245 - loss 0.02643506 - samples/sec: 184.50 - lr: 0.006250\n",
            "2022-12-12 00:32:54,180 epoch 38 - iter 144/245 - loss 0.02620568 - samples/sec: 158.07 - lr: 0.006250\n",
            "2022-12-12 00:32:57,583 epoch 38 - iter 168/245 - loss 0.02661031 - samples/sec: 225.87 - lr: 0.006250\n",
            "2022-12-12 00:33:01,686 epoch 38 - iter 192/245 - loss 0.02669671 - samples/sec: 187.41 - lr: 0.006250\n",
            "2022-12-12 00:33:05,364 epoch 38 - iter 216/245 - loss 0.02687976 - samples/sec: 209.05 - lr: 0.006250\n",
            "2022-12-12 00:33:09,083 epoch 38 - iter 240/245 - loss 0.02656119 - samples/sec: 206.71 - lr: 0.006250\n",
            "2022-12-12 00:33:09,714 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:33:09,715 EPOCH 38 done: loss 0.0265 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:33:17,740 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:33:17,761 DEV : loss 0.05393466725945473 - f1-score (micro avg)  0.8034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:33:17,845 Epoch    38: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2022-12-12 00:33:17,846 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 00:33:17,849 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:33:21,883 epoch 39 - iter 24/245 - loss 0.02316003 - samples/sec: 190.66 - lr: 0.003125\n",
            "2022-12-12 00:33:26,259 epoch 39 - iter 48/245 - loss 0.02206484 - samples/sec: 175.64 - lr: 0.003125\n",
            "2022-12-12 00:33:30,814 epoch 39 - iter 72/245 - loss 0.02385982 - samples/sec: 168.77 - lr: 0.003125\n",
            "2022-12-12 00:33:34,264 epoch 39 - iter 96/245 - loss 0.02455100 - samples/sec: 222.85 - lr: 0.003125\n",
            "2022-12-12 00:33:37,499 epoch 39 - iter 120/245 - loss 0.02514075 - samples/sec: 237.69 - lr: 0.003125\n",
            "2022-12-12 00:33:41,609 epoch 39 - iter 144/245 - loss 0.02489528 - samples/sec: 187.02 - lr: 0.003125\n",
            "2022-12-12 00:33:44,641 epoch 39 - iter 168/245 - loss 0.02512818 - samples/sec: 253.67 - lr: 0.003125\n",
            "2022-12-12 00:33:47,601 epoch 39 - iter 192/245 - loss 0.02529252 - samples/sec: 259.80 - lr: 0.003125\n",
            "2022-12-12 00:33:50,902 epoch 39 - iter 216/245 - loss 0.02566297 - samples/sec: 232.92 - lr: 0.003125\n",
            "2022-12-12 00:33:55,447 epoch 39 - iter 240/245 - loss 0.02611069 - samples/sec: 169.15 - lr: 0.003125\n",
            "2022-12-12 00:33:56,077 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:33:56,079 EPOCH 39 done: loss 0.0262 - lr 0.003125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:34:03,616 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:34:03,641 DEV : loss 0.05306617170572281 - f1-score (micro avg)  0.8016\n",
            "2022-12-12 00:34:03,727 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 00:34:03,731 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:34:08,584 epoch 40 - iter 24/245 - loss 0.03402282 - samples/sec: 158.45 - lr: 0.003125\n",
            "2022-12-12 00:34:11,380 epoch 40 - iter 48/245 - loss 0.02866341 - samples/sec: 275.05 - lr: 0.003125\n",
            "2022-12-12 00:34:14,485 epoch 40 - iter 72/245 - loss 0.02635898 - samples/sec: 247.64 - lr: 0.003125\n",
            "2022-12-12 00:34:17,511 epoch 40 - iter 96/245 - loss 0.02575466 - samples/sec: 254.10 - lr: 0.003125\n",
            "2022-12-12 00:34:20,595 epoch 40 - iter 120/245 - loss 0.02528801 - samples/sec: 249.30 - lr: 0.003125\n",
            "2022-12-12 00:34:24,286 epoch 40 - iter 144/245 - loss 0.02536216 - samples/sec: 208.28 - lr: 0.003125\n",
            "2022-12-12 00:34:29,053 epoch 40 - iter 168/245 - loss 0.02637214 - samples/sec: 161.26 - lr: 0.003125\n",
            "2022-12-12 00:34:33,466 epoch 40 - iter 192/245 - loss 0.02647185 - samples/sec: 174.21 - lr: 0.003125\n",
            "2022-12-12 00:34:37,870 epoch 40 - iter 216/245 - loss 0.02633829 - samples/sec: 174.56 - lr: 0.003125\n",
            "2022-12-12 00:34:41,022 epoch 40 - iter 240/245 - loss 0.02638062 - samples/sec: 243.98 - lr: 0.003125\n",
            "2022-12-12 00:34:41,814 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:34:41,816 EPOCH 40 done: loss 0.0264 - lr 0.003125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:34:49,822 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:34:49,843 DEV : loss 0.0536733977496624 - f1-score (micro avg)  0.803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:34:49,925 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 00:34:49,927 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:34:54,118 epoch 41 - iter 24/245 - loss 0.02560113 - samples/sec: 183.49 - lr: 0.003125\n",
            "2022-12-12 00:34:57,978 epoch 41 - iter 48/245 - loss 0.02715970 - samples/sec: 199.16 - lr: 0.003125\n",
            "2022-12-12 00:35:01,987 epoch 41 - iter 72/245 - loss 0.02771466 - samples/sec: 191.75 - lr: 0.003125\n",
            "2022-12-12 00:35:06,158 epoch 41 - iter 96/245 - loss 0.02774666 - samples/sec: 184.31 - lr: 0.003125\n",
            "2022-12-12 00:35:10,542 epoch 41 - iter 120/245 - loss 0.02766871 - samples/sec: 175.35 - lr: 0.003125\n",
            "2022-12-12 00:35:14,695 epoch 41 - iter 144/245 - loss 0.02717703 - samples/sec: 185.11 - lr: 0.003125\n",
            "2022-12-12 00:35:18,021 epoch 41 - iter 168/245 - loss 0.02659295 - samples/sec: 231.20 - lr: 0.003125\n",
            "2022-12-12 00:35:21,741 epoch 41 - iter 192/245 - loss 0.02690659 - samples/sec: 206.62 - lr: 0.003125\n",
            "2022-12-12 00:35:25,072 epoch 41 - iter 216/245 - loss 0.02684993 - samples/sec: 230.90 - lr: 0.003125\n",
            "2022-12-12 00:35:28,082 epoch 41 - iter 240/245 - loss 0.02684630 - samples/sec: 255.45 - lr: 0.003125\n",
            "2022-12-12 00:35:28,609 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:35:28,610 EPOCH 41 done: loss 0.0268 - lr 0.003125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:35:35,868 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:35:35,888 DEV : loss 0.05328686162829399 - f1-score (micro avg)  0.803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:35:35,972 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 00:35:35,974 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:35:39,084 epoch 42 - iter 24/245 - loss 0.02198495 - samples/sec: 247.22 - lr: 0.003125\n",
            "2022-12-12 00:35:41,931 epoch 42 - iter 48/245 - loss 0.02390467 - samples/sec: 270.17 - lr: 0.003125\n",
            "2022-12-12 00:35:45,664 epoch 42 - iter 72/245 - loss 0.02394672 - samples/sec: 205.96 - lr: 0.003125\n",
            "2022-12-12 00:35:49,546 epoch 42 - iter 96/245 - loss 0.02454406 - samples/sec: 198.04 - lr: 0.003125\n",
            "2022-12-12 00:35:54,171 epoch 42 - iter 120/245 - loss 0.02515285 - samples/sec: 166.21 - lr: 0.003125\n",
            "2022-12-12 00:35:59,075 epoch 42 - iter 144/245 - loss 0.02601843 - samples/sec: 156.73 - lr: 0.003125\n",
            "2022-12-12 00:36:03,026 epoch 42 - iter 168/245 - loss 0.02652777 - samples/sec: 194.58 - lr: 0.003125\n",
            "2022-12-12 00:36:06,039 epoch 42 - iter 192/245 - loss 0.02650944 - samples/sec: 255.26 - lr: 0.003125\n",
            "2022-12-12 00:36:09,966 epoch 42 - iter 216/245 - loss 0.02625783 - samples/sec: 195.77 - lr: 0.003125\n",
            "2022-12-12 00:36:14,674 epoch 42 - iter 240/245 - loss 0.02631688 - samples/sec: 163.25 - lr: 0.003125\n",
            "2022-12-12 00:36:15,413 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:36:15,414 EPOCH 42 done: loss 0.0264 - lr 0.003125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:36:22,615 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:36:22,634 DEV : loss 0.05319751054048538 - f1-score (micro avg)  0.8032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:36:22,718 Epoch    42: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2022-12-12 00:36:22,719 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 00:36:22,722 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:36:26,119 epoch 43 - iter 24/245 - loss 0.02508161 - samples/sec: 226.46 - lr: 0.001563\n",
            "2022-12-12 00:36:31,311 epoch 43 - iter 48/245 - loss 0.02857420 - samples/sec: 148.03 - lr: 0.001563\n",
            "2022-12-12 00:36:34,806 epoch 43 - iter 72/245 - loss 0.02882846 - samples/sec: 220.02 - lr: 0.001563\n",
            "2022-12-12 00:36:38,773 epoch 43 - iter 96/245 - loss 0.02738163 - samples/sec: 193.85 - lr: 0.001563\n",
            "2022-12-12 00:36:42,356 epoch 43 - iter 120/245 - loss 0.02730848 - samples/sec: 214.56 - lr: 0.001563\n",
            "2022-12-12 00:36:46,515 epoch 43 - iter 144/245 - loss 0.02665134 - samples/sec: 184.82 - lr: 0.001563\n",
            "2022-12-12 00:36:50,267 epoch 43 - iter 168/245 - loss 0.02702321 - samples/sec: 204.96 - lr: 0.001563\n",
            "2022-12-12 00:36:53,249 epoch 43 - iter 192/245 - loss 0.02675220 - samples/sec: 257.83 - lr: 0.001563\n",
            "2022-12-12 00:36:56,782 epoch 43 - iter 216/245 - loss 0.02656263 - samples/sec: 217.71 - lr: 0.001563\n",
            "2022-12-12 00:37:00,354 epoch 43 - iter 240/245 - loss 0.02659338 - samples/sec: 215.22 - lr: 0.001563\n",
            "2022-12-12 00:37:01,212 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:37:01,214 EPOCH 43 done: loss 0.0265 - lr 0.001563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:37:09,284 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:37:09,305 DEV : loss 0.053099218755960464 - f1-score (micro avg)  0.8026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:37:09,393 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 00:37:09,395 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:37:12,432 epoch 44 - iter 24/245 - loss 0.02273614 - samples/sec: 253.27 - lr: 0.001563\n",
            "2022-12-12 00:37:15,963 epoch 44 - iter 48/245 - loss 0.02636880 - samples/sec: 217.73 - lr: 0.001563\n",
            "2022-12-12 00:37:20,457 epoch 44 - iter 72/245 - loss 0.02612038 - samples/sec: 171.08 - lr: 0.001563\n",
            "2022-12-12 00:37:23,882 epoch 44 - iter 96/245 - loss 0.02619903 - samples/sec: 224.44 - lr: 0.001563\n",
            "2022-12-12 00:37:27,845 epoch 44 - iter 120/245 - loss 0.02576437 - samples/sec: 194.03 - lr: 0.001563\n",
            "2022-12-12 00:37:32,501 epoch 44 - iter 144/245 - loss 0.02560221 - samples/sec: 165.11 - lr: 0.001563\n",
            "2022-12-12 00:37:35,658 epoch 44 - iter 168/245 - loss 0.02560387 - samples/sec: 243.55 - lr: 0.001563\n",
            "2022-12-12 00:37:39,145 epoch 44 - iter 192/245 - loss 0.02553265 - samples/sec: 220.50 - lr: 0.001563\n",
            "2022-12-12 00:37:42,671 epoch 44 - iter 216/245 - loss 0.02605844 - samples/sec: 218.01 - lr: 0.001563\n",
            "2022-12-12 00:37:45,679 epoch 44 - iter 240/245 - loss 0.02608496 - samples/sec: 255.63 - lr: 0.001563\n",
            "2022-12-12 00:37:47,489 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:37:47,491 EPOCH 44 done: loss 0.0261 - lr 0.001563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:37:54,758 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:37:54,780 DEV : loss 0.05307067930698395 - f1-score (micro avg)  0.8022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:37:54,864 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 00:37:54,866 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:37:57,949 epoch 45 - iter 24/245 - loss 0.02540571 - samples/sec: 249.55 - lr: 0.001563\n",
            "2022-12-12 00:38:01,101 epoch 45 - iter 48/245 - loss 0.02309963 - samples/sec: 244.01 - lr: 0.001563\n",
            "2022-12-12 00:38:04,708 epoch 45 - iter 72/245 - loss 0.02400251 - samples/sec: 213.17 - lr: 0.001563\n",
            "2022-12-12 00:38:09,579 epoch 45 - iter 96/245 - loss 0.02385688 - samples/sec: 157.80 - lr: 0.001563\n",
            "2022-12-12 00:38:14,134 epoch 45 - iter 120/245 - loss 0.02593165 - samples/sec: 168.76 - lr: 0.001563\n",
            "2022-12-12 00:38:17,602 epoch 45 - iter 144/245 - loss 0.02579112 - samples/sec: 221.74 - lr: 0.001563\n",
            "2022-12-12 00:38:22,609 epoch 45 - iter 168/245 - loss 0.02572135 - samples/sec: 153.50 - lr: 0.001563\n",
            "2022-12-12 00:38:25,290 epoch 45 - iter 192/245 - loss 0.02620190 - samples/sec: 286.88 - lr: 0.001563\n",
            "2022-12-12 00:38:29,490 epoch 45 - iter 216/245 - loss 0.02639126 - samples/sec: 183.04 - lr: 0.001563\n",
            "2022-12-12 00:38:33,206 epoch 45 - iter 240/245 - loss 0.02654320 - samples/sec: 206.88 - lr: 0.001563\n",
            "2022-12-12 00:38:33,734 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:38:33,736 EPOCH 45 done: loss 0.0266 - lr 0.001563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:38:41,867 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:38:41,893 DEV : loss 0.05302637815475464 - f1-score (micro avg)  0.8022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:38:41,985 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 00:38:41,988 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:38:45,754 epoch 46 - iter 24/245 - loss 0.02647346 - samples/sec: 204.23 - lr: 0.001563\n",
            "2022-12-12 00:38:48,979 epoch 46 - iter 48/245 - loss 0.02588446 - samples/sec: 238.41 - lr: 0.001563\n",
            "2022-12-12 00:38:51,982 epoch 46 - iter 72/245 - loss 0.02559113 - samples/sec: 256.15 - lr: 0.001563\n",
            "2022-12-12 00:38:56,233 epoch 46 - iter 96/245 - loss 0.02588637 - samples/sec: 180.80 - lr: 0.001563\n",
            "2022-12-12 00:38:59,836 epoch 46 - iter 120/245 - loss 0.02543800 - samples/sec: 213.41 - lr: 0.001563\n",
            "2022-12-12 00:39:03,396 epoch 46 - iter 144/245 - loss 0.02595242 - samples/sec: 215.95 - lr: 0.001563\n",
            "2022-12-12 00:39:07,810 epoch 46 - iter 168/245 - loss 0.02635067 - samples/sec: 174.14 - lr: 0.001563\n",
            "2022-12-12 00:39:12,820 epoch 46 - iter 192/245 - loss 0.02669359 - samples/sec: 153.44 - lr: 0.001563\n",
            "2022-12-12 00:39:16,100 epoch 46 - iter 216/245 - loss 0.02648317 - samples/sec: 234.44 - lr: 0.001563\n",
            "2022-12-12 00:39:19,449 epoch 46 - iter 240/245 - loss 0.02646745 - samples/sec: 229.60 - lr: 0.001563\n",
            "2022-12-12 00:39:20,047 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:39:20,049 EPOCH 46 done: loss 0.0266 - lr 0.001563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:39:27,707 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:39:27,731 DEV : loss 0.052497994154691696 - f1-score (micro avg)  0.801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:39:27,819 Epoch    46: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2022-12-12 00:39:27,821 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 00:39:27,823 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:39:30,793 epoch 47 - iter 24/245 - loss 0.02510992 - samples/sec: 259.06 - lr: 0.000781\n",
            "2022-12-12 00:39:34,428 epoch 47 - iter 48/245 - loss 0.02715738 - samples/sec: 211.52 - lr: 0.000781\n",
            "2022-12-12 00:39:37,751 epoch 47 - iter 72/245 - loss 0.02623227 - samples/sec: 231.45 - lr: 0.000781\n",
            "2022-12-12 00:39:42,805 epoch 47 - iter 96/245 - loss 0.02647805 - samples/sec: 152.06 - lr: 0.000781\n",
            "2022-12-12 00:39:47,412 epoch 47 - iter 120/245 - loss 0.02622758 - samples/sec: 166.85 - lr: 0.000781\n",
            "2022-12-12 00:39:51,059 epoch 47 - iter 144/245 - loss 0.02687353 - samples/sec: 210.82 - lr: 0.000781\n",
            "2022-12-12 00:39:55,635 epoch 47 - iter 168/245 - loss 0.02679963 - samples/sec: 167.97 - lr: 0.000781\n",
            "2022-12-12 00:39:59,598 epoch 47 - iter 192/245 - loss 0.02639758 - samples/sec: 194.00 - lr: 0.000781\n",
            "2022-12-12 00:40:03,210 epoch 47 - iter 216/245 - loss 0.02670413 - samples/sec: 212.87 - lr: 0.000781\n",
            "2022-12-12 00:40:06,614 epoch 47 - iter 240/245 - loss 0.02617354 - samples/sec: 225.91 - lr: 0.000781\n",
            "2022-12-12 00:40:07,182 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:40:07,183 EPOCH 47 done: loss 0.0264 - lr 0.000781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:40:14,581 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:40:14,602 DEV : loss 0.05272059515118599 - f1-score (micro avg)  0.8008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:40:14,687 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 00:40:14,690 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:40:19,003 epoch 48 - iter 24/245 - loss 0.02377653 - samples/sec: 178.26 - lr: 0.000781\n",
            "2022-12-12 00:40:22,398 epoch 48 - iter 48/245 - loss 0.02406732 - samples/sec: 226.48 - lr: 0.000781\n",
            "2022-12-12 00:40:26,658 epoch 48 - iter 72/245 - loss 0.02486197 - samples/sec: 180.45 - lr: 0.000781\n",
            "2022-12-12 00:40:31,389 epoch 48 - iter 96/245 - loss 0.02452774 - samples/sec: 162.45 - lr: 0.000781\n",
            "2022-12-12 00:40:34,739 epoch 48 - iter 120/245 - loss 0.02472448 - samples/sec: 229.52 - lr: 0.000781\n",
            "2022-12-12 00:40:38,205 epoch 48 - iter 144/245 - loss 0.02604778 - samples/sec: 221.83 - lr: 0.000781\n",
            "2022-12-12 00:40:41,924 epoch 48 - iter 168/245 - loss 0.02613275 - samples/sec: 206.74 - lr: 0.000781\n",
            "2022-12-12 00:40:45,742 epoch 48 - iter 192/245 - loss 0.02644681 - samples/sec: 201.36 - lr: 0.000781\n",
            "2022-12-12 00:40:48,764 epoch 48 - iter 216/245 - loss 0.02601400 - samples/sec: 254.47 - lr: 0.000781\n",
            "2022-12-12 00:40:51,672 epoch 48 - iter 240/245 - loss 0.02596649 - samples/sec: 264.47 - lr: 0.000781\n",
            "2022-12-12 00:40:52,339 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:40:52,341 EPOCH 48 done: loss 0.0259 - lr 0.000781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:41:00,403 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:41:00,424 DEV : loss 0.05287087708711624 - f1-score (micro avg)  0.8032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:41:00,509 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 00:41:00,513 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:41:04,108 epoch 49 - iter 24/245 - loss 0.02400593 - samples/sec: 213.96 - lr: 0.000781\n",
            "2022-12-12 00:41:08,034 epoch 49 - iter 48/245 - loss 0.02513051 - samples/sec: 195.83 - lr: 0.000781\n",
            "2022-12-12 00:41:11,881 epoch 49 - iter 72/245 - loss 0.02618339 - samples/sec: 199.85 - lr: 0.000781\n",
            "2022-12-12 00:41:15,401 epoch 49 - iter 96/245 - loss 0.02540211 - samples/sec: 218.39 - lr: 0.000781\n",
            "2022-12-12 00:41:19,545 epoch 49 - iter 120/245 - loss 0.02567124 - samples/sec: 185.47 - lr: 0.000781\n",
            "2022-12-12 00:41:23,152 epoch 49 - iter 144/245 - loss 0.02528351 - samples/sec: 213.17 - lr: 0.000781\n",
            "2022-12-12 00:41:27,629 epoch 49 - iter 168/245 - loss 0.02557259 - samples/sec: 171.68 - lr: 0.000781\n",
            "2022-12-12 00:41:31,082 epoch 49 - iter 192/245 - loss 0.02524521 - samples/sec: 222.70 - lr: 0.000781\n",
            "2022-12-12 00:41:34,190 epoch 49 - iter 216/245 - loss 0.02529774 - samples/sec: 247.42 - lr: 0.000781\n",
            "2022-12-12 00:41:37,497 epoch 49 - iter 240/245 - loss 0.02591163 - samples/sec: 232.52 - lr: 0.000781\n",
            "2022-12-12 00:41:38,351 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:41:38,353 EPOCH 49 done: loss 0.0258 - lr 0.000781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:41:45,682 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:41:45,702 DEV : loss 0.0527239628136158 - f1-score (micro avg)  0.8008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:41:45,787 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 00:41:45,789 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:41:49,916 epoch 50 - iter 24/245 - loss 0.02354179 - samples/sec: 186.31 - lr: 0.000781\n",
            "2022-12-12 00:41:53,165 epoch 50 - iter 48/245 - loss 0.02304942 - samples/sec: 236.68 - lr: 0.000781\n",
            "2022-12-12 00:41:58,055 epoch 50 - iter 72/245 - loss 0.02683802 - samples/sec: 157.17 - lr: 0.000781\n",
            "2022-12-12 00:42:01,006 epoch 50 - iter 96/245 - loss 0.02633873 - samples/sec: 260.55 - lr: 0.000781\n",
            "2022-12-12 00:42:04,451 epoch 50 - iter 120/245 - loss 0.02602177 - samples/sec: 223.18 - lr: 0.000781\n",
            "2022-12-12 00:42:07,836 epoch 50 - iter 144/245 - loss 0.02596853 - samples/sec: 227.16 - lr: 0.000781\n",
            "2022-12-12 00:42:11,429 epoch 50 - iter 168/245 - loss 0.02633474 - samples/sec: 214.00 - lr: 0.000781\n",
            "2022-12-12 00:42:14,314 epoch 50 - iter 192/245 - loss 0.02611443 - samples/sec: 266.59 - lr: 0.000781\n",
            "2022-12-12 00:42:18,500 epoch 50 - iter 216/245 - loss 0.02638354 - samples/sec: 183.63 - lr: 0.000781\n",
            "2022-12-12 00:42:22,886 epoch 50 - iter 240/245 - loss 0.02628028 - samples/sec: 175.27 - lr: 0.000781\n",
            "2022-12-12 00:42:23,482 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:42:23,483 EPOCH 50 done: loss 0.0262 - lr 0.000781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:42:31,485 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:42:31,506 DEV : loss 0.05290211737155914 - f1-score (micro avg)  0.8016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:42:31,588 Epoch    50: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2022-12-12 00:42:31,589 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 00:42:31,591 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:42:34,857 epoch 51 - iter 24/245 - loss 0.02606544 - samples/sec: 235.55 - lr: 0.000391\n",
            "2022-12-12 00:42:39,012 epoch 51 - iter 48/245 - loss 0.02824679 - samples/sec: 185.00 - lr: 0.000391\n",
            "2022-12-12 00:42:42,801 epoch 51 - iter 72/245 - loss 0.02721593 - samples/sec: 202.91 - lr: 0.000391\n",
            "2022-12-12 00:42:46,300 epoch 51 - iter 96/245 - loss 0.02702886 - samples/sec: 219.70 - lr: 0.000391\n",
            "2022-12-12 00:42:49,888 epoch 51 - iter 120/245 - loss 0.02681326 - samples/sec: 214.27 - lr: 0.000391\n",
            "2022-12-12 00:42:54,163 epoch 51 - iter 144/245 - loss 0.02653610 - samples/sec: 179.83 - lr: 0.000391\n",
            "2022-12-12 00:42:58,732 epoch 51 - iter 168/245 - loss 0.02672649 - samples/sec: 168.24 - lr: 0.000391\n",
            "2022-12-12 00:43:02,361 epoch 51 - iter 192/245 - loss 0.02662238 - samples/sec: 211.85 - lr: 0.000391\n",
            "2022-12-12 00:43:05,328 epoch 51 - iter 216/245 - loss 0.02642848 - samples/sec: 259.20 - lr: 0.000391\n",
            "2022-12-12 00:43:08,705 epoch 51 - iter 240/245 - loss 0.02610125 - samples/sec: 227.66 - lr: 0.000391\n",
            "2022-12-12 00:43:09,637 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:43:09,639 EPOCH 51 done: loss 0.0265 - lr 0.000391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:43:17,019 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:43:17,041 DEV : loss 0.052991803735494614 - f1-score (micro avg)  0.8013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:43:17,124 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 00:43:17,126 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:43:20,062 epoch 52 - iter 24/245 - loss 0.02661215 - samples/sec: 262.07 - lr: 0.000391\n",
            "2022-12-12 00:43:23,842 epoch 52 - iter 48/245 - loss 0.02616719 - samples/sec: 203.36 - lr: 0.000391\n",
            "2022-12-12 00:43:27,017 epoch 52 - iter 72/245 - loss 0.02665110 - samples/sec: 242.19 - lr: 0.000391\n",
            "2022-12-12 00:43:32,451 epoch 52 - iter 96/245 - loss 0.02627430 - samples/sec: 141.44 - lr: 0.000391\n",
            "2022-12-12 00:43:36,300 epoch 52 - iter 120/245 - loss 0.02621390 - samples/sec: 199.76 - lr: 0.000391\n",
            "2022-12-12 00:43:40,349 epoch 52 - iter 144/245 - loss 0.02565733 - samples/sec: 189.82 - lr: 0.000391\n",
            "2022-12-12 00:43:44,580 epoch 52 - iter 168/245 - loss 0.02616870 - samples/sec: 181.72 - lr: 0.000391\n",
            "2022-12-12 00:43:47,726 epoch 52 - iter 192/245 - loss 0.02583370 - samples/sec: 244.39 - lr: 0.000391\n",
            "2022-12-12 00:43:51,366 epoch 52 - iter 216/245 - loss 0.02570324 - samples/sec: 211.23 - lr: 0.000391\n",
            "2022-12-12 00:43:54,303 epoch 52 - iter 240/245 - loss 0.02561724 - samples/sec: 261.79 - lr: 0.000391\n",
            "2022-12-12 00:43:55,332 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:43:55,334 EPOCH 52 done: loss 0.0257 - lr 0.000391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:44:02,632 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:44:02,653 DEV : loss 0.05290910601615906 - f1-score (micro avg)  0.8016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:44:02,738 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 00:44:02,740 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:44:06,961 epoch 53 - iter 24/245 - loss 0.02839747 - samples/sec: 182.16 - lr: 0.000391\n",
            "2022-12-12 00:44:10,372 epoch 53 - iter 48/245 - loss 0.02782537 - samples/sec: 225.45 - lr: 0.000391\n",
            "2022-12-12 00:44:13,421 epoch 53 - iter 72/245 - loss 0.02663294 - samples/sec: 252.22 - lr: 0.000391\n",
            "2022-12-12 00:44:16,788 epoch 53 - iter 96/245 - loss 0.02628096 - samples/sec: 228.34 - lr: 0.000391\n",
            "2022-12-12 00:44:20,485 epoch 53 - iter 120/245 - loss 0.02626413 - samples/sec: 207.96 - lr: 0.000391\n",
            "2022-12-12 00:44:24,134 epoch 53 - iter 144/245 - loss 0.02582245 - samples/sec: 210.70 - lr: 0.000391\n",
            "2022-12-12 00:44:27,370 epoch 53 - iter 168/245 - loss 0.02618170 - samples/sec: 237.60 - lr: 0.000391\n",
            "2022-12-12 00:44:31,748 epoch 53 - iter 192/245 - loss 0.02659458 - samples/sec: 175.58 - lr: 0.000391\n",
            "2022-12-12 00:44:36,221 epoch 53 - iter 216/245 - loss 0.02630856 - samples/sec: 171.85 - lr: 0.000391\n",
            "2022-12-12 00:44:40,093 epoch 53 - iter 240/245 - loss 0.02635251 - samples/sec: 198.57 - lr: 0.000391\n",
            "2022-12-12 00:44:40,653 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:44:40,655 EPOCH 53 done: loss 0.0264 - lr 0.000391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:44:48,883 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:44:48,903 DEV : loss 0.05285537242889404 - f1-score (micro avg)  0.8014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:44:48,987 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 00:44:48,990 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:44:52,527 epoch 54 - iter 24/245 - loss 0.02629050 - samples/sec: 217.52 - lr: 0.000391\n",
            "2022-12-12 00:44:56,444 epoch 54 - iter 48/245 - loss 0.02723530 - samples/sec: 196.32 - lr: 0.000391\n",
            "2022-12-12 00:44:59,340 epoch 54 - iter 72/245 - loss 0.02534500 - samples/sec: 265.52 - lr: 0.000391\n",
            "2022-12-12 00:45:03,014 epoch 54 - iter 96/245 - loss 0.02516725 - samples/sec: 209.23 - lr: 0.000391\n",
            "2022-12-12 00:45:07,410 epoch 54 - iter 120/245 - loss 0.02553682 - samples/sec: 174.88 - lr: 0.000391\n",
            "2022-12-12 00:45:10,519 epoch 54 - iter 144/245 - loss 0.02547046 - samples/sec: 247.34 - lr: 0.000391\n",
            "2022-12-12 00:45:14,896 epoch 54 - iter 168/245 - loss 0.02541109 - samples/sec: 175.62 - lr: 0.000391\n",
            "2022-12-12 00:45:18,950 epoch 54 - iter 192/245 - loss 0.02581585 - samples/sec: 189.65 - lr: 0.000391\n",
            "2022-12-12 00:45:22,115 epoch 54 - iter 216/245 - loss 0.02526168 - samples/sec: 242.96 - lr: 0.000391\n",
            "2022-12-12 00:45:26,495 epoch 54 - iter 240/245 - loss 0.02564079 - samples/sec: 175.50 - lr: 0.000391\n",
            "2022-12-12 00:45:27,142 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:45:27,144 EPOCH 54 done: loss 0.0256 - lr 0.000391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:45:34,482 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:45:34,503 DEV : loss 0.05279255658388138 - f1-score (micro avg)  0.8034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:45:34,587 Epoch    54: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2022-12-12 00:45:34,589 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 00:45:34,592 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:45:38,507 epoch 55 - iter 24/245 - loss 0.02436786 - samples/sec: 196.38 - lr: 0.000195\n",
            "2022-12-12 00:45:42,734 epoch 55 - iter 48/245 - loss 0.02560804 - samples/sec: 181.84 - lr: 0.000195\n",
            "2022-12-12 00:45:46,019 epoch 55 - iter 72/245 - loss 0.02491226 - samples/sec: 234.11 - lr: 0.000195\n",
            "2022-12-12 00:45:49,723 epoch 55 - iter 96/245 - loss 0.02494316 - samples/sec: 207.52 - lr: 0.000195\n",
            "2022-12-12 00:45:52,869 epoch 55 - iter 120/245 - loss 0.02510293 - samples/sec: 244.50 - lr: 0.000195\n",
            "2022-12-12 00:45:56,793 epoch 55 - iter 144/245 - loss 0.02511961 - samples/sec: 195.91 - lr: 0.000195\n",
            "2022-12-12 00:45:59,489 epoch 55 - iter 168/245 - loss 0.02535129 - samples/sec: 285.29 - lr: 0.000195\n",
            "2022-12-12 00:46:03,051 epoch 55 - iter 192/245 - loss 0.02575224 - samples/sec: 215.82 - lr: 0.000195\n",
            "2022-12-12 00:46:07,327 epoch 55 - iter 216/245 - loss 0.02564056 - samples/sec: 179.79 - lr: 0.000195\n",
            "2022-12-12 00:46:12,187 epoch 55 - iter 240/245 - loss 0.02553576 - samples/sec: 158.15 - lr: 0.000195\n",
            "2022-12-12 00:46:12,772 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:46:12,774 EPOCH 55 done: loss 0.0255 - lr 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:46:20,770 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:46:20,790 DEV : loss 0.05284939706325531 - f1-score (micro avg)  0.8034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:46:20,874 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 00:46:20,876 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:46:25,824 epoch 56 - iter 24/245 - loss 0.02647208 - samples/sec: 155.34 - lr: 0.000195\n",
            "2022-12-12 00:46:30,102 epoch 56 - iter 48/245 - loss 0.02732099 - samples/sec: 179.69 - lr: 0.000195\n",
            "2022-12-12 00:46:33,190 epoch 56 - iter 72/245 - loss 0.02791748 - samples/sec: 249.07 - lr: 0.000195\n",
            "2022-12-12 00:46:37,168 epoch 56 - iter 96/245 - loss 0.02725817 - samples/sec: 193.24 - lr: 0.000195\n",
            "2022-12-12 00:46:40,268 epoch 56 - iter 120/245 - loss 0.02617114 - samples/sec: 248.07 - lr: 0.000195\n",
            "2022-12-12 00:46:43,282 epoch 56 - iter 144/245 - loss 0.02656387 - samples/sec: 255.11 - lr: 0.000195\n",
            "2022-12-12 00:46:47,127 epoch 56 - iter 168/245 - loss 0.02647422 - samples/sec: 199.99 - lr: 0.000195\n",
            "2022-12-12 00:46:50,375 epoch 56 - iter 192/245 - loss 0.02606114 - samples/sec: 236.72 - lr: 0.000195\n",
            "2022-12-12 00:46:54,012 epoch 56 - iter 216/245 - loss 0.02627121 - samples/sec: 211.40 - lr: 0.000195\n",
            "2022-12-12 00:46:58,198 epoch 56 - iter 240/245 - loss 0.02631779 - samples/sec: 183.60 - lr: 0.000195\n",
            "2022-12-12 00:46:58,772 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:46:58,773 EPOCH 56 done: loss 0.0263 - lr 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:47:06,044 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:47:06,068 DEV : loss 0.05289311707019806 - f1-score (micro avg)  0.8027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:47:06,151 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 00:47:06,153 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:47:09,719 epoch 57 - iter 24/245 - loss 0.02778393 - samples/sec: 215.67 - lr: 0.000195\n",
            "2022-12-12 00:47:12,766 epoch 57 - iter 48/245 - loss 0.02427305 - samples/sec: 252.41 - lr: 0.000195\n",
            "2022-12-12 00:47:16,024 epoch 57 - iter 72/245 - loss 0.02513660 - samples/sec: 235.99 - lr: 0.000195\n",
            "2022-12-12 00:47:19,166 epoch 57 - iter 96/245 - loss 0.02426736 - samples/sec: 244.74 - lr: 0.000195\n",
            "2022-12-12 00:47:23,074 epoch 57 - iter 120/245 - loss 0.02610872 - samples/sec: 196.72 - lr: 0.000195\n",
            "2022-12-12 00:47:27,246 epoch 57 - iter 144/245 - loss 0.02659660 - samples/sec: 184.28 - lr: 0.000195\n",
            "2022-12-12 00:47:30,735 epoch 57 - iter 168/245 - loss 0.02621336 - samples/sec: 220.39 - lr: 0.000195\n",
            "2022-12-12 00:47:34,432 epoch 57 - iter 192/245 - loss 0.02651921 - samples/sec: 207.96 - lr: 0.000195\n",
            "2022-12-12 00:47:38,889 epoch 57 - iter 216/245 - loss 0.02663146 - samples/sec: 172.43 - lr: 0.000195\n",
            "2022-12-12 00:47:42,526 epoch 57 - iter 240/245 - loss 0.02653052 - samples/sec: 211.41 - lr: 0.000195\n",
            "2022-12-12 00:47:43,447 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:47:43,449 EPOCH 57 done: loss 0.0266 - lr 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:08<00:00,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:47:51,541 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:47:51,564 DEV : loss 0.05288544297218323 - f1-score (micro avg)  0.8021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:47:51,649 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 00:47:51,651 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:47:55,006 epoch 58 - iter 24/245 - loss 0.02627087 - samples/sec: 229.29 - lr: 0.000195\n",
            "2022-12-12 00:47:59,413 epoch 58 - iter 48/245 - loss 0.02629019 - samples/sec: 174.43 - lr: 0.000195\n",
            "2022-12-12 00:48:04,575 epoch 58 - iter 72/245 - loss 0.02764349 - samples/sec: 148.90 - lr: 0.000195\n",
            "2022-12-12 00:48:08,237 epoch 58 - iter 96/245 - loss 0.02717192 - samples/sec: 209.93 - lr: 0.000195\n",
            "2022-12-12 00:48:11,974 epoch 58 - iter 120/245 - loss 0.02600061 - samples/sec: 205.72 - lr: 0.000195\n",
            "2022-12-12 00:48:15,501 epoch 58 - iter 144/245 - loss 0.02559039 - samples/sec: 218.05 - lr: 0.000195\n",
            "2022-12-12 00:48:18,840 epoch 58 - iter 168/245 - loss 0.02549325 - samples/sec: 230.23 - lr: 0.000195\n",
            "2022-12-12 00:48:22,401 epoch 58 - iter 192/245 - loss 0.02565497 - samples/sec: 215.93 - lr: 0.000195\n",
            "2022-12-12 00:48:26,212 epoch 58 - iter 216/245 - loss 0.02554123 - samples/sec: 201.75 - lr: 0.000195\n",
            "2022-12-12 00:48:29,115 epoch 58 - iter 240/245 - loss 0.02562570 - samples/sec: 264.89 - lr: 0.000195\n",
            "2022-12-12 00:48:29,599 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:48:29,601 EPOCH 58 done: loss 0.0257 - lr 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:07<00:00,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:48:37,597 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:48:37,618 DEV : loss 0.052935414016246796 - f1-score (micro avg)  0.8009\n",
            "2022-12-12 00:48:37,699 Epoch    58: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2022-12-12 00:48:37,701 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 00:48:37,703 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:48:37,704 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:48:37,707 learning rate too small - quitting training!\n",
            "2022-12-12 00:48:37,708 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:48:39,984 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 00:48:39,987 loading file resources/taggers/sota-ner-flair/best-model.pt\n",
            "2022-12-12 00:48:41,901 SequenceTagger predicts: Dictionary with 27 tags: O, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-LEGISLACAO, B-LEGISLACAO, E-LEGISLACAO, I-LEGISLACAO, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-TEMPO, B-TEMPO, E-TEMPO, I-TEMPO, S-JURISPRUDENCIA, B-JURISPRUDENCIA, E-JURISPRUDENCIA, I-JURISPRUDENCIA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL, <START>, <STOP>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44/44 [00:08<00:00,  5.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-12 00:48:50,382 Evaluating as a multi-label problem: False\n",
            "2022-12-12 00:48:50,402 0.8704\t0.8086\t0.8383\t0.728\n",
            "2022-12-12 00:48:50,403 \n",
            "Results:\n",
            "- F-score (micro) 0.8383\n",
            "- F-score (macro) 0.8219\n",
            "- Accuracy 0.728\n",
            "\n",
            "By class:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   ORGANIZACAO     0.8529    0.7525    0.7996       501\n",
            "    LEGISLACAO     0.9054    0.8862    0.8957       378\n",
            "        PESSOA     0.8991    0.8798    0.8894       233\n",
            "         TEMPO     0.8750    0.8385    0.8564       192\n",
            "JURISPRUDENCIA     0.8377    0.6973    0.7611       185\n",
            "         LOCAL     0.7143    0.7447    0.7292        47\n",
            "\n",
            "     micro avg     0.8704    0.8086    0.8383      1536\n",
            "     macro avg     0.8474    0.7998    0.8219      1536\n",
            "  weighted avg     0.8695    0.8086    0.8372      1536\n",
            "\n",
            "2022-12-12 00:48:50,405 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_score': 0.8383395207559906,\n",
              " 'dev_score_history': [0.32655737704918036,\n",
              "  0.4511825348696179,\n",
              "  0.567515923566879,\n",
              "  0.599316133043208,\n",
              "  0.636336245857186,\n",
              "  0.6696750902527077,\n",
              "  0.678129713423831,\n",
              "  0.7148760330578512,\n",
              "  0.7014542343883661,\n",
              "  0.7322274881516588,\n",
              "  0.7622619734564338,\n",
              "  0.7377238590410167,\n",
              "  0.7336368810472397,\n",
              "  0.7471763683753258,\n",
              "  0.727056727056727,\n",
              "  0.7724377533294731,\n",
              "  0.7980714690867838,\n",
              "  0.787369640787949,\n",
              "  0.7912467607255974,\n",
              "  0.7876598110061145,\n",
              "  0.7924421883812747,\n",
              "  0.789443488238669,\n",
              "  0.7911392405063291,\n",
              "  0.7792059411596687,\n",
              "  0.7920392269974043,\n",
              "  0.7996580222285552,\n",
              "  0.7952981651376148,\n",
              "  0.7967990854529865,\n",
              "  0.7959942775393419,\n",
              "  0.7990828317569504,\n",
              "  0.801254633589963,\n",
              "  0.8028612303290414,\n",
              "  0.8001142204454598,\n",
              "  0.8037865748709122,\n",
              "  0.8031990859754357,\n",
              "  0.8011510791366907,\n",
              "  0.8006853226727585,\n",
              "  0.8034433285509326,\n",
              "  0.8015940791346428,\n",
              "  0.8029697315819532,\n",
              "  0.8029697315819532,\n",
              "  0.8032082497851618,\n",
              "  0.8026353480378114,\n",
              "  0.8021757801316921,\n",
              "  0.8021757801316921,\n",
              "  0.8010276905509562,\n",
              "  0.8007990867579909,\n",
              "  0.8031990859754357,\n",
              "  0.8008002286367535,\n",
              "  0.801600914808462,\n",
              "  0.8012582213325709,\n",
              "  0.801600914808462,\n",
              "  0.8013718205201487,\n",
              "  0.8034285714285715,\n",
              "  0.8034285714285715,\n",
              "  0.8027444253859348,\n",
              "  0.8020594965675057,\n",
              "  0.8009153318077802],\n",
              " 'train_loss_history': [0.5048003804188342,\n",
              "  0.1958829199709849,\n",
              "  0.12749621082999493,\n",
              "  0.10089903746682506,\n",
              "  0.08703214769280172,\n",
              "  0.07722613695204109,\n",
              "  0.07146074901688242,\n",
              "  0.06507828246680053,\n",
              "  0.06261597257356821,\n",
              "  0.057776428304381816,\n",
              "  0.05381184701324708,\n",
              "  0.05289683797464421,\n",
              "  0.04961062042311266,\n",
              "  0.04798701930075302,\n",
              "  0.0469837466491133,\n",
              "  0.03979200956975623,\n",
              "  0.03899199772205127,\n",
              "  0.03740283527471683,\n",
              "  0.03609392497257684,\n",
              "  0.03541480733457782,\n",
              "  0.03475482253044353,\n",
              "  0.03154560057948464,\n",
              "  0.03123658529379855,\n",
              "  0.030952589212502782,\n",
              "  0.03082815125440515,\n",
              "  0.029772981003873045,\n",
              "  0.02922758875590443,\n",
              "  0.028695498342343542,\n",
              "  0.0287057931017939,\n",
              "  0.028201011273345122,\n",
              "  0.028182619559937325,\n",
              "  0.02727203594751109,\n",
              "  0.02790072544959263,\n",
              "  0.02728578713943723,\n",
              "  0.027310440042912068,\n",
              "  0.025949751402642874,\n",
              "  0.027226286666892013,\n",
              "  0.026496847375799798,\n",
              "  0.026221018527125484,\n",
              "  0.026382674361961733,\n",
              "  0.02676527992750036,\n",
              "  0.02641855268477104,\n",
              "  0.026538066877074457,\n",
              "  0.02609422942826799,\n",
              "  0.02656836124057908,\n",
              "  0.02655430550777553,\n",
              "  0.026421123180148904,\n",
              "  0.025927933071950085,\n",
              "  0.025838668520365104,\n",
              "  0.026233298126420224,\n",
              "  0.02653653352440498,\n",
              "  0.02569521911882243,\n",
              "  0.02644479644164046,\n",
              "  0.025603375553233644,\n",
              "  0.02550248733655142,\n",
              "  0.026290102453854942,\n",
              "  0.026608914159373814,\n",
              "  0.025660465254637405],\n",
              " 'dev_loss_history': [0.2923157811164856,\n",
              "  0.15578848123550415,\n",
              "  0.11385537683963776,\n",
              "  0.09648843109607697,\n",
              "  0.08739913254976273,\n",
              "  0.08484203368425369,\n",
              "  0.08396030217409134,\n",
              "  0.0750160664319992,\n",
              "  0.07586988061666489,\n",
              "  0.0714409276843071,\n",
              "  0.06436680257320404,\n",
              "  0.06989233940839767,\n",
              "  0.0637994259595871,\n",
              "  0.06944262236356735,\n",
              "  0.075251005589962,\n",
              "  0.06169668585062027,\n",
              "  0.05496588721871376,\n",
              "  0.05796543508768082,\n",
              "  0.058128539472818375,\n",
              "  0.05565234646201134,\n",
              "  0.05434331297874451,\n",
              "  0.05765221640467644,\n",
              "  0.05738389119505882,\n",
              "  0.055567171424627304,\n",
              "  0.05524937063455582,\n",
              "  0.05366700515151024,\n",
              "  0.05467750132083893,\n",
              "  0.053843773901462555,\n",
              "  0.053881824016571045,\n",
              "  0.053141385316848755,\n",
              "  0.05262794718146324,\n",
              "  0.053773507475852966,\n",
              "  0.053234782069921494,\n",
              "  0.054175663739442825,\n",
              "  0.05312367528676987,\n",
              "  0.05461762845516205,\n",
              "  0.05320560187101364,\n",
              "  0.05393466725945473,\n",
              "  0.05306617170572281,\n",
              "  0.0536733977496624,\n",
              "  0.05328686162829399,\n",
              "  0.05319751054048538,\n",
              "  0.053099218755960464,\n",
              "  0.05307067930698395,\n",
              "  0.05302637815475464,\n",
              "  0.052497994154691696,\n",
              "  0.05272059515118599,\n",
              "  0.05287087708711624,\n",
              "  0.0527239628136158,\n",
              "  0.05290211737155914,\n",
              "  0.052991803735494614,\n",
              "  0.05290910601615906,\n",
              "  0.05285537242889404,\n",
              "  0.05279255658388138,\n",
              "  0.05284939706325531,\n",
              "  0.05289311707019806,\n",
              "  0.05288544297218323,\n",
              "  0.052935414016246796]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# Initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# Start training\n",
        "trainer.train('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTcj9YXEf5HQ"
      },
      "source": [
        "## Teste 2.2 NER Flair Stacked Embeddings com Corpus Lener_br\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLzcp2Rff5HV"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw5JyQQif5HV"
      },
      "outputs": [],
      "source": [
        "## Importes\n",
        "## datasets\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import FlairEmbeddings, StackedEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljmFfYgSf5HV"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83XBVxjof5HV",
        "outputId": "fbef11d0-c23f-43aa-a95a-2bcb31d3b7e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8v2EiBnf5HW",
        "outputId": "e9114c67-4a10-40a5-9bc4-32988b52c17e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:36:41,670 Reading data from /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig\n",
            "2022-12-15 22:36:41,674 Train: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig/train.txt\n",
            "2022-12-15 22:36:41,675 Dev: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig/dev.txt\n",
            "2022-12-15 22:36:41,677 Test: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig/test.txt\n"
          ]
        }
      ],
      "source": [
        "## carregando um corpus e definindo as colunas\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Fv6acGf5HW",
        "outputId": "293cb092-36fd-4523-ad20-f1fd4376d140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:36:49,338 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7827it [00:00, 49652.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:36:49,548 Dictionary created for label 'ner' with 7 values: ORGANIZACAO (seen 2400 times), LEGISLACAO (seen 1920 times), PESSOA (seen 1525 times), TEMPO (seen 1334 times), JURISPRUDENCIA (seen 1104 times), LOCAL (seen 611 times)\n",
            "Dictionary with 7 tags: <unk>, ORGANIZACAO, LEGISLACAO, PESSOA, TEMPO, JURISPRUDENCIA, LOCAL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCyAXFcqf5HW"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "587jiNMHf5HW",
        "outputId": "eb76d7a8-feeb-4574-ec90-4140df741238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:37:16,551 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-forward.pt not found in cache, downloading to /tmp/tmpj6hq3w1h\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 72819080/72819080 [01:36<00:00, 758206.02B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:39:09,224 copying /tmp/tmpj6hq3w1h to cache at /root/.flair/embeddings/lm-pt-forward.pt\n",
            "2022-12-15 22:39:09,280 removing temp file /tmp/tmpj6hq3w1h\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:39:28,913 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-backward.pt not found in cache, downloading to /tmp/tmpfd8qtr6v\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 72819080/72819080 [01:41<00:00, 717468.69B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:41:21,566 copying /tmp/tmpfd8qtr6v to cache at /root/.flair/embeddings/lm-pt-backward.pt\n",
            "2022-12-15 22:41:21,624 removing temp file /tmp/tmpfd8qtr6v\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Empilhando os Embeddings\n",
        "# init Flair embeddings\n",
        "flair_embedding_forward = FlairEmbeddings('pt-forward')\n",
        "flair_embedding_backward = FlairEmbeddings('pt-backward')\n",
        "\n",
        "# create a StackedEmbedding object that combines glove and forward/backward flair embeddings\n",
        "embeddings = StackedEmbeddings([\n",
        "                                        flair_embedding_forward,\n",
        "                                        flair_embedding_backward,\n",
        "                                       ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMiKWbCFf5HW"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzaVRDGIf5HX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f869a412-26d8-437a-98b5-51ef6cdcbe64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:41:21,854 SequenceTagger predicts: Dictionary with 25 tags: O, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-LEGISLACAO, B-LEGISLACAO, E-LEGISLACAO, I-LEGISLACAO, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-TEMPO, B-TEMPO, E-TEMPO, I-TEMPO, S-JURISPRUDENCIA, B-JURISPRUDENCIA, E-JURISPRUDENCIA, I-JURISPRUDENCIA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVRmATIZf5HX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ecda1a5-42b5-41f5-c195-180c8e9f0f0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:41:22,092 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:41:22,093 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (rnn): LSTM(4096, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=27, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-12-15 22:41:22,096 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:41:22,097 Corpus: \"Corpus: 7827 train + 1176 dev + 1389 test sentences\"\n",
            "2022-12-15 22:41:22,098 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:41:22,099 Parameters:\n",
            "2022-12-15 22:41:22,104  - learning_rate: \"0.100000\"\n",
            "2022-12-15 22:41:22,106  - mini_batch_size: \"32\"\n",
            "2022-12-15 22:41:22,109  - patience: \"3\"\n",
            "2022-12-15 22:41:22,110  - anneal_factor: \"0.5\"\n",
            "2022-12-15 22:41:22,115  - max_epochs: \"150\"\n",
            "2022-12-15 22:41:22,118  - shuffle: \"True\"\n",
            "2022-12-15 22:41:22,120  - train_with_dev: \"False\"\n",
            "2022-12-15 22:41:22,123  - batch_growth_annealing: \"False\"\n",
            "2022-12-15 22:41:22,125 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:41:22,126 Model training base path: \"resources/taggers/sota-ner-flair\"\n",
            "2022-12-15 22:41:22,132 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:41:22,134 Device: cuda:0\n",
            "2022-12-15 22:41:22,136 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:41:22,138 Embeddings storage mode: cpu\n",
            "2022-12-15 22:41:22,139 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:41:52,854 epoch 1 - iter 24/245 - loss 1.00406232 - samples/sec: 25.01 - lr: 0.100000\n",
            "2022-12-15 22:42:18,396 epoch 1 - iter 48/245 - loss 0.82255041 - samples/sec: 30.07 - lr: 0.100000\n",
            "2022-12-15 22:42:43,898 epoch 1 - iter 72/245 - loss 0.68627406 - samples/sec: 30.12 - lr: 0.100000\n",
            "2022-12-15 22:43:11,251 epoch 1 - iter 96/245 - loss 0.57390769 - samples/sec: 28.08 - lr: 0.100000\n",
            "2022-12-15 22:43:30,514 epoch 1 - iter 120/245 - loss 0.51751841 - samples/sec: 39.88 - lr: 0.100000\n",
            "2022-12-15 22:43:52,155 epoch 1 - iter 144/245 - loss 0.48678445 - samples/sec: 35.50 - lr: 0.100000\n",
            "2022-12-15 22:44:15,987 epoch 1 - iter 168/245 - loss 0.43429244 - samples/sec: 32.23 - lr: 0.100000\n",
            "2022-12-15 22:44:46,203 epoch 1 - iter 192/245 - loss 0.40681921 - samples/sec: 25.42 - lr: 0.100000\n",
            "2022-12-15 22:45:14,893 epoch 1 - iter 216/245 - loss 0.38040665 - samples/sec: 26.77 - lr: 0.100000\n",
            "2022-12-15 22:45:42,986 epoch 1 - iter 240/245 - loss 0.35370371 - samples/sec: 27.34 - lr: 0.100000\n",
            "2022-12-15 22:45:47,331 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:45:47,333 EPOCH 1 done: loss 0.3501 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:42<00:00,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:46:30,313 Evaluating as a multi-label problem: False\n",
            "2022-12-15 22:46:30,341 DEV : loss 0.17013703286647797 - f1-score (micro avg)  0.596\n",
            "2022-12-15 22:46:30,469 BAD EPOCHS (no improvement): 0\n",
            "2022-12-15 22:46:30,471 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:46:30,866 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:46:37,990 epoch 2 - iter 24/245 - loss 0.15698277 - samples/sec: 107.91 - lr: 0.100000\n",
            "2022-12-15 22:46:44,692 epoch 2 - iter 48/245 - loss 0.15709476 - samples/sec: 114.67 - lr: 0.100000\n",
            "2022-12-15 22:46:49,519 epoch 2 - iter 72/245 - loss 0.14674881 - samples/sec: 159.24 - lr: 0.100000\n",
            "2022-12-15 22:46:55,200 epoch 2 - iter 96/245 - loss 0.14350264 - samples/sec: 135.31 - lr: 0.100000\n",
            "2022-12-15 22:47:00,922 epoch 2 - iter 120/245 - loss 0.13685348 - samples/sec: 134.32 - lr: 0.100000\n",
            "2022-12-15 22:47:06,815 epoch 2 - iter 144/245 - loss 0.13138519 - samples/sec: 130.42 - lr: 0.100000\n",
            "2022-12-15 22:47:13,332 epoch 2 - iter 168/245 - loss 0.12520622 - samples/sec: 117.93 - lr: 0.100000\n",
            "2022-12-15 22:47:18,506 epoch 2 - iter 192/245 - loss 0.12164040 - samples/sec: 148.57 - lr: 0.100000\n",
            "2022-12-15 22:47:23,814 epoch 2 - iter 216/245 - loss 0.11856064 - samples/sec: 144.78 - lr: 0.100000\n",
            "2022-12-15 22:47:29,399 epoch 2 - iter 240/245 - loss 0.11491279 - samples/sec: 137.64 - lr: 0.100000\n",
            "2022-12-15 22:47:30,165 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:47:30,167 EPOCH 2 done: loss 0.1144 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:47:41,017 Evaluating as a multi-label problem: False\n",
            "2022-12-15 22:47:41,040 DEV : loss 0.08818749338388443 - f1-score (micro avg)  0.7386\n",
            "2022-12-15 22:47:41,170 BAD EPOCHS (no improvement): 0\n",
            "2022-12-15 22:47:41,173 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:47:41,638 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:47:47,959 epoch 3 - iter 24/245 - loss 0.07915326 - samples/sec: 121.62 - lr: 0.100000\n",
            "2022-12-15 22:47:54,804 epoch 3 - iter 48/245 - loss 0.07974518 - samples/sec: 112.27 - lr: 0.100000\n",
            "2022-12-15 22:48:02,505 epoch 3 - iter 72/245 - loss 0.08251373 - samples/sec: 99.78 - lr: 0.100000\n",
            "2022-12-15 22:48:07,459 epoch 3 - iter 96/245 - loss 0.08165152 - samples/sec: 155.15 - lr: 0.100000\n",
            "2022-12-15 22:48:13,199 epoch 3 - iter 120/245 - loss 0.08041906 - samples/sec: 133.91 - lr: 0.100000\n",
            "2022-12-15 22:48:18,656 epoch 3 - iter 144/245 - loss 0.08086948 - samples/sec: 140.83 - lr: 0.100000\n",
            "2022-12-15 22:48:23,152 epoch 3 - iter 168/245 - loss 0.07787205 - samples/sec: 170.99 - lr: 0.100000\n",
            "2022-12-15 22:48:28,830 epoch 3 - iter 192/245 - loss 0.07684415 - samples/sec: 135.38 - lr: 0.100000\n",
            "2022-12-15 22:48:34,574 epoch 3 - iter 216/245 - loss 0.07527850 - samples/sec: 133.80 - lr: 0.100000\n",
            "2022-12-15 22:48:39,468 epoch 3 - iter 240/245 - loss 0.07363338 - samples/sec: 157.09 - lr: 0.100000\n",
            "2022-12-15 22:48:41,032 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:48:41,033 EPOCH 3 done: loss 0.0742 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:48:51,039 Evaluating as a multi-label problem: False\n",
            "2022-12-15 22:48:51,062 DEV : loss 0.060143593698740005 - f1-score (micro avg)  0.7974\n",
            "2022-12-15 22:48:51,199 BAD EPOCHS (no improvement): 0\n",
            "2022-12-15 22:48:51,201 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:48:51,662 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:48:57,101 epoch 4 - iter 24/245 - loss 0.05479600 - samples/sec: 141.37 - lr: 0.100000\n",
            "2022-12-15 22:49:02,918 epoch 4 - iter 48/245 - loss 0.06093690 - samples/sec: 132.14 - lr: 0.100000\n",
            "2022-12-15 22:49:09,927 epoch 4 - iter 72/245 - loss 0.06155248 - samples/sec: 109.65 - lr: 0.100000\n",
            "2022-12-15 22:49:16,444 epoch 4 - iter 96/245 - loss 0.06063725 - samples/sec: 117.95 - lr: 0.100000\n",
            "2022-12-15 22:49:22,470 epoch 4 - iter 120/245 - loss 0.06099043 - samples/sec: 127.54 - lr: 0.100000\n",
            "2022-12-15 22:49:27,655 epoch 4 - iter 144/245 - loss 0.06099086 - samples/sec: 148.26 - lr: 0.100000\n",
            "2022-12-15 22:49:34,415 epoch 4 - iter 168/245 - loss 0.06037620 - samples/sec: 113.68 - lr: 0.100000\n",
            "2022-12-15 22:49:41,413 epoch 4 - iter 192/245 - loss 0.06035901 - samples/sec: 109.82 - lr: 0.100000\n",
            "2022-12-15 22:49:47,522 epoch 4 - iter 216/245 - loss 0.05950757 - samples/sec: 125.80 - lr: 0.100000\n",
            "2022-12-15 22:49:51,999 epoch 4 - iter 240/245 - loss 0.05802808 - samples/sec: 171.75 - lr: 0.100000\n",
            "2022-12-15 22:49:52,904 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:49:52,906 EPOCH 4 done: loss 0.0580 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:50:03,159 Evaluating as a multi-label problem: False\n",
            "2022-12-15 22:50:03,188 DEV : loss 0.05808359757065773 - f1-score (micro avg)  0.7867\n",
            "2022-12-15 22:50:03,320 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 22:50:03,322 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:50:09,570 epoch 5 - iter 24/245 - loss 0.04502739 - samples/sec: 123.03 - lr: 0.100000\n",
            "2022-12-15 22:50:14,998 epoch 5 - iter 48/245 - loss 0.04593921 - samples/sec: 141.59 - lr: 0.100000\n",
            "2022-12-15 22:50:20,869 epoch 5 - iter 72/245 - loss 0.04871098 - samples/sec: 130.92 - lr: 0.100000\n",
            "2022-12-15 22:50:26,547 epoch 5 - iter 96/245 - loss 0.04831732 - samples/sec: 135.38 - lr: 0.100000\n",
            "2022-12-15 22:50:33,610 epoch 5 - iter 120/245 - loss 0.04716250 - samples/sec: 108.80 - lr: 0.100000\n",
            "2022-12-15 22:50:38,610 epoch 5 - iter 144/245 - loss 0.04772626 - samples/sec: 153.75 - lr: 0.100000\n",
            "2022-12-15 22:50:43,743 epoch 5 - iter 168/245 - loss 0.05018310 - samples/sec: 149.76 - lr: 0.100000\n",
            "2022-12-15 22:50:50,294 epoch 5 - iter 192/245 - loss 0.04912082 - samples/sec: 117.31 - lr: 0.100000\n",
            "2022-12-15 22:50:54,937 epoch 5 - iter 216/245 - loss 0.04820535 - samples/sec: 165.57 - lr: 0.100000\n",
            "2022-12-15 22:51:01,857 epoch 5 - iter 240/245 - loss 0.04782338 - samples/sec: 111.05 - lr: 0.100000\n",
            "2022-12-15 22:51:03,090 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:51:03,092 EPOCH 5 done: loss 0.0485 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:51:14,014 Evaluating as a multi-label problem: False\n",
            "2022-12-15 22:51:14,039 DEV : loss 0.048343438655138016 - f1-score (micro avg)  0.8264\n",
            "2022-12-15 22:51:14,182 BAD EPOCHS (no improvement): 0\n",
            "2022-12-15 22:51:14,185 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:51:14,638 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:51:20,720 epoch 6 - iter 24/245 - loss 0.04739896 - samples/sec: 126.40 - lr: 0.100000\n",
            "2022-12-15 22:51:26,350 epoch 6 - iter 48/245 - loss 0.04189560 - samples/sec: 136.51 - lr: 0.100000\n",
            "2022-12-15 22:51:31,285 epoch 6 - iter 72/245 - loss 0.04045147 - samples/sec: 155.76 - lr: 0.100000\n",
            "2022-12-15 22:51:35,947 epoch 6 - iter 96/245 - loss 0.04174507 - samples/sec: 164.92 - lr: 0.100000\n",
            "2022-12-15 22:51:40,844 epoch 6 - iter 120/245 - loss 0.04124404 - samples/sec: 156.96 - lr: 0.100000\n",
            "2022-12-15 22:51:47,127 epoch 6 - iter 144/245 - loss 0.04143596 - samples/sec: 122.31 - lr: 0.100000\n",
            "2022-12-15 22:51:52,499 epoch 6 - iter 168/245 - loss 0.04092975 - samples/sec: 143.07 - lr: 0.100000\n",
            "2022-12-15 22:52:00,166 epoch 6 - iter 192/245 - loss 0.04086186 - samples/sec: 100.22 - lr: 0.100000\n",
            "2022-12-15 22:52:05,690 epoch 6 - iter 216/245 - loss 0.04026154 - samples/sec: 139.13 - lr: 0.100000\n",
            "2022-12-15 22:52:12,749 epoch 6 - iter 240/245 - loss 0.04024682 - samples/sec: 108.87 - lr: 0.100000\n",
            "2022-12-15 22:52:14,049 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:52:14,051 EPOCH 6 done: loss 0.0402 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:52:24,454 Evaluating as a multi-label problem: False\n",
            "2022-12-15 22:52:24,480 DEV : loss 0.05134847015142441 - f1-score (micro avg)  0.8141\n",
            "2022-12-15 22:52:24,615 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 22:52:24,617 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:52:30,041 epoch 7 - iter 24/245 - loss 0.03685288 - samples/sec: 141.75 - lr: 0.100000\n",
            "2022-12-15 22:52:35,383 epoch 7 - iter 48/245 - loss 0.03557998 - samples/sec: 143.90 - lr: 0.100000\n",
            "2022-12-15 22:52:41,874 epoch 7 - iter 72/245 - loss 0.03687271 - samples/sec: 118.39 - lr: 0.100000\n",
            "2022-12-15 22:52:49,049 epoch 7 - iter 96/245 - loss 0.03617751 - samples/sec: 107.11 - lr: 0.100000\n",
            "2022-12-15 22:52:54,020 epoch 7 - iter 120/245 - loss 0.03592187 - samples/sec: 154.63 - lr: 0.100000\n",
            "2022-12-15 22:53:00,095 epoch 7 - iter 144/245 - loss 0.03567195 - samples/sec: 126.53 - lr: 0.100000\n",
            "2022-12-15 22:53:06,214 epoch 7 - iter 168/245 - loss 0.03519841 - samples/sec: 125.60 - lr: 0.100000\n",
            "2022-12-15 22:53:13,048 epoch 7 - iter 192/245 - loss 0.03646793 - samples/sec: 112.46 - lr: 0.100000\n",
            "2022-12-15 22:53:18,514 epoch 7 - iter 216/245 - loss 0.03665363 - samples/sec: 140.59 - lr: 0.100000\n",
            "2022-12-15 22:53:23,371 epoch 7 - iter 240/245 - loss 0.03641915 - samples/sec: 158.29 - lr: 0.100000\n",
            "2022-12-15 22:53:24,951 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:53:24,953 EPOCH 7 done: loss 0.0364 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:11<00:00,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:53:36,066 Evaluating as a multi-label problem: False\n",
            "2022-12-15 22:53:36,090 DEV : loss 0.0450560636818409 - f1-score (micro avg)  0.8288\n",
            "2022-12-15 22:53:36,226 BAD EPOCHS (no improvement): 0\n",
            "2022-12-15 22:53:36,228 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:53:36,697 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:53:42,257 epoch 8 - iter 24/245 - loss 0.03232879 - samples/sec: 138.31 - lr: 0.100000\n",
            "2022-12-15 22:53:48,001 epoch 8 - iter 48/245 - loss 0.03555335 - samples/sec: 133.79 - lr: 0.100000\n",
            "2022-12-15 22:53:53,404 epoch 8 - iter 72/245 - loss 0.03278374 - samples/sec: 142.27 - lr: 0.100000\n",
            "2022-12-15 22:53:58,333 epoch 8 - iter 96/245 - loss 0.03278495 - samples/sec: 155.96 - lr: 0.100000\n",
            "2022-12-15 22:54:04,044 epoch 8 - iter 120/245 - loss 0.03295208 - samples/sec: 134.59 - lr: 0.100000\n",
            "2022-12-15 22:54:10,611 epoch 8 - iter 144/245 - loss 0.03283708 - samples/sec: 117.03 - lr: 0.100000\n",
            "2022-12-15 22:54:17,679 epoch 8 - iter 168/245 - loss 0.03307726 - samples/sec: 108.73 - lr: 0.100000\n",
            "2022-12-15 22:54:24,958 epoch 8 - iter 192/245 - loss 0.03254179 - samples/sec: 105.58 - lr: 0.100000\n",
            "2022-12-15 22:54:29,843 epoch 8 - iter 216/245 - loss 0.03190358 - samples/sec: 157.37 - lr: 0.100000\n",
            "2022-12-15 22:54:36,735 epoch 8 - iter 240/245 - loss 0.03152113 - samples/sec: 111.50 - lr: 0.100000\n",
            "2022-12-15 22:54:37,723 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:54:37,725 EPOCH 8 done: loss 0.0314 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:11<00:00,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:54:48,820 Evaluating as a multi-label problem: False\n",
            "2022-12-15 22:54:48,843 DEV : loss 0.04213937744498253 - f1-score (micro avg)  0.8443\n",
            "2022-12-15 22:54:48,978 BAD EPOCHS (no improvement): 0\n",
            "2022-12-15 22:54:48,981 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:54:49,447 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:54:55,356 epoch 9 - iter 24/245 - loss 0.03133572 - samples/sec: 130.15 - lr: 0.100000\n",
            "2022-12-15 22:55:02,604 epoch 9 - iter 48/245 - loss 0.03046789 - samples/sec: 106.01 - lr: 0.100000\n",
            "2022-12-15 22:55:07,548 epoch 9 - iter 72/245 - loss 0.02959853 - samples/sec: 155.49 - lr: 0.100000\n",
            "2022-12-15 22:55:12,833 epoch 9 - iter 96/245 - loss 0.03006850 - samples/sec: 145.46 - lr: 0.100000\n",
            "2022-12-15 22:55:17,666 epoch 9 - iter 120/245 - loss 0.03038277 - samples/sec: 159.05 - lr: 0.100000\n",
            "2022-12-15 22:55:23,128 epoch 9 - iter 144/245 - loss 0.02945554 - samples/sec: 140.72 - lr: 0.100000\n",
            "2022-12-15 22:55:31,365 epoch 9 - iter 168/245 - loss 0.03000327 - samples/sec: 93.29 - lr: 0.100000\n",
            "2022-12-15 22:55:37,048 epoch 9 - iter 192/245 - loss 0.02983885 - samples/sec: 135.25 - lr: 0.100000\n",
            "2022-12-15 22:55:42,533 epoch 9 - iter 216/245 - loss 0.02967886 - samples/sec: 140.12 - lr: 0.100000\n",
            "2022-12-15 22:55:48,030 epoch 9 - iter 240/245 - loss 0.02937185 - samples/sec: 139.84 - lr: 0.100000\n",
            "2022-12-15 22:55:49,018 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:55:49,020 EPOCH 9 done: loss 0.0295 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:55:59,298 Evaluating as a multi-label problem: False\n",
            "2022-12-15 22:55:59,320 DEV : loss 0.03852430731058121 - f1-score (micro avg)  0.8573\n",
            "2022-12-15 22:55:59,448 BAD EPOCHS (no improvement): 0\n",
            "2022-12-15 22:55:59,450 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:55:59,924 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:56:05,115 epoch 10 - iter 24/245 - loss 0.02552663 - samples/sec: 148.17 - lr: 0.100000\n",
            "2022-12-15 22:56:11,835 epoch 10 - iter 48/245 - loss 0.02779606 - samples/sec: 114.36 - lr: 0.100000\n",
            "2022-12-15 22:56:17,986 epoch 10 - iter 72/245 - loss 0.02717635 - samples/sec: 124.93 - lr: 0.100000\n",
            "2022-12-15 22:56:24,001 epoch 10 - iter 96/245 - loss 0.02771204 - samples/sec: 127.77 - lr: 0.100000\n",
            "2022-12-15 22:56:30,259 epoch 10 - iter 120/245 - loss 0.02773326 - samples/sec: 122.81 - lr: 0.100000\n",
            "2022-12-15 22:56:35,768 epoch 10 - iter 144/245 - loss 0.02674901 - samples/sec: 139.52 - lr: 0.100000\n",
            "2022-12-15 22:56:43,479 epoch 10 - iter 168/245 - loss 0.02695934 - samples/sec: 99.66 - lr: 0.100000\n",
            "2022-12-15 22:56:49,016 epoch 10 - iter 192/245 - loss 0.02727299 - samples/sec: 138.82 - lr: 0.100000\n",
            "2022-12-15 22:56:54,614 epoch 10 - iter 216/245 - loss 0.02758214 - samples/sec: 137.30 - lr: 0.100000\n",
            "2022-12-15 22:56:59,441 epoch 10 - iter 240/245 - loss 0.02734702 - samples/sec: 159.26 - lr: 0.100000\n",
            "2022-12-15 22:57:00,160 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:57:00,162 EPOCH 10 done: loss 0.0275 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:57:11,090 Evaluating as a multi-label problem: False\n",
            "2022-12-15 22:57:11,114 DEV : loss 0.040289729833602905 - f1-score (micro avg)  0.8403\n",
            "2022-12-15 22:57:11,254 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 22:57:11,258 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:57:16,772 epoch 11 - iter 24/245 - loss 0.02588168 - samples/sec: 139.44 - lr: 0.100000\n",
            "2022-12-15 22:57:22,770 epoch 11 - iter 48/245 - loss 0.02721431 - samples/sec: 128.14 - lr: 0.100000\n",
            "2022-12-15 22:57:29,142 epoch 11 - iter 72/245 - loss 0.02721008 - samples/sec: 120.63 - lr: 0.100000\n",
            "2022-12-15 22:57:36,102 epoch 11 - iter 96/245 - loss 0.02699674 - samples/sec: 110.41 - lr: 0.100000\n",
            "2022-12-15 22:57:41,864 epoch 11 - iter 120/245 - loss 0.02608022 - samples/sec: 133.38 - lr: 0.100000\n",
            "2022-12-15 22:57:47,334 epoch 11 - iter 144/245 - loss 0.02575935 - samples/sec: 140.53 - lr: 0.100000\n",
            "2022-12-15 22:57:53,313 epoch 11 - iter 168/245 - loss 0.02670625 - samples/sec: 128.54 - lr: 0.100000\n",
            "2022-12-15 22:57:58,255 epoch 11 - iter 192/245 - loss 0.02638669 - samples/sec: 155.56 - lr: 0.100000\n",
            "2022-12-15 22:58:03,358 epoch 11 - iter 216/245 - loss 0.02604832 - samples/sec: 150.63 - lr: 0.100000\n",
            "2022-12-15 22:58:08,492 epoch 11 - iter 240/245 - loss 0.02600988 - samples/sec: 149.69 - lr: 0.100000\n",
            "2022-12-15 22:58:11,132 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:58:11,134 EPOCH 11 done: loss 0.0260 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:58:21,343 Evaluating as a multi-label problem: False\n",
            "2022-12-15 22:58:21,366 DEV : loss 0.038068242371082306 - f1-score (micro avg)  0.8523\n",
            "2022-12-15 22:58:21,494 BAD EPOCHS (no improvement): 2\n",
            "2022-12-15 22:58:21,496 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:58:27,441 epoch 12 - iter 24/245 - loss 0.02270496 - samples/sec: 129.29 - lr: 0.100000\n",
            "2022-12-15 22:58:34,879 epoch 12 - iter 48/245 - loss 0.02515265 - samples/sec: 103.32 - lr: 0.100000\n",
            "2022-12-15 22:58:39,691 epoch 12 - iter 72/245 - loss 0.02404308 - samples/sec: 159.76 - lr: 0.100000\n",
            "2022-12-15 22:58:45,811 epoch 12 - iter 96/245 - loss 0.02500026 - samples/sec: 125.57 - lr: 0.100000\n",
            "2022-12-15 22:58:50,919 epoch 12 - iter 120/245 - loss 0.02442879 - samples/sec: 150.49 - lr: 0.100000\n",
            "2022-12-15 22:58:57,255 epoch 12 - iter 144/245 - loss 0.02430141 - samples/sec: 121.31 - lr: 0.100000\n",
            "2022-12-15 22:59:03,157 epoch 12 - iter 168/245 - loss 0.02403574 - samples/sec: 130.23 - lr: 0.100000\n",
            "2022-12-15 22:59:09,262 epoch 12 - iter 192/245 - loss 0.02453010 - samples/sec: 125.88 - lr: 0.100000\n",
            "2022-12-15 22:59:14,162 epoch 12 - iter 216/245 - loss 0.02433856 - samples/sec: 156.86 - lr: 0.100000\n",
            "2022-12-15 22:59:20,515 epoch 12 - iter 240/245 - loss 0.02490983 - samples/sec: 120.99 - lr: 0.100000\n",
            "2022-12-15 22:59:22,141 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:59:22,144 EPOCH 12 done: loss 0.0248 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:59:32,235 Evaluating as a multi-label problem: False\n",
            "2022-12-15 22:59:32,257 DEV : loss 0.03655008226633072 - f1-score (micro avg)  0.873\n",
            "2022-12-15 22:59:32,394 BAD EPOCHS (no improvement): 0\n",
            "2022-12-15 22:59:32,397 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 22:59:32,866 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 22:59:39,345 epoch 13 - iter 24/245 - loss 0.02182342 - samples/sec: 118.67 - lr: 0.100000\n",
            "2022-12-15 22:59:44,653 epoch 13 - iter 48/245 - loss 0.02332172 - samples/sec: 144.80 - lr: 0.100000\n",
            "2022-12-15 22:59:50,187 epoch 13 - iter 72/245 - loss 0.02167305 - samples/sec: 138.89 - lr: 0.100000\n",
            "2022-12-15 22:59:55,584 epoch 13 - iter 96/245 - loss 0.02217682 - samples/sec: 142.42 - lr: 0.100000\n",
            "2022-12-15 23:00:02,317 epoch 13 - iter 120/245 - loss 0.02166204 - samples/sec: 114.15 - lr: 0.100000\n",
            "2022-12-15 23:00:07,789 epoch 13 - iter 144/245 - loss 0.02233704 - samples/sec: 140.47 - lr: 0.100000\n",
            "2022-12-15 23:00:12,847 epoch 13 - iter 168/245 - loss 0.02245241 - samples/sec: 151.98 - lr: 0.100000\n",
            "2022-12-15 23:00:18,877 epoch 13 - iter 192/245 - loss 0.02307469 - samples/sec: 127.45 - lr: 0.100000\n",
            "2022-12-15 23:00:24,189 epoch 13 - iter 216/245 - loss 0.02280700 - samples/sec: 144.69 - lr: 0.100000\n",
            "2022-12-15 23:00:31,144 epoch 13 - iter 240/245 - loss 0.02208853 - samples/sec: 110.50 - lr: 0.100000\n",
            "2022-12-15 23:00:33,436 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:00:33,437 EPOCH 13 done: loss 0.0220 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:00:44,409 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:00:44,433 DEV : loss 0.03754721209406853 - f1-score (micro avg)  0.879\n",
            "2022-12-15 23:00:44,567 BAD EPOCHS (no improvement): 0\n",
            "2022-12-15 23:00:44,569 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:00:45,031 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:00:51,752 epoch 14 - iter 24/245 - loss 0.01746260 - samples/sec: 114.35 - lr: 0.100000\n",
            "2022-12-15 23:00:58,748 epoch 14 - iter 48/245 - loss 0.02054311 - samples/sec: 109.85 - lr: 0.100000\n",
            "2022-12-15 23:01:04,493 epoch 14 - iter 72/245 - loss 0.02179114 - samples/sec: 133.80 - lr: 0.100000\n",
            "2022-12-15 23:01:09,906 epoch 14 - iter 96/245 - loss 0.02176379 - samples/sec: 141.98 - lr: 0.100000\n",
            "2022-12-15 23:01:15,375 epoch 14 - iter 120/245 - loss 0.02128218 - samples/sec: 140.56 - lr: 0.100000\n",
            "2022-12-15 23:01:20,569 epoch 14 - iter 144/245 - loss 0.02108804 - samples/sec: 147.99 - lr: 0.100000\n",
            "2022-12-15 23:01:26,726 epoch 14 - iter 168/245 - loss 0.02082528 - samples/sec: 124.82 - lr: 0.100000\n",
            "2022-12-15 23:01:31,497 epoch 14 - iter 192/245 - loss 0.02051729 - samples/sec: 161.13 - lr: 0.100000\n",
            "2022-12-15 23:01:37,822 epoch 14 - iter 216/245 - loss 0.02100339 - samples/sec: 121.52 - lr: 0.100000\n",
            "2022-12-15 23:01:43,967 epoch 14 - iter 240/245 - loss 0.02077521 - samples/sec: 125.06 - lr: 0.100000\n",
            "2022-12-15 23:01:44,914 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:01:44,916 EPOCH 14 done: loss 0.0208 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:01:54,998 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:01:55,021 DEV : loss 0.04365716874599457 - f1-score (micro avg)  0.8575\n",
            "2022-12-15 23:01:55,149 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 23:01:55,151 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:02:00,165 epoch 15 - iter 24/245 - loss 0.02104026 - samples/sec: 153.35 - lr: 0.100000\n",
            "2022-12-15 23:02:05,131 epoch 15 - iter 48/245 - loss 0.01907400 - samples/sec: 154.81 - lr: 0.100000\n",
            "2022-12-15 23:02:12,009 epoch 15 - iter 72/245 - loss 0.02021537 - samples/sec: 111.72 - lr: 0.100000\n",
            "2022-12-15 23:02:19,049 epoch 15 - iter 96/245 - loss 0.02027062 - samples/sec: 109.16 - lr: 0.100000\n",
            "2022-12-15 23:02:24,339 epoch 15 - iter 120/245 - loss 0.02028997 - samples/sec: 145.32 - lr: 0.100000\n",
            "2022-12-15 23:02:31,409 epoch 15 - iter 144/245 - loss 0.02018605 - samples/sec: 108.70 - lr: 0.100000\n",
            "2022-12-15 23:02:36,831 epoch 15 - iter 168/245 - loss 0.02027218 - samples/sec: 141.75 - lr: 0.100000\n",
            "2022-12-15 23:02:43,288 epoch 15 - iter 192/245 - loss 0.02068665 - samples/sec: 119.01 - lr: 0.100000\n",
            "2022-12-15 23:02:48,082 epoch 15 - iter 216/245 - loss 0.02028542 - samples/sec: 160.36 - lr: 0.100000\n",
            "2022-12-15 23:02:54,052 epoch 15 - iter 240/245 - loss 0.02026813 - samples/sec: 128.75 - lr: 0.100000\n",
            "2022-12-15 23:02:55,149 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:02:55,151 EPOCH 15 done: loss 0.0206 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:03:06,124 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:03:06,150 DEV : loss 0.03462392836809158 - f1-score (micro avg)  0.8776\n",
            "2022-12-15 23:03:06,290 BAD EPOCHS (no improvement): 2\n",
            "2022-12-15 23:03:06,292 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:03:12,267 epoch 16 - iter 24/245 - loss 0.02112419 - samples/sec: 128.67 - lr: 0.100000\n",
            "2022-12-15 23:03:17,582 epoch 16 - iter 48/245 - loss 0.01938359 - samples/sec: 144.62 - lr: 0.100000\n",
            "2022-12-15 23:03:22,266 epoch 16 - iter 72/245 - loss 0.01893187 - samples/sec: 164.10 - lr: 0.100000\n",
            "2022-12-15 23:03:27,511 epoch 16 - iter 96/245 - loss 0.01825479 - samples/sec: 146.56 - lr: 0.100000\n",
            "2022-12-15 23:03:33,663 epoch 16 - iter 120/245 - loss 0.01954917 - samples/sec: 124.94 - lr: 0.100000\n",
            "2022-12-15 23:03:39,157 epoch 16 - iter 144/245 - loss 0.01941626 - samples/sec: 139.91 - lr: 0.100000\n",
            "2022-12-15 23:03:45,245 epoch 16 - iter 168/245 - loss 0.01998785 - samples/sec: 126.24 - lr: 0.100000\n",
            "2022-12-15 23:03:53,199 epoch 16 - iter 192/245 - loss 0.01929207 - samples/sec: 96.60 - lr: 0.100000\n",
            "2022-12-15 23:04:00,560 epoch 16 - iter 216/245 - loss 0.01947257 - samples/sec: 104.39 - lr: 0.100000\n",
            "2022-12-15 23:04:05,907 epoch 16 - iter 240/245 - loss 0.01954070 - samples/sec: 143.76 - lr: 0.100000\n",
            "2022-12-15 23:04:07,231 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:04:07,233 EPOCH 16 done: loss 0.0195 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:04:17,421 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:04:17,443 DEV : loss 0.03850279003381729 - f1-score (micro avg)  0.8681\n",
            "2022-12-15 23:04:17,580 BAD EPOCHS (no improvement): 3\n",
            "2022-12-15 23:04:17,582 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:04:24,311 epoch 17 - iter 24/245 - loss 0.01971782 - samples/sec: 114.23 - lr: 0.100000\n",
            "2022-12-15 23:04:29,694 epoch 17 - iter 48/245 - loss 0.01804821 - samples/sec: 142.81 - lr: 0.100000\n",
            "2022-12-15 23:04:34,993 epoch 17 - iter 72/245 - loss 0.01817479 - samples/sec: 145.04 - lr: 0.100000\n",
            "2022-12-15 23:04:41,375 epoch 17 - iter 96/245 - loss 0.01751053 - samples/sec: 120.41 - lr: 0.100000\n",
            "2022-12-15 23:04:47,947 epoch 17 - iter 120/245 - loss 0.01696950 - samples/sec: 116.95 - lr: 0.100000\n",
            "2022-12-15 23:04:55,871 epoch 17 - iter 144/245 - loss 0.01733691 - samples/sec: 96.97 - lr: 0.100000\n",
            "2022-12-15 23:05:02,230 epoch 17 - iter 168/245 - loss 0.01699515 - samples/sec: 120.86 - lr: 0.100000\n",
            "2022-12-15 23:05:07,501 epoch 17 - iter 192/245 - loss 0.01731574 - samples/sec: 145.81 - lr: 0.100000\n",
            "2022-12-15 23:05:12,686 epoch 17 - iter 216/245 - loss 0.01730638 - samples/sec: 148.24 - lr: 0.100000\n",
            "2022-12-15 23:05:17,730 epoch 17 - iter 240/245 - loss 0.01748616 - samples/sec: 152.38 - lr: 0.100000\n",
            "2022-12-15 23:05:18,560 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:05:18,562 EPOCH 17 done: loss 0.0175 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:05:28,934 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:05:28,958 DEV : loss 0.03672116994857788 - f1-score (micro avg)  0.8758\n",
            "2022-12-15 23:05:29,092 Epoch    17: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2022-12-15 23:05:29,093 BAD EPOCHS (no improvement): 4\n",
            "2022-12-15 23:05:29,096 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:05:34,196 epoch 18 - iter 24/245 - loss 0.01324520 - samples/sec: 150.76 - lr: 0.050000\n",
            "2022-12-15 23:05:40,823 epoch 18 - iter 48/245 - loss 0.01555244 - samples/sec: 115.97 - lr: 0.050000\n",
            "2022-12-15 23:05:48,044 epoch 18 - iter 72/245 - loss 0.01539623 - samples/sec: 106.43 - lr: 0.050000\n",
            "2022-12-15 23:05:53,530 epoch 18 - iter 96/245 - loss 0.01542566 - samples/sec: 140.09 - lr: 0.050000\n",
            "2022-12-15 23:05:59,053 epoch 18 - iter 120/245 - loss 0.01557728 - samples/sec: 139.18 - lr: 0.050000\n",
            "2022-12-15 23:06:05,300 epoch 18 - iter 144/245 - loss 0.01514302 - samples/sec: 123.02 - lr: 0.050000\n",
            "2022-12-15 23:06:11,870 epoch 18 - iter 168/245 - loss 0.01532643 - samples/sec: 116.97 - lr: 0.050000\n",
            "2022-12-15 23:06:16,887 epoch 18 - iter 192/245 - loss 0.01545735 - samples/sec: 153.22 - lr: 0.050000\n",
            "2022-12-15 23:06:22,164 epoch 18 - iter 216/245 - loss 0.01534360 - samples/sec: 145.67 - lr: 0.050000\n",
            "2022-12-15 23:06:27,967 epoch 18 - iter 240/245 - loss 0.01499382 - samples/sec: 132.44 - lr: 0.050000\n",
            "2022-12-15 23:06:28,825 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:06:28,827 EPOCH 18 done: loss 0.0149 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:06:39,643 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:06:39,666 DEV : loss 0.03697904571890831 - f1-score (micro avg)  0.8761\n",
            "2022-12-15 23:06:39,794 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 23:06:39,797 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:06:45,355 epoch 19 - iter 24/245 - loss 0.01521576 - samples/sec: 138.32 - lr: 0.050000\n",
            "2022-12-15 23:06:53,522 epoch 19 - iter 48/245 - loss 0.01479439 - samples/sec: 94.09 - lr: 0.050000\n",
            "2022-12-15 23:06:59,203 epoch 19 - iter 72/245 - loss 0.01453195 - samples/sec: 135.26 - lr: 0.050000\n",
            "2022-12-15 23:07:05,931 epoch 19 - iter 96/245 - loss 0.01466325 - samples/sec: 114.24 - lr: 0.050000\n",
            "2022-12-15 23:07:11,016 epoch 19 - iter 120/245 - loss 0.01450738 - samples/sec: 151.17 - lr: 0.050000\n",
            "2022-12-15 23:07:16,048 epoch 19 - iter 144/245 - loss 0.01397157 - samples/sec: 152.74 - lr: 0.050000\n",
            "2022-12-15 23:07:21,423 epoch 19 - iter 168/245 - loss 0.01390420 - samples/sec: 143.00 - lr: 0.050000\n",
            "2022-12-15 23:07:27,496 epoch 19 - iter 192/245 - loss 0.01356414 - samples/sec: 126.56 - lr: 0.050000\n",
            "2022-12-15 23:07:32,887 epoch 19 - iter 216/245 - loss 0.01349872 - samples/sec: 142.56 - lr: 0.050000\n",
            "2022-12-15 23:07:38,315 epoch 19 - iter 240/245 - loss 0.01372345 - samples/sec: 141.60 - lr: 0.050000\n",
            "2022-12-15 23:07:39,384 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:07:39,386 EPOCH 19 done: loss 0.0137 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:07:49,447 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:07:49,469 DEV : loss 0.03511109575629234 - f1-score (micro avg)  0.8907\n",
            "2022-12-15 23:07:49,600 BAD EPOCHS (no improvement): 0\n",
            "2022-12-15 23:07:49,602 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:07:50,066 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:07:56,825 epoch 20 - iter 24/245 - loss 0.01512915 - samples/sec: 113.79 - lr: 0.050000\n",
            "2022-12-15 23:08:02,175 epoch 20 - iter 48/245 - loss 0.01397794 - samples/sec: 143.65 - lr: 0.050000\n",
            "2022-12-15 23:08:07,686 epoch 20 - iter 72/245 - loss 0.01361242 - samples/sec: 139.48 - lr: 0.050000\n",
            "2022-12-15 23:08:13,035 epoch 20 - iter 96/245 - loss 0.01381715 - samples/sec: 143.71 - lr: 0.050000\n",
            "2022-12-15 23:08:20,563 epoch 20 - iter 120/245 - loss 0.01383550 - samples/sec: 102.07 - lr: 0.050000\n",
            "2022-12-15 23:08:26,546 epoch 20 - iter 144/245 - loss 0.01357807 - samples/sec: 128.44 - lr: 0.050000\n",
            "2022-12-15 23:08:31,985 epoch 20 - iter 168/245 - loss 0.01325687 - samples/sec: 141.33 - lr: 0.050000\n",
            "2022-12-15 23:08:37,192 epoch 20 - iter 192/245 - loss 0.01288673 - samples/sec: 147.61 - lr: 0.050000\n",
            "2022-12-15 23:08:42,885 epoch 20 - iter 216/245 - loss 0.01281741 - samples/sec: 135.01 - lr: 0.050000\n",
            "2022-12-15 23:08:48,797 epoch 20 - iter 240/245 - loss 0.01301607 - samples/sec: 130.00 - lr: 0.050000\n",
            "2022-12-15 23:08:49,904 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:08:49,906 EPOCH 20 done: loss 0.0133 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:09:00,789 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:09:00,811 DEV : loss 0.03325570747256279 - f1-score (micro avg)  0.8786\n",
            "2022-12-15 23:09:00,940 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 23:09:00,942 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:09:06,552 epoch 21 - iter 24/245 - loss 0.01303465 - samples/sec: 137.04 - lr: 0.050000\n",
            "2022-12-15 23:09:12,440 epoch 21 - iter 48/245 - loss 0.01345655 - samples/sec: 130.53 - lr: 0.050000\n",
            "2022-12-15 23:09:19,192 epoch 21 - iter 72/245 - loss 0.01260666 - samples/sec: 113.83 - lr: 0.050000\n",
            "2022-12-15 23:09:25,212 epoch 21 - iter 96/245 - loss 0.01292987 - samples/sec: 127.65 - lr: 0.050000\n",
            "2022-12-15 23:09:31,597 epoch 21 - iter 120/245 - loss 0.01343948 - samples/sec: 120.35 - lr: 0.050000\n",
            "2022-12-15 23:09:37,341 epoch 21 - iter 144/245 - loss 0.01274685 - samples/sec: 133.82 - lr: 0.050000\n",
            "2022-12-15 23:09:43,661 epoch 21 - iter 168/245 - loss 0.01261731 - samples/sec: 121.61 - lr: 0.050000\n",
            "2022-12-15 23:09:49,031 epoch 21 - iter 192/245 - loss 0.01233957 - samples/sec: 143.13 - lr: 0.050000\n",
            "2022-12-15 23:09:54,266 epoch 21 - iter 216/245 - loss 0.01244585 - samples/sec: 146.82 - lr: 0.050000\n",
            "2022-12-15 23:09:59,689 epoch 21 - iter 240/245 - loss 0.01241034 - samples/sec: 141.73 - lr: 0.050000\n",
            "2022-12-15 23:10:00,648 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:10:00,650 EPOCH 21 done: loss 0.0124 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:10:11,474 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:10:11,496 DEV : loss 0.03420386090874672 - f1-score (micro avg)  0.8827\n",
            "2022-12-15 23:10:11,633 BAD EPOCHS (no improvement): 2\n",
            "2022-12-15 23:10:11,635 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:10:16,912 epoch 22 - iter 24/245 - loss 0.01098540 - samples/sec: 145.69 - lr: 0.050000\n",
            "2022-12-15 23:10:22,722 epoch 22 - iter 48/245 - loss 0.01104128 - samples/sec: 132.27 - lr: 0.050000\n",
            "2022-12-15 23:10:28,378 epoch 22 - iter 72/245 - loss 0.01124632 - samples/sec: 135.88 - lr: 0.050000\n",
            "2022-12-15 23:10:35,004 epoch 22 - iter 96/245 - loss 0.01151679 - samples/sec: 115.99 - lr: 0.050000\n",
            "2022-12-15 23:10:40,570 epoch 22 - iter 120/245 - loss 0.01201699 - samples/sec: 138.08 - lr: 0.050000\n",
            "2022-12-15 23:10:46,319 epoch 22 - iter 144/245 - loss 0.01243386 - samples/sec: 133.68 - lr: 0.050000\n",
            "2022-12-15 23:10:51,891 epoch 22 - iter 168/245 - loss 0.01225797 - samples/sec: 137.94 - lr: 0.050000\n",
            "2022-12-15 23:10:58,902 epoch 22 - iter 192/245 - loss 0.01232341 - samples/sec: 109.61 - lr: 0.050000\n",
            "2022-12-15 23:11:04,500 epoch 22 - iter 216/245 - loss 0.01272064 - samples/sec: 137.30 - lr: 0.050000\n",
            "2022-12-15 23:11:10,014 epoch 22 - iter 240/245 - loss 0.01263408 - samples/sec: 139.41 - lr: 0.050000\n",
            "2022-12-15 23:11:10,932 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:11:10,934 EPOCH 22 done: loss 0.0126 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:11:20,792 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:11:20,814 DEV : loss 0.03575759381055832 - f1-score (micro avg)  0.8869\n",
            "2022-12-15 23:11:20,944 BAD EPOCHS (no improvement): 3\n",
            "2022-12-15 23:11:20,946 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:11:25,936 epoch 23 - iter 24/245 - loss 0.00966276 - samples/sec: 154.09 - lr: 0.050000\n",
            "2022-12-15 23:11:32,822 epoch 23 - iter 48/245 - loss 0.01111512 - samples/sec: 111.61 - lr: 0.050000\n",
            "2022-12-15 23:11:38,275 epoch 23 - iter 72/245 - loss 0.01112601 - samples/sec: 140.95 - lr: 0.050000\n",
            "2022-12-15 23:11:43,886 epoch 23 - iter 96/245 - loss 0.01102208 - samples/sec: 136.96 - lr: 0.050000\n",
            "2022-12-15 23:11:49,346 epoch 23 - iter 120/245 - loss 0.01039649 - samples/sec: 140.78 - lr: 0.050000\n",
            "2022-12-15 23:11:55,458 epoch 23 - iter 144/245 - loss 0.01078584 - samples/sec: 125.75 - lr: 0.050000\n",
            "2022-12-15 23:12:00,262 epoch 23 - iter 168/245 - loss 0.01087833 - samples/sec: 160.01 - lr: 0.050000\n",
            "2022-12-15 23:12:06,069 epoch 23 - iter 192/245 - loss 0.01087505 - samples/sec: 132.36 - lr: 0.050000\n",
            "2022-12-15 23:12:13,254 epoch 23 - iter 216/245 - loss 0.01134550 - samples/sec: 106.95 - lr: 0.050000\n",
            "2022-12-15 23:12:18,958 epoch 23 - iter 240/245 - loss 0.01182049 - samples/sec: 134.73 - lr: 0.050000\n",
            "2022-12-15 23:12:20,101 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:12:20,104 EPOCH 23 done: loss 0.0118 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:12:31,014 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:12:31,039 DEV : loss 0.034832391887903214 - f1-score (micro avg)  0.8853\n",
            "2022-12-15 23:12:31,164 Epoch    23: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2022-12-15 23:12:31,165 BAD EPOCHS (no improvement): 4\n",
            "2022-12-15 23:12:31,168 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:12:37,628 epoch 24 - iter 24/245 - loss 0.01240101 - samples/sec: 118.98 - lr: 0.025000\n",
            "2022-12-15 23:12:42,761 epoch 24 - iter 48/245 - loss 0.01213300 - samples/sec: 149.75 - lr: 0.025000\n",
            "2022-12-15 23:12:47,360 epoch 24 - iter 72/245 - loss 0.01182752 - samples/sec: 167.16 - lr: 0.025000\n",
            "2022-12-15 23:12:52,241 epoch 24 - iter 96/245 - loss 0.01132326 - samples/sec: 157.49 - lr: 0.025000\n",
            "2022-12-15 23:12:58,120 epoch 24 - iter 120/245 - loss 0.01141803 - samples/sec: 130.72 - lr: 0.025000\n",
            "2022-12-15 23:13:04,263 epoch 24 - iter 144/245 - loss 0.01110918 - samples/sec: 125.12 - lr: 0.025000\n",
            "2022-12-15 23:13:10,308 epoch 24 - iter 168/245 - loss 0.01105549 - samples/sec: 127.14 - lr: 0.025000\n",
            "2022-12-15 23:13:17,457 epoch 24 - iter 192/245 - loss 0.01083175 - samples/sec: 107.48 - lr: 0.025000\n",
            "2022-12-15 23:13:23,427 epoch 24 - iter 216/245 - loss 0.01061389 - samples/sec: 128.74 - lr: 0.025000\n",
            "2022-12-15 23:13:28,802 epoch 24 - iter 240/245 - loss 0.01072514 - samples/sec: 143.00 - lr: 0.025000\n",
            "2022-12-15 23:13:29,700 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:13:29,702 EPOCH 24 done: loss 0.0107 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:13:39,690 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:13:39,715 DEV : loss 0.035583849996328354 - f1-score (micro avg)  0.8828\n",
            "2022-12-15 23:13:39,844 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 23:13:39,846 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:13:45,757 epoch 25 - iter 24/245 - loss 0.00778649 - samples/sec: 130.05 - lr: 0.025000\n",
            "2022-12-15 23:13:50,952 epoch 25 - iter 48/245 - loss 0.00809361 - samples/sec: 147.96 - lr: 0.025000\n",
            "2022-12-15 23:13:58,528 epoch 25 - iter 72/245 - loss 0.00969816 - samples/sec: 101.43 - lr: 0.025000\n",
            "2022-12-15 23:14:03,677 epoch 25 - iter 96/245 - loss 0.01059929 - samples/sec: 149.27 - lr: 0.025000\n",
            "2022-12-15 23:14:10,842 epoch 25 - iter 120/245 - loss 0.01068352 - samples/sec: 107.27 - lr: 0.025000\n",
            "2022-12-15 23:14:16,272 epoch 25 - iter 144/245 - loss 0.01024095 - samples/sec: 141.53 - lr: 0.025000\n",
            "2022-12-15 23:14:22,451 epoch 25 - iter 168/245 - loss 0.01039740 - samples/sec: 124.38 - lr: 0.025000\n",
            "2022-12-15 23:14:27,783 epoch 25 - iter 192/245 - loss 0.01019105 - samples/sec: 144.16 - lr: 0.025000\n",
            "2022-12-15 23:14:33,719 epoch 25 - iter 216/245 - loss 0.00982837 - samples/sec: 129.46 - lr: 0.025000\n",
            "2022-12-15 23:14:38,782 epoch 25 - iter 240/245 - loss 0.00990218 - samples/sec: 151.83 - lr: 0.025000\n",
            "2022-12-15 23:14:39,768 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:14:39,771 EPOCH 25 done: loss 0.0099 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:14:49,685 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:14:49,707 DEV : loss 0.03561178222298622 - f1-score (micro avg)  0.8861\n",
            "2022-12-15 23:14:49,838 BAD EPOCHS (no improvement): 2\n",
            "2022-12-15 23:14:49,840 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:14:56,620 epoch 26 - iter 24/245 - loss 0.01183768 - samples/sec: 113.36 - lr: 0.025000\n",
            "2022-12-15 23:15:01,992 epoch 26 - iter 48/245 - loss 0.01130369 - samples/sec: 143.07 - lr: 0.025000\n",
            "2022-12-15 23:15:07,037 epoch 26 - iter 72/245 - loss 0.01110815 - samples/sec: 152.37 - lr: 0.025000\n",
            "2022-12-15 23:15:12,030 epoch 26 - iter 96/245 - loss 0.01048987 - samples/sec: 153.97 - lr: 0.025000\n",
            "2022-12-15 23:15:17,878 epoch 26 - iter 120/245 - loss 0.00992621 - samples/sec: 131.42 - lr: 0.025000\n",
            "2022-12-15 23:15:23,591 epoch 26 - iter 144/245 - loss 0.00999739 - samples/sec: 134.54 - lr: 0.025000\n",
            "2022-12-15 23:15:29,099 epoch 26 - iter 168/245 - loss 0.00979949 - samples/sec: 139.55 - lr: 0.025000\n",
            "2022-12-15 23:15:36,867 epoch 26 - iter 192/245 - loss 0.00971587 - samples/sec: 98.92 - lr: 0.025000\n",
            "2022-12-15 23:15:42,389 epoch 26 - iter 216/245 - loss 0.01001906 - samples/sec: 139.19 - lr: 0.025000\n",
            "2022-12-15 23:15:48,100 epoch 26 - iter 240/245 - loss 0.00974754 - samples/sec: 134.59 - lr: 0.025000\n",
            "2022-12-15 23:15:48,923 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:15:48,924 EPOCH 26 done: loss 0.0098 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:15:59,476 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:15:59,500 DEV : loss 0.03284444287419319 - f1-score (micro avg)  0.8936\n",
            "2022-12-15 23:15:59,629 BAD EPOCHS (no improvement): 0\n",
            "2022-12-15 23:15:59,631 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:16:00,090 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:16:06,651 epoch 27 - iter 24/245 - loss 0.00811691 - samples/sec: 117.20 - lr: 0.025000\n",
            "2022-12-15 23:16:11,785 epoch 27 - iter 48/245 - loss 0.00867090 - samples/sec: 149.72 - lr: 0.025000\n",
            "2022-12-15 23:16:16,884 epoch 27 - iter 72/245 - loss 0.00992008 - samples/sec: 150.75 - lr: 0.025000\n",
            "2022-12-15 23:16:22,095 epoch 27 - iter 96/245 - loss 0.00964465 - samples/sec: 147.51 - lr: 0.025000\n",
            "2022-12-15 23:16:28,345 epoch 27 - iter 120/245 - loss 0.00972894 - samples/sec: 122.97 - lr: 0.025000\n",
            "2022-12-15 23:16:34,153 epoch 27 - iter 144/245 - loss 0.00944300 - samples/sec: 132.32 - lr: 0.025000\n",
            "2022-12-15 23:16:39,880 epoch 27 - iter 168/245 - loss 0.00911140 - samples/sec: 134.19 - lr: 0.025000\n",
            "2022-12-15 23:16:44,763 epoch 27 - iter 192/245 - loss 0.00908719 - samples/sec: 157.41 - lr: 0.025000\n",
            "2022-12-15 23:16:51,609 epoch 27 - iter 216/245 - loss 0.00933211 - samples/sec: 112.26 - lr: 0.025000\n",
            "2022-12-15 23:16:57,994 epoch 27 - iter 240/245 - loss 0.00979726 - samples/sec: 120.37 - lr: 0.025000\n",
            "2022-12-15 23:16:58,889 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:16:58,890 EPOCH 27 done: loss 0.0098 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:17:08,654 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:17:08,676 DEV : loss 0.034081846475601196 - f1-score (micro avg)  0.8882\n",
            "2022-12-15 23:17:08,802 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 23:17:08,804 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:17:14,288 epoch 28 - iter 24/245 - loss 0.00992644 - samples/sec: 140.18 - lr: 0.025000\n",
            "2022-12-15 23:17:20,070 epoch 28 - iter 48/245 - loss 0.00925463 - samples/sec: 132.93 - lr: 0.025000\n",
            "2022-12-15 23:17:26,870 epoch 28 - iter 72/245 - loss 0.00977202 - samples/sec: 113.01 - lr: 0.025000\n",
            "2022-12-15 23:17:31,632 epoch 28 - iter 96/245 - loss 0.00913838 - samples/sec: 161.40 - lr: 0.025000\n",
            "2022-12-15 23:17:37,156 epoch 28 - iter 120/245 - loss 0.00893151 - samples/sec: 139.15 - lr: 0.025000\n",
            "2022-12-15 23:17:44,481 epoch 28 - iter 144/245 - loss 0.00978836 - samples/sec: 104.90 - lr: 0.025000\n",
            "2022-12-15 23:17:49,577 epoch 28 - iter 168/245 - loss 0.00980911 - samples/sec: 150.82 - lr: 0.025000\n",
            "2022-12-15 23:17:54,244 epoch 28 - iter 192/245 - loss 0.00990503 - samples/sec: 164.75 - lr: 0.025000\n",
            "2022-12-15 23:18:00,652 epoch 28 - iter 216/245 - loss 0.01007673 - samples/sec: 119.91 - lr: 0.025000\n",
            "2022-12-15 23:18:06,118 epoch 28 - iter 240/245 - loss 0.01015355 - samples/sec: 140.63 - lr: 0.025000\n",
            "2022-12-15 23:18:07,036 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:18:07,037 EPOCH 28 done: loss 0.0102 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:18:17,618 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:18:17,639 DEV : loss 0.03136078640818596 - f1-score (micro avg)  0.8981\n",
            "2022-12-15 23:18:17,764 BAD EPOCHS (no improvement): 0\n",
            "2022-12-15 23:18:17,765 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:18:18,212 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:18:23,818 epoch 29 - iter 24/245 - loss 0.00941908 - samples/sec: 137.19 - lr: 0.025000\n",
            "2022-12-15 23:18:30,481 epoch 29 - iter 48/245 - loss 0.00996259 - samples/sec: 115.32 - lr: 0.025000\n",
            "2022-12-15 23:18:36,321 epoch 29 - iter 72/245 - loss 0.00969673 - samples/sec: 131.61 - lr: 0.025000\n",
            "2022-12-15 23:18:43,709 epoch 29 - iter 96/245 - loss 0.00925748 - samples/sec: 104.00 - lr: 0.025000\n",
            "2022-12-15 23:18:49,187 epoch 29 - iter 120/245 - loss 0.00908041 - samples/sec: 140.33 - lr: 0.025000\n",
            "2022-12-15 23:18:54,218 epoch 29 - iter 144/245 - loss 0.00874128 - samples/sec: 152.76 - lr: 0.025000\n",
            "2022-12-15 23:19:00,233 epoch 29 - iter 168/245 - loss 0.00943298 - samples/sec: 127.78 - lr: 0.025000\n",
            "2022-12-15 23:19:05,685 epoch 29 - iter 192/245 - loss 0.00928370 - samples/sec: 140.96 - lr: 0.025000\n",
            "2022-12-15 23:19:10,970 epoch 29 - iter 216/245 - loss 0.00920121 - samples/sec: 145.41 - lr: 0.025000\n",
            "2022-12-15 23:19:15,550 epoch 29 - iter 240/245 - loss 0.00945528 - samples/sec: 167.85 - lr: 0.025000\n",
            "2022-12-15 23:19:17,036 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:19:17,038 EPOCH 29 done: loss 0.0095 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:19:26,861 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:19:26,883 DEV : loss 0.03398556634783745 - f1-score (micro avg)  0.8929\n",
            "2022-12-15 23:19:27,014 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 23:19:27,016 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:19:36,208 epoch 30 - iter 24/245 - loss 0.00904317 - samples/sec: 83.60 - lr: 0.025000\n",
            "2022-12-15 23:19:42,138 epoch 30 - iter 48/245 - loss 0.00757147 - samples/sec: 129.61 - lr: 0.025000\n",
            "2022-12-15 23:19:46,967 epoch 30 - iter 72/245 - loss 0.00798363 - samples/sec: 159.17 - lr: 0.025000\n",
            "2022-12-15 23:19:51,552 epoch 30 - iter 96/245 - loss 0.00809754 - samples/sec: 167.66 - lr: 0.025000\n",
            "2022-12-15 23:19:57,296 epoch 30 - iter 120/245 - loss 0.00791459 - samples/sec: 133.80 - lr: 0.025000\n",
            "2022-12-15 23:20:02,467 epoch 30 - iter 144/245 - loss 0.00829111 - samples/sec: 148.66 - lr: 0.025000\n",
            "2022-12-15 23:20:07,855 epoch 30 - iter 168/245 - loss 0.00864693 - samples/sec: 142.65 - lr: 0.025000\n",
            "2022-12-15 23:20:13,449 epoch 30 - iter 192/245 - loss 0.00883375 - samples/sec: 137.37 - lr: 0.025000\n",
            "2022-12-15 23:20:18,291 epoch 30 - iter 216/245 - loss 0.00905158 - samples/sec: 158.73 - lr: 0.025000\n",
            "2022-12-15 23:20:23,330 epoch 30 - iter 240/245 - loss 0.00944997 - samples/sec: 152.54 - lr: 0.025000\n",
            "2022-12-15 23:20:25,918 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:20:25,921 EPOCH 30 done: loss 0.0095 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:20:35,696 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:20:35,719 DEV : loss 0.033835023641586304 - f1-score (micro avg)  0.8974\n",
            "2022-12-15 23:20:35,847 BAD EPOCHS (no improvement): 2\n",
            "2022-12-15 23:20:35,849 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:20:41,626 epoch 31 - iter 24/245 - loss 0.00954704 - samples/sec: 133.06 - lr: 0.025000\n",
            "2022-12-15 23:20:46,742 epoch 31 - iter 48/245 - loss 0.00933156 - samples/sec: 150.25 - lr: 0.025000\n",
            "2022-12-15 23:20:52,756 epoch 31 - iter 72/245 - loss 0.00905828 - samples/sec: 127.78 - lr: 0.025000\n",
            "2022-12-15 23:20:58,540 epoch 31 - iter 96/245 - loss 0.00871444 - samples/sec: 132.88 - lr: 0.025000\n",
            "2022-12-15 23:21:05,626 epoch 31 - iter 120/245 - loss 0.00864675 - samples/sec: 108.44 - lr: 0.025000\n",
            "2022-12-15 23:21:11,764 epoch 31 - iter 144/245 - loss 0.00844951 - samples/sec: 125.20 - lr: 0.025000\n",
            "2022-12-15 23:21:17,037 epoch 31 - iter 168/245 - loss 0.00865813 - samples/sec: 145.76 - lr: 0.025000\n",
            "2022-12-15 23:21:22,427 epoch 31 - iter 192/245 - loss 0.00878536 - samples/sec: 142.60 - lr: 0.025000\n",
            "2022-12-15 23:21:28,215 epoch 31 - iter 216/245 - loss 0.00859897 - samples/sec: 132.78 - lr: 0.025000\n",
            "2022-12-15 23:21:33,532 epoch 31 - iter 240/245 - loss 0.00861498 - samples/sec: 144.56 - lr: 0.025000\n",
            "2022-12-15 23:21:34,584 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:21:34,586 EPOCH 31 done: loss 0.0086 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:21:45,031 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:21:45,052 DEV : loss 0.03534458577632904 - f1-score (micro avg)  0.8885\n",
            "2022-12-15 23:21:45,178 BAD EPOCHS (no improvement): 3\n",
            "2022-12-15 23:21:45,180 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:21:50,654 epoch 32 - iter 24/245 - loss 0.00749384 - samples/sec: 140.44 - lr: 0.025000\n",
            "2022-12-15 23:21:57,089 epoch 32 - iter 48/245 - loss 0.00723466 - samples/sec: 119.44 - lr: 0.025000\n",
            "2022-12-15 23:22:03,223 epoch 32 - iter 72/245 - loss 0.00777014 - samples/sec: 125.27 - lr: 0.025000\n",
            "2022-12-15 23:22:09,550 epoch 32 - iter 96/245 - loss 0.00783861 - samples/sec: 121.48 - lr: 0.025000\n",
            "2022-12-15 23:22:15,906 epoch 32 - iter 120/245 - loss 0.00831365 - samples/sec: 120.90 - lr: 0.025000\n",
            "2022-12-15 23:22:21,290 epoch 32 - iter 144/245 - loss 0.00814228 - samples/sec: 142.76 - lr: 0.025000\n",
            "2022-12-15 23:22:26,797 epoch 32 - iter 168/245 - loss 0.00840159 - samples/sec: 139.56 - lr: 0.025000\n",
            "2022-12-15 23:22:31,653 epoch 32 - iter 192/245 - loss 0.00834352 - samples/sec: 158.30 - lr: 0.025000\n",
            "2022-12-15 23:22:37,605 epoch 32 - iter 216/245 - loss 0.00838621 - samples/sec: 129.14 - lr: 0.025000\n",
            "2022-12-15 23:22:42,368 epoch 32 - iter 240/245 - loss 0.00845182 - samples/sec: 161.36 - lr: 0.025000\n",
            "2022-12-15 23:22:43,470 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:22:43,472 EPOCH 32 done: loss 0.0085 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:22:53,394 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:22:53,417 DEV : loss 0.03412977606058121 - f1-score (micro avg)  0.89\n",
            "2022-12-15 23:22:53,545 Epoch    32: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2022-12-15 23:22:53,547 BAD EPOCHS (no improvement): 4\n",
            "2022-12-15 23:22:53,550 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:22:58,430 epoch 33 - iter 24/245 - loss 0.00655633 - samples/sec: 157.54 - lr: 0.012500\n",
            "2022-12-15 23:23:04,666 epoch 33 - iter 48/245 - loss 0.00692137 - samples/sec: 123.24 - lr: 0.012500\n",
            "2022-12-15 23:23:10,342 epoch 33 - iter 72/245 - loss 0.00711720 - samples/sec: 135.40 - lr: 0.012500\n",
            "2022-12-15 23:23:16,221 epoch 33 - iter 96/245 - loss 0.00732810 - samples/sec: 130.72 - lr: 0.012500\n",
            "2022-12-15 23:23:21,889 epoch 33 - iter 120/245 - loss 0.00762800 - samples/sec: 135.59 - lr: 0.012500\n",
            "2022-12-15 23:23:26,851 epoch 33 - iter 144/245 - loss 0.00744406 - samples/sec: 154.90 - lr: 0.012500\n",
            "2022-12-15 23:23:33,750 epoch 33 - iter 168/245 - loss 0.00762743 - samples/sec: 111.39 - lr: 0.012500\n",
            "2022-12-15 23:23:40,149 epoch 33 - iter 192/245 - loss 0.00781574 - samples/sec: 120.09 - lr: 0.012500\n",
            "2022-12-15 23:23:44,694 epoch 33 - iter 216/245 - loss 0.00801845 - samples/sec: 169.15 - lr: 0.012500\n",
            "2022-12-15 23:23:50,827 epoch 33 - iter 240/245 - loss 0.00824224 - samples/sec: 125.29 - lr: 0.012500\n",
            "2022-12-15 23:23:51,769 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:23:51,770 EPOCH 33 done: loss 0.0082 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:24:02,501 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:24:02,521 DEV : loss 0.036615852266550064 - f1-score (micro avg)  0.8893\n",
            "2022-12-15 23:24:02,650 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 23:24:02,652 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:24:08,084 epoch 34 - iter 24/245 - loss 0.00669907 - samples/sec: 141.53 - lr: 0.012500\n",
            "2022-12-15 23:24:13,793 epoch 34 - iter 48/245 - loss 0.00739704 - samples/sec: 134.63 - lr: 0.012500\n",
            "2022-12-15 23:24:18,692 epoch 34 - iter 72/245 - loss 0.00790446 - samples/sec: 156.90 - lr: 0.012500\n",
            "2022-12-15 23:24:24,187 epoch 34 - iter 96/245 - loss 0.00805655 - samples/sec: 139.85 - lr: 0.012500\n",
            "2022-12-15 23:24:31,093 epoch 34 - iter 120/245 - loss 0.00788679 - samples/sec: 111.28 - lr: 0.012500\n",
            "2022-12-15 23:24:38,205 epoch 34 - iter 144/245 - loss 0.00839979 - samples/sec: 108.05 - lr: 0.012500\n",
            "2022-12-15 23:24:43,387 epoch 34 - iter 168/245 - loss 0.00818045 - samples/sec: 148.31 - lr: 0.012500\n",
            "2022-12-15 23:24:48,654 epoch 34 - iter 192/245 - loss 0.00797692 - samples/sec: 145.94 - lr: 0.012500\n",
            "2022-12-15 23:24:53,972 epoch 34 - iter 216/245 - loss 0.00801003 - samples/sec: 144.51 - lr: 0.012500\n",
            "2022-12-15 23:24:59,995 epoch 34 - iter 240/245 - loss 0.00812817 - samples/sec: 127.60 - lr: 0.012500\n",
            "2022-12-15 23:25:00,917 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:25:00,919 EPOCH 34 done: loss 0.0081 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:25:11,465 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:25:11,487 DEV : loss 0.034274082630872726 - f1-score (micro avg)  0.8905\n",
            "2022-12-15 23:25:11,613 BAD EPOCHS (no improvement): 2\n",
            "2022-12-15 23:25:11,615 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:25:16,542 epoch 35 - iter 24/245 - loss 0.00668325 - samples/sec: 156.06 - lr: 0.012500\n",
            "2022-12-15 23:25:22,287 epoch 35 - iter 48/245 - loss 0.00665956 - samples/sec: 133.77 - lr: 0.012500\n",
            "2022-12-15 23:25:29,208 epoch 35 - iter 72/245 - loss 0.00698320 - samples/sec: 111.03 - lr: 0.012500\n",
            "2022-12-15 23:25:34,571 epoch 35 - iter 96/245 - loss 0.00723871 - samples/sec: 143.32 - lr: 0.012500\n",
            "2022-12-15 23:25:39,967 epoch 35 - iter 120/245 - loss 0.00746848 - samples/sec: 142.46 - lr: 0.012500\n",
            "2022-12-15 23:25:46,381 epoch 35 - iter 144/245 - loss 0.00747135 - samples/sec: 119.82 - lr: 0.012500\n",
            "2022-12-15 23:25:51,108 epoch 35 - iter 168/245 - loss 0.00751551 - samples/sec: 162.62 - lr: 0.012500\n",
            "2022-12-15 23:25:57,551 epoch 35 - iter 192/245 - loss 0.00749425 - samples/sec: 119.26 - lr: 0.012500\n",
            "2022-12-15 23:26:04,439 epoch 35 - iter 216/245 - loss 0.00761419 - samples/sec: 111.56 - lr: 0.012500\n",
            "2022-12-15 23:26:10,079 epoch 35 - iter 240/245 - loss 0.00775824 - samples/sec: 136.29 - lr: 0.012500\n",
            "2022-12-15 23:26:10,929 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:26:10,931 EPOCH 35 done: loss 0.0077 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:26:20,895 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:26:20,918 DEV : loss 0.034948382526636124 - f1-score (micro avg)  0.8975\n",
            "2022-12-15 23:26:21,057 BAD EPOCHS (no improvement): 3\n",
            "2022-12-15 23:26:21,059 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:26:29,436 epoch 36 - iter 24/245 - loss 0.00810446 - samples/sec: 91.77 - lr: 0.012500\n",
            "2022-12-15 23:26:35,150 epoch 36 - iter 48/245 - loss 0.00786966 - samples/sec: 134.49 - lr: 0.012500\n",
            "2022-12-15 23:26:40,461 epoch 36 - iter 72/245 - loss 0.00738554 - samples/sec: 144.73 - lr: 0.012500\n",
            "2022-12-15 23:26:45,046 epoch 36 - iter 96/245 - loss 0.00755897 - samples/sec: 167.63 - lr: 0.012500\n",
            "2022-12-15 23:26:49,818 epoch 36 - iter 120/245 - loss 0.00728690 - samples/sec: 161.09 - lr: 0.012500\n",
            "2022-12-15 23:26:57,127 epoch 36 - iter 144/245 - loss 0.00827208 - samples/sec: 105.14 - lr: 0.012500\n",
            "2022-12-15 23:27:02,724 epoch 36 - iter 168/245 - loss 0.00826247 - samples/sec: 137.33 - lr: 0.012500\n",
            "2022-12-15 23:27:08,112 epoch 36 - iter 192/245 - loss 0.00811300 - samples/sec: 142.66 - lr: 0.012500\n",
            "2022-12-15 23:27:12,907 epoch 36 - iter 216/245 - loss 0.00809177 - samples/sec: 160.28 - lr: 0.012500\n",
            "2022-12-15 23:27:19,467 epoch 36 - iter 240/245 - loss 0.00807160 - samples/sec: 117.16 - lr: 0.012500\n",
            "2022-12-15 23:27:20,430 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:27:20,432 EPOCH 36 done: loss 0.0080 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:27:30,893 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:27:30,915 DEV : loss 0.03463789075613022 - f1-score (micro avg)  0.8922\n",
            "2022-12-15 23:27:31,042 Epoch    36: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2022-12-15 23:27:31,045 BAD EPOCHS (no improvement): 4\n",
            "2022-12-15 23:27:31,047 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:27:37,185 epoch 37 - iter 24/245 - loss 0.00895508 - samples/sec: 125.23 - lr: 0.006250\n",
            "2022-12-15 23:27:42,871 epoch 37 - iter 48/245 - loss 0.00753025 - samples/sec: 135.17 - lr: 0.006250\n",
            "2022-12-15 23:27:48,658 epoch 37 - iter 72/245 - loss 0.00828203 - samples/sec: 132.80 - lr: 0.006250\n",
            "2022-12-15 23:27:53,828 epoch 37 - iter 96/245 - loss 0.00794043 - samples/sec: 148.66 - lr: 0.006250\n",
            "2022-12-15 23:28:00,661 epoch 37 - iter 120/245 - loss 0.00755870 - samples/sec: 112.46 - lr: 0.006250\n",
            "2022-12-15 23:28:06,219 epoch 37 - iter 144/245 - loss 0.00745279 - samples/sec: 138.27 - lr: 0.006250\n",
            "2022-12-15 23:28:11,435 epoch 37 - iter 168/245 - loss 0.00735838 - samples/sec: 147.35 - lr: 0.006250\n",
            "2022-12-15 23:28:17,761 epoch 37 - iter 192/245 - loss 0.00760037 - samples/sec: 121.49 - lr: 0.006250\n",
            "2022-12-15 23:28:23,016 epoch 37 - iter 216/245 - loss 0.00764990 - samples/sec: 146.25 - lr: 0.006250\n",
            "2022-12-15 23:28:27,988 epoch 37 - iter 240/245 - loss 0.00759403 - samples/sec: 154.59 - lr: 0.006250\n",
            "2022-12-15 23:28:29,116 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:28:29,117 EPOCH 37 done: loss 0.0076 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:28:39,216 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:28:39,237 DEV : loss 0.03494878485798836 - f1-score (micro avg)  0.8923\n",
            "2022-12-15 23:28:39,367 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 23:28:39,369 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:28:45,345 epoch 38 - iter 24/245 - loss 0.00663739 - samples/sec: 128.64 - lr: 0.006250\n",
            "2022-12-15 23:28:52,420 epoch 38 - iter 48/245 - loss 0.00609812 - samples/sec: 108.61 - lr: 0.006250\n",
            "2022-12-15 23:28:58,460 epoch 38 - iter 72/245 - loss 0.00726966 - samples/sec: 127.25 - lr: 0.006250\n",
            "2022-12-15 23:29:04,726 epoch 38 - iter 96/245 - loss 0.00743411 - samples/sec: 122.65 - lr: 0.006250\n",
            "2022-12-15 23:29:11,543 epoch 38 - iter 120/245 - loss 0.00762640 - samples/sec: 112.72 - lr: 0.006250\n",
            "2022-12-15 23:29:16,868 epoch 38 - iter 144/245 - loss 0.00776595 - samples/sec: 144.33 - lr: 0.006250\n",
            "2022-12-15 23:29:21,754 epoch 38 - iter 168/245 - loss 0.00758409 - samples/sec: 157.34 - lr: 0.006250\n",
            "2022-12-15 23:29:26,713 epoch 38 - iter 192/245 - loss 0.00733328 - samples/sec: 155.00 - lr: 0.006250\n",
            "2022-12-15 23:29:32,378 epoch 38 - iter 216/245 - loss 0.00748264 - samples/sec: 135.68 - lr: 0.006250\n",
            "2022-12-15 23:29:37,543 epoch 38 - iter 240/245 - loss 0.00748369 - samples/sec: 148.80 - lr: 0.006250\n",
            "2022-12-15 23:29:38,880 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:29:38,882 EPOCH 38 done: loss 0.0075 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:29:48,849 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:29:48,872 DEV : loss 0.03536289930343628 - f1-score (micro avg)  0.8934\n",
            "2022-12-15 23:29:49,008 BAD EPOCHS (no improvement): 2\n",
            "2022-12-15 23:29:49,010 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:29:54,614 epoch 39 - iter 24/245 - loss 0.00800882 - samples/sec: 137.17 - lr: 0.006250\n",
            "2022-12-15 23:29:59,721 epoch 39 - iter 48/245 - loss 0.00750602 - samples/sec: 150.52 - lr: 0.006250\n",
            "2022-12-15 23:30:07,174 epoch 39 - iter 72/245 - loss 0.00748605 - samples/sec: 103.10 - lr: 0.006250\n",
            "2022-12-15 23:30:12,717 epoch 39 - iter 96/245 - loss 0.00757584 - samples/sec: 138.66 - lr: 0.006250\n",
            "2022-12-15 23:30:19,296 epoch 39 - iter 120/245 - loss 0.00732091 - samples/sec: 116.82 - lr: 0.006250\n",
            "2022-12-15 23:30:24,936 epoch 39 - iter 144/245 - loss 0.00773654 - samples/sec: 136.27 - lr: 0.006250\n",
            "2022-12-15 23:30:30,143 epoch 39 - iter 168/245 - loss 0.00767398 - samples/sec: 147.62 - lr: 0.006250\n",
            "2022-12-15 23:30:36,109 epoch 39 - iter 192/245 - loss 0.00773977 - samples/sec: 128.82 - lr: 0.006250\n",
            "2022-12-15 23:30:42,020 epoch 39 - iter 216/245 - loss 0.00766172 - samples/sec: 130.02 - lr: 0.006250\n",
            "2022-12-15 23:30:47,447 epoch 39 - iter 240/245 - loss 0.00773529 - samples/sec: 141.61 - lr: 0.006250\n",
            "2022-12-15 23:30:48,327 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:30:48,330 EPOCH 39 done: loss 0.0077 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:30:59,216 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:30:59,237 DEV : loss 0.03524079918861389 - f1-score (micro avg)  0.8933\n",
            "2022-12-15 23:30:59,363 BAD EPOCHS (no improvement): 3\n",
            "2022-12-15 23:30:59,365 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:31:04,391 epoch 40 - iter 24/245 - loss 0.00570720 - samples/sec: 153.00 - lr: 0.006250\n",
            "2022-12-15 23:31:10,926 epoch 40 - iter 48/245 - loss 0.00682666 - samples/sec: 117.59 - lr: 0.006250\n",
            "2022-12-15 23:31:19,292 epoch 40 - iter 72/245 - loss 0.00749827 - samples/sec: 91.84 - lr: 0.006250\n",
            "2022-12-15 23:31:24,217 epoch 40 - iter 96/245 - loss 0.00704808 - samples/sec: 156.09 - lr: 0.006250\n",
            "2022-12-15 23:31:29,190 epoch 40 - iter 120/245 - loss 0.00692509 - samples/sec: 154.55 - lr: 0.006250\n",
            "2022-12-15 23:31:35,298 epoch 40 - iter 144/245 - loss 0.00683587 - samples/sec: 125.82 - lr: 0.006250\n",
            "2022-12-15 23:31:41,122 epoch 40 - iter 168/245 - loss 0.00703633 - samples/sec: 131.94 - lr: 0.006250\n",
            "2022-12-15 23:31:46,521 epoch 40 - iter 192/245 - loss 0.00703547 - samples/sec: 142.37 - lr: 0.006250\n",
            "2022-12-15 23:31:51,332 epoch 40 - iter 216/245 - loss 0.00724106 - samples/sec: 159.79 - lr: 0.006250\n",
            "2022-12-15 23:31:56,160 epoch 40 - iter 240/245 - loss 0.00738637 - samples/sec: 159.22 - lr: 0.006250\n",
            "2022-12-15 23:31:56,970 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:31:56,972 EPOCH 40 done: loss 0.0073 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:32:06,747 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:32:06,770 DEV : loss 0.035714857280254364 - f1-score (micro avg)  0.8863\n",
            "2022-12-15 23:32:06,894 Epoch    40: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2022-12-15 23:32:06,896 BAD EPOCHS (no improvement): 4\n",
            "2022-12-15 23:32:06,900 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:32:12,760 epoch 41 - iter 24/245 - loss 0.00668577 - samples/sec: 131.16 - lr: 0.003125\n",
            "2022-12-15 23:32:19,523 epoch 41 - iter 48/245 - loss 0.00585152 - samples/sec: 113.62 - lr: 0.003125\n",
            "2022-12-15 23:32:23,844 epoch 41 - iter 72/245 - loss 0.00620706 - samples/sec: 177.91 - lr: 0.003125\n",
            "2022-12-15 23:32:30,539 epoch 41 - iter 96/245 - loss 0.00714716 - samples/sec: 114.79 - lr: 0.003125\n",
            "2022-12-15 23:32:36,228 epoch 41 - iter 120/245 - loss 0.00732952 - samples/sec: 135.09 - lr: 0.003125\n",
            "2022-12-15 23:32:41,330 epoch 41 - iter 144/245 - loss 0.00727813 - samples/sec: 150.67 - lr: 0.003125\n",
            "2022-12-15 23:32:47,516 epoch 41 - iter 168/245 - loss 0.00728558 - samples/sec: 124.25 - lr: 0.003125\n",
            "2022-12-15 23:32:52,705 epoch 41 - iter 192/245 - loss 0.00726879 - samples/sec: 148.11 - lr: 0.003125\n",
            "2022-12-15 23:32:58,766 epoch 41 - iter 216/245 - loss 0.00734295 - samples/sec: 126.81 - lr: 0.003125\n",
            "2022-12-15 23:33:03,392 epoch 41 - iter 240/245 - loss 0.00747417 - samples/sec: 166.17 - lr: 0.003125\n",
            "2022-12-15 23:33:04,248 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:33:04,250 EPOCH 41 done: loss 0.0075 - lr 0.003125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:33:15,125 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:33:15,150 DEV : loss 0.03561308979988098 - f1-score (micro avg)  0.89\n",
            "2022-12-15 23:33:15,284 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 23:33:15,287 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:33:21,603 epoch 42 - iter 24/245 - loss 0.00691721 - samples/sec: 121.70 - lr: 0.003125\n",
            "2022-12-15 23:33:26,957 epoch 42 - iter 48/245 - loss 0.00726528 - samples/sec: 143.55 - lr: 0.003125\n",
            "2022-12-15 23:33:33,881 epoch 42 - iter 72/245 - loss 0.00810640 - samples/sec: 110.98 - lr: 0.003125\n",
            "2022-12-15 23:33:39,272 epoch 42 - iter 96/245 - loss 0.00836689 - samples/sec: 142.58 - lr: 0.003125\n",
            "2022-12-15 23:33:44,224 epoch 42 - iter 120/245 - loss 0.00818378 - samples/sec: 155.22 - lr: 0.003125\n",
            "2022-12-15 23:33:51,105 epoch 42 - iter 144/245 - loss 0.00785820 - samples/sec: 111.68 - lr: 0.003125\n",
            "2022-12-15 23:33:56,285 epoch 42 - iter 168/245 - loss 0.00741714 - samples/sec: 148.37 - lr: 0.003125\n",
            "2022-12-15 23:34:01,694 epoch 42 - iter 192/245 - loss 0.00756595 - samples/sec: 142.09 - lr: 0.003125\n",
            "2022-12-15 23:34:07,103 epoch 42 - iter 216/245 - loss 0.00762352 - samples/sec: 142.11 - lr: 0.003125\n",
            "2022-12-15 23:34:12,509 epoch 42 - iter 240/245 - loss 0.00758818 - samples/sec: 142.17 - lr: 0.003125\n",
            "2022-12-15 23:34:13,374 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:34:13,376 EPOCH 42 done: loss 0.0076 - lr 0.003125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:34:23,330 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:34:23,352 DEV : loss 0.03502008318901062 - f1-score (micro avg)  0.8922\n",
            "2022-12-15 23:34:23,481 BAD EPOCHS (no improvement): 2\n",
            "2022-12-15 23:34:23,483 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:34:28,555 epoch 43 - iter 24/245 - loss 0.00769678 - samples/sec: 151.59 - lr: 0.003125\n",
            "2022-12-15 23:34:35,129 epoch 43 - iter 48/245 - loss 0.00774329 - samples/sec: 116.90 - lr: 0.003125\n",
            "2022-12-15 23:34:41,211 epoch 43 - iter 72/245 - loss 0.00762484 - samples/sec: 126.35 - lr: 0.003125\n",
            "2022-12-15 23:34:46,430 epoch 43 - iter 96/245 - loss 0.00777302 - samples/sec: 147.27 - lr: 0.003125\n",
            "2022-12-15 23:34:50,938 epoch 43 - iter 120/245 - loss 0.00752931 - samples/sec: 170.53 - lr: 0.003125\n",
            "2022-12-15 23:34:58,507 epoch 43 - iter 144/245 - loss 0.00791385 - samples/sec: 101.51 - lr: 0.003125\n",
            "2022-12-15 23:35:04,075 epoch 43 - iter 168/245 - loss 0.00775537 - samples/sec: 138.04 - lr: 0.003125\n",
            "2022-12-15 23:35:08,712 epoch 43 - iter 192/245 - loss 0.00779415 - samples/sec: 165.77 - lr: 0.003125\n",
            "2022-12-15 23:35:16,046 epoch 43 - iter 216/245 - loss 0.00789956 - samples/sec: 104.78 - lr: 0.003125\n",
            "2022-12-15 23:35:21,668 epoch 43 - iter 240/245 - loss 0.00789342 - samples/sec: 136.71 - lr: 0.003125\n",
            "2022-12-15 23:35:22,746 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:35:22,748 EPOCH 43 done: loss 0.0079 - lr 0.003125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:35:32,407 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:35:32,432 DEV : loss 0.03572358936071396 - f1-score (micro avg)  0.8931\n",
            "2022-12-15 23:35:32,568 BAD EPOCHS (no improvement): 3\n",
            "2022-12-15 23:35:32,570 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:35:37,616 epoch 44 - iter 24/245 - loss 0.00714540 - samples/sec: 152.32 - lr: 0.003125\n",
            "2022-12-15 23:35:44,215 epoch 44 - iter 48/245 - loss 0.00701974 - samples/sec: 116.47 - lr: 0.003125\n",
            "2022-12-15 23:35:49,385 epoch 44 - iter 72/245 - loss 0.00744287 - samples/sec: 148.65 - lr: 0.003125\n",
            "2022-12-15 23:35:54,582 epoch 44 - iter 96/245 - loss 0.00711496 - samples/sec: 147.92 - lr: 0.003125\n",
            "2022-12-15 23:36:01,214 epoch 44 - iter 120/245 - loss 0.00715829 - samples/sec: 115.88 - lr: 0.003125\n",
            "2022-12-15 23:36:06,139 epoch 44 - iter 144/245 - loss 0.00741338 - samples/sec: 156.07 - lr: 0.003125\n",
            "2022-12-15 23:36:12,354 epoch 44 - iter 168/245 - loss 0.00719174 - samples/sec: 123.64 - lr: 0.003125\n",
            "2022-12-15 23:36:17,954 epoch 44 - iter 192/245 - loss 0.00698478 - samples/sec: 137.24 - lr: 0.003125\n",
            "2022-12-15 23:36:23,669 epoch 44 - iter 216/245 - loss 0.00711166 - samples/sec: 134.49 - lr: 0.003125\n",
            "2022-12-15 23:36:29,553 epoch 44 - iter 240/245 - loss 0.00700992 - samples/sec: 130.60 - lr: 0.003125\n",
            "2022-12-15 23:36:30,751 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:36:30,753 EPOCH 44 done: loss 0.0070 - lr 0.003125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:36:41,392 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:36:41,417 DEV : loss 0.035541433840990067 - f1-score (micro avg)  0.8903\n",
            "2022-12-15 23:36:41,551 Epoch    44: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2022-12-15 23:36:41,553 BAD EPOCHS (no improvement): 4\n",
            "2022-12-15 23:36:41,556 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:36:47,570 epoch 45 - iter 24/245 - loss 0.00834227 - samples/sec: 127.90 - lr: 0.001563\n",
            "2022-12-15 23:36:52,592 epoch 45 - iter 48/245 - loss 0.00710847 - samples/sec: 153.08 - lr: 0.001563\n",
            "2022-12-15 23:36:59,307 epoch 45 - iter 72/245 - loss 0.00743390 - samples/sec: 114.43 - lr: 0.001563\n",
            "2022-12-15 23:37:05,610 epoch 45 - iter 96/245 - loss 0.00733177 - samples/sec: 121.94 - lr: 0.001563\n",
            "2022-12-15 23:37:12,628 epoch 45 - iter 120/245 - loss 0.00811917 - samples/sec: 109.51 - lr: 0.001563\n",
            "2022-12-15 23:37:18,156 epoch 45 - iter 144/245 - loss 0.00783678 - samples/sec: 139.04 - lr: 0.001563\n",
            "2022-12-15 23:37:24,165 epoch 45 - iter 168/245 - loss 0.00746653 - samples/sec: 127.88 - lr: 0.001563\n",
            "2022-12-15 23:37:28,842 epoch 45 - iter 192/245 - loss 0.00738708 - samples/sec: 164.36 - lr: 0.001563\n",
            "2022-12-15 23:37:33,971 epoch 45 - iter 216/245 - loss 0.00750279 - samples/sec: 149.85 - lr: 0.001563\n",
            "2022-12-15 23:37:40,404 epoch 45 - iter 240/245 - loss 0.00747667 - samples/sec: 119.48 - lr: 0.001563\n",
            "2022-12-15 23:37:41,306 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:37:41,308 EPOCH 45 done: loss 0.0075 - lr 0.001563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:37:51,350 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:37:51,374 DEV : loss 0.03545683994889259 - f1-score (micro avg)  0.8905\n",
            "2022-12-15 23:37:51,507 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 23:37:51,509 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:37:58,151 epoch 46 - iter 24/245 - loss 0.00617512 - samples/sec: 115.75 - lr: 0.001563\n",
            "2022-12-15 23:38:04,274 epoch 46 - iter 48/245 - loss 0.00824552 - samples/sec: 125.51 - lr: 0.001563\n",
            "2022-12-15 23:38:10,009 epoch 46 - iter 72/245 - loss 0.00761188 - samples/sec: 134.01 - lr: 0.001563\n",
            "2022-12-15 23:38:15,921 epoch 46 - iter 96/245 - loss 0.00782098 - samples/sec: 130.00 - lr: 0.001563\n",
            "2022-12-15 23:38:21,423 epoch 46 - iter 120/245 - loss 0.00807661 - samples/sec: 139.69 - lr: 0.001563\n",
            "2022-12-15 23:38:26,880 epoch 46 - iter 144/245 - loss 0.00770473 - samples/sec: 140.84 - lr: 0.001563\n",
            "2022-12-15 23:38:33,333 epoch 46 - iter 168/245 - loss 0.00748593 - samples/sec: 119.11 - lr: 0.001563\n",
            "2022-12-15 23:38:38,953 epoch 46 - iter 192/245 - loss 0.00765638 - samples/sec: 136.76 - lr: 0.001563\n",
            "2022-12-15 23:38:45,370 epoch 46 - iter 216/245 - loss 0.00749687 - samples/sec: 119.78 - lr: 0.001563\n",
            "2022-12-15 23:38:50,810 epoch 46 - iter 240/245 - loss 0.00743430 - samples/sec: 141.29 - lr: 0.001563\n",
            "2022-12-15 23:38:51,892 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:38:51,894 EPOCH 46 done: loss 0.0073 - lr 0.001563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:11<00:00,  3.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:39:02,970 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:39:02,996 DEV : loss 0.03555715084075928 - f1-score (micro avg)  0.8917\n",
            "2022-12-15 23:39:03,140 BAD EPOCHS (no improvement): 2\n",
            "2022-12-15 23:39:03,142 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:39:08,954 epoch 47 - iter 24/245 - loss 0.00610444 - samples/sec: 132.29 - lr: 0.001563\n",
            "2022-12-15 23:39:15,017 epoch 47 - iter 48/245 - loss 0.00703853 - samples/sec: 126.77 - lr: 0.001563\n",
            "2022-12-15 23:39:20,872 epoch 47 - iter 72/245 - loss 0.00668319 - samples/sec: 131.28 - lr: 0.001563\n",
            "2022-12-15 23:39:27,810 epoch 47 - iter 96/245 - loss 0.00647034 - samples/sec: 110.76 - lr: 0.001563\n",
            "2022-12-15 23:39:34,211 epoch 47 - iter 120/245 - loss 0.00629132 - samples/sec: 120.04 - lr: 0.001563\n",
            "2022-12-15 23:39:42,225 epoch 47 - iter 144/245 - loss 0.00677417 - samples/sec: 95.89 - lr: 0.001563\n",
            "2022-12-15 23:39:47,633 epoch 47 - iter 168/245 - loss 0.00690644 - samples/sec: 142.10 - lr: 0.001563\n",
            "2022-12-15 23:39:52,638 epoch 47 - iter 192/245 - loss 0.00685584 - samples/sec: 153.60 - lr: 0.001563\n",
            "2022-12-15 23:39:57,859 epoch 47 - iter 216/245 - loss 0.00711158 - samples/sec: 147.23 - lr: 0.001563\n",
            "2022-12-15 23:40:02,460 epoch 47 - iter 240/245 - loss 0.00703365 - samples/sec: 167.08 - lr: 0.001563\n",
            "2022-12-15 23:40:03,479 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:40:03,481 EPOCH 47 done: loss 0.0070 - lr 0.001563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:40:14,269 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:40:14,294 DEV : loss 0.035418882966041565 - f1-score (micro avg)  0.8897\n",
            "2022-12-15 23:40:14,431 BAD EPOCHS (no improvement): 3\n",
            "2022-12-15 23:40:14,433 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:40:19,598 epoch 48 - iter 24/245 - loss 0.00844975 - samples/sec: 148.85 - lr: 0.001563\n",
            "2022-12-15 23:40:24,154 epoch 48 - iter 48/245 - loss 0.00809639 - samples/sec: 168.74 - lr: 0.001563\n",
            "2022-12-15 23:40:30,553 epoch 48 - iter 72/245 - loss 0.00757812 - samples/sec: 120.10 - lr: 0.001563\n",
            "2022-12-15 23:40:35,801 epoch 48 - iter 96/245 - loss 0.00732206 - samples/sec: 146.47 - lr: 0.001563\n",
            "2022-12-15 23:40:42,276 epoch 48 - iter 120/245 - loss 0.00732192 - samples/sec: 118.68 - lr: 0.001563\n",
            "2022-12-15 23:40:48,642 epoch 48 - iter 144/245 - loss 0.00764993 - samples/sec: 120.74 - lr: 0.001563\n",
            "2022-12-15 23:40:53,966 epoch 48 - iter 168/245 - loss 0.00729898 - samples/sec: 144.37 - lr: 0.001563\n",
            "2022-12-15 23:41:00,132 epoch 48 - iter 192/245 - loss 0.00732454 - samples/sec: 124.63 - lr: 0.001563\n",
            "2022-12-15 23:41:05,316 epoch 48 - iter 216/245 - loss 0.00721489 - samples/sec: 148.29 - lr: 0.001563\n",
            "2022-12-15 23:41:12,699 epoch 48 - iter 240/245 - loss 0.00709498 - samples/sec: 104.07 - lr: 0.001563\n",
            "2022-12-15 23:41:13,651 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:41:13,653 EPOCH 48 done: loss 0.0071 - lr 0.001563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:41:23,648 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:41:23,671 DEV : loss 0.035394567996263504 - f1-score (micro avg)  0.8916\n",
            "2022-12-15 23:41:23,805 Epoch    48: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2022-12-15 23:41:23,807 BAD EPOCHS (no improvement): 4\n",
            "2022-12-15 23:41:23,808 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:41:28,635 epoch 49 - iter 24/245 - loss 0.00686675 - samples/sec: 159.35 - lr: 0.000781\n",
            "2022-12-15 23:41:34,622 epoch 49 - iter 48/245 - loss 0.00632789 - samples/sec: 128.36 - lr: 0.000781\n",
            "2022-12-15 23:41:40,532 epoch 49 - iter 72/245 - loss 0.00609964 - samples/sec: 130.03 - lr: 0.000781\n",
            "2022-12-15 23:41:46,941 epoch 49 - iter 96/245 - loss 0.00658742 - samples/sec: 119.91 - lr: 0.000781\n",
            "2022-12-15 23:41:54,330 epoch 49 - iter 120/245 - loss 0.00714936 - samples/sec: 104.00 - lr: 0.000781\n",
            "2022-12-15 23:41:59,843 epoch 49 - iter 144/245 - loss 0.00741282 - samples/sec: 139.41 - lr: 0.000781\n",
            "2022-12-15 23:42:05,507 epoch 49 - iter 168/245 - loss 0.00725508 - samples/sec: 135.73 - lr: 0.000781\n",
            "2022-12-15 23:42:11,104 epoch 49 - iter 192/245 - loss 0.00752202 - samples/sec: 137.33 - lr: 0.000781\n",
            "2022-12-15 23:42:17,555 epoch 49 - iter 216/245 - loss 0.00748266 - samples/sec: 119.14 - lr: 0.000781\n",
            "2022-12-15 23:42:22,682 epoch 49 - iter 240/245 - loss 0.00748094 - samples/sec: 149.90 - lr: 0.000781\n",
            "2022-12-15 23:42:23,490 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:42:23,492 EPOCH 49 done: loss 0.0075 - lr 0.000781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:11<00:00,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:42:34,516 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:42:34,540 DEV : loss 0.03555220365524292 - f1-score (micro avg)  0.889\n",
            "2022-12-15 23:42:34,669 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 23:42:34,671 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:42:39,765 epoch 50 - iter 24/245 - loss 0.00679563 - samples/sec: 150.91 - lr: 0.000781\n",
            "2022-12-15 23:42:44,679 epoch 50 - iter 48/245 - loss 0.00665822 - samples/sec: 156.42 - lr: 0.000781\n",
            "2022-12-15 23:42:49,594 epoch 50 - iter 72/245 - loss 0.00755486 - samples/sec: 156.39 - lr: 0.000781\n",
            "2022-12-15 23:42:55,610 epoch 50 - iter 96/245 - loss 0.00739975 - samples/sec: 127.75 - lr: 0.000781\n",
            "2022-12-15 23:43:01,263 epoch 50 - iter 120/245 - loss 0.00743119 - samples/sec: 135.97 - lr: 0.000781\n",
            "2022-12-15 23:43:09,440 epoch 50 - iter 144/245 - loss 0.00762778 - samples/sec: 93.97 - lr: 0.000781\n",
            "2022-12-15 23:43:14,764 epoch 50 - iter 168/245 - loss 0.00754695 - samples/sec: 144.36 - lr: 0.000781\n",
            "2022-12-15 23:43:20,656 epoch 50 - iter 192/245 - loss 0.00735202 - samples/sec: 130.44 - lr: 0.000781\n",
            "2022-12-15 23:43:27,511 epoch 50 - iter 216/245 - loss 0.00725760 - samples/sec: 112.11 - lr: 0.000781\n",
            "2022-12-15 23:43:33,471 epoch 50 - iter 240/245 - loss 0.00722071 - samples/sec: 128.95 - lr: 0.000781\n",
            "2022-12-15 23:43:34,303 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:43:34,305 EPOCH 50 done: loss 0.0073 - lr 0.000781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:43:44,229 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:43:44,251 DEV : loss 0.035571396350860596 - f1-score (micro avg)  0.8882\n",
            "2022-12-15 23:43:44,385 BAD EPOCHS (no improvement): 2\n",
            "2022-12-15 23:43:44,386 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:43:50,318 epoch 51 - iter 24/245 - loss 0.00658672 - samples/sec: 129.61 - lr: 0.000781\n",
            "2022-12-15 23:43:56,335 epoch 51 - iter 48/245 - loss 0.00631476 - samples/sec: 127.73 - lr: 0.000781\n",
            "2022-12-15 23:44:02,265 epoch 51 - iter 72/245 - loss 0.00624902 - samples/sec: 129.61 - lr: 0.000781\n",
            "2022-12-15 23:44:07,055 epoch 51 - iter 96/245 - loss 0.00631890 - samples/sec: 160.49 - lr: 0.000781\n",
            "2022-12-15 23:44:12,907 epoch 51 - iter 120/245 - loss 0.00704744 - samples/sec: 131.33 - lr: 0.000781\n",
            "2022-12-15 23:44:18,948 epoch 51 - iter 144/245 - loss 0.00689887 - samples/sec: 127.22 - lr: 0.000781\n",
            "2022-12-15 23:44:24,465 epoch 51 - iter 168/245 - loss 0.00673511 - samples/sec: 139.32 - lr: 0.000781\n",
            "2022-12-15 23:44:32,727 epoch 51 - iter 192/245 - loss 0.00671438 - samples/sec: 93.01 - lr: 0.000781\n",
            "2022-12-15 23:44:37,975 epoch 51 - iter 216/245 - loss 0.00695038 - samples/sec: 146.45 - lr: 0.000781\n",
            "2022-12-15 23:44:43,426 epoch 51 - iter 240/245 - loss 0.00683220 - samples/sec: 141.01 - lr: 0.000781\n",
            "2022-12-15 23:44:44,764 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:44:44,766 EPOCH 51 done: loss 0.0068 - lr 0.000781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:44:54,865 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:44:54,888 DEV : loss 0.03548908978700638 - f1-score (micro avg)  0.89\n",
            "2022-12-15 23:44:55,023 BAD EPOCHS (no improvement): 3\n",
            "2022-12-15 23:44:55,027 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:45:00,606 epoch 52 - iter 24/245 - loss 0.00710273 - samples/sec: 137.78 - lr: 0.000781\n",
            "2022-12-15 23:45:05,640 epoch 52 - iter 48/245 - loss 0.00736617 - samples/sec: 152.67 - lr: 0.000781\n",
            "2022-12-15 23:45:11,280 epoch 52 - iter 72/245 - loss 0.00723066 - samples/sec: 136.30 - lr: 0.000781\n",
            "2022-12-15 23:45:20,973 epoch 52 - iter 96/245 - loss 0.00713478 - samples/sec: 79.26 - lr: 0.000781\n",
            "2022-12-15 23:45:26,672 epoch 52 - iter 120/245 - loss 0.00729291 - samples/sec: 134.88 - lr: 0.000781\n",
            "2022-12-15 23:45:32,732 epoch 52 - iter 144/245 - loss 0.00726305 - samples/sec: 126.81 - lr: 0.000781\n",
            "2022-12-15 23:45:37,592 epoch 52 - iter 168/245 - loss 0.00724526 - samples/sec: 158.16 - lr: 0.000781\n",
            "2022-12-15 23:45:42,099 epoch 52 - iter 192/245 - loss 0.00715929 - samples/sec: 170.58 - lr: 0.000781\n",
            "2022-12-15 23:45:47,032 epoch 52 - iter 216/245 - loss 0.00701965 - samples/sec: 155.80 - lr: 0.000781\n",
            "2022-12-15 23:45:53,324 epoch 52 - iter 240/245 - loss 0.00701068 - samples/sec: 122.17 - lr: 0.000781\n",
            "2022-12-15 23:45:54,458 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:45:54,461 EPOCH 52 done: loss 0.0070 - lr 0.000781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:46:05,179 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:46:05,202 DEV : loss 0.035630691796541214 - f1-score (micro avg)  0.8901\n",
            "2022-12-15 23:46:05,339 Epoch    52: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2022-12-15 23:46:05,340 BAD EPOCHS (no improvement): 4\n",
            "2022-12-15 23:46:05,346 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:46:11,967 epoch 53 - iter 24/245 - loss 0.00673890 - samples/sec: 116.09 - lr: 0.000391\n",
            "2022-12-15 23:46:17,109 epoch 53 - iter 48/245 - loss 0.00596844 - samples/sec: 149.51 - lr: 0.000391\n",
            "2022-12-15 23:46:22,703 epoch 53 - iter 72/245 - loss 0.00668473 - samples/sec: 137.40 - lr: 0.000391\n",
            "2022-12-15 23:46:27,481 epoch 53 - iter 96/245 - loss 0.00662421 - samples/sec: 160.87 - lr: 0.000391\n",
            "2022-12-15 23:46:33,403 epoch 53 - iter 120/245 - loss 0.00685039 - samples/sec: 129.78 - lr: 0.000391\n",
            "2022-12-15 23:46:38,463 epoch 53 - iter 144/245 - loss 0.00662366 - samples/sec: 151.90 - lr: 0.000391\n",
            "2022-12-15 23:46:43,459 epoch 53 - iter 168/245 - loss 0.00692946 - samples/sec: 153.82 - lr: 0.000391\n",
            "2022-12-15 23:46:48,973 epoch 53 - iter 192/245 - loss 0.00666774 - samples/sec: 139.39 - lr: 0.000391\n",
            "2022-12-15 23:46:55,481 epoch 53 - iter 216/245 - loss 0.00671520 - samples/sec: 118.09 - lr: 0.000391\n",
            "2022-12-15 23:47:03,748 epoch 53 - iter 240/245 - loss 0.00677187 - samples/sec: 92.94 - lr: 0.000391\n",
            "2022-12-15 23:47:04,894 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:47:04,896 EPOCH 53 done: loss 0.0067 - lr 0.000391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:47:14,994 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:47:15,016 DEV : loss 0.035685762763023376 - f1-score (micro avg)  0.8898\n",
            "2022-12-15 23:47:15,149 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 23:47:15,152 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:47:22,743 epoch 54 - iter 24/245 - loss 0.00529054 - samples/sec: 101.26 - lr: 0.000391\n",
            "2022-12-15 23:47:29,974 epoch 54 - iter 48/245 - loss 0.00576506 - samples/sec: 106.27 - lr: 0.000391\n",
            "2022-12-15 23:47:34,982 epoch 54 - iter 72/245 - loss 0.00612709 - samples/sec: 153.47 - lr: 0.000391\n",
            "2022-12-15 23:47:39,730 epoch 54 - iter 96/245 - loss 0.00619416 - samples/sec: 161.92 - lr: 0.000391\n",
            "2022-12-15 23:47:45,244 epoch 54 - iter 120/245 - loss 0.00664890 - samples/sec: 139.37 - lr: 0.000391\n",
            "2022-12-15 23:47:50,273 epoch 54 - iter 144/245 - loss 0.00706668 - samples/sec: 152.86 - lr: 0.000391\n",
            "2022-12-15 23:47:57,463 epoch 54 - iter 168/245 - loss 0.00702117 - samples/sec: 106.88 - lr: 0.000391\n",
            "2022-12-15 23:48:02,638 epoch 54 - iter 192/245 - loss 0.00706326 - samples/sec: 148.50 - lr: 0.000391\n",
            "2022-12-15 23:48:08,206 epoch 54 - iter 216/245 - loss 0.00720293 - samples/sec: 138.05 - lr: 0.000391\n",
            "2022-12-15 23:48:14,358 epoch 54 - iter 240/245 - loss 0.00705461 - samples/sec: 124.91 - lr: 0.000391\n",
            "2022-12-15 23:48:15,325 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:48:15,327 EPOCH 54 done: loss 0.0070 - lr 0.000391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:11<00:00,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:48:26,423 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:48:26,447 DEV : loss 0.035681385546922684 - f1-score (micro avg)  0.8913\n",
            "2022-12-15 23:48:26,584 BAD EPOCHS (no improvement): 2\n",
            "2022-12-15 23:48:26,586 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:48:32,004 epoch 55 - iter 24/245 - loss 0.00818410 - samples/sec: 141.93 - lr: 0.000391\n",
            "2022-12-15 23:48:37,976 epoch 55 - iter 48/245 - loss 0.00770026 - samples/sec: 128.68 - lr: 0.000391\n",
            "2022-12-15 23:48:43,290 epoch 55 - iter 72/245 - loss 0.00783347 - samples/sec: 144.66 - lr: 0.000391\n",
            "2022-12-15 23:48:50,192 epoch 55 - iter 96/245 - loss 0.00705417 - samples/sec: 111.35 - lr: 0.000391\n",
            "2022-12-15 23:48:56,636 epoch 55 - iter 120/245 - loss 0.00759185 - samples/sec: 119.27 - lr: 0.000391\n",
            "2022-12-15 23:49:02,022 epoch 55 - iter 144/245 - loss 0.00729633 - samples/sec: 142.71 - lr: 0.000391\n",
            "2022-12-15 23:49:07,302 epoch 55 - iter 168/245 - loss 0.00704415 - samples/sec: 145.56 - lr: 0.000391\n",
            "2022-12-15 23:49:13,733 epoch 55 - iter 192/245 - loss 0.00710268 - samples/sec: 119.51 - lr: 0.000391\n",
            "2022-12-15 23:49:18,384 epoch 55 - iter 216/245 - loss 0.00710597 - samples/sec: 165.27 - lr: 0.000391\n",
            "2022-12-15 23:49:24,810 epoch 55 - iter 240/245 - loss 0.00726156 - samples/sec: 119.59 - lr: 0.000391\n",
            "2022-12-15 23:49:25,782 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:49:25,784 EPOCH 55 done: loss 0.0072 - lr 0.000391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:49:35,919 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:49:35,943 DEV : loss 0.03565187379717827 - f1-score (micro avg)  0.8913\n",
            "2022-12-15 23:49:36,082 BAD EPOCHS (no improvement): 3\n",
            "2022-12-15 23:49:36,086 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:49:42,944 epoch 56 - iter 24/245 - loss 0.00878279 - samples/sec: 112.06 - lr: 0.000391\n",
            "2022-12-15 23:49:47,862 epoch 56 - iter 48/245 - loss 0.00979479 - samples/sec: 156.28 - lr: 0.000391\n",
            "2022-12-15 23:49:53,090 epoch 56 - iter 72/245 - loss 0.00825337 - samples/sec: 147.04 - lr: 0.000391\n",
            "2022-12-15 23:49:59,017 epoch 56 - iter 96/245 - loss 0.00737849 - samples/sec: 129.67 - lr: 0.000391\n",
            "2022-12-15 23:50:06,100 epoch 56 - iter 120/245 - loss 0.00726007 - samples/sec: 108.49 - lr: 0.000391\n",
            "2022-12-15 23:50:12,461 epoch 56 - iter 144/245 - loss 0.00731062 - samples/sec: 120.82 - lr: 0.000391\n",
            "2022-12-15 23:50:17,392 epoch 56 - iter 168/245 - loss 0.00722211 - samples/sec: 155.88 - lr: 0.000391\n",
            "2022-12-15 23:50:22,912 epoch 56 - iter 192/245 - loss 0.00706391 - samples/sec: 139.27 - lr: 0.000391\n",
            "2022-12-15 23:50:28,698 epoch 56 - iter 216/245 - loss 0.00705743 - samples/sec: 132.83 - lr: 0.000391\n",
            "2022-12-15 23:50:35,121 epoch 56 - iter 240/245 - loss 0.00690463 - samples/sec: 119.65 - lr: 0.000391\n",
            "2022-12-15 23:50:35,897 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:50:35,899 EPOCH 56 done: loss 0.0069 - lr 0.000391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:09<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:50:45,910 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:50:45,932 DEV : loss 0.035618700087070465 - f1-score (micro avg)  0.8902\n",
            "2022-12-15 23:50:46,066 Epoch    56: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2022-12-15 23:50:46,068 BAD EPOCHS (no improvement): 4\n",
            "2022-12-15 23:50:46,071 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:50:52,522 epoch 57 - iter 24/245 - loss 0.00819368 - samples/sec: 119.15 - lr: 0.000195\n",
            "2022-12-15 23:50:58,909 epoch 57 - iter 48/245 - loss 0.00726786 - samples/sec: 120.32 - lr: 0.000195\n",
            "2022-12-15 23:51:05,382 epoch 57 - iter 72/245 - loss 0.00714264 - samples/sec: 118.73 - lr: 0.000195\n",
            "2022-12-15 23:51:10,683 epoch 57 - iter 96/245 - loss 0.00661354 - samples/sec: 144.97 - lr: 0.000195\n",
            "2022-12-15 23:51:17,845 epoch 57 - iter 120/245 - loss 0.00702420 - samples/sec: 107.30 - lr: 0.000195\n",
            "2022-12-15 23:51:23,048 epoch 57 - iter 144/245 - loss 0.00702116 - samples/sec: 147.75 - lr: 0.000195\n",
            "2022-12-15 23:51:27,920 epoch 57 - iter 168/245 - loss 0.00698959 - samples/sec: 157.76 - lr: 0.000195\n",
            "2022-12-15 23:51:33,350 epoch 57 - iter 192/245 - loss 0.00677020 - samples/sec: 141.54 - lr: 0.000195\n",
            "2022-12-15 23:51:39,827 epoch 57 - iter 216/245 - loss 0.00695834 - samples/sec: 118.65 - lr: 0.000195\n",
            "2022-12-15 23:51:45,503 epoch 57 - iter 240/245 - loss 0.00714746 - samples/sec: 135.42 - lr: 0.000195\n",
            "2022-12-15 23:51:46,669 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:51:46,671 EPOCH 57 done: loss 0.0071 - lr 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:51:57,394 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:51:57,418 DEV : loss 0.035603173077106476 - f1-score (micro avg)  0.8898\n",
            "2022-12-15 23:51:57,552 BAD EPOCHS (no improvement): 1\n",
            "2022-12-15 23:51:57,554 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:52:04,605 epoch 58 - iter 24/245 - loss 0.00610341 - samples/sec: 109.02 - lr: 0.000195\n",
            "2022-12-15 23:52:09,785 epoch 58 - iter 48/245 - loss 0.00642826 - samples/sec: 148.38 - lr: 0.000195\n",
            "2022-12-15 23:52:14,970 epoch 58 - iter 72/245 - loss 0.00714228 - samples/sec: 148.25 - lr: 0.000195\n",
            "2022-12-15 23:52:21,091 epoch 58 - iter 96/245 - loss 0.00697135 - samples/sec: 125.56 - lr: 0.000195\n",
            "2022-12-15 23:52:27,048 epoch 58 - iter 120/245 - loss 0.00654548 - samples/sec: 129.03 - lr: 0.000195\n",
            "2022-12-15 23:52:31,834 epoch 58 - iter 144/245 - loss 0.00637312 - samples/sec: 160.62 - lr: 0.000195\n",
            "2022-12-15 23:52:38,273 epoch 58 - iter 168/245 - loss 0.00648585 - samples/sec: 119.35 - lr: 0.000195\n",
            "2022-12-15 23:52:45,232 epoch 58 - iter 192/245 - loss 0.00682250 - samples/sec: 110.43 - lr: 0.000195\n",
            "2022-12-15 23:52:50,323 epoch 58 - iter 216/245 - loss 0.00702892 - samples/sec: 150.97 - lr: 0.000195\n",
            "2022-12-15 23:52:57,037 epoch 58 - iter 240/245 - loss 0.00696824 - samples/sec: 114.47 - lr: 0.000195\n",
            "2022-12-15 23:52:58,013 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:52:58,015 EPOCH 58 done: loss 0.0071 - lr 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:53:08,121 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:53:08,146 DEV : loss 0.03560180962085724 - f1-score (micro avg)  0.8896\n",
            "2022-12-15 23:53:08,279 BAD EPOCHS (no improvement): 2\n",
            "2022-12-15 23:53:08,282 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:53:14,249 epoch 59 - iter 24/245 - loss 0.00641920 - samples/sec: 128.81 - lr: 0.000195\n",
            "2022-12-15 23:53:19,689 epoch 59 - iter 48/245 - loss 0.00735354 - samples/sec: 141.29 - lr: 0.000195\n",
            "2022-12-15 23:53:26,880 epoch 59 - iter 72/245 - loss 0.00723171 - samples/sec: 106.86 - lr: 0.000195\n",
            "2022-12-15 23:53:32,287 epoch 59 - iter 96/245 - loss 0.00728061 - samples/sec: 142.15 - lr: 0.000195\n",
            "2022-12-15 23:53:38,058 epoch 59 - iter 120/245 - loss 0.00755098 - samples/sec: 133.17 - lr: 0.000195\n",
            "2022-12-15 23:53:43,418 epoch 59 - iter 144/245 - loss 0.00751893 - samples/sec: 143.40 - lr: 0.000195\n",
            "2022-12-15 23:53:48,493 epoch 59 - iter 168/245 - loss 0.00747900 - samples/sec: 151.45 - lr: 0.000195\n",
            "2022-12-15 23:53:54,247 epoch 59 - iter 192/245 - loss 0.00728050 - samples/sec: 133.58 - lr: 0.000195\n",
            "2022-12-15 23:54:02,487 epoch 59 - iter 216/245 - loss 0.00707707 - samples/sec: 93.25 - lr: 0.000195\n",
            "2022-12-15 23:54:08,726 epoch 59 - iter 240/245 - loss 0.00719397 - samples/sec: 123.21 - lr: 0.000195\n",
            "2022-12-15 23:54:09,549 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:54:09,551 EPOCH 59 done: loss 0.0072 - lr 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:10<00:00,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:54:19,720 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:54:19,745 DEV : loss 0.03561580553650856 - f1-score (micro avg)  0.8899\n",
            "2022-12-15 23:54:19,876 BAD EPOCHS (no improvement): 3\n",
            "2022-12-15 23:54:19,879 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:54:25,136 epoch 60 - iter 24/245 - loss 0.00832094 - samples/sec: 146.22 - lr: 0.000195\n",
            "2022-12-15 23:54:31,173 epoch 60 - iter 48/245 - loss 0.00701704 - samples/sec: 127.31 - lr: 0.000195\n",
            "2022-12-15 23:54:38,188 epoch 60 - iter 72/245 - loss 0.00663483 - samples/sec: 109.54 - lr: 0.000195\n",
            "2022-12-15 23:54:43,957 epoch 60 - iter 96/245 - loss 0.00665982 - samples/sec: 133.23 - lr: 0.000195\n",
            "2022-12-15 23:54:48,994 epoch 60 - iter 120/245 - loss 0.00692155 - samples/sec: 152.59 - lr: 0.000195\n",
            "2022-12-15 23:54:53,815 epoch 60 - iter 144/245 - loss 0.00710772 - samples/sec: 159.44 - lr: 0.000195\n",
            "2022-12-15 23:55:00,988 epoch 60 - iter 168/245 - loss 0.00737087 - samples/sec: 107.14 - lr: 0.000195\n",
            "2022-12-15 23:55:06,988 epoch 60 - iter 192/245 - loss 0.00725396 - samples/sec: 128.08 - lr: 0.000195\n",
            "2022-12-15 23:55:12,053 epoch 60 - iter 216/245 - loss 0.00724795 - samples/sec: 151.77 - lr: 0.000195\n",
            "2022-12-15 23:55:19,060 epoch 60 - iter 240/245 - loss 0.00730834 - samples/sec: 109.67 - lr: 0.000195\n",
            "2022-12-15 23:55:19,910 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:55:19,913 EPOCH 60 done: loss 0.0073 - lr 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [00:11<00:00,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:55:31,103 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:55:31,126 DEV : loss 0.03563614562153816 - f1-score (micro avg)  0.891\n",
            "2022-12-15 23:55:31,257 Epoch    60: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2022-12-15 23:55:31,259 BAD EPOCHS (no improvement): 4\n",
            "2022-12-15 23:55:31,263 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:55:31,265 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:55:31,267 learning rate too small - quitting training!\n",
            "2022-12-15 23:55:31,269 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:55:31,637 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-15 23:55:31,639 loading file resources/taggers/sota-ner-flair/best-model.pt\n",
            "2022-12-15 23:55:32,304 SequenceTagger predicts: Dictionary with 27 tags: O, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-LEGISLACAO, B-LEGISLACAO, E-LEGISLACAO, I-LEGISLACAO, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-TEMPO, B-TEMPO, E-TEMPO, I-TEMPO, S-JURISPRUDENCIA, B-JURISPRUDENCIA, E-JURISPRUDENCIA, I-JURISPRUDENCIA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL, <START>, <STOP>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44/44 [00:50<00:00,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-15 23:56:23,221 Evaluating as a multi-label problem: False\n",
            "2022-12-15 23:56:23,241 0.8899\t0.8997\t0.8948\t0.8187\n",
            "2022-12-15 23:56:23,242 \n",
            "Results:\n",
            "- F-score (micro) 0.8948\n",
            "- F-score (macro) 0.8802\n",
            "- Accuracy 0.8187\n",
            "\n",
            "By class:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   ORGANIZACAO     0.8595    0.8423    0.8508       501\n",
            "    LEGISLACAO     0.9409    0.9683    0.9544       378\n",
            "        PESSOA     0.9170    0.9485    0.9325       233\n",
            "JURISPRUDENCIA     0.8571    0.9081    0.8819       185\n",
            "         TEMPO     0.9027    0.8698    0.8859       192\n",
            "         LOCAL     0.7451    0.8085    0.7755        47\n",
            "\n",
            "     micro avg     0.8899    0.8997    0.8948      1536\n",
            "     macro avg     0.8704    0.8909    0.8802      1536\n",
            "  weighted avg     0.8899    0.8997    0.8945      1536\n",
            "\n",
            "2022-12-15 23:56:23,244 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_score': 0.8947879572677242,\n",
              " 'dev_score_history': [0.5959595959595959,\n",
              "  0.7385892116182572,\n",
              "  0.7973967176004527,\n",
              "  0.7867378477100309,\n",
              "  0.8264417845484223,\n",
              "  0.8140837556681781,\n",
              "  0.8287800919664593,\n",
              "  0.8443213296398894,\n",
              "  0.8572987721691678,\n",
              "  0.8402893711741792,\n",
              "  0.8522975929978118,\n",
              "  0.8730245231607631,\n",
              "  0.8789740849585893,\n",
              "  0.8574502420656267,\n",
              "  0.8776019983347211,\n",
              "  0.8681408681408682,\n",
              "  0.8757814623539005,\n",
              "  0.8761230601687994,\n",
              "  0.8906549739654699,\n",
              "  0.878550175818231,\n",
              "  0.8827361563517915,\n",
              "  0.8868999186330351,\n",
              "  0.8852997536271558,\n",
              "  0.8827738029719318,\n",
              "  0.8861171366594359,\n",
              "  0.8935936211163046,\n",
              "  0.8882224645583425,\n",
              "  0.8981481481481481,\n",
              "  0.8929447017161536,\n",
              "  0.8973591069970052,\n",
              "  0.8885236921391401,\n",
              "  0.88998088998089,\n",
              "  0.8892525913802509,\n",
              "  0.8905228758169934,\n",
              "  0.8974707642099539,\n",
              "  0.8922237380627558,\n",
              "  0.8922659430122115,\n",
              "  0.8933623503808488,\n",
              "  0.893336989306279,\n",
              "  0.8863325116406463,\n",
              "  0.8900409276944066,\n",
              "  0.8921729611384783,\n",
              "  0.8930714675395527,\n",
              "  0.8902872777017784,\n",
              "  0.8905309250136837,\n",
              "  0.8917441224712959,\n",
              "  0.8897400820793434,\n",
              "  0.8916256157635469,\n",
              "  0.8890103881902679,\n",
              "  0.8881596937380366,\n",
              "  0.8899835796387521,\n",
              "  0.890103881902679,\n",
              "  0.8898003828274541,\n",
              "  0.8913222009307419,\n",
              "  0.8913222009307419,\n",
              "  0.8901639344262294,\n",
              "  0.8898003828274541,\n",
              "  0.8895571350464735,\n",
              "  0.8899207866703086,\n",
              "  0.8909538125170813],\n",
              " 'train_loss_history': [0.350116548965096,\n",
              "  0.11435557651061816,\n",
              "  0.07419619267850679,\n",
              "  0.05797558526026924,\n",
              "  0.048529182989489786,\n",
              "  0.040234275332076484,\n",
              "  0.03637322090200936,\n",
              "  0.03142888475580302,\n",
              "  0.02951550340513331,\n",
              "  0.027460622353433294,\n",
              "  0.025951244291839128,\n",
              "  0.02478436078070958,\n",
              "  0.022008745408801364,\n",
              "  0.020843814792668912,\n",
              "  0.020552565101383917,\n",
              "  0.01948297707644574,\n",
              "  0.017478446428201476,\n",
              "  0.01494987759756757,\n",
              "  0.01370943788108925,\n",
              "  0.013278682912072515,\n",
              "  0.01238936604930935,\n",
              "  0.012561316643595955,\n",
              "  0.011778576309987483,\n",
              "  0.010687710887103808,\n",
              "  0.009885741885088778,\n",
              "  0.009768008085607148,\n",
              "  0.009773866770598447,\n",
              "  0.010158335785561788,\n",
              "  0.009458496589959961,\n",
              "  0.00947531022791209,\n",
              "  0.008558571908243086,\n",
              "  0.008487251842203971,\n",
              "  0.008174439379004436,\n",
              "  0.008086318452952107,\n",
              "  0.007736594783547848,\n",
              "  0.007998101692357934,\n",
              "  0.0076246344827981,\n",
              "  0.007454977528546256,\n",
              "  0.007698344023413818,\n",
              "  0.0073368454833018576,\n",
              "  0.00747906394339598,\n",
              "  0.007573735692797358,\n",
              "  0.007869197844610449,\n",
              "  0.007018613044347013,\n",
              "  0.007451350723551643,\n",
              "  0.007349680922939283,\n",
              "  0.0070104522006950104,\n",
              "  0.007054184696622426,\n",
              "  0.0074520471212223644,\n",
              "  0.007272857824541929,\n",
              "  0.006774626819442203,\n",
              "  0.006992626975912324,\n",
              "  0.006697403345625597,\n",
              "  0.007046115428199296,\n",
              "  0.007214607460353633,\n",
              "  0.006940222518776414,\n",
              "  0.007086549086230847,\n",
              "  0.007054448774026614,\n",
              "  0.0071893326971850646,\n",
              "  0.00731155155322492],\n",
              " 'dev_loss_history': [0.17013703286647797,\n",
              "  0.08818749338388443,\n",
              "  0.060143593698740005,\n",
              "  0.05808359757065773,\n",
              "  0.048343438655138016,\n",
              "  0.05134847015142441,\n",
              "  0.0450560636818409,\n",
              "  0.04213937744498253,\n",
              "  0.03852430731058121,\n",
              "  0.040289729833602905,\n",
              "  0.038068242371082306,\n",
              "  0.03655008226633072,\n",
              "  0.03754721209406853,\n",
              "  0.04365716874599457,\n",
              "  0.03462392836809158,\n",
              "  0.03850279003381729,\n",
              "  0.03672116994857788,\n",
              "  0.03697904571890831,\n",
              "  0.03511109575629234,\n",
              "  0.03325570747256279,\n",
              "  0.03420386090874672,\n",
              "  0.03575759381055832,\n",
              "  0.034832391887903214,\n",
              "  0.035583849996328354,\n",
              "  0.03561178222298622,\n",
              "  0.03284444287419319,\n",
              "  0.034081846475601196,\n",
              "  0.03136078640818596,\n",
              "  0.03398556634783745,\n",
              "  0.033835023641586304,\n",
              "  0.03534458577632904,\n",
              "  0.03412977606058121,\n",
              "  0.036615852266550064,\n",
              "  0.034274082630872726,\n",
              "  0.034948382526636124,\n",
              "  0.03463789075613022,\n",
              "  0.03494878485798836,\n",
              "  0.03536289930343628,\n",
              "  0.03524079918861389,\n",
              "  0.035714857280254364,\n",
              "  0.03561308979988098,\n",
              "  0.03502008318901062,\n",
              "  0.03572358936071396,\n",
              "  0.035541433840990067,\n",
              "  0.03545683994889259,\n",
              "  0.03555715084075928,\n",
              "  0.035418882966041565,\n",
              "  0.035394567996263504,\n",
              "  0.03555220365524292,\n",
              "  0.035571396350860596,\n",
              "  0.03548908978700638,\n",
              "  0.035630691796541214,\n",
              "  0.035685762763023376,\n",
              "  0.035681385546922684,\n",
              "  0.03565187379717827,\n",
              "  0.035618700087070465,\n",
              "  0.035603173077106476,\n",
              "  0.03560180962085724,\n",
              "  0.03561580553650856,\n",
              "  0.03563614562153816]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# Initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# Start training\n",
        "trainer.train('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knRAUHLJn2ze"
      },
      "source": [
        "## Teste 2.3 NER Flair Stacked Embeddings (Word e Flair Embeddings) com Corpus Lener_br\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irBiiaDkn2zm"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xxcq2Z4n2zm"
      },
      "outputs": [],
      "source": [
        "## Importes\n",
        "## datasets\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bJPzMJEn2zm"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq9JAufOljve",
        "outputId": "bb07dce6-c773-42ca-ba81-f73f7db216c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahzWdLNon2zn",
        "outputId": "0bda3a25-1cec-45a0-d598-979b5a00aa9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 03:40:03,613 Reading data from /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig\n",
            "2022-09-11 03:40:03,619 Train: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig/train.txt\n",
            "2022-09-11 03:40:03,621 Dev: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig/dev.txt\n",
            "2022-09-11 03:40:03,624 Test: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig/test.txt\n"
          ]
        }
      ],
      "source": [
        "## carregando um corpus e definindo as colunas\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM_mljCTn2zn",
        "outputId": "e4f062a1-9bac-4837-d833-5b0ae77f8947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 03:40:13,242 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7827it [00:00, 28374.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 03:40:13,572 Dictionary created for label 'ner' with 7 values: ORGANIZACAO (seen 2400 times), LEGISLACAO (seen 1920 times), PESSOA (seen 1525 times), TEMPO (seen 1334 times), JURISPRUDENCIA (seen 1104 times), LOCAL (seen 611 times)\n",
            "Dictionary with 7 tags: <unk>, ORGANIZACAO, LEGISLACAO, PESSOA, TEMPO, JURISPRUDENCIA, LOCAL\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha3l1o97n2zn"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQWs5uWTn2zn",
        "outputId": "7d23c3db-33f0-4fae-95a8-bdb25528b721"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 03:40:14,711 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpqoqis1c5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 710528528/710528528 [01:06<00:00, 10706795.83B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 03:41:21,924 copying /tmp/tmpqoqis1c5 to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M.vectors.npy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 03:41:23,977 removing temp file /tmp/tmpqoqis1c5\n",
            "2022-09-11 03:41:25,214 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmpdn1ngcky\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23541010/23541010 [00:03<00:00, 6159174.95B/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 03:41:29,885 copying /tmp/tmpdn1ngcky to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M\n",
            "2022-09-11 03:41:29,918 removing temp file /tmp/tmpdn1ngcky\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 03:41:33,958 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-forward.pt not found in cache, downloading to /tmp/tmpohy5wift\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:08<00:00, 8544064.06B/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 03:41:43,315 copying /tmp/tmpohy5wift to cache at /root/.flair/embeddings/lm-pt-forward.pt\n",
            "2022-09-11 03:41:43,411 removing temp file /tmp/tmpohy5wift\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 03:41:54,449 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-backward.pt not found in cache, downloading to /tmp/tmpprh54y5r\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:08<00:00, 8713097.57B/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 03:42:03,885 copying /tmp/tmpprh54y5r to cache at /root/.flair/embeddings/lm-pt-backward.pt\n",
            "2022-09-11 03:42:03,981 removing temp file /tmp/tmpprh54y5r\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Stacked Embeddings\n",
        "# Initialize embedding stack with \n",
        "embedding_types = [\n",
        "    WordEmbeddings('pt'),\n",
        "    FlairEmbeddings('pt-forward'),\n",
        "    FlairEmbeddings('pt-backward')\n",
        "]\n",
        "\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C7591KDn2zn"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzBtDqDVn2zn",
        "outputId": "0b76db7f-ee2f-483f-f8cb-650bd615a4c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 03:42:04,208 SequenceTagger predicts: Dictionary with 25 tags: O, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-LEGISLACAO, B-LEGISLACAO, E-LEGISLACAO, I-LEGISLACAO, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-TEMPO, B-TEMPO, E-TEMPO, I-TEMPO, S-JURISPRUDENCIA, B-JURISPRUDENCIA, E-JURISPRUDENCIA, I-JURISPRUDENCIA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9-BqtQhn2zn",
        "outputId": "45d1e0f8-a5d3-46fd-a947-19907e8f93d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:45:31,812 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:45:31,815 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'pt'\n",
            "      (embedding): Embedding(592108, 300)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4396, out_features=4396, bias=True)\n",
            "  (rnn): LSTM(4396, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=27, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-09-11 06:45:31,816 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:45:31,819 Corpus: \"Corpus: 7827 train + 1176 dev + 1389 test sentences\"\n",
            "2022-09-11 06:45:31,821 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:45:31,823 Parameters:\n",
            "2022-09-11 06:45:31,825  - learning_rate: \"0.100000\"\n",
            "2022-09-11 06:45:31,827  - mini_batch_size: \"32\"\n",
            "2022-09-11 06:45:31,829  - patience: \"3\"\n",
            "2022-09-11 06:45:31,831  - anneal_factor: \"0.5\"\n",
            "2022-09-11 06:45:31,833  - max_epochs: \"150\"\n",
            "2022-09-11 06:45:31,839  - shuffle: \"True\"\n",
            "2022-09-11 06:45:31,842  - train_with_dev: \"False\"\n",
            "2022-09-11 06:45:31,845  - batch_growth_annealing: \"False\"\n",
            "2022-09-11 06:45:31,847 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:45:31,849 Model training base path: \"resources/taggers/sota-ner-flair\"\n",
            "2022-09-11 06:45:31,851 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:45:31,852 Device: cuda:0\n",
            "2022-09-11 06:45:31,855 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:45:31,857 Embeddings storage mode: cpu\n",
            "2022-09-11 06:45:31,859 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/flair/trainers/trainer.py:65: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
            "  \"There should be no best model saved at epoch 1 except there \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:45:39,867 epoch 1 - iter 24/245 - loss 0.00537267 - samples/sec: 95.97 - lr: 0.100000\n",
            "2022-09-11 06:45:46,894 epoch 1 - iter 48/245 - loss 0.00634968 - samples/sec: 109.38 - lr: 0.100000\n",
            "2022-09-11 06:45:53,297 epoch 1 - iter 72/245 - loss 0.00599587 - samples/sec: 120.04 - lr: 0.100000\n",
            "2022-09-11 06:46:00,257 epoch 1 - iter 96/245 - loss 0.00604685 - samples/sec: 110.43 - lr: 0.100000\n",
            "2022-09-11 06:46:05,258 epoch 1 - iter 120/245 - loss 0.00586165 - samples/sec: 153.76 - lr: 0.100000\n",
            "2022-09-11 06:46:10,997 epoch 1 - iter 144/245 - loss 0.00646426 - samples/sec: 133.95 - lr: 0.100000\n",
            "2022-09-11 06:46:17,571 epoch 1 - iter 168/245 - loss 0.00642237 - samples/sec: 116.89 - lr: 0.100000\n",
            "2022-09-11 06:46:25,013 epoch 1 - iter 192/245 - loss 0.00674661 - samples/sec: 103.28 - lr: 0.100000\n",
            "2022-09-11 06:46:32,381 epoch 1 - iter 216/245 - loss 0.00690267 - samples/sec: 104.32 - lr: 0.100000\n",
            "2022-09-11 06:46:39,770 epoch 1 - iter 240/245 - loss 0.00699894 - samples/sec: 104.02 - lr: 0.100000\n",
            "2022-09-11 06:46:40,899 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:46:40,902 EPOCH 1 done: loss 0.0070 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:46:55,478 Evaluating as a multi-label problem: False\n",
            "2022-09-11 06:46:55,508 DEV : loss 0.04608402028679848 - f1-score (micro avg)  0.8865\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:46:55,746 BAD EPOCHS (no improvement): 0\n",
            "2022-09-11 06:46:55,749 saving best model\n",
            "2022-09-11 06:46:59,932 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:47:06,361 epoch 2 - iter 24/245 - loss 0.00673832 - samples/sec: 119.58 - lr: 0.100000\n",
            "2022-09-11 06:47:13,589 epoch 2 - iter 48/245 - loss 0.00568705 - samples/sec: 106.34 - lr: 0.100000\n",
            "2022-09-11 06:47:22,069 epoch 2 - iter 72/245 - loss 0.00582133 - samples/sec: 90.62 - lr: 0.100000\n",
            "2022-09-11 06:47:29,196 epoch 2 - iter 96/245 - loss 0.00639223 - samples/sec: 107.85 - lr: 0.100000\n",
            "2022-09-11 06:47:37,077 epoch 2 - iter 120/245 - loss 0.00676326 - samples/sec: 97.52 - lr: 0.100000\n",
            "2022-09-11 06:47:44,135 epoch 2 - iter 144/245 - loss 0.00724198 - samples/sec: 108.90 - lr: 0.100000\n",
            "2022-09-11 06:47:50,857 epoch 2 - iter 168/245 - loss 0.00748454 - samples/sec: 114.35 - lr: 0.100000\n",
            "2022-09-11 06:47:57,104 epoch 2 - iter 192/245 - loss 0.00742090 - samples/sec: 123.07 - lr: 0.100000\n",
            "2022-09-11 06:48:05,485 epoch 2 - iter 216/245 - loss 0.00755948 - samples/sec: 91.70 - lr: 0.100000\n",
            "2022-09-11 06:48:12,026 epoch 2 - iter 240/245 - loss 0.00769689 - samples/sec: 117.52 - lr: 0.100000\n",
            "2022-09-11 06:48:13,537 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:48:13,539 EPOCH 2 done: loss 0.0077 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:48:26,862 Evaluating as a multi-label problem: False\n",
            "2022-09-11 06:48:26,894 DEV : loss 0.039582714438438416 - f1-score (micro avg)  0.8829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:48:27,117 BAD EPOCHS (no improvement): 1\n",
            "2022-09-11 06:48:27,120 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:48:35,207 epoch 3 - iter 24/245 - loss 0.01029669 - samples/sec: 95.06 - lr: 0.100000\n",
            "2022-09-11 06:48:41,747 epoch 3 - iter 48/245 - loss 0.00816216 - samples/sec: 117.52 - lr: 0.100000\n",
            "2022-09-11 06:48:48,682 epoch 3 - iter 72/245 - loss 0.00777300 - samples/sec: 110.83 - lr: 0.100000\n",
            "2022-09-11 06:48:55,626 epoch 3 - iter 96/245 - loss 0.00804909 - samples/sec: 110.68 - lr: 0.100000\n",
            "2022-09-11 06:49:03,925 epoch 3 - iter 120/245 - loss 0.00784910 - samples/sec: 92.61 - lr: 0.100000\n",
            "2022-09-11 06:49:11,025 epoch 3 - iter 144/245 - loss 0.00785120 - samples/sec: 108.26 - lr: 0.100000\n",
            "2022-09-11 06:49:19,189 epoch 3 - iter 168/245 - loss 0.00810683 - samples/sec: 94.13 - lr: 0.100000\n",
            "2022-09-11 06:49:25,788 epoch 3 - iter 192/245 - loss 0.00809338 - samples/sec: 116.50 - lr: 0.100000\n",
            "2022-09-11 06:49:32,118 epoch 3 - iter 216/245 - loss 0.00794585 - samples/sec: 121.43 - lr: 0.100000\n",
            "2022-09-11 06:49:38,873 epoch 3 - iter 240/245 - loss 0.00784346 - samples/sec: 113.80 - lr: 0.100000\n",
            "2022-09-11 06:49:40,293 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:49:40,295 EPOCH 3 done: loss 0.0079 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:49:55,080 Evaluating as a multi-label problem: False\n",
            "2022-09-11 06:49:55,108 DEV : loss 0.03870369866490364 - f1-score (micro avg)  0.8812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:49:55,352 BAD EPOCHS (no improvement): 2\n",
            "2022-09-11 06:49:55,356 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:50:02,371 epoch 4 - iter 24/245 - loss 0.00691332 - samples/sec: 109.60 - lr: 0.100000\n",
            "2022-09-11 06:50:09,874 epoch 4 - iter 48/245 - loss 0.00754436 - samples/sec: 102.44 - lr: 0.100000\n",
            "2022-09-11 06:50:17,907 epoch 4 - iter 72/245 - loss 0.00765944 - samples/sec: 95.69 - lr: 0.100000\n",
            "2022-09-11 06:50:25,609 epoch 4 - iter 96/245 - loss 0.00767813 - samples/sec: 99.80 - lr: 0.100000\n",
            "2022-09-11 06:50:32,441 epoch 4 - iter 120/245 - loss 0.00737611 - samples/sec: 112.49 - lr: 0.100000\n",
            "2022-09-11 06:50:39,636 epoch 4 - iter 144/245 - loss 0.00730054 - samples/sec: 106.83 - lr: 0.100000\n",
            "2022-09-11 06:50:47,471 epoch 4 - iter 168/245 - loss 0.00733246 - samples/sec: 98.09 - lr: 0.100000\n",
            "2022-09-11 06:50:54,002 epoch 4 - iter 192/245 - loss 0.00740800 - samples/sec: 117.70 - lr: 0.100000\n",
            "2022-09-11 06:50:59,909 epoch 4 - iter 216/245 - loss 0.00733639 - samples/sec: 130.15 - lr: 0.100000\n",
            "2022-09-11 06:51:08,256 epoch 4 - iter 240/245 - loss 0.00729275 - samples/sec: 92.06 - lr: 0.100000\n",
            "2022-09-11 06:51:09,638 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:51:09,641 EPOCH 4 done: loss 0.0073 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:51:24,261 Evaluating as a multi-label problem: False\n",
            "2022-09-11 06:51:24,289 DEV : loss 0.04017338156700134 - f1-score (micro avg)  0.8873\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:51:24,521 BAD EPOCHS (no improvement): 0\n",
            "2022-09-11 06:51:24,524 saving best model\n",
            "2022-09-11 06:51:29,111 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:51:37,076 epoch 5 - iter 24/245 - loss 0.00612529 - samples/sec: 96.50 - lr: 0.100000\n",
            "2022-09-11 06:51:44,742 epoch 5 - iter 48/245 - loss 0.00663136 - samples/sec: 100.26 - lr: 0.100000\n",
            "2022-09-11 06:51:52,400 epoch 5 - iter 72/245 - loss 0.00673999 - samples/sec: 100.35 - lr: 0.100000\n",
            "2022-09-11 06:51:59,897 epoch 5 - iter 96/245 - loss 0.00777118 - samples/sec: 102.52 - lr: 0.100000\n",
            "2022-09-11 06:52:06,925 epoch 5 - iter 120/245 - loss 0.00789020 - samples/sec: 109.36 - lr: 0.100000\n",
            "2022-09-11 06:52:13,470 epoch 5 - iter 144/245 - loss 0.00789962 - samples/sec: 117.46 - lr: 0.100000\n",
            "2022-09-11 06:52:19,662 epoch 5 - iter 168/245 - loss 0.00788581 - samples/sec: 124.12 - lr: 0.100000\n",
            "2022-09-11 06:52:27,930 epoch 5 - iter 192/245 - loss 0.00792509 - samples/sec: 92.96 - lr: 0.100000\n",
            "2022-09-11 06:52:35,331 epoch 5 - iter 216/245 - loss 0.00794642 - samples/sec: 103.84 - lr: 0.100000\n",
            "2022-09-11 06:52:42,210 epoch 5 - iter 240/245 - loss 0.00777100 - samples/sec: 111.74 - lr: 0.100000\n",
            "2022-09-11 06:52:43,522 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:52:43,525 EPOCH 5 done: loss 0.0077 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:52:57,115 Evaluating as a multi-label problem: False\n",
            "2022-09-11 06:52:57,143 DEV : loss 0.0396902933716774 - f1-score (micro avg)  0.884\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:52:57,379 BAD EPOCHS (no improvement): 1\n",
            "2022-09-11 06:52:57,381 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:53:05,096 epoch 6 - iter 24/245 - loss 0.00577606 - samples/sec: 99.65 - lr: 0.100000\n",
            "2022-09-11 06:53:12,573 epoch 6 - iter 48/245 - loss 0.00643076 - samples/sec: 102.80 - lr: 0.100000\n",
            "2022-09-11 06:53:19,231 epoch 6 - iter 72/245 - loss 0.00619170 - samples/sec: 115.44 - lr: 0.100000\n",
            "2022-09-11 06:53:25,941 epoch 6 - iter 96/245 - loss 0.00664313 - samples/sec: 114.56 - lr: 0.100000\n",
            "2022-09-11 06:53:32,716 epoch 6 - iter 120/245 - loss 0.00679414 - samples/sec: 113.46 - lr: 0.100000\n",
            "2022-09-11 06:53:39,740 epoch 6 - iter 144/245 - loss 0.00725570 - samples/sec: 109.42 - lr: 0.100000\n",
            "2022-09-11 06:53:47,184 epoch 6 - iter 168/245 - loss 0.00763300 - samples/sec: 103.24 - lr: 0.100000\n",
            "2022-09-11 06:53:53,872 epoch 6 - iter 192/245 - loss 0.00789568 - samples/sec: 114.95 - lr: 0.100000\n",
            "2022-09-11 06:54:01,533 epoch 6 - iter 216/245 - loss 0.00766174 - samples/sec: 100.33 - lr: 0.100000\n",
            "2022-09-11 06:54:10,468 epoch 6 - iter 240/245 - loss 0.00768940 - samples/sec: 86.01 - lr: 0.100000\n",
            "2022-09-11 06:54:11,576 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:54:11,579 EPOCH 6 done: loss 0.0076 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:54:26,168 Evaluating as a multi-label problem: False\n",
            "2022-09-11 06:54:26,195 DEV : loss 0.042866069823503494 - f1-score (micro avg)  0.8803\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:54:26,425 BAD EPOCHS (no improvement): 2\n",
            "2022-09-11 06:54:26,428 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:54:33,534 epoch 7 - iter 24/245 - loss 0.00765168 - samples/sec: 108.20 - lr: 0.100000\n",
            "2022-09-11 06:54:41,443 epoch 7 - iter 48/245 - loss 0.00743981 - samples/sec: 97.17 - lr: 0.100000\n",
            "2022-09-11 06:54:47,856 epoch 7 - iter 72/245 - loss 0.00709278 - samples/sec: 119.86 - lr: 0.100000\n",
            "2022-09-11 06:54:56,586 epoch 7 - iter 96/245 - loss 0.00687619 - samples/sec: 88.03 - lr: 0.100000\n",
            "2022-09-11 06:55:03,523 epoch 7 - iter 120/245 - loss 0.00656287 - samples/sec: 110.80 - lr: 0.100000\n",
            "2022-09-11 06:55:11,494 epoch 7 - iter 144/245 - loss 0.00670800 - samples/sec: 96.42 - lr: 0.100000\n",
            "2022-09-11 06:55:17,344 epoch 7 - iter 168/245 - loss 0.00659667 - samples/sec: 131.40 - lr: 0.100000\n",
            "2022-09-11 06:55:24,640 epoch 7 - iter 192/245 - loss 0.00642141 - samples/sec: 105.35 - lr: 0.100000\n",
            "2022-09-11 06:55:31,504 epoch 7 - iter 216/245 - loss 0.00650827 - samples/sec: 111.97 - lr: 0.100000\n",
            "2022-09-11 06:55:38,344 epoch 7 - iter 240/245 - loss 0.00661963 - samples/sec: 112.38 - lr: 0.100000\n",
            "2022-09-11 06:55:40,326 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:55:40,329 EPOCH 7 done: loss 0.0070 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:55:53,853 Evaluating as a multi-label problem: False\n",
            "2022-09-11 06:55:53,879 DEV : loss 0.0430731326341629 - f1-score (micro avg)  0.8768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:55:54,113 BAD EPOCHS (no improvement): 3\n",
            "2022-09-11 06:55:54,116 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:56:00,894 epoch 8 - iter 24/245 - loss 0.00508945 - samples/sec: 113.45 - lr: 0.100000\n",
            "2022-09-11 06:56:07,624 epoch 8 - iter 48/245 - loss 0.00684875 - samples/sec: 114.20 - lr: 0.100000\n",
            "2022-09-11 06:56:15,740 epoch 8 - iter 72/245 - loss 0.00736121 - samples/sec: 94.69 - lr: 0.100000\n",
            "2022-09-11 06:56:22,024 epoch 8 - iter 96/245 - loss 0.00734199 - samples/sec: 122.31 - lr: 0.100000\n",
            "2022-09-11 06:56:28,447 epoch 8 - iter 120/245 - loss 0.00772750 - samples/sec: 119.68 - lr: 0.100000\n",
            "2022-09-11 06:56:36,280 epoch 8 - iter 144/245 - loss 0.00750897 - samples/sec: 98.11 - lr: 0.100000\n",
            "2022-09-11 06:56:43,797 epoch 8 - iter 168/245 - loss 0.00769892 - samples/sec: 102.25 - lr: 0.100000\n",
            "2022-09-11 06:56:52,031 epoch 8 - iter 192/245 - loss 0.00795690 - samples/sec: 93.33 - lr: 0.100000\n",
            "2022-09-11 06:56:58,539 epoch 8 - iter 216/245 - loss 0.00793033 - samples/sec: 118.10 - lr: 0.100000\n",
            "2022-09-11 06:57:05,927 epoch 8 - iter 240/245 - loss 0.00795991 - samples/sec: 104.05 - lr: 0.100000\n",
            "2022-09-11 06:57:07,287 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:57:07,289 EPOCH 8 done: loss 0.0080 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:57:21,871 Evaluating as a multi-label problem: False\n",
            "2022-09-11 06:57:21,898 DEV : loss 0.03850177302956581 - f1-score (micro avg)  0.888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:57:22,131 BAD EPOCHS (no improvement): 0\n",
            "2022-09-11 06:57:22,135 saving best model\n",
            "2022-09-11 06:57:26,682 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:57:34,744 epoch 9 - iter 24/245 - loss 0.00724780 - samples/sec: 95.37 - lr: 0.100000\n",
            "2022-09-11 06:57:43,103 epoch 9 - iter 48/245 - loss 0.00674161 - samples/sec: 91.94 - lr: 0.100000\n",
            "2022-09-11 06:57:49,782 epoch 9 - iter 72/245 - loss 0.00686786 - samples/sec: 115.08 - lr: 0.100000\n",
            "2022-09-11 06:57:57,112 epoch 9 - iter 96/245 - loss 0.00668718 - samples/sec: 104.85 - lr: 0.100000\n",
            "2022-09-11 06:58:03,771 epoch 9 - iter 120/245 - loss 0.00693210 - samples/sec: 115.44 - lr: 0.100000\n",
            "2022-09-11 06:58:10,999 epoch 9 - iter 144/245 - loss 0.00689589 - samples/sec: 106.34 - lr: 0.100000\n",
            "2022-09-11 06:58:18,006 epoch 9 - iter 168/245 - loss 0.00701067 - samples/sec: 109.68 - lr: 0.100000\n",
            "2022-09-11 06:58:25,152 epoch 9 - iter 192/245 - loss 0.00728944 - samples/sec: 107.57 - lr: 0.100000\n",
            "2022-09-11 06:58:32,071 epoch 9 - iter 216/245 - loss 0.00730188 - samples/sec: 111.10 - lr: 0.100000\n",
            "2022-09-11 06:58:39,126 epoch 9 - iter 240/245 - loss 0.00718346 - samples/sec: 108.96 - lr: 0.100000\n",
            "2022-09-11 06:58:40,439 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:58:40,442 EPOCH 9 done: loss 0.0072 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:58:54,954 Evaluating as a multi-label problem: False\n",
            "2022-09-11 06:58:54,980 DEV : loss 0.04363260418176651 - f1-score (micro avg)  0.9006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 06:58:55,215 BAD EPOCHS (no improvement): 0\n",
            "2022-09-11 06:58:55,218 saving best model\n",
            "2022-09-11 06:58:59,742 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 06:59:06,249 epoch 10 - iter 24/245 - loss 0.00661824 - samples/sec: 118.18 - lr: 0.100000\n",
            "2022-09-11 06:59:13,436 epoch 10 - iter 48/245 - loss 0.00545514 - samples/sec: 106.94 - lr: 0.100000\n",
            "2022-09-11 06:59:21,620 epoch 10 - iter 72/245 - loss 0.00572943 - samples/sec: 93.89 - lr: 0.100000\n",
            "2022-09-11 06:59:27,702 epoch 10 - iter 96/245 - loss 0.00599443 - samples/sec: 126.40 - lr: 0.100000\n",
            "2022-09-11 06:59:35,089 epoch 10 - iter 120/245 - loss 0.00643794 - samples/sec: 104.04 - lr: 0.100000\n",
            "2022-09-11 06:59:42,055 epoch 10 - iter 144/245 - loss 0.00683349 - samples/sec: 110.33 - lr: 0.100000\n",
            "2022-09-11 06:59:49,199 epoch 10 - iter 168/245 - loss 0.00692005 - samples/sec: 107.60 - lr: 0.100000\n",
            "2022-09-11 06:59:57,705 epoch 10 - iter 192/245 - loss 0.00695794 - samples/sec: 90.35 - lr: 0.100000\n",
            "2022-09-11 07:00:04,550 epoch 10 - iter 216/245 - loss 0.00730705 - samples/sec: 112.29 - lr: 0.100000\n",
            "2022-09-11 07:00:12,046 epoch 10 - iter 240/245 - loss 0.00737181 - samples/sec: 102.54 - lr: 0.100000\n",
            "2022-09-11 07:00:13,171 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:00:13,173 EPOCH 10 done: loss 0.0073 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:00:26,683 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:00:26,712 DEV : loss 0.04165041819214821 - f1-score (micro avg)  0.8845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:00:26,943 BAD EPOCHS (no improvement): 1\n",
            "2022-09-11 07:00:26,947 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:00:33,563 epoch 11 - iter 24/245 - loss 0.00579247 - samples/sec: 116.21 - lr: 0.100000\n",
            "2022-09-11 07:00:41,834 epoch 11 - iter 48/245 - loss 0.00641276 - samples/sec: 92.92 - lr: 0.100000\n",
            "2022-09-11 07:00:51,051 epoch 11 - iter 72/245 - loss 0.00673719 - samples/sec: 83.38 - lr: 0.100000\n",
            "2022-09-11 07:00:57,842 epoch 11 - iter 96/245 - loss 0.00754211 - samples/sec: 113.18 - lr: 0.100000\n",
            "2022-09-11 07:01:04,982 epoch 11 - iter 120/245 - loss 0.00740787 - samples/sec: 107.65 - lr: 0.100000\n",
            "2022-09-11 07:01:11,843 epoch 11 - iter 144/245 - loss 0.00753686 - samples/sec: 112.04 - lr: 0.100000\n",
            "2022-09-11 07:01:18,242 epoch 11 - iter 168/245 - loss 0.00742432 - samples/sec: 120.11 - lr: 0.100000\n",
            "2022-09-11 07:01:26,005 epoch 11 - iter 192/245 - loss 0.00760879 - samples/sec: 99.00 - lr: 0.100000\n",
            "2022-09-11 07:01:32,920 epoch 11 - iter 216/245 - loss 0.00767823 - samples/sec: 111.15 - lr: 0.100000\n",
            "2022-09-11 07:01:39,674 epoch 11 - iter 240/245 - loss 0.00752942 - samples/sec: 113.82 - lr: 0.100000\n",
            "2022-09-11 07:01:40,917 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:01:40,919 EPOCH 11 done: loss 0.0075 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:01:55,372 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:01:55,399 DEV : loss 0.04661846533417702 - f1-score (micro avg)  0.8867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:01:55,633 BAD EPOCHS (no improvement): 2\n",
            "2022-09-11 07:01:55,636 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:02:03,084 epoch 12 - iter 24/245 - loss 0.00722058 - samples/sec: 103.21 - lr: 0.100000\n",
            "2022-09-11 07:02:11,142 epoch 12 - iter 48/245 - loss 0.00699144 - samples/sec: 95.37 - lr: 0.100000\n",
            "2022-09-11 07:02:18,075 epoch 12 - iter 72/245 - loss 0.00676439 - samples/sec: 110.86 - lr: 0.100000\n",
            "2022-09-11 07:02:25,072 epoch 12 - iter 96/245 - loss 0.00671927 - samples/sec: 109.86 - lr: 0.100000\n",
            "2022-09-11 07:02:31,815 epoch 12 - iter 120/245 - loss 0.00667223 - samples/sec: 113.98 - lr: 0.100000\n",
            "2022-09-11 07:02:39,127 epoch 12 - iter 144/245 - loss 0.00685470 - samples/sec: 105.10 - lr: 0.100000\n",
            "2022-09-11 07:02:47,178 epoch 12 - iter 168/245 - loss 0.00718337 - samples/sec: 95.47 - lr: 0.100000\n",
            "2022-09-11 07:02:54,290 epoch 12 - iter 192/245 - loss 0.00703002 - samples/sec: 108.05 - lr: 0.100000\n",
            "2022-09-11 07:03:02,132 epoch 12 - iter 216/245 - loss 0.00689037 - samples/sec: 98.00 - lr: 0.100000\n",
            "2022-09-11 07:03:08,253 epoch 12 - iter 240/245 - loss 0.00674807 - samples/sec: 125.60 - lr: 0.100000\n",
            "2022-09-11 07:03:09,385 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:03:09,387 EPOCH 12 done: loss 0.0068 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:03:22,937 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:03:22,965 DEV : loss 0.04888354241847992 - f1-score (micro avg)  0.8794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:03:23,201 BAD EPOCHS (no improvement): 3\n",
            "2022-09-11 07:03:23,204 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:03:30,357 epoch 13 - iter 24/245 - loss 0.00628936 - samples/sec: 107.48 - lr: 0.100000\n",
            "2022-09-11 07:03:37,797 epoch 13 - iter 48/245 - loss 0.00656516 - samples/sec: 103.31 - lr: 0.100000\n",
            "2022-09-11 07:03:44,598 epoch 13 - iter 72/245 - loss 0.00622849 - samples/sec: 113.01 - lr: 0.100000\n",
            "2022-09-11 07:03:51,544 epoch 13 - iter 96/245 - loss 0.00621040 - samples/sec: 110.64 - lr: 0.100000\n",
            "2022-09-11 07:03:59,120 epoch 13 - iter 120/245 - loss 0.00647866 - samples/sec: 101.46 - lr: 0.100000\n",
            "2022-09-11 07:04:07,025 epoch 13 - iter 144/245 - loss 0.00684050 - samples/sec: 97.22 - lr: 0.100000\n",
            "2022-09-11 07:04:13,886 epoch 13 - iter 168/245 - loss 0.00707213 - samples/sec: 112.03 - lr: 0.100000\n",
            "2022-09-11 07:04:23,236 epoch 13 - iter 192/245 - loss 0.00688581 - samples/sec: 82.19 - lr: 0.100000\n",
            "2022-09-11 07:04:30,194 epoch 13 - iter 216/245 - loss 0.00670566 - samples/sec: 110.47 - lr: 0.100000\n",
            "2022-09-11 07:04:37,152 epoch 13 - iter 240/245 - loss 0.00662062 - samples/sec: 110.44 - lr: 0.100000\n",
            "2022-09-11 07:04:38,494 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:04:38,497 EPOCH 13 done: loss 0.0066 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:04:52,029 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:04:52,057 DEV : loss 0.04375133663415909 - f1-score (micro avg)  0.8889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:04:52,288 Epoch    13: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2022-09-11 07:04:52,289 BAD EPOCHS (no improvement): 4\n",
            "2022-09-11 07:04:52,292 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:04:59,876 epoch 14 - iter 24/245 - loss 0.00602066 - samples/sec: 101.40 - lr: 0.050000\n",
            "2022-09-11 07:05:06,885 epoch 14 - iter 48/245 - loss 0.00569052 - samples/sec: 109.65 - lr: 0.050000\n",
            "2022-09-11 07:05:14,672 epoch 14 - iter 72/245 - loss 0.00562634 - samples/sec: 98.69 - lr: 0.050000\n",
            "2022-09-11 07:05:21,246 epoch 14 - iter 96/245 - loss 0.00562009 - samples/sec: 116.93 - lr: 0.050000\n",
            "2022-09-11 07:05:27,866 epoch 14 - iter 120/245 - loss 0.00540252 - samples/sec: 116.11 - lr: 0.050000\n",
            "2022-09-11 07:05:35,002 epoch 14 - iter 144/245 - loss 0.00571646 - samples/sec: 107.70 - lr: 0.050000\n",
            "2022-09-11 07:05:41,401 epoch 14 - iter 168/245 - loss 0.00553306 - samples/sec: 120.13 - lr: 0.050000\n",
            "2022-09-11 07:05:49,137 epoch 14 - iter 192/245 - loss 0.00556623 - samples/sec: 99.34 - lr: 0.050000\n",
            "2022-09-11 07:05:56,914 epoch 14 - iter 216/245 - loss 0.00554262 - samples/sec: 98.83 - lr: 0.050000\n",
            "2022-09-11 07:06:04,316 epoch 14 - iter 240/245 - loss 0.00576608 - samples/sec: 103.82 - lr: 0.050000\n",
            "2022-09-11 07:06:05,891 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:06:05,894 EPOCH 14 done: loss 0.0057 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:06:20,482 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:06:20,509 DEV : loss 0.040513183921575546 - f1-score (micro avg)  0.8993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:06:20,739 BAD EPOCHS (no improvement): 1\n",
            "2022-09-11 07:06:20,741 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:06:28,675 epoch 15 - iter 24/245 - loss 0.00584684 - samples/sec: 96.90 - lr: 0.050000\n",
            "2022-09-11 07:06:35,795 epoch 15 - iter 48/245 - loss 0.00672858 - samples/sec: 107.97 - lr: 0.050000\n",
            "2022-09-11 07:06:42,553 epoch 15 - iter 72/245 - loss 0.00627825 - samples/sec: 113.71 - lr: 0.050000\n",
            "2022-09-11 07:06:51,772 epoch 15 - iter 96/245 - loss 0.00605102 - samples/sec: 83.36 - lr: 0.050000\n",
            "2022-09-11 07:06:57,962 epoch 15 - iter 120/245 - loss 0.00546245 - samples/sec: 124.19 - lr: 0.050000\n",
            "2022-09-11 07:07:05,252 epoch 15 - iter 144/245 - loss 0.00533745 - samples/sec: 105.43 - lr: 0.050000\n",
            "2022-09-11 07:07:12,460 epoch 15 - iter 168/245 - loss 0.00556317 - samples/sec: 106.63 - lr: 0.050000\n",
            "2022-09-11 07:07:19,415 epoch 15 - iter 192/245 - loss 0.00561121 - samples/sec: 110.49 - lr: 0.050000\n",
            "2022-09-11 07:07:27,297 epoch 15 - iter 216/245 - loss 0.00558281 - samples/sec: 97.51 - lr: 0.050000\n",
            "2022-09-11 07:07:33,762 epoch 15 - iter 240/245 - loss 0.00549839 - samples/sec: 118.89 - lr: 0.050000\n",
            "2022-09-11 07:07:34,829 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:07:34,831 EPOCH 15 done: loss 0.0055 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:07:48,351 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:07:48,378 DEV : loss 0.04207519441843033 - f1-score (micro avg)  0.903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:07:48,610 BAD EPOCHS (no improvement): 0\n",
            "2022-09-11 07:07:48,613 saving best model\n",
            "2022-09-11 07:07:53,176 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:08:00,887 epoch 16 - iter 24/245 - loss 0.00492307 - samples/sec: 99.71 - lr: 0.050000\n",
            "2022-09-11 07:08:08,690 epoch 16 - iter 48/245 - loss 0.00526985 - samples/sec: 98.48 - lr: 0.050000\n",
            "2022-09-11 07:08:15,826 epoch 16 - iter 72/245 - loss 0.00515836 - samples/sec: 107.71 - lr: 0.050000\n",
            "2022-09-11 07:08:22,024 epoch 16 - iter 96/245 - loss 0.00512663 - samples/sec: 124.04 - lr: 0.050000\n",
            "2022-09-11 07:08:30,379 epoch 16 - iter 120/245 - loss 0.00512718 - samples/sec: 91.97 - lr: 0.050000\n",
            "2022-09-11 07:08:37,579 epoch 16 - iter 144/245 - loss 0.00518206 - samples/sec: 106.75 - lr: 0.050000\n",
            "2022-09-11 07:08:44,416 epoch 16 - iter 168/245 - loss 0.00508120 - samples/sec: 112.43 - lr: 0.050000\n",
            "2022-09-11 07:08:52,067 epoch 16 - iter 192/245 - loss 0.00500066 - samples/sec: 100.45 - lr: 0.050000\n",
            "2022-09-11 07:08:58,950 epoch 16 - iter 216/245 - loss 0.00508867 - samples/sec: 111.68 - lr: 0.050000\n",
            "2022-09-11 07:09:05,218 epoch 16 - iter 240/245 - loss 0.00517993 - samples/sec: 122.61 - lr: 0.050000\n",
            "2022-09-11 07:09:06,371 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:09:06,373 EPOCH 16 done: loss 0.0052 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:09:20,985 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:09:21,009 DEV : loss 0.042186904698610306 - f1-score (micro avg)  0.8981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:09:21,236 BAD EPOCHS (no improvement): 1\n",
            "2022-09-11 07:09:21,239 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:09:28,518 epoch 17 - iter 24/245 - loss 0.00573337 - samples/sec: 105.62 - lr: 0.050000\n",
            "2022-09-11 07:09:36,881 epoch 17 - iter 48/245 - loss 0.00505809 - samples/sec: 91.89 - lr: 0.050000\n",
            "2022-09-11 07:09:43,856 epoch 17 - iter 72/245 - loss 0.00493804 - samples/sec: 110.19 - lr: 0.050000\n",
            "2022-09-11 07:09:50,804 epoch 17 - iter 96/245 - loss 0.00460201 - samples/sec: 110.63 - lr: 0.050000\n",
            "2022-09-11 07:09:58,170 epoch 17 - iter 120/245 - loss 0.00506209 - samples/sec: 104.35 - lr: 0.050000\n",
            "2022-09-11 07:10:04,989 epoch 17 - iter 144/245 - loss 0.00506827 - samples/sec: 112.71 - lr: 0.050000\n",
            "2022-09-11 07:10:11,162 epoch 17 - iter 168/245 - loss 0.00481242 - samples/sec: 124.53 - lr: 0.050000\n",
            "2022-09-11 07:10:18,453 epoch 17 - iter 192/245 - loss 0.00492562 - samples/sec: 105.40 - lr: 0.050000\n",
            "2022-09-11 07:10:26,963 epoch 17 - iter 216/245 - loss 0.00523467 - samples/sec: 90.31 - lr: 0.050000\n",
            "2022-09-11 07:10:32,788 epoch 17 - iter 240/245 - loss 0.00502440 - samples/sec: 131.97 - lr: 0.050000\n",
            "2022-09-11 07:10:34,234 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:10:34,237 EPOCH 17 done: loss 0.0050 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:10:47,729 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:10:47,759 DEV : loss 0.04267817363142967 - f1-score (micro avg)  0.8933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:10:47,992 BAD EPOCHS (no improvement): 2\n",
            "2022-09-11 07:10:47,995 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:10:55,895 epoch 18 - iter 24/245 - loss 0.00482172 - samples/sec: 97.31 - lr: 0.050000\n",
            "2022-09-11 07:11:01,708 epoch 18 - iter 48/245 - loss 0.00504459 - samples/sec: 132.25 - lr: 0.050000\n",
            "2022-09-11 07:11:08,945 epoch 18 - iter 72/245 - loss 0.00516035 - samples/sec: 106.20 - lr: 0.050000\n",
            "2022-09-11 07:11:16,036 epoch 18 - iter 96/245 - loss 0.00475880 - samples/sec: 108.39 - lr: 0.050000\n",
            "2022-09-11 07:11:24,009 epoch 18 - iter 120/245 - loss 0.00445617 - samples/sec: 96.39 - lr: 0.050000\n",
            "2022-09-11 07:11:32,023 epoch 18 - iter 144/245 - loss 0.00448985 - samples/sec: 95.90 - lr: 0.050000\n",
            "2022-09-11 07:11:39,142 epoch 18 - iter 168/245 - loss 0.00463770 - samples/sec: 107.96 - lr: 0.050000\n",
            "2022-09-11 07:11:47,147 epoch 18 - iter 192/245 - loss 0.00455480 - samples/sec: 96.01 - lr: 0.050000\n",
            "2022-09-11 07:11:54,199 epoch 18 - iter 216/245 - loss 0.00444920 - samples/sec: 108.98 - lr: 0.050000\n",
            "2022-09-11 07:12:01,004 epoch 18 - iter 240/245 - loss 0.00467270 - samples/sec: 112.97 - lr: 0.050000\n",
            "2022-09-11 07:12:02,789 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:12:02,791 EPOCH 18 done: loss 0.0046 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:12:16,329 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:12:16,356 DEV : loss 0.04357725754380226 - f1-score (micro avg)  0.8843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:12:16,592 BAD EPOCHS (no improvement): 3\n",
            "2022-09-11 07:12:16,595 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:12:23,672 epoch 19 - iter 24/245 - loss 0.00363628 - samples/sec: 108.64 - lr: 0.050000\n",
            "2022-09-11 07:12:30,981 epoch 19 - iter 48/245 - loss 0.00315081 - samples/sec: 105.15 - lr: 0.050000\n",
            "2022-09-11 07:12:40,366 epoch 19 - iter 72/245 - loss 0.00406087 - samples/sec: 81.88 - lr: 0.050000\n",
            "2022-09-11 07:12:47,326 epoch 19 - iter 96/245 - loss 0.00423151 - samples/sec: 110.43 - lr: 0.050000\n",
            "2022-09-11 07:12:55,840 epoch 19 - iter 120/245 - loss 0.00386203 - samples/sec: 90.26 - lr: 0.050000\n",
            "2022-09-11 07:13:02,431 epoch 19 - iter 144/245 - loss 0.00418073 - samples/sec: 116.62 - lr: 0.050000\n",
            "2022-09-11 07:13:09,618 epoch 19 - iter 168/245 - loss 0.00428714 - samples/sec: 106.93 - lr: 0.050000\n",
            "2022-09-11 07:13:16,220 epoch 19 - iter 192/245 - loss 0.00431804 - samples/sec: 116.43 - lr: 0.050000\n",
            "2022-09-11 07:13:22,404 epoch 19 - iter 216/245 - loss 0.00430250 - samples/sec: 124.30 - lr: 0.050000\n",
            "2022-09-11 07:13:29,116 epoch 19 - iter 240/245 - loss 0.00422028 - samples/sec: 114.52 - lr: 0.050000\n",
            "2022-09-11 07:13:30,650 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:13:30,652 EPOCH 19 done: loss 0.0043 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:13:45,223 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:13:45,250 DEV : loss 0.04396483674645424 - f1-score (micro avg)  0.8935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:13:45,487 Epoch    19: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2022-09-11 07:13:45,488 BAD EPOCHS (no improvement): 4\n",
            "2022-09-11 07:13:45,492 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:13:52,441 epoch 20 - iter 24/245 - loss 0.00547099 - samples/sec: 110.66 - lr: 0.025000\n",
            "2022-09-11 07:13:58,943 epoch 20 - iter 48/245 - loss 0.00532268 - samples/sec: 118.23 - lr: 0.025000\n",
            "2022-09-11 07:14:06,598 epoch 20 - iter 72/245 - loss 0.00490106 - samples/sec: 100.41 - lr: 0.025000\n",
            "2022-09-11 07:14:14,233 epoch 20 - iter 96/245 - loss 0.00480678 - samples/sec: 100.66 - lr: 0.025000\n",
            "2022-09-11 07:14:20,463 epoch 20 - iter 120/245 - loss 0.00453319 - samples/sec: 123.39 - lr: 0.025000\n",
            "2022-09-11 07:14:27,490 epoch 20 - iter 144/245 - loss 0.00430751 - samples/sec: 109.39 - lr: 0.025000\n",
            "2022-09-11 07:14:36,150 epoch 20 - iter 168/245 - loss 0.00418997 - samples/sec: 88.74 - lr: 0.025000\n",
            "2022-09-11 07:14:43,633 epoch 20 - iter 192/245 - loss 0.00426113 - samples/sec: 102.71 - lr: 0.025000\n",
            "2022-09-11 07:14:50,166 epoch 20 - iter 216/245 - loss 0.00424364 - samples/sec: 117.68 - lr: 0.025000\n",
            "2022-09-11 07:14:57,544 epoch 20 - iter 240/245 - loss 0.00426690 - samples/sec: 104.18 - lr: 0.025000\n",
            "2022-09-11 07:14:59,106 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:14:59,108 EPOCH 20 done: loss 0.0043 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:15:12,697 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:15:12,727 DEV : loss 0.04220595210790634 - f1-score (micro avg)  0.8933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:15:12,961 BAD EPOCHS (no improvement): 1\n",
            "2022-09-11 07:15:12,965 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:15:20,090 epoch 21 - iter 24/245 - loss 0.00530895 - samples/sec: 107.89 - lr: 0.025000\n",
            "2022-09-11 07:15:27,799 epoch 21 - iter 48/245 - loss 0.00506245 - samples/sec: 99.71 - lr: 0.025000\n",
            "2022-09-11 07:15:34,653 epoch 21 - iter 72/245 - loss 0.00526058 - samples/sec: 112.15 - lr: 0.025000\n",
            "2022-09-11 07:15:42,031 epoch 21 - iter 96/245 - loss 0.00505237 - samples/sec: 104.17 - lr: 0.025000\n",
            "2022-09-11 07:15:48,448 epoch 21 - iter 120/245 - loss 0.00510597 - samples/sec: 119.80 - lr: 0.025000\n",
            "2022-09-11 07:15:57,481 epoch 21 - iter 144/245 - loss 0.00457259 - samples/sec: 85.07 - lr: 0.025000\n",
            "2022-09-11 07:16:03,637 epoch 21 - iter 168/245 - loss 0.00454423 - samples/sec: 124.88 - lr: 0.025000\n",
            "2022-09-11 07:16:11,601 epoch 21 - iter 192/245 - loss 0.00467789 - samples/sec: 96.51 - lr: 0.025000\n",
            "2022-09-11 07:16:18,551 epoch 21 - iter 216/245 - loss 0.00470781 - samples/sec: 110.59 - lr: 0.025000\n",
            "2022-09-11 07:16:25,474 epoch 21 - iter 240/245 - loss 0.00465223 - samples/sec: 111.03 - lr: 0.025000\n",
            "2022-09-11 07:16:26,784 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:16:26,786 EPOCH 21 done: loss 0.0046 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:16:41,600 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:16:41,629 DEV : loss 0.042547840625047684 - f1-score (micro avg)  0.8933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:16:41,865 BAD EPOCHS (no improvement): 2\n",
            "2022-09-11 07:16:41,869 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:16:50,256 epoch 22 - iter 24/245 - loss 0.00381541 - samples/sec: 91.66 - lr: 0.025000\n",
            "2022-09-11 07:16:57,483 epoch 22 - iter 48/245 - loss 0.00426409 - samples/sec: 106.34 - lr: 0.025000\n",
            "2022-09-11 07:17:05,627 epoch 22 - iter 72/245 - loss 0.00446020 - samples/sec: 94.37 - lr: 0.025000\n",
            "2022-09-11 07:17:12,171 epoch 22 - iter 96/245 - loss 0.00407161 - samples/sec: 117.44 - lr: 0.025000\n",
            "2022-09-11 07:17:18,984 epoch 22 - iter 120/245 - loss 0.00427092 - samples/sec: 112.82 - lr: 0.025000\n",
            "2022-09-11 07:17:26,114 epoch 22 - iter 144/245 - loss 0.00427844 - samples/sec: 107.81 - lr: 0.025000\n",
            "2022-09-11 07:17:33,071 epoch 22 - iter 168/245 - loss 0.00411637 - samples/sec: 110.48 - lr: 0.025000\n",
            "2022-09-11 07:17:39,828 epoch 22 - iter 192/245 - loss 0.00416575 - samples/sec: 113.76 - lr: 0.025000\n",
            "2022-09-11 07:17:46,835 epoch 22 - iter 216/245 - loss 0.00423661 - samples/sec: 109.69 - lr: 0.025000\n",
            "2022-09-11 07:17:54,396 epoch 22 - iter 240/245 - loss 0.00437566 - samples/sec: 101.66 - lr: 0.025000\n",
            "2022-09-11 07:17:55,886 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:17:55,888 EPOCH 22 done: loss 0.0043 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:18:09,422 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:18:09,448 DEV : loss 0.042904652655124664 - f1-score (micro avg)  0.8966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:18:09,677 BAD EPOCHS (no improvement): 3\n",
            "2022-09-11 07:18:09,681 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:18:17,584 epoch 23 - iter 24/245 - loss 0.00266614 - samples/sec: 97.28 - lr: 0.025000\n",
            "2022-09-11 07:18:24,886 epoch 23 - iter 48/245 - loss 0.00353906 - samples/sec: 105.25 - lr: 0.025000\n",
            "2022-09-11 07:18:32,168 epoch 23 - iter 72/245 - loss 0.00340270 - samples/sec: 105.53 - lr: 0.025000\n",
            "2022-09-11 07:18:38,343 epoch 23 - iter 96/245 - loss 0.00368231 - samples/sec: 124.48 - lr: 0.025000\n",
            "2022-09-11 07:18:46,169 epoch 23 - iter 120/245 - loss 0.00352236 - samples/sec: 98.19 - lr: 0.025000\n",
            "2022-09-11 07:18:53,038 epoch 23 - iter 144/245 - loss 0.00377715 - samples/sec: 111.88 - lr: 0.025000\n",
            "2022-09-11 07:18:59,911 epoch 23 - iter 168/245 - loss 0.00364895 - samples/sec: 111.83 - lr: 0.025000\n",
            "2022-09-11 07:19:08,682 epoch 23 - iter 192/245 - loss 0.00379788 - samples/sec: 87.62 - lr: 0.025000\n",
            "2022-09-11 07:19:15,906 epoch 23 - iter 216/245 - loss 0.00380707 - samples/sec: 106.41 - lr: 0.025000\n",
            "2022-09-11 07:19:23,149 epoch 23 - iter 240/245 - loss 0.00377256 - samples/sec: 106.11 - lr: 0.025000\n",
            "2022-09-11 07:19:24,991 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:19:24,993 EPOCH 23 done: loss 0.0038 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:19:38,461 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:19:38,489 DEV : loss 0.04290531575679779 - f1-score (micro avg)  0.8921\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:19:38,729 Epoch    23: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2022-09-11 07:19:38,731 BAD EPOCHS (no improvement): 4\n",
            "2022-09-11 07:19:38,734 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:19:46,820 epoch 24 - iter 24/245 - loss 0.00403963 - samples/sec: 95.09 - lr: 0.012500\n",
            "2022-09-11 07:19:54,626 epoch 24 - iter 48/245 - loss 0.00380496 - samples/sec: 98.44 - lr: 0.012500\n",
            "2022-09-11 07:20:02,816 epoch 24 - iter 72/245 - loss 0.00400043 - samples/sec: 93.85 - lr: 0.012500\n",
            "2022-09-11 07:20:10,571 epoch 24 - iter 96/245 - loss 0.00427338 - samples/sec: 99.11 - lr: 0.012500\n",
            "2022-09-11 07:20:17,605 epoch 24 - iter 120/245 - loss 0.00389660 - samples/sec: 109.27 - lr: 0.012500\n",
            "2022-09-11 07:20:24,470 epoch 24 - iter 144/245 - loss 0.00388098 - samples/sec: 111.97 - lr: 0.012500\n",
            "2022-09-11 07:20:30,861 epoch 24 - iter 168/245 - loss 0.00372307 - samples/sec: 120.27 - lr: 0.012500\n",
            "2022-09-11 07:20:38,606 epoch 24 - iter 192/245 - loss 0.00377051 - samples/sec: 99.23 - lr: 0.012500\n",
            "2022-09-11 07:20:44,599 epoch 24 - iter 216/245 - loss 0.00368185 - samples/sec: 128.28 - lr: 0.012500\n",
            "2022-09-11 07:20:52,100 epoch 24 - iter 240/245 - loss 0.00370402 - samples/sec: 102.47 - lr: 0.012500\n",
            "2022-09-11 07:20:53,307 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:20:53,309 EPOCH 24 done: loss 0.0037 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:21:07,984 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:21:08,013 DEV : loss 0.04375961422920227 - f1-score (micro avg)  0.8959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:21:08,250 BAD EPOCHS (no improvement): 1\n",
            "2022-09-11 07:21:08,254 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:21:14,814 epoch 25 - iter 24/245 - loss 0.00449195 - samples/sec: 117.20 - lr: 0.012500\n",
            "2022-09-11 07:21:21,371 epoch 25 - iter 48/245 - loss 0.00452405 - samples/sec: 117.23 - lr: 0.012500\n",
            "2022-09-11 07:21:28,641 epoch 25 - iter 72/245 - loss 0.00381095 - samples/sec: 105.72 - lr: 0.012500\n",
            "2022-09-11 07:21:36,714 epoch 25 - iter 96/245 - loss 0.00381035 - samples/sec: 95.19 - lr: 0.012500\n",
            "2022-09-11 07:21:43,701 epoch 25 - iter 120/245 - loss 0.00379497 - samples/sec: 110.02 - lr: 0.012500\n",
            "2022-09-11 07:21:50,031 epoch 25 - iter 144/245 - loss 0.00401150 - samples/sec: 121.47 - lr: 0.012500\n",
            "2022-09-11 07:21:57,630 epoch 25 - iter 168/245 - loss 0.00411889 - samples/sec: 101.15 - lr: 0.012500\n",
            "2022-09-11 07:22:05,675 epoch 25 - iter 192/245 - loss 0.00422707 - samples/sec: 95.54 - lr: 0.012500\n",
            "2022-09-11 07:22:12,794 epoch 25 - iter 216/245 - loss 0.00407503 - samples/sec: 107.96 - lr: 0.012500\n",
            "2022-09-11 07:22:20,582 epoch 25 - iter 240/245 - loss 0.00388110 - samples/sec: 98.69 - lr: 0.012500\n",
            "2022-09-11 07:22:22,104 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:22:22,106 EPOCH 25 done: loss 0.0038 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:22:35,637 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:22:35,665 DEV : loss 0.0437433160841465 - f1-score (micro avg)  0.895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:22:35,902 BAD EPOCHS (no improvement): 2\n",
            "2022-09-11 07:22:35,905 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:22:44,112 epoch 26 - iter 24/245 - loss 0.00286475 - samples/sec: 93.67 - lr: 0.012500\n",
            "2022-09-11 07:22:51,319 epoch 26 - iter 48/245 - loss 0.00288282 - samples/sec: 106.65 - lr: 0.012500\n",
            "2022-09-11 07:22:58,553 epoch 26 - iter 72/245 - loss 0.00295247 - samples/sec: 106.27 - lr: 0.012500\n",
            "2022-09-11 07:23:05,330 epoch 26 - iter 96/245 - loss 0.00302275 - samples/sec: 113.42 - lr: 0.012500\n",
            "2022-09-11 07:23:11,818 epoch 26 - iter 120/245 - loss 0.00298220 - samples/sec: 118.48 - lr: 0.012500\n",
            "2022-09-11 07:23:18,935 epoch 26 - iter 144/245 - loss 0.00301745 - samples/sec: 108.00 - lr: 0.012500\n",
            "2022-09-11 07:23:25,153 epoch 26 - iter 168/245 - loss 0.00302503 - samples/sec: 123.60 - lr: 0.012500\n",
            "2022-09-11 07:23:31,824 epoch 26 - iter 192/245 - loss 0.00295289 - samples/sec: 115.24 - lr: 0.012500\n",
            "2022-09-11 07:23:39,350 epoch 26 - iter 216/245 - loss 0.00295542 - samples/sec: 102.13 - lr: 0.012500\n",
            "2022-09-11 07:23:47,194 epoch 26 - iter 240/245 - loss 0.00308124 - samples/sec: 97.98 - lr: 0.012500\n",
            "2022-09-11 07:23:49,331 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:23:49,333 EPOCH 26 done: loss 0.0031 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:24:03,862 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:24:03,889 DEV : loss 0.04366707056760788 - f1-score (micro avg)  0.8951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:24:04,121 BAD EPOCHS (no improvement): 3\n",
            "2022-09-11 07:24:04,125 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:24:11,766 epoch 27 - iter 24/245 - loss 0.00347305 - samples/sec: 100.64 - lr: 0.012500\n",
            "2022-09-11 07:24:18,992 epoch 27 - iter 48/245 - loss 0.00339958 - samples/sec: 106.37 - lr: 0.012500\n",
            "2022-09-11 07:24:26,136 epoch 27 - iter 72/245 - loss 0.00348676 - samples/sec: 107.58 - lr: 0.012500\n",
            "2022-09-11 07:24:34,983 epoch 27 - iter 96/245 - loss 0.00385107 - samples/sec: 86.87 - lr: 0.012500\n",
            "2022-09-11 07:24:41,678 epoch 27 - iter 120/245 - loss 0.00366369 - samples/sec: 114.81 - lr: 0.012500\n",
            "2022-09-11 07:24:48,429 epoch 27 - iter 144/245 - loss 0.00364732 - samples/sec: 113.87 - lr: 0.012500\n",
            "2022-09-11 07:24:55,611 epoch 27 - iter 168/245 - loss 0.00367992 - samples/sec: 107.01 - lr: 0.012500\n",
            "2022-09-11 07:25:02,282 epoch 27 - iter 192/245 - loss 0.00372378 - samples/sec: 115.23 - lr: 0.012500\n",
            "2022-09-11 07:25:09,820 epoch 27 - iter 216/245 - loss 0.00362317 - samples/sec: 101.95 - lr: 0.012500\n",
            "2022-09-11 07:25:16,206 epoch 27 - iter 240/245 - loss 0.00361827 - samples/sec: 120.37 - lr: 0.012500\n",
            "2022-09-11 07:25:17,719 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:25:17,722 EPOCH 27 done: loss 0.0036 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:25:31,140 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:25:31,168 DEV : loss 0.04408752918243408 - f1-score (micro avg)  0.8937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:25:31,390 Epoch    27: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2022-09-11 07:25:31,391 BAD EPOCHS (no improvement): 4\n",
            "2022-09-11 07:25:31,394 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:25:39,878 epoch 28 - iter 24/245 - loss 0.00404642 - samples/sec: 90.62 - lr: 0.006250\n",
            "2022-09-11 07:25:47,204 epoch 28 - iter 48/245 - loss 0.00370386 - samples/sec: 104.92 - lr: 0.006250\n",
            "2022-09-11 07:25:53,963 epoch 28 - iter 72/245 - loss 0.00351283 - samples/sec: 113.73 - lr: 0.006250\n",
            "2022-09-11 07:26:00,933 epoch 28 - iter 96/245 - loss 0.00360662 - samples/sec: 110.28 - lr: 0.006250\n",
            "2022-09-11 07:26:07,980 epoch 28 - iter 120/245 - loss 0.00372274 - samples/sec: 109.06 - lr: 0.006250\n",
            "2022-09-11 07:26:15,147 epoch 28 - iter 144/245 - loss 0.00371578 - samples/sec: 107.25 - lr: 0.006250\n",
            "2022-09-11 07:26:22,801 epoch 28 - iter 168/245 - loss 0.00341560 - samples/sec: 100.42 - lr: 0.006250\n",
            "2022-09-11 07:26:30,369 epoch 28 - iter 192/245 - loss 0.00357125 - samples/sec: 101.54 - lr: 0.006250\n",
            "2022-09-11 07:26:37,876 epoch 28 - iter 216/245 - loss 0.00361054 - samples/sec: 102.39 - lr: 0.006250\n",
            "2022-09-11 07:26:44,723 epoch 28 - iter 240/245 - loss 0.00349261 - samples/sec: 112.27 - lr: 0.006250\n",
            "2022-09-11 07:26:45,923 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:26:45,926 EPOCH 28 done: loss 0.0036 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:26:59,322 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:26:59,349 DEV : loss 0.04408428072929382 - f1-score (micro avg)  0.8955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:26:59,570 BAD EPOCHS (no improvement): 1\n",
            "2022-09-11 07:26:59,573 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:27:06,082 epoch 29 - iter 24/245 - loss 0.00405447 - samples/sec: 118.13 - lr: 0.006250\n",
            "2022-09-11 07:27:13,650 epoch 29 - iter 48/245 - loss 0.00405224 - samples/sec: 101.56 - lr: 0.006250\n",
            "2022-09-11 07:27:20,152 epoch 29 - iter 72/245 - loss 0.00314415 - samples/sec: 118.23 - lr: 0.006250\n",
            "2022-09-11 07:27:26,332 epoch 29 - iter 96/245 - loss 0.00327527 - samples/sec: 124.37 - lr: 0.006250\n",
            "2022-09-11 07:27:33,022 epoch 29 - iter 120/245 - loss 0.00325955 - samples/sec: 114.89 - lr: 0.006250\n",
            "2022-09-11 07:27:40,299 epoch 29 - iter 144/245 - loss 0.00318890 - samples/sec: 105.63 - lr: 0.006250\n",
            "2022-09-11 07:27:47,612 epoch 29 - iter 168/245 - loss 0.00322812 - samples/sec: 105.10 - lr: 0.006250\n",
            "2022-09-11 07:27:56,031 epoch 29 - iter 192/245 - loss 0.00323334 - samples/sec: 91.28 - lr: 0.006250\n",
            "2022-09-11 07:28:03,617 epoch 29 - iter 216/245 - loss 0.00330850 - samples/sec: 101.29 - lr: 0.006250\n",
            "2022-09-11 07:28:11,144 epoch 29 - iter 240/245 - loss 0.00330620 - samples/sec: 102.12 - lr: 0.006250\n",
            "2022-09-11 07:28:12,201 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:28:12,204 EPOCH 29 done: loss 0.0033 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:28:26,463 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:28:26,488 DEV : loss 0.043866127729415894 - f1-score (micro avg)  0.8946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:28:26,710 BAD EPOCHS (no improvement): 2\n",
            "2022-09-11 07:28:26,713 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:28:33,375 epoch 30 - iter 24/245 - loss 0.00242523 - samples/sec: 115.43 - lr: 0.006250\n",
            "2022-09-11 07:28:40,408 epoch 30 - iter 48/245 - loss 0.00273201 - samples/sec: 109.29 - lr: 0.006250\n",
            "2022-09-11 07:28:46,701 epoch 30 - iter 72/245 - loss 0.00299400 - samples/sec: 122.13 - lr: 0.006250\n",
            "2022-09-11 07:28:53,835 epoch 30 - iter 96/245 - loss 0.00300725 - samples/sec: 107.74 - lr: 0.006250\n",
            "2022-09-11 07:29:01,232 epoch 30 - iter 120/245 - loss 0.00289616 - samples/sec: 103.90 - lr: 0.006250\n",
            "2022-09-11 07:29:07,889 epoch 30 - iter 144/245 - loss 0.00302854 - samples/sec: 115.46 - lr: 0.006250\n",
            "2022-09-11 07:29:14,254 epoch 30 - iter 168/245 - loss 0.00295420 - samples/sec: 120.77 - lr: 0.006250\n",
            "2022-09-11 07:29:22,502 epoch 30 - iter 192/245 - loss 0.00330713 - samples/sec: 93.18 - lr: 0.006250\n",
            "2022-09-11 07:29:29,189 epoch 30 - iter 216/245 - loss 0.00321316 - samples/sec: 114.96 - lr: 0.006250\n",
            "2022-09-11 07:29:37,234 epoch 30 - iter 240/245 - loss 0.00320503 - samples/sec: 95.53 - lr: 0.006250\n",
            "2022-09-11 07:29:38,875 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:29:38,878 EPOCH 30 done: loss 0.0032 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:29:52,149 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:29:52,176 DEV : loss 0.043949324637651443 - f1-score (micro avg)  0.8955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:29:52,405 BAD EPOCHS (no improvement): 3\n",
            "2022-09-11 07:29:52,411 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:29:59,040 epoch 31 - iter 24/245 - loss 0.00454805 - samples/sec: 116.01 - lr: 0.006250\n",
            "2022-09-11 07:30:06,236 epoch 31 - iter 48/245 - loss 0.00560938 - samples/sec: 106.80 - lr: 0.006250\n",
            "2022-09-11 07:30:13,017 epoch 31 - iter 72/245 - loss 0.00504959 - samples/sec: 113.35 - lr: 0.006250\n",
            "2022-09-11 07:30:22,086 epoch 31 - iter 96/245 - loss 0.00439140 - samples/sec: 84.74 - lr: 0.006250\n",
            "2022-09-11 07:30:28,657 epoch 31 - iter 120/245 - loss 0.00388366 - samples/sec: 116.99 - lr: 0.006250\n",
            "2022-09-11 07:30:36,069 epoch 31 - iter 144/245 - loss 0.00369791 - samples/sec: 103.69 - lr: 0.006250\n",
            "2022-09-11 07:30:43,280 epoch 31 - iter 168/245 - loss 0.00360715 - samples/sec: 106.57 - lr: 0.006250\n",
            "2022-09-11 07:30:49,828 epoch 31 - iter 192/245 - loss 0.00350980 - samples/sec: 117.38 - lr: 0.006250\n",
            "2022-09-11 07:30:56,998 epoch 31 - iter 216/245 - loss 0.00337062 - samples/sec: 107.17 - lr: 0.006250\n",
            "2022-09-11 07:31:04,405 epoch 31 - iter 240/245 - loss 0.00328076 - samples/sec: 103.77 - lr: 0.006250\n",
            "2022-09-11 07:31:05,467 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:31:05,469 EPOCH 31 done: loss 0.0033 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:31:18,846 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:31:18,873 DEV : loss 0.04438399150967598 - f1-score (micro avg)  0.8971\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:31:19,099 Epoch    31: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2022-09-11 07:31:19,101 BAD EPOCHS (no improvement): 4\n",
            "2022-09-11 07:31:19,105 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:31:26,827 epoch 32 - iter 24/245 - loss 0.00429142 - samples/sec: 99.56 - lr: 0.003125\n",
            "2022-09-11 07:31:34,759 epoch 32 - iter 48/245 - loss 0.00340359 - samples/sec: 96.90 - lr: 0.003125\n",
            "2022-09-11 07:31:41,577 epoch 32 - iter 72/245 - loss 0.00363354 - samples/sec: 112.75 - lr: 0.003125\n",
            "2022-09-11 07:31:48,515 epoch 32 - iter 96/245 - loss 0.00363110 - samples/sec: 110.78 - lr: 0.003125\n",
            "2022-09-11 07:31:55,943 epoch 32 - iter 120/245 - loss 0.00357428 - samples/sec: 103.48 - lr: 0.003125\n",
            "2022-09-11 07:32:02,801 epoch 32 - iter 144/245 - loss 0.00366022 - samples/sec: 112.07 - lr: 0.003125\n",
            "2022-09-11 07:32:10,416 epoch 32 - iter 168/245 - loss 0.00362102 - samples/sec: 100.95 - lr: 0.003125\n",
            "2022-09-11 07:32:17,213 epoch 32 - iter 192/245 - loss 0.00347367 - samples/sec: 113.07 - lr: 0.003125\n",
            "2022-09-11 07:32:24,423 epoch 32 - iter 216/245 - loss 0.00347509 - samples/sec: 106.60 - lr: 0.003125\n",
            "2022-09-11 07:32:32,296 epoch 32 - iter 240/245 - loss 0.00356241 - samples/sec: 97.62 - lr: 0.003125\n",
            "2022-09-11 07:32:33,679 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:32:33,682 EPOCH 32 done: loss 0.0035 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:32:48,470 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:32:48,496 DEV : loss 0.043678104877471924 - f1-score (micro avg)  0.8933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:32:48,733 BAD EPOCHS (no improvement): 1\n",
            "2022-09-11 07:32:48,736 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:32:56,215 epoch 33 - iter 24/245 - loss 0.00243913 - samples/sec: 102.81 - lr: 0.003125\n",
            "2022-09-11 07:33:03,961 epoch 33 - iter 48/245 - loss 0.00257112 - samples/sec: 99.23 - lr: 0.003125\n",
            "2022-09-11 07:33:10,262 epoch 33 - iter 72/245 - loss 0.00248630 - samples/sec: 121.98 - lr: 0.003125\n",
            "2022-09-11 07:33:16,800 epoch 33 - iter 96/245 - loss 0.00246568 - samples/sec: 117.58 - lr: 0.003125\n",
            "2022-09-11 07:33:24,300 epoch 33 - iter 120/245 - loss 0.00258169 - samples/sec: 102.47 - lr: 0.003125\n",
            "2022-09-11 07:33:33,703 epoch 33 - iter 144/245 - loss 0.00263748 - samples/sec: 81.73 - lr: 0.003125\n",
            "2022-09-11 07:33:41,361 epoch 33 - iter 168/245 - loss 0.00285047 - samples/sec: 100.38 - lr: 0.003125\n",
            "2022-09-11 07:33:48,283 epoch 33 - iter 192/245 - loss 0.00301002 - samples/sec: 111.04 - lr: 0.003125\n",
            "2022-09-11 07:33:55,201 epoch 33 - iter 216/245 - loss 0.00291833 - samples/sec: 111.12 - lr: 0.003125\n",
            "2022-09-11 07:34:01,701 epoch 33 - iter 240/245 - loss 0.00304029 - samples/sec: 118.23 - lr: 0.003125\n",
            "2022-09-11 07:34:02,931 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:34:02,933 EPOCH 33 done: loss 0.0030 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:34:16,587 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:34:16,613 DEV : loss 0.04361075535416603 - f1-score (micro avg)  0.8954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:34:16,846 BAD EPOCHS (no improvement): 2\n",
            "2022-09-11 07:34:16,850 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:34:24,716 epoch 34 - iter 24/245 - loss 0.00260229 - samples/sec: 97.74 - lr: 0.003125\n",
            "2022-09-11 07:34:32,704 epoch 34 - iter 48/245 - loss 0.00296325 - samples/sec: 96.20 - lr: 0.003125\n",
            "2022-09-11 07:34:38,990 epoch 34 - iter 72/245 - loss 0.00358775 - samples/sec: 122.30 - lr: 0.003125\n",
            "2022-09-11 07:34:46,589 epoch 34 - iter 96/245 - loss 0.00367484 - samples/sec: 101.15 - lr: 0.003125\n",
            "2022-09-11 07:34:53,518 epoch 34 - iter 120/245 - loss 0.00366027 - samples/sec: 110.93 - lr: 0.003125\n",
            "2022-09-11 07:35:00,197 epoch 34 - iter 144/245 - loss 0.00359607 - samples/sec: 115.08 - lr: 0.003125\n",
            "2022-09-11 07:35:07,052 epoch 34 - iter 168/245 - loss 0.00351314 - samples/sec: 112.12 - lr: 0.003125\n",
            "2022-09-11 07:35:14,421 epoch 34 - iter 192/245 - loss 0.00343708 - samples/sec: 104.32 - lr: 0.003125\n",
            "2022-09-11 07:35:22,355 epoch 34 - iter 216/245 - loss 0.00343899 - samples/sec: 96.87 - lr: 0.003125\n",
            "2022-09-11 07:35:29,172 epoch 34 - iter 240/245 - loss 0.00337846 - samples/sec: 112.75 - lr: 0.003125\n",
            "2022-09-11 07:35:31,076 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:35:31,077 EPOCH 34 done: loss 0.0033 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:35:45,841 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:35:45,869 DEV : loss 0.04416164010763168 - f1-score (micro avg)  0.8931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:35:46,104 BAD EPOCHS (no improvement): 3\n",
            "2022-09-11 07:35:46,107 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:35:53,321 epoch 35 - iter 24/245 - loss 0.00361474 - samples/sec: 106.57 - lr: 0.003125\n",
            "2022-09-11 07:35:59,961 epoch 35 - iter 48/245 - loss 0.00327079 - samples/sec: 115.76 - lr: 0.003125\n",
            "2022-09-11 07:36:07,085 epoch 35 - iter 72/245 - loss 0.00346754 - samples/sec: 107.90 - lr: 0.003125\n",
            "2022-09-11 07:36:14,815 epoch 35 - iter 96/245 - loss 0.00318446 - samples/sec: 99.42 - lr: 0.003125\n",
            "2022-09-11 07:36:22,201 epoch 35 - iter 120/245 - loss 0.00345268 - samples/sec: 104.07 - lr: 0.003125\n",
            "2022-09-11 07:36:29,413 epoch 35 - iter 144/245 - loss 0.00333674 - samples/sec: 106.58 - lr: 0.003125\n",
            "2022-09-11 07:36:37,928 epoch 35 - iter 168/245 - loss 0.00316901 - samples/sec: 90.25 - lr: 0.003125\n",
            "2022-09-11 07:36:45,746 epoch 35 - iter 192/245 - loss 0.00302181 - samples/sec: 98.30 - lr: 0.003125\n",
            "2022-09-11 07:36:53,091 epoch 35 - iter 216/245 - loss 0.00305037 - samples/sec: 104.64 - lr: 0.003125\n",
            "2022-09-11 07:36:59,558 epoch 35 - iter 240/245 - loss 0.00300187 - samples/sec: 118.86 - lr: 0.003125\n",
            "2022-09-11 07:37:01,290 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:37:01,292 EPOCH 35 done: loss 0.0030 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:37:14,979 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:37:15,008 DEV : loss 0.04418227821588516 - f1-score (micro avg)  0.8946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:37:15,240 Epoch    35: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2022-09-11 07:37:15,242 BAD EPOCHS (no improvement): 4\n",
            "2022-09-11 07:37:15,246 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:37:21,794 epoch 36 - iter 24/245 - loss 0.00393147 - samples/sec: 117.45 - lr: 0.001563\n",
            "2022-09-11 07:37:28,499 epoch 36 - iter 48/245 - loss 0.00365323 - samples/sec: 114.63 - lr: 0.001563\n",
            "2022-09-11 07:37:36,346 epoch 36 - iter 72/245 - loss 0.00346865 - samples/sec: 97.94 - lr: 0.001563\n",
            "2022-09-11 07:37:44,070 epoch 36 - iter 96/245 - loss 0.00314774 - samples/sec: 99.50 - lr: 0.001563\n",
            "2022-09-11 07:37:50,694 epoch 36 - iter 120/245 - loss 0.00314635 - samples/sec: 116.05 - lr: 0.001563\n",
            "2022-09-11 07:37:58,699 epoch 36 - iter 144/245 - loss 0.00309456 - samples/sec: 96.02 - lr: 0.001563\n",
            "2022-09-11 07:38:07,208 epoch 36 - iter 168/245 - loss 0.00314451 - samples/sec: 90.32 - lr: 0.001563\n",
            "2022-09-11 07:38:14,293 epoch 36 - iter 192/245 - loss 0.00309618 - samples/sec: 108.49 - lr: 0.001563\n",
            "2022-09-11 07:38:21,738 epoch 36 - iter 216/245 - loss 0.00318250 - samples/sec: 103.24 - lr: 0.001563\n",
            "2022-09-11 07:38:29,489 epoch 36 - iter 240/245 - loss 0.00310299 - samples/sec: 99.16 - lr: 0.001563\n",
            "2022-09-11 07:38:31,007 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:38:31,009 EPOCH 36 done: loss 0.0032 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:38:44,616 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:38:44,643 DEV : loss 0.04426480829715729 - f1-score (micro avg)  0.8938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:38:44,879 BAD EPOCHS (no improvement): 1\n",
            "2022-09-11 07:38:44,882 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:38:52,155 epoch 37 - iter 24/245 - loss 0.00308358 - samples/sec: 105.70 - lr: 0.001563\n",
            "2022-09-11 07:38:58,634 epoch 37 - iter 48/245 - loss 0.00295320 - samples/sec: 118.63 - lr: 0.001563\n",
            "2022-09-11 07:39:06,150 epoch 37 - iter 72/245 - loss 0.00342832 - samples/sec: 102.25 - lr: 0.001563\n",
            "2022-09-11 07:39:13,546 epoch 37 - iter 96/245 - loss 0.00344793 - samples/sec: 103.92 - lr: 0.001563\n",
            "2022-09-11 07:39:20,535 epoch 37 - iter 120/245 - loss 0.00344344 - samples/sec: 110.00 - lr: 0.001563\n",
            "2022-09-11 07:39:27,854 epoch 37 - iter 144/245 - loss 0.00323409 - samples/sec: 105.01 - lr: 0.001563\n",
            "2022-09-11 07:39:34,831 epoch 37 - iter 168/245 - loss 0.00313559 - samples/sec: 110.17 - lr: 0.001563\n",
            "2022-09-11 07:39:42,315 epoch 37 - iter 192/245 - loss 0.00322865 - samples/sec: 102.70 - lr: 0.001563\n",
            "2022-09-11 07:39:50,511 epoch 37 - iter 216/245 - loss 0.00331975 - samples/sec: 93.77 - lr: 0.001563\n",
            "2022-09-11 07:39:58,311 epoch 37 - iter 240/245 - loss 0.00332378 - samples/sec: 98.53 - lr: 0.001563\n",
            "2022-09-11 07:39:59,999 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:40:00,001 EPOCH 37 done: loss 0.0034 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:40:14,728 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:40:14,759 DEV : loss 0.044284120202064514 - f1-score (micro avg)  0.8943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:40:14,997 BAD EPOCHS (no improvement): 2\n",
            "2022-09-11 07:40:15,001 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:40:22,045 epoch 38 - iter 24/245 - loss 0.00211057 - samples/sec: 109.15 - lr: 0.001563\n",
            "2022-09-11 07:40:28,813 epoch 38 - iter 48/245 - loss 0.00284537 - samples/sec: 113.58 - lr: 0.001563\n",
            "2022-09-11 07:40:37,124 epoch 38 - iter 72/245 - loss 0.00296843 - samples/sec: 92.48 - lr: 0.001563\n",
            "2022-09-11 07:40:44,708 epoch 38 - iter 96/245 - loss 0.00280432 - samples/sec: 101.35 - lr: 0.001563\n",
            "2022-09-11 07:40:51,841 epoch 38 - iter 120/245 - loss 0.00299036 - samples/sec: 107.76 - lr: 0.001563\n",
            "2022-09-11 07:40:58,741 epoch 38 - iter 144/245 - loss 0.00326511 - samples/sec: 111.39 - lr: 0.001563\n",
            "2022-09-11 07:41:06,351 epoch 38 - iter 168/245 - loss 0.00319926 - samples/sec: 100.99 - lr: 0.001563\n",
            "2022-09-11 07:41:12,208 epoch 38 - iter 192/245 - loss 0.00319481 - samples/sec: 131.26 - lr: 0.001563\n",
            "2022-09-11 07:41:20,375 epoch 38 - iter 216/245 - loss 0.00317155 - samples/sec: 94.09 - lr: 0.001563\n",
            "2022-09-11 07:41:27,168 epoch 38 - iter 240/245 - loss 0.00316694 - samples/sec: 113.14 - lr: 0.001563\n",
            "2022-09-11 07:41:28,885 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:41:28,887 EPOCH 38 done: loss 0.0032 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:41:42,479 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:41:42,511 DEV : loss 0.044395118951797485 - f1-score (micro avg)  0.8937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:41:42,744 BAD EPOCHS (no improvement): 3\n",
            "2022-09-11 07:41:42,747 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:41:49,808 epoch 39 - iter 24/245 - loss 0.00196330 - samples/sec: 108.89 - lr: 0.001563\n",
            "2022-09-11 07:41:55,727 epoch 39 - iter 48/245 - loss 0.00233870 - samples/sec: 129.87 - lr: 0.001563\n",
            "2022-09-11 07:42:02,903 epoch 39 - iter 72/245 - loss 0.00257846 - samples/sec: 107.11 - lr: 0.001563\n",
            "2022-09-11 07:42:10,152 epoch 39 - iter 96/245 - loss 0.00250408 - samples/sec: 106.03 - lr: 0.001563\n",
            "2022-09-11 07:42:17,954 epoch 39 - iter 120/245 - loss 0.00255778 - samples/sec: 98.50 - lr: 0.001563\n",
            "2022-09-11 07:42:25,732 epoch 39 - iter 144/245 - loss 0.00278644 - samples/sec: 98.82 - lr: 0.001563\n",
            "2022-09-11 07:42:32,578 epoch 39 - iter 168/245 - loss 0.00267218 - samples/sec: 112.27 - lr: 0.001563\n",
            "2022-09-11 07:42:39,530 epoch 39 - iter 192/245 - loss 0.00271845 - samples/sec: 110.56 - lr: 0.001563\n",
            "2022-09-11 07:42:48,029 epoch 39 - iter 216/245 - loss 0.00303339 - samples/sec: 90.43 - lr: 0.001563\n",
            "2022-09-11 07:42:54,904 epoch 39 - iter 240/245 - loss 0.00296334 - samples/sec: 111.80 - lr: 0.001563\n",
            "2022-09-11 07:42:56,091 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:42:56,094 EPOCH 39 done: loss 0.0030 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:43:10,733 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:43:10,759 DEV : loss 0.044437699019908905 - f1-score (micro avg)  0.8951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:43:10,987 Epoch    39: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2022-09-11 07:43:10,988 BAD EPOCHS (no improvement): 4\n",
            "2022-09-11 07:43:10,992 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:43:18,708 epoch 40 - iter 24/245 - loss 0.00512617 - samples/sec: 99.66 - lr: 0.000781\n",
            "2022-09-11 07:43:26,374 epoch 40 - iter 48/245 - loss 0.00446527 - samples/sec: 100.25 - lr: 0.000781\n",
            "2022-09-11 07:43:32,759 epoch 40 - iter 72/245 - loss 0.00416410 - samples/sec: 120.37 - lr: 0.000781\n",
            "2022-09-11 07:43:40,726 epoch 40 - iter 96/245 - loss 0.00405825 - samples/sec: 96.47 - lr: 0.000781\n",
            "2022-09-11 07:43:48,015 epoch 40 - iter 120/245 - loss 0.00397989 - samples/sec: 105.45 - lr: 0.000781\n",
            "2022-09-11 07:43:55,971 epoch 40 - iter 144/245 - loss 0.00388383 - samples/sec: 96.60 - lr: 0.000781\n",
            "2022-09-11 07:44:04,032 epoch 40 - iter 168/245 - loss 0.00362526 - samples/sec: 95.34 - lr: 0.000781\n",
            "2022-09-11 07:44:10,900 epoch 40 - iter 192/245 - loss 0.00367166 - samples/sec: 111.92 - lr: 0.000781\n",
            "2022-09-11 07:44:17,839 epoch 40 - iter 216/245 - loss 0.00367142 - samples/sec: 110.75 - lr: 0.000781\n",
            "2022-09-11 07:44:24,045 epoch 40 - iter 240/245 - loss 0.00364366 - samples/sec: 123.87 - lr: 0.000781\n",
            "2022-09-11 07:44:25,191 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:44:25,195 EPOCH 40 done: loss 0.0036 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:44:38,790 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:44:38,816 DEV : loss 0.0444183424115181 - f1-score (micro avg)  0.8942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:44:39,046 BAD EPOCHS (no improvement): 1\n",
            "2022-09-11 07:44:39,049 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:44:45,449 epoch 41 - iter 24/245 - loss 0.00261871 - samples/sec: 120.15 - lr: 0.000781\n",
            "2022-09-11 07:44:53,112 epoch 41 - iter 48/245 - loss 0.00244484 - samples/sec: 100.30 - lr: 0.000781\n",
            "2022-09-11 07:44:59,838 epoch 41 - iter 72/245 - loss 0.00276735 - samples/sec: 114.26 - lr: 0.000781\n",
            "2022-09-11 07:45:07,665 epoch 41 - iter 96/245 - loss 0.00318430 - samples/sec: 98.20 - lr: 0.000781\n",
            "2022-09-11 07:45:14,600 epoch 41 - iter 120/245 - loss 0.00311658 - samples/sec: 110.84 - lr: 0.000781\n",
            "2022-09-11 07:45:22,359 epoch 41 - iter 144/245 - loss 0.00310530 - samples/sec: 99.04 - lr: 0.000781\n",
            "2022-09-11 07:45:30,963 epoch 41 - iter 168/245 - loss 0.00312851 - samples/sec: 89.32 - lr: 0.000781\n",
            "2022-09-11 07:45:39,392 epoch 41 - iter 192/245 - loss 0.00328040 - samples/sec: 91.18 - lr: 0.000781\n",
            "2022-09-11 07:45:46,867 epoch 41 - iter 216/245 - loss 0.00328948 - samples/sec: 102.81 - lr: 0.000781\n",
            "2022-09-11 07:45:53,334 epoch 41 - iter 240/245 - loss 0.00322690 - samples/sec: 118.86 - lr: 0.000781\n",
            "2022-09-11 07:45:54,532 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:45:54,535 EPOCH 41 done: loss 0.0033 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:46:08,085 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:46:08,111 DEV : loss 0.04442427307367325 - f1-score (micro avg)  0.8951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:46:08,344 BAD EPOCHS (no improvement): 2\n",
            "2022-09-11 07:46:08,348 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:46:15,558 epoch 42 - iter 24/245 - loss 0.00319939 - samples/sec: 106.64 - lr: 0.000781\n",
            "2022-09-11 07:46:22,273 epoch 42 - iter 48/245 - loss 0.00305363 - samples/sec: 114.48 - lr: 0.000781\n",
            "2022-09-11 07:46:29,794 epoch 42 - iter 72/245 - loss 0.00352813 - samples/sec: 102.19 - lr: 0.000781\n",
            "2022-09-11 07:46:36,989 epoch 42 - iter 96/245 - loss 0.00326044 - samples/sec: 106.82 - lr: 0.000781\n",
            "2022-09-11 07:46:44,089 epoch 42 - iter 120/245 - loss 0.00327930 - samples/sec: 108.25 - lr: 0.000781\n",
            "2022-09-11 07:46:50,673 epoch 42 - iter 144/245 - loss 0.00329026 - samples/sec: 116.77 - lr: 0.000781\n",
            "2022-09-11 07:46:57,032 epoch 42 - iter 168/245 - loss 0.00329463 - samples/sec: 120.88 - lr: 0.000781\n",
            "2022-09-11 07:47:05,727 epoch 42 - iter 192/245 - loss 0.00324120 - samples/sec: 88.38 - lr: 0.000781\n",
            "2022-09-11 07:47:13,226 epoch 42 - iter 216/245 - loss 0.00332341 - samples/sec: 102.49 - lr: 0.000781\n",
            "2022-09-11 07:47:21,096 epoch 42 - iter 240/245 - loss 0.00328419 - samples/sec: 97.66 - lr: 0.000781\n",
            "2022-09-11 07:47:22,506 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:47:22,508 EPOCH 42 done: loss 0.0033 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:47:37,136 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:47:37,163 DEV : loss 0.04427662491798401 - f1-score (micro avg)  0.8951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:47:37,401 BAD EPOCHS (no improvement): 3\n",
            "2022-09-11 07:47:37,405 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:47:44,992 epoch 43 - iter 24/245 - loss 0.00289363 - samples/sec: 101.34 - lr: 0.000781\n",
            "2022-09-11 07:47:52,895 epoch 43 - iter 48/245 - loss 0.00314890 - samples/sec: 97.24 - lr: 0.000781\n",
            "2022-09-11 07:47:59,949 epoch 43 - iter 72/245 - loss 0.00300594 - samples/sec: 108.96 - lr: 0.000781\n",
            "2022-09-11 07:48:06,519 epoch 43 - iter 96/245 - loss 0.00316608 - samples/sec: 117.02 - lr: 0.000781\n",
            "2022-09-11 07:48:14,841 epoch 43 - iter 120/245 - loss 0.00325343 - samples/sec: 92.35 - lr: 0.000781\n",
            "2022-09-11 07:48:23,105 epoch 43 - iter 144/245 - loss 0.00325899 - samples/sec: 93.00 - lr: 0.000781\n",
            "2022-09-11 07:48:30,358 epoch 43 - iter 168/245 - loss 0.00336237 - samples/sec: 105.97 - lr: 0.000781\n",
            "2022-09-11 07:48:36,935 epoch 43 - iter 192/245 - loss 0.00331150 - samples/sec: 116.85 - lr: 0.000781\n",
            "2022-09-11 07:48:43,182 epoch 43 - iter 216/245 - loss 0.00347671 - samples/sec: 123.06 - lr: 0.000781\n",
            "2022-09-11 07:48:50,099 epoch 43 - iter 240/245 - loss 0.00348943 - samples/sec: 111.11 - lr: 0.000781\n",
            "2022-09-11 07:48:51,733 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:48:51,736 EPOCH 43 done: loss 0.0035 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:49:05,264 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:49:05,290 DEV : loss 0.04427645727992058 - f1-score (micro avg)  0.896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:49:05,520 Epoch    43: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2022-09-11 07:49:05,522 BAD EPOCHS (no improvement): 4\n",
            "2022-09-11 07:49:05,524 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:49:12,350 epoch 44 - iter 24/245 - loss 0.00181734 - samples/sec: 112.68 - lr: 0.000391\n",
            "2022-09-11 07:49:18,518 epoch 44 - iter 48/245 - loss 0.00216948 - samples/sec: 124.64 - lr: 0.000391\n",
            "2022-09-11 07:49:25,656 epoch 44 - iter 72/245 - loss 0.00286764 - samples/sec: 107.68 - lr: 0.000391\n",
            "2022-09-11 07:49:32,994 epoch 44 - iter 96/245 - loss 0.00294446 - samples/sec: 104.74 - lr: 0.000391\n",
            "2022-09-11 07:49:40,906 epoch 44 - iter 120/245 - loss 0.00326432 - samples/sec: 97.15 - lr: 0.000391\n",
            "2022-09-11 07:49:48,631 epoch 44 - iter 144/245 - loss 0.00335884 - samples/sec: 99.49 - lr: 0.000391\n",
            "2022-09-11 07:49:56,283 epoch 44 - iter 168/245 - loss 0.00323294 - samples/sec: 100.44 - lr: 0.000391\n",
            "2022-09-11 07:50:03,201 epoch 44 - iter 192/245 - loss 0.00338044 - samples/sec: 111.10 - lr: 0.000391\n",
            "2022-09-11 07:50:11,562 epoch 44 - iter 216/245 - loss 0.00318708 - samples/sec: 91.91 - lr: 0.000391\n",
            "2022-09-11 07:50:18,565 epoch 44 - iter 240/245 - loss 0.00307777 - samples/sec: 109.76 - lr: 0.000391\n",
            "2022-09-11 07:50:20,282 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:50:20,283 EPOCH 44 done: loss 0.0031 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:50:35,044 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:50:35,072 DEV : loss 0.04428698867559433 - f1-score (micro avg)  0.8957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:50:35,308 BAD EPOCHS (no improvement): 1\n",
            "2022-09-11 07:50:35,311 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:50:43,191 epoch 45 - iter 24/245 - loss 0.00387270 - samples/sec: 97.57 - lr: 0.000391\n",
            "2022-09-11 07:50:52,297 epoch 45 - iter 48/245 - loss 0.00392892 - samples/sec: 84.40 - lr: 0.000391\n",
            "2022-09-11 07:50:59,124 epoch 45 - iter 72/245 - loss 0.00408650 - samples/sec: 112.59 - lr: 0.000391\n",
            "2022-09-11 07:51:06,020 epoch 45 - iter 96/245 - loss 0.00387405 - samples/sec: 111.46 - lr: 0.000391\n",
            "2022-09-11 07:51:13,210 epoch 45 - iter 120/245 - loss 0.00367962 - samples/sec: 106.90 - lr: 0.000391\n",
            "2022-09-11 07:51:20,230 epoch 45 - iter 144/245 - loss 0.00348704 - samples/sec: 109.51 - lr: 0.000391\n",
            "2022-09-11 07:51:27,182 epoch 45 - iter 168/245 - loss 0.00345561 - samples/sec: 110.56 - lr: 0.000391\n",
            "2022-09-11 07:51:34,906 epoch 45 - iter 192/245 - loss 0.00337509 - samples/sec: 99.49 - lr: 0.000391\n",
            "2022-09-11 07:51:41,459 epoch 45 - iter 216/245 - loss 0.00339980 - samples/sec: 117.30 - lr: 0.000391\n",
            "2022-09-11 07:51:48,877 epoch 45 - iter 240/245 - loss 0.00324872 - samples/sec: 103.61 - lr: 0.000391\n",
            "2022-09-11 07:51:49,863 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:51:49,865 EPOCH 45 done: loss 0.0032 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:52:03,527 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:52:03,558 DEV : loss 0.04430179297924042 - f1-score (micro avg)  0.8957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:52:03,802 BAD EPOCHS (no improvement): 2\n",
            "2022-09-11 07:52:03,805 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:52:11,845 epoch 46 - iter 24/245 - loss 0.00411291 - samples/sec: 95.63 - lr: 0.000391\n",
            "2022-09-11 07:52:19,544 epoch 46 - iter 48/245 - loss 0.00416715 - samples/sec: 99.81 - lr: 0.000391\n",
            "2022-09-11 07:52:27,342 epoch 46 - iter 72/245 - loss 0.00439639 - samples/sec: 98.56 - lr: 0.000391\n",
            "2022-09-11 07:52:34,473 epoch 46 - iter 96/245 - loss 0.00399346 - samples/sec: 107.78 - lr: 0.000391\n",
            "2022-09-11 07:52:42,110 epoch 46 - iter 120/245 - loss 0.00380030 - samples/sec: 100.65 - lr: 0.000391\n",
            "2022-09-11 07:52:49,491 epoch 46 - iter 144/245 - loss 0.00347998 - samples/sec: 104.13 - lr: 0.000391\n",
            "2022-09-11 07:52:57,674 epoch 46 - iter 168/245 - loss 0.00349105 - samples/sec: 93.92 - lr: 0.000391\n",
            "2022-09-11 07:53:04,703 epoch 46 - iter 192/245 - loss 0.00345159 - samples/sec: 109.35 - lr: 0.000391\n",
            "2022-09-11 07:53:11,876 epoch 46 - iter 216/245 - loss 0.00339308 - samples/sec: 107.16 - lr: 0.000391\n",
            "2022-09-11 07:53:18,581 epoch 46 - iter 240/245 - loss 0.00327489 - samples/sec: 114.64 - lr: 0.000391\n",
            "2022-09-11 07:53:20,240 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:53:20,243 EPOCH 46 done: loss 0.0033 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:53:33,852 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:53:33,879 DEV : loss 0.04433118551969528 - f1-score (micro avg)  0.896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:53:34,111 BAD EPOCHS (no improvement): 3\n",
            "2022-09-11 07:53:34,114 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:53:41,708 epoch 47 - iter 24/245 - loss 0.00340322 - samples/sec: 101.26 - lr: 0.000391\n",
            "2022-09-11 07:53:49,823 epoch 47 - iter 48/245 - loss 0.00357361 - samples/sec: 94.70 - lr: 0.000391\n",
            "2022-09-11 07:53:57,244 epoch 47 - iter 72/245 - loss 0.00314236 - samples/sec: 103.59 - lr: 0.000391\n",
            "2022-09-11 07:54:04,262 epoch 47 - iter 96/245 - loss 0.00306778 - samples/sec: 109.54 - lr: 0.000391\n",
            "2022-09-11 07:54:11,884 epoch 47 - iter 120/245 - loss 0.00306203 - samples/sec: 100.84 - lr: 0.000391\n",
            "2022-09-11 07:54:18,847 epoch 47 - iter 144/245 - loss 0.00314432 - samples/sec: 110.40 - lr: 0.000391\n",
            "2022-09-11 07:54:26,520 epoch 47 - iter 168/245 - loss 0.00323129 - samples/sec: 100.15 - lr: 0.000391\n",
            "2022-09-11 07:54:34,083 epoch 47 - iter 192/245 - loss 0.00319975 - samples/sec: 101.64 - lr: 0.000391\n",
            "2022-09-11 07:54:40,318 epoch 47 - iter 216/245 - loss 0.00320373 - samples/sec: 123.27 - lr: 0.000391\n",
            "2022-09-11 07:54:47,012 epoch 47 - iter 240/245 - loss 0.00320748 - samples/sec: 114.80 - lr: 0.000391\n",
            "2022-09-11 07:54:48,199 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:54:48,201 EPOCH 47 done: loss 0.0032 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:55:02,994 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:55:03,020 DEV : loss 0.04430649057030678 - f1-score (micro avg)  0.896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:55:03,261 Epoch    47: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2022-09-11 07:55:03,263 BAD EPOCHS (no improvement): 4\n",
            "2022-09-11 07:55:03,265 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:55:11,122 epoch 48 - iter 24/245 - loss 0.00254217 - samples/sec: 97.87 - lr: 0.000195\n",
            "2022-09-11 07:55:17,510 epoch 48 - iter 48/245 - loss 0.00252657 - samples/sec: 120.35 - lr: 0.000195\n",
            "2022-09-11 07:55:26,192 epoch 48 - iter 72/245 - loss 0.00309463 - samples/sec: 88.51 - lr: 0.000195\n",
            "2022-09-11 07:55:32,341 epoch 48 - iter 96/245 - loss 0.00356310 - samples/sec: 125.04 - lr: 0.000195\n",
            "2022-09-11 07:55:39,901 epoch 48 - iter 120/245 - loss 0.00335675 - samples/sec: 101.67 - lr: 0.000195\n",
            "2022-09-11 07:55:47,219 epoch 48 - iter 144/245 - loss 0.00339791 - samples/sec: 105.02 - lr: 0.000195\n",
            "2022-09-11 07:55:54,299 epoch 48 - iter 168/245 - loss 0.00325185 - samples/sec: 108.56 - lr: 0.000195\n",
            "2022-09-11 07:56:01,675 epoch 48 - iter 192/245 - loss 0.00316857 - samples/sec: 104.22 - lr: 0.000195\n",
            "2022-09-11 07:56:07,922 epoch 48 - iter 216/245 - loss 0.00312154 - samples/sec: 123.05 - lr: 0.000195\n",
            "2022-09-11 07:56:16,022 epoch 48 - iter 240/245 - loss 0.00308690 - samples/sec: 94.90 - lr: 0.000195\n",
            "2022-09-11 07:56:17,635 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:56:17,638 EPOCH 48 done: loss 0.0031 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:56:31,304 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:56:31,335 DEV : loss 0.04428604245185852 - f1-score (micro avg)  0.8957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:56:31,566 BAD EPOCHS (no improvement): 1\n",
            "2022-09-11 07:56:31,569 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:56:39,115 epoch 49 - iter 24/245 - loss 0.00535039 - samples/sec: 101.90 - lr: 0.000195\n",
            "2022-09-11 07:56:45,727 epoch 49 - iter 48/245 - loss 0.00411403 - samples/sec: 116.24 - lr: 0.000195\n",
            "2022-09-11 07:56:52,156 epoch 49 - iter 72/245 - loss 0.00352356 - samples/sec: 119.58 - lr: 0.000195\n",
            "2022-09-11 07:57:00,127 epoch 49 - iter 96/245 - loss 0.00314097 - samples/sec: 96.42 - lr: 0.000195\n",
            "2022-09-11 07:57:06,706 epoch 49 - iter 120/245 - loss 0.00300373 - samples/sec: 116.85 - lr: 0.000195\n",
            "2022-09-11 07:57:13,578 epoch 49 - iter 144/245 - loss 0.00311646 - samples/sec: 111.85 - lr: 0.000195\n",
            "2022-09-11 07:57:21,545 epoch 49 - iter 168/245 - loss 0.00334224 - samples/sec: 96.46 - lr: 0.000195\n",
            "2022-09-11 07:57:28,291 epoch 49 - iter 192/245 - loss 0.00321776 - samples/sec: 113.95 - lr: 0.000195\n",
            "2022-09-11 07:57:35,937 epoch 49 - iter 216/245 - loss 0.00303918 - samples/sec: 100.52 - lr: 0.000195\n",
            "2022-09-11 07:57:44,807 epoch 49 - iter 240/245 - loss 0.00306626 - samples/sec: 86.63 - lr: 0.000195\n",
            "2022-09-11 07:57:46,385 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:57:46,389 EPOCH 49 done: loss 0.0031 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:14<00:00,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:58:01,049 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:58:01,075 DEV : loss 0.044288791716098785 - f1-score (micro avg)  0.8963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:58:01,312 BAD EPOCHS (no improvement): 2\n",
            "2022-09-11 07:58:01,316 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:58:08,246 epoch 50 - iter 24/245 - loss 0.00314183 - samples/sec: 110.96 - lr: 0.000195\n",
            "2022-09-11 07:58:15,843 epoch 50 - iter 48/245 - loss 0.00322227 - samples/sec: 101.16 - lr: 0.000195\n",
            "2022-09-11 07:58:22,925 epoch 50 - iter 72/245 - loss 0.00317290 - samples/sec: 108.54 - lr: 0.000195\n",
            "2022-09-11 07:58:29,465 epoch 50 - iter 96/245 - loss 0.00325495 - samples/sec: 117.55 - lr: 0.000195\n",
            "2022-09-11 07:58:36,578 epoch 50 - iter 120/245 - loss 0.00311008 - samples/sec: 108.04 - lr: 0.000195\n",
            "2022-09-11 07:58:42,880 epoch 50 - iter 144/245 - loss 0.00306380 - samples/sec: 121.96 - lr: 0.000195\n",
            "2022-09-11 07:58:50,828 epoch 50 - iter 168/245 - loss 0.00322382 - samples/sec: 96.70 - lr: 0.000195\n",
            "2022-09-11 07:58:58,106 epoch 50 - iter 192/245 - loss 0.00317520 - samples/sec: 105.61 - lr: 0.000195\n",
            "2022-09-11 07:59:05,898 epoch 50 - iter 216/245 - loss 0.00335524 - samples/sec: 98.64 - lr: 0.000195\n",
            "2022-09-11 07:59:14,674 epoch 50 - iter 240/245 - loss 0.00333605 - samples/sec: 87.57 - lr: 0.000195\n",
            "2022-09-11 07:59:15,931 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:59:15,933 EPOCH 50 done: loss 0.0033 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:59:29,547 Evaluating as a multi-label problem: False\n",
            "2022-09-11 07:59:29,574 DEV : loss 0.04428573325276375 - f1-score (micro avg)  0.8957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 07:59:29,811 BAD EPOCHS (no improvement): 3\n",
            "2022-09-11 07:59:29,814 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 07:59:37,381 epoch 51 - iter 24/245 - loss 0.00307417 - samples/sec: 101.61 - lr: 0.000195\n",
            "2022-09-11 07:59:44,774 epoch 51 - iter 48/245 - loss 0.00342369 - samples/sec: 103.97 - lr: 0.000195\n",
            "2022-09-11 07:59:53,436 epoch 51 - iter 72/245 - loss 0.00319220 - samples/sec: 88.72 - lr: 0.000195\n",
            "2022-09-11 08:00:00,039 epoch 51 - iter 96/245 - loss 0.00326406 - samples/sec: 116.40 - lr: 0.000195\n",
            "2022-09-11 08:00:06,998 epoch 51 - iter 120/245 - loss 0.00315743 - samples/sec: 110.45 - lr: 0.000195\n",
            "2022-09-11 08:00:13,887 epoch 51 - iter 144/245 - loss 0.00292692 - samples/sec: 111.58 - lr: 0.000195\n",
            "2022-09-11 08:00:21,026 epoch 51 - iter 168/245 - loss 0.00315130 - samples/sec: 107.66 - lr: 0.000195\n",
            "2022-09-11 08:00:28,891 epoch 51 - iter 192/245 - loss 0.00340183 - samples/sec: 97.71 - lr: 0.000195\n",
            "2022-09-11 08:00:36,001 epoch 51 - iter 216/245 - loss 0.00348497 - samples/sec: 108.12 - lr: 0.000195\n",
            "2022-09-11 08:00:43,243 epoch 51 - iter 240/245 - loss 0.00339848 - samples/sec: 106.13 - lr: 0.000195\n",
            "2022-09-11 08:00:45,629 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 08:00:45,632 EPOCH 51 done: loss 0.0034 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [00:13<00:00,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 08:00:59,277 Evaluating as a multi-label problem: False\n",
            "2022-09-11 08:00:59,306 DEV : loss 0.04428378865122795 - f1-score (micro avg)  0.8966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 08:00:59,543 Epoch    51: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2022-09-11 08:00:59,545 BAD EPOCHS (no improvement): 4\n",
            "2022-09-11 08:00:59,549 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 08:00:59,552 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 08:00:59,555 learning rate too small - quitting training!\n",
            "2022-09-11 08:00:59,556 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 08:01:04,238 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-11 08:01:04,241 loading file resources/taggers/sota-ner-flair/best-model.pt\n",
            "2022-09-11 08:01:06,203 SequenceTagger predicts: Dictionary with 27 tags: O, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-LEGISLACAO, B-LEGISLACAO, E-LEGISLACAO, I-LEGISLACAO, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-TEMPO, B-TEMPO, E-TEMPO, I-TEMPO, S-JURISPRUDENCIA, B-JURISPRUDENCIA, E-JURISPRUDENCIA, I-JURISPRUDENCIA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44/44 [00:29<00:00,  1.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-11 08:01:36,609 Evaluating as a multi-label problem: False\n",
            "2022-09-11 08:01:36,636 0.8976\t0.9134\t0.9055\t0.8341\n",
            "2022-09-11 08:01:36,637 \n",
            "Results:\n",
            "- F-score (micro) 0.9055\n",
            "- F-score (macro) 0.8873\n",
            "- Accuracy 0.8341\n",
            "\n",
            "By class:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   ORGANIZACAO     0.8605    0.8743    0.8673       501\n",
            "    LEGISLACAO     0.9479    0.9630    0.9554       378\n",
            "        PESSOA     0.9174    0.9528    0.9347       233\n",
            "JURISPRUDENCIA     0.8342    0.8973    0.8646       185\n",
            "         TEMPO     0.9727    0.9271    0.9493       192\n",
            "         LOCAL     0.7609    0.7447    0.7527        47\n",
            "\n",
            "     micro avg     0.8976    0.9134    0.9055      1536\n",
            "     macro avg     0.8823    0.8932    0.8873      1536\n",
            "  weighted avg     0.8984    0.9134    0.9056      1536\n",
            "\n",
            "2022-09-11 08:01:36,641 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_score': 0.9054533720555019,\n",
              " 'dev_score_history': [0.8864688265722843,\n",
              "  0.8829026937877955,\n",
              "  0.8812071330589849,\n",
              "  0.8873007146783947,\n",
              "  0.8839900799118214,\n",
              "  0.8802797955340329,\n",
              "  0.8768175582990398,\n",
              "  0.8880351262349067,\n",
              "  0.9005975013579577,\n",
              "  0.8845303867403315,\n",
              "  0.8867048867048868,\n",
              "  0.8793817278498481,\n",
              "  0.8889496717724289,\n",
              "  0.8993178717598909,\n",
              "  0.902981029810298,\n",
              "  0.8981152690521715,\n",
              "  0.8932676518883416,\n",
              "  0.884308876064853,\n",
              "  0.893467064245053,\n",
              "  0.8933260393873086,\n",
              "  0.8932676518883416,\n",
              "  0.8965517241379312,\n",
              "  0.8921139101861995,\n",
              "  0.895856052344602,\n",
              "  0.8950095445868557,\n",
              "  0.8951239444293109,\n",
              "  0.8936750272628134,\n",
              "  0.8955142231947483,\n",
              "  0.8945791337510215,\n",
              "  0.8954979536152796,\n",
              "  0.8970588235294118,\n",
              "  0.8932568932568933,\n",
              "  0.8954408954408954,\n",
              "  0.8930817610062892,\n",
              "  0.8945931185144729,\n",
              "  0.8938028938028939,\n",
              "  0.8943488943488944,\n",
              "  0.8937448784485114,\n",
              "  0.8950819672131148,\n",
              "  0.8941755537325676,\n",
              "  0.8950819672131148,\n",
              "  0.8951392681594756,\n",
              "  0.896043656207367,\n",
              "  0.8957423580786026,\n",
              "  0.8957423580786026,\n",
              "  0.896043656207367,\n",
              "  0.896043656207367,\n",
              "  0.8957423580786026,\n",
              "  0.896288209606987,\n",
              "  0.8957423580786026,\n",
              "  0.8965893587994543],\n",
              " 'train_loss_history': [0.006987824600537778,\n",
              "  0.007722130156699102,\n",
              "  0.007865784005264375,\n",
              "  0.007314198716236256,\n",
              "  0.007749240683758075,\n",
              "  0.00764437852807412,\n",
              "  0.006951873869407965,\n",
              "  0.007970814403810674,\n",
              "  0.0071547896689920926,\n",
              "  0.007297451097635175,\n",
              "  0.007453831773357118,\n",
              "  0.00679683274761533,\n",
              "  0.006608532780490411,\n",
              "  0.00569830695035372,\n",
              "  0.005457992253229718,\n",
              "  0.00517223707567702,\n",
              "  0.0049992280421171775,\n",
              "  0.004637186439601443,\n",
              "  0.004255402921466174,\n",
              "  0.004262937646111472,\n",
              "  0.004602541187897173,\n",
              "  0.004322861920297283,\n",
              "  0.0038496991016870423,\n",
              "  0.003697373291913275,\n",
              "  0.0038282428125967715,\n",
              "  0.0031128209204913707,\n",
              "  0.0036019327365206717,\n",
              "  0.003566525067794633,\n",
              "  0.003290527976257976,\n",
              "  0.003167442350028568,\n",
              "  0.003264237366945878,\n",
              "  0.0035492833688889423,\n",
              "  0.0030179489833803653,\n",
              "  0.0033360813284803973,\n",
              "  0.0029973850203574713,\n",
              "  0.003233329662373461,\n",
              "  0.0033649424331703573,\n",
              "  0.003159175023552297,\n",
              "  0.002996890940052862,\n",
              "  0.0036378685600550863,\n",
              "  0.0032840708577942836,\n",
              "  0.00329638879090576,\n",
              "  0.0035259231669007357,\n",
              "  0.003144182241895175,\n",
              "  0.003218315584151485,\n",
              "  0.0032856169884026747,\n",
              "  0.0031942291693017617,\n",
              "  0.0031216760321576085,\n",
              "  0.003054694076379227,\n",
              "  0.003303851107230555,\n",
              "  0.0033603040413451852],\n",
              " 'dev_loss_history': [0.04608402028679848,\n",
              "  0.039582714438438416,\n",
              "  0.03870369866490364,\n",
              "  0.04017338156700134,\n",
              "  0.0396902933716774,\n",
              "  0.042866069823503494,\n",
              "  0.0430731326341629,\n",
              "  0.03850177302956581,\n",
              "  0.04363260418176651,\n",
              "  0.04165041819214821,\n",
              "  0.04661846533417702,\n",
              "  0.04888354241847992,\n",
              "  0.04375133663415909,\n",
              "  0.040513183921575546,\n",
              "  0.04207519441843033,\n",
              "  0.042186904698610306,\n",
              "  0.04267817363142967,\n",
              "  0.04357725754380226,\n",
              "  0.04396483674645424,\n",
              "  0.04220595210790634,\n",
              "  0.042547840625047684,\n",
              "  0.042904652655124664,\n",
              "  0.04290531575679779,\n",
              "  0.04375961422920227,\n",
              "  0.0437433160841465,\n",
              "  0.04366707056760788,\n",
              "  0.04408752918243408,\n",
              "  0.04408428072929382,\n",
              "  0.043866127729415894,\n",
              "  0.043949324637651443,\n",
              "  0.04438399150967598,\n",
              "  0.043678104877471924,\n",
              "  0.04361075535416603,\n",
              "  0.04416164010763168,\n",
              "  0.04418227821588516,\n",
              "  0.04426480829715729,\n",
              "  0.044284120202064514,\n",
              "  0.044395118951797485,\n",
              "  0.044437699019908905,\n",
              "  0.0444183424115181,\n",
              "  0.04442427307367325,\n",
              "  0.04427662491798401,\n",
              "  0.04427645727992058,\n",
              "  0.04428698867559433,\n",
              "  0.04430179297924042,\n",
              "  0.04433118551969528,\n",
              "  0.04430649057030678,\n",
              "  0.04428604245185852,\n",
              "  0.044288791716098785,\n",
              "  0.04428573325276375,\n",
              "  0.04428378865122795]}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# Initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# Start training\n",
        "trainer.train('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc2JIPoZ3wAF"
      },
      "source": [
        "Quero testar o curpus Lener-br, Ulisses e o Harem, gostaria de testar uma rede treinada em um corpus diferente e também quero lidar com as entidades."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5m1lHNkbDIh"
      },
      "source": [
        "## Teste 2.4 NER Flair Bert Embeddings com Corpus Lener_br\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw1iuzGfbDIh"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6tmn77CbDIi"
      },
      "outputs": [],
      "source": [
        "## Importes\n",
        "## datasets\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgRc9E3UbDIi"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEz35RrfbDIi",
        "outputId": "379c426b-7614-424e-eacf-2f892040a9e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6wgyKrlbDIi",
        "outputId": "9ee25ffd-ef20-4909-a597-98d76fe606ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-15 19:49:26,744 Reading data from /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br\n",
            "2022-08-15 19:49:26,748 Train: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/train.txt\n",
            "2022-08-15 19:49:26,750 Dev: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/dev.txt\n",
            "2022-08-15 19:49:26,751 Test: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/test.txt\n"
          ]
        }
      ],
      "source": [
        "## carregando um corpus e definindo as colunas\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6qetll4bDIi",
        "outputId": "33c51433-fac7-4492-bd4c-7346e212a55c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-15 19:49:34,091 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7827it [00:00, 44212.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-15 19:49:34,323 Dictionary created for label 'ner' with 7 values: ORG (seen 2400 times), LEGISLACAO (seen 1920 times), PER (seen 1525 times), TEMPO (seen 1334 times), JURISPRUDENCIA (seen 1104 times), LOC (seen 611 times)\n",
            "Dictionary with 7 tags: <unk>, ORG, LEGISLACAO, PER, TEMPO, JURISPRUDENCIA, LOC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ4y9dIzbDIi"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo9aMJ8QbDIi",
        "outputId": "71b4003a-cf15-441e-a296-961a93637d34"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cf72a2a8dd34d2996a3753bbe3937ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "819a92510dda41a4832f4f6990c61bf5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d2f4c2c720b42d2bfc50964c88028c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4467122264040f4819cf3a4b8126cf1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e07adbef4c6341b0a141a50eabf8fd36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ed013386d114bb38bb6095795e4264e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/418M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Apenas Bert\n",
        "embeddings = TransformerWordEmbeddings('neuralmind/bert-base-portuguese-cased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOq8J_9VbDIi"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXSdGTvWbDIj",
        "outputId": "bb3bb9dd-1f0d-4628-c1eb-1d75b3b9834c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-15 19:51:42,147 SequenceTagger predicts: Dictionary with 25 tags: O, S-ORG, B-ORG, E-ORG, I-ORG, S-LEGISLACAO, B-LEGISLACAO, E-LEGISLACAO, I-LEGISLACAO, S-PER, B-PER, E-PER, I-PER, S-TEMPO, B-TEMPO, E-TEMPO, I-TEMPO, S-JURISPRUDENCIA, B-JURISPRUDENCIA, E-JURISPRUDENCIA, I-JURISPRUDENCIA, S-LOC, B-LOC, E-LOC, I-LOC\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S7HbpXLabDIj",
        "outputId": "ac0f9032-c95d-4da4-c86a-0e6bea565c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-15 19:51:44,405 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-15 19:51:44,409 Model: \"SequenceTagger(\n",
            "  (embeddings): TransformerWordEmbeddings(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (rnn): LSTM(768, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=27, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-08-15 19:51:44,411 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-15 19:51:44,413 Corpus: \"Corpus: 7827 train + 1176 dev + 1389 test sentences\"\n",
            "2022-08-15 19:51:44,415 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-15 19:51:44,416 Parameters:\n",
            "2022-08-15 19:51:44,418  - learning_rate: \"0.100000\"\n",
            "2022-08-15 19:51:44,419  - mini_batch_size: \"32\"\n",
            "2022-08-15 19:51:44,421  - patience: \"3\"\n",
            "2022-08-15 19:51:44,424  - anneal_factor: \"0.5\"\n",
            "2022-08-15 19:51:44,426  - max_epochs: \"3\"\n",
            "2022-08-15 19:51:44,427  - shuffle: \"True\"\n",
            "2022-08-15 19:51:44,429  - train_with_dev: \"False\"\n",
            "2022-08-15 19:51:44,430  - batch_growth_annealing: \"False\"\n",
            "2022-08-15 19:51:44,432 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-15 19:51:44,433 Model training base path: \"resources/taggers/sota-ner-flair\"\n",
            "2022-08-15 19:51:44,434 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-15 19:51:44,435 Device: cuda:0\n",
            "2022-08-15 19:51:44,437 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-15 19:51:44,438 Embeddings storage mode: cpu\n",
            "2022-08-15 19:51:44,439 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1f2b26fa351a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m               \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m               \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m               max_epochs=3)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, learning_rate, mini_batch_size, eval_batch_size, mini_batch_chunk_size, max_epochs, train_with_dev, train_with_test, monitor_train, monitor_test, main_evaluation_metric, scheduler, anneal_factor, patience, min_learning_rate, initial_extra_patience, optimizer, cycle_momentum, warmup_fraction, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, anneal_with_prestarts, anneal_against_dev_loss, batch_growth_annealing, shuffle, param_selection_mode, write_weights, num_workers, sampler, use_amp, amp_opt_level, eval_on_train_fraction, eval_on_train_shuffle, save_model_each_k_epochs, tensorboard_comment, use_swa, use_final_model_for_eval, gold_label_dictionary_for_eval, exclude_labels, create_file_logs, create_loss_file, epoch, use_tensorboard, tensorboard_log_dir, metrics_for_tensorboard, optimizer_state_dict, scheduler_state_dict, save_optimizer_state, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward_loss\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# forward pass to get scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# calculate loss given scores and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# make a zero-padded tensor for the whole sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/embeddings/base.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, data_points)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_everything_embedded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/embeddings/base.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mexpanded_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_to_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;31m# move embeddings from context back to original sentence (if using context)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/embeddings/base.py\u001b[0m in \u001b[0;36m_add_embeddings_to_sentences\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgradient_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;31m# make the tuple a tensor; makes working with it easier.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m         )\n\u001b[1;32m   1018\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 15.90 GiB total capacity; 14.87 GiB already allocated; 33.75 MiB free; 14.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# Initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# Start training\n",
        "trainer.train('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHhtWpYeaa2q"
      },
      "source": [
        "## Teste 2.5 NER Flair Stacked Embeddings (Bert e Flair Embeddings) com Corpus Lener_br\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woNuyNwxaa2x"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN_qeQ_qaa2x"
      },
      "outputs": [],
      "source": [
        "## Importes\n",
        "## datasets\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import FlairEmbeddings, TransformerWordEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSlgwCNaaa2y"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUlOChN5aa2y",
        "outputId": "e9c122cc-7dc7-4932-8f90-5d62fdc5e3b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_s6MWRaaa2y",
        "outputId": "ab62603e-8cb4-442b-a474-30bb8da5c8a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-09 00:49:24,547 Reading data from /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br\n",
            "2022-07-09 00:49:24,549 Train: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/train.txt\n",
            "2022-07-09 00:49:24,551 Dev: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/dev.txt\n",
            "2022-07-09 00:49:24,553 Test: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/test.txt\n"
          ]
        }
      ],
      "source": [
        "## carregando um corpus e definindo as colunas\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Orig'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZtqDU7Waa2y",
        "outputId": "a5774f47-b7e4-47fc-9e8f-c20a148b2ef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-09 00:49:34,686 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7827it [00:00, 37228.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-09 00:49:34,907 Dictionary created for label 'ner' with 7 values: ORGANIZACAO (seen 2400 times), LEGISLACAO (seen 1920 times), PESSOA (seen 1525 times), TEMPO (seen 1334 times), JURISPRUDENCIA (seen 1104 times), LOCAL (seen 611 times)\n",
            "Dictionary with 7 tags: <unk>, ORGANIZACAO, LEGISLACAO, PESSOA, TEMPO, JURISPRUDENCIA, LOCAL\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBRuD12Caa2y"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "bRSqzI6Eaa2y",
        "outputId": "ac728733-20d4-4829-8140-0d81b6d37389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-09 00:49:40,018 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-forward.pt not found in cache, downloading to /tmp/tmpgc10qujd\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:05<00:00, 12821460.56B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-09 00:49:46,439 copying /tmp/tmpgc10qujd to cache at /root/.flair/embeddings/lm-pt-forward.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-09 00:49:46,537 removing temp file /tmp/tmpgc10qujd\n",
            "2022-07-09 00:50:02,487 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-backward.pt not found in cache, downloading to /tmp/tmpz2gfzlkv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:04<00:00, 14726595.23B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-09 00:50:07,940 copying /tmp/tmpz2gfzlkv to cache at /root/.flair/embeddings/lm-pt-backward.pt\n",
            "2022-07-09 00:50:08,032 removing temp file /tmp/tmpz2gfzlkv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae3d24f2f1314f63a22458f8fa51e2b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57b099f396ac484aa5a3bc217058c478",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8f7d29df6424444adca532c044de491",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b358f1e2d0ac4d6bafa9fefc67b611b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c67829d824d44a749ba6e20aa69455ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2602bf5f9bf42f5a629c38a46fb7ee8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# init Flair embeddings\n",
        "flair_embedding_forward = FlairEmbeddings('pt-forward')\n",
        "flair_embedding_backward = FlairEmbeddings('pt-backward')\n",
        "\n",
        "# init pt BERT\n",
        "bert_embedding = TransformerWordEmbeddings('neuralmind/bert-base-portuguese-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gve-C-ObKRJ"
      },
      "outputs": [],
      "source": [
        "## Empilhando os Embeddings\n",
        "from flair.embeddings import StackedEmbeddings\n",
        "\n",
        "# create a StackedEmbedding object that combines Bert and forward/backward flair embeddings\n",
        "embeddings = StackedEmbeddings([\n",
        "                                        bert_embedding,\n",
        "                                        flair_embedding_forward,\n",
        "                                        flair_embedding_backward,\n",
        "                                       ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tncSoOGCaa2y"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRXKA7Vcaa2y",
        "outputId": "df40947a-9576-453c-d992-295eabf0b879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-09 01:01:56,014 SequenceTagger predicts: Dictionary with 25 tags: O, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-LEGISLACAO, B-LEGISLACAO, E-LEGISLACAO, I-LEGISLACAO, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-TEMPO, B-TEMPO, E-TEMPO, I-TEMPO, S-JURISPRUDENCIA, B-JURISPRUDENCIA, E-JURISPRUDENCIA, I-JURISPRUDENCIA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "lihUsn6-aa2y",
        "outputId": "4d6380ac-7951-4cc1-bff8-7e332a332af5"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7244d67ffdb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m               \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m               max_epochs=50)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, learning_rate, mini_batch_size, eval_batch_size, mini_batch_chunk_size, max_epochs, train_with_dev, train_with_test, monitor_train, monitor_test, main_evaluation_metric, scheduler, anneal_factor, patience, min_learning_rate, initial_extra_patience, optimizer, cycle_momentum, warmup_fraction, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, anneal_with_prestarts, anneal_against_dev_loss, batch_growth_annealing, shuffle, param_selection_mode, write_weights, num_workers, sampler, use_amp, amp_opt_level, eval_on_train_fraction, eval_on_train_shuffle, save_model_each_k_epochs, tensorboard_comment, use_swa, use_final_model_for_eval, gold_label_dictionary_for_eval, exclude_labels, create_file_logs, create_loss_file, epoch, use_tensorboard, tensorboard_log_dir, metrics_for_tensorboard, optimizer_state_dict, scheduler_state_dict, save_optimizer_state, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'train_batch_size'"
          ]
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# Initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# Start training\n",
        "trainer.train('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSvIPgvRDpN8"
      },
      "source": [
        "## Teste 3.1 NER Flair Classic Word Embeddings com Corpus Lener_br + Multi_Wikiner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNL0hdTlDpN9"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0U74xB1DpN9"
      },
      "outputs": [],
      "source": [
        "## Importes\n",
        "## datasets\n",
        "from flair.data import MultiCorpus\n",
        "from flair.datasets import NER_MULTI_WIKINER\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import WordEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9ICFtkWDpN-"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kitJivQGDpN-",
        "outputId": "59972382-b06a-4bb6-de02-d4222248c99a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvQa6ySWDpN-",
        "outputId": "26e61804-15d2-4d00-d726-174fda5d68b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:26:35,607 Reading data from /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Alter\n",
            "2022-09-12 12:26:35,611 Train: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Alter/train.txt\n",
            "2022-09-12 12:26:35,613 Dev: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Alter/dev.txt\n",
            "2022-09-12 12:26:35,614 Test: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Alter/test.txt\n",
            "2022-09-12 12:26:46,708 https://raw.githubusercontent.com/dice-group/FOX/master/input/Wikiner/aij-wikiner-en-wp3.bz2 not found in cache, downloading to /tmp/tmpf76r2_5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6208404/6208404 [00:00<00:00, 29644193.33B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:26:47,019 copying /tmp/tmpf76r2_5s to cache at /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.bz2\n",
            "2022-09-12 12:26:47,030 removing temp file /tmp/tmpf76r2_5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:26:50,750 Read data for language en\n",
            "2022-09-12 12:26:50,752 Reading data from /root/.flair/datasets/ner_multi_wikiner/en\n",
            "2022-09-12 12:26:50,753 Train: /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.train\n",
            "2022-09-12 12:26:50,754 Dev: None\n",
            "2022-09-12 12:26:50,756 Test: None\n",
            "MultiCorpus: 122971 train + 13970 dev + 15604 test sentences\n",
            " - ColumnCorpus Corpus: 7827 train + 1176 dev + 1389 test sentences - /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Alter\n",
            " - NER_MULTI_WIKINER MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en - wikiner\n"
          ]
        }
      ],
      "source": [
        "## carregando um corpus e definindo as colunas\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Alter'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "le_corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')\n",
        "\n",
        "wiki_corpus = NER_MULTI_WIKINER()\n",
        "\n",
        "# make a multi corpus consisting of three UDs\n",
        "corpus = MultiCorpus([le_corpus, wiki_corpus])\n",
        "\n",
        "print(corpus)\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB8M8fU8DpN-",
        "outputId": "5ce57dd8-de56-472b-bbf2-bf9f16a41141"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:26:53,579 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "122971it [01:00, 2030.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:27:54,190 Dictionary created for label 'ner' with 8 values: PER (seen 79427 times), LOC (seen 70202 times), MISC (seen 59349 times), ORG (seen 42691 times), LEGISLACAO (seen 1920 times), TEMPO (seen 1334 times), JURISPRUDENCIA (seen 1104 times)\n",
            "Dictionary with 8 tags: <unk>, PER, LOC, MISC, ORG, LEGISLACAO, TEMPO, JURISPRUDENCIA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ulqqiJHDpN-"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PMI7a4tDpN-",
        "outputId": "23e43475-98b5-4902-fa9b-a27257e70d51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:27:55,341 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmp7w9el43j\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 710528528/710528528 [01:07<00:00, 10587549.70B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:29:03,313 copying /tmp/tmp7w9el43j to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M.vectors.npy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:29:05,242 removing temp file /tmp/tmp7w9el43j\n",
            "2022-09-12 12:29:06,693 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmppbtk3g4c\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23541010/23541010 [00:03<00:00, 6230016.36B/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:29:11,339 copying /tmp/tmppbtk3g4c to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M\n",
            "2022-09-12 12:29:11,369 removing temp file /tmp/tmppbtk3g4c\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Embeddings\n",
        "# Initialize embedding\n",
        "embeddings = WordEmbeddings('pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EegwNYeDpN-"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2fP1BWyDpN-",
        "outputId": "8ef2abef-8c54-4899-ba78-43b83d083443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:29:14,449 SequenceTagger predicts: Dictionary with 29 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, S-LEGISLACAO, B-LEGISLACAO, E-LEGISLACAO, I-LEGISLACAO, S-TEMPO, B-TEMPO, E-TEMPO, I-TEMPO, S-JURISPRUDENCIA, B-JURISPRUDENCIA, E-JURISPRUDENCIA, I-JURISPRUDENCIA\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdziZM51DpN-",
        "outputId": "05f0c2ae-18b5-4383-e0f7-4cccb7d1864d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:29:23,745 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 12:29:23,747 Model: \"SequenceTagger(\n",
            "  (embeddings): WordEmbeddings(\n",
            "    'pt'\n",
            "    (embedding): Embedding(592108, 300)\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=300, out_features=300, bias=True)\n",
            "  (rnn): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=31, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-09-12 12:29:23,749 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 12:29:23,751 Corpus: \"MultiCorpus: 122971 train + 13970 dev + 15604 test sentences\n",
            " - ColumnCorpus Corpus: 7827 train + 1176 dev + 1389 test sentences - /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Alter\n",
            " - NER_MULTI_WIKINER MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en - wikiner\"\n",
            "2022-09-12 12:29:23,753 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 12:29:23,755 Parameters:\n",
            "2022-09-12 12:29:23,756  - learning_rate: \"0.100000\"\n",
            "2022-09-12 12:29:23,761  - mini_batch_size: \"32\"\n",
            "2022-09-12 12:29:23,762  - patience: \"3\"\n",
            "2022-09-12 12:29:23,763  - anneal_factor: \"0.5\"\n",
            "2022-09-12 12:29:23,768  - max_epochs: \"100\"\n",
            "2022-09-12 12:29:23,771  - shuffle: \"True\"\n",
            "2022-09-12 12:29:23,773  - train_with_dev: \"False\"\n",
            "2022-09-12 12:29:23,774  - batch_growth_annealing: \"False\"\n",
            "2022-09-12 12:29:23,778 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 12:29:23,780 Model training base path: \"resources/taggers/sota-ner-flair\"\n",
            "2022-09-12 12:29:23,781 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 12:29:23,783 Device: cuda:0\n",
            "2022-09-12 12:29:23,786 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 12:29:23,787 Embeddings storage mode: cpu\n",
            "2022-09-12 12:29:23,791 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 12:30:14,310 epoch 1 - iter 384/3843 - loss 0.49332804 - samples/sec: 264.28 - lr: 0.100000\n",
            "2022-09-12 12:30:54,804 epoch 1 - iter 768/3843 - loss 0.39752277 - samples/sec: 444.53 - lr: 0.100000\n",
            "2022-09-12 12:31:34,926 epoch 1 - iter 1152/3843 - loss 0.35164624 - samples/sec: 435.39 - lr: 0.100000\n",
            "2022-09-12 12:32:15,835 epoch 1 - iter 1536/3843 - loss 0.32146206 - samples/sec: 427.20 - lr: 0.100000\n",
            "2022-09-12 12:32:58,399 epoch 1 - iter 1920/3843 - loss 0.29810843 - samples/sec: 391.33 - lr: 0.100000\n",
            "2022-09-12 12:33:39,106 epoch 1 - iter 2304/3843 - loss 0.28290038 - samples/sec: 432.42 - lr: 0.100000\n",
            "2022-09-12 12:34:20,848 epoch 1 - iter 2688/3843 - loss 0.27158637 - samples/sec: 437.04 - lr: 0.100000\n",
            "2022-09-12 12:35:01,966 epoch 1 - iter 3072/3843 - loss 0.26041516 - samples/sec: 427.93 - lr: 0.100000\n",
            "2022-09-12 12:35:43,314 epoch 1 - iter 3456/3843 - loss 0.25198396 - samples/sec: 426.36 - lr: 0.100000\n",
            "2022-09-12 12:36:24,748 epoch 1 - iter 3840/3843 - loss 0.24489688 - samples/sec: 442.87 - lr: 0.100000\n",
            "2022-09-12 12:36:24,984 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 12:36:24,985 EPOCH 1 done: loss 0.2448 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:13<00:00,  5.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:37:38,970 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:37:39,255 DEV : loss 0.23824256658554077 - f1-score (micro avg)  0.5975\n",
            "2022-09-12 12:37:50,861 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 12:37:50,863 saving best model\n",
            "2022-09-12 12:37:54,088 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 12:38:38,556 epoch 2 - iter 384/3843 - loss 0.19419264 - samples/sec: 380.30 - lr: 0.100000\n",
            "2022-09-12 12:39:23,239 epoch 2 - iter 768/3843 - loss 0.19016661 - samples/sec: 373.85 - lr: 0.100000\n",
            "2022-09-12 12:40:09,715 epoch 2 - iter 1152/3843 - loss 0.18746823 - samples/sec: 330.17 - lr: 0.100000\n",
            "2022-09-12 12:40:52,585 epoch 2 - iter 1536/3843 - loss 0.18445965 - samples/sec: 381.17 - lr: 0.100000\n",
            "2022-09-12 12:41:38,237 epoch 2 - iter 1920/3843 - loss 0.18248113 - samples/sec: 382.66 - lr: 0.100000\n",
            "2022-09-12 12:42:23,367 epoch 2 - iter 2304/3843 - loss 0.18043281 - samples/sec: 358.01 - lr: 0.100000\n",
            "2022-09-12 12:43:08,859 epoch 2 - iter 2688/3843 - loss 0.17879753 - samples/sec: 386.27 - lr: 0.100000\n",
            "2022-09-12 12:43:54,023 epoch 2 - iter 3072/3843 - loss 0.17741722 - samples/sec: 357.84 - lr: 0.100000\n",
            "2022-09-12 12:44:37,271 epoch 2 - iter 3456/3843 - loss 0.17628293 - samples/sec: 396.97 - lr: 0.100000\n",
            "2022-09-12 12:45:22,596 epoch 2 - iter 3840/3843 - loss 0.17520403 - samples/sec: 357.40 - lr: 0.100000\n",
            "2022-09-12 12:45:22,888 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 12:45:22,890 EPOCH 2 done: loss 0.1752 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:46:37,443 Evaluating as a multi-label problem: False\n",
            "2022-09-12 12:46:37,714 DEV : loss 0.12456756085157394 - f1-score (micro avg)  0.6813\n",
            "2022-09-12 12:46:49,647 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 12:46:49,649 saving best model\n",
            "2022-09-12 12:46:52,754 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 12:47:38,721 epoch 3 - iter 384/3843 - loss 0.15990526 - samples/sec: 353.25 - lr: 0.100000\n",
            "2022-09-12 12:48:22,038 epoch 3 - iter 768/3843 - loss 0.15963045 - samples/sec: 363.62 - lr: 0.100000\n",
            "2022-09-12 12:49:07,021 epoch 3 - iter 1152/3843 - loss 0.15907115 - samples/sec: 378.32 - lr: 0.100000\n",
            "2022-09-12 12:49:52,470 epoch 3 - iter 1536/3843 - loss 0.15868743 - samples/sec: 389.64 - lr: 0.100000\n",
            "2022-09-12 12:50:36,808 epoch 3 - iter 1920/3843 - loss 0.15821162 - samples/sec: 368.25 - lr: 0.100000\n",
            "2022-09-12 12:51:21,543 epoch 3 - iter 2304/3843 - loss 0.15822603 - samples/sec: 400.02 - lr: 0.100000\n",
            "2022-09-12 12:52:04,354 epoch 3 - iter 2688/3843 - loss 0.15834151 - samples/sec: 386.94 - lr: 0.100000\n",
            "2022-09-12 12:52:51,540 epoch 3 - iter 3072/3843 - loss 0.15744939 - samples/sec: 354.53 - lr: 0.100000\n",
            "2022-09-12 12:53:35,641 epoch 3 - iter 3456/3843 - loss 0.15698823 - samples/sec: 389.66 - lr: 0.100000\n",
            "2022-09-12 12:54:21,446 epoch 3 - iter 3840/3843 - loss 0.15637284 - samples/sec: 339.39 - lr: 0.100000\n",
            "2022-09-12 12:54:21,723 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 12:54:21,725 EPOCH 3 done: loss 0.1564 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 12:55:37,859 Evaluating as a multi-label problem: False\n",
            "2022-09-12 12:55:38,137 DEV : loss 0.11420633643865585 - f1-score (micro avg)  0.7062\n",
            "2022-09-12 12:55:48,598 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 12:55:48,601 saving best model\n",
            "2022-09-12 12:55:51,781 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 12:56:37,356 epoch 4 - iter 384/3843 - loss 0.15045837 - samples/sec: 354.49 - lr: 0.100000\n",
            "2022-09-12 12:57:21,856 epoch 4 - iter 768/3843 - loss 0.15049078 - samples/sec: 385.21 - lr: 0.100000\n",
            "2022-09-12 12:58:06,915 epoch 4 - iter 1152/3843 - loss 0.14969021 - samples/sec: 378.38 - lr: 0.100000\n",
            "2022-09-12 12:58:52,174 epoch 4 - iter 1536/3843 - loss 0.14979118 - samples/sec: 344.62 - lr: 0.100000\n",
            "2022-09-12 12:59:36,573 epoch 4 - iter 1920/3843 - loss 0.14890443 - samples/sec: 385.98 - lr: 0.100000\n",
            "2022-09-12 13:00:21,483 epoch 4 - iter 2304/3843 - loss 0.14872227 - samples/sec: 381.96 - lr: 0.100000\n",
            "2022-09-12 13:01:06,468 epoch 4 - iter 2688/3843 - loss 0.14851111 - samples/sec: 379.29 - lr: 0.100000\n",
            "2022-09-12 13:01:49,555 epoch 4 - iter 3072/3843 - loss 0.14826020 - samples/sec: 367.20 - lr: 0.100000\n",
            "2022-09-12 13:02:35,147 epoch 4 - iter 3456/3843 - loss 0.14819254 - samples/sec: 357.33 - lr: 0.100000\n",
            "2022-09-12 13:03:19,435 epoch 4 - iter 3840/3843 - loss 0.14819205 - samples/sec: 388.61 - lr: 0.100000\n",
            "2022-09-12 13:03:19,694 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:03:19,696 EPOCH 4 done: loss 0.1482 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 13:04:34,392 Evaluating as a multi-label problem: False\n",
            "2022-09-12 13:04:34,649 DEV : loss 0.11365457624197006 - f1-score (micro avg)  0.7135\n",
            "2022-09-12 13:04:46,738 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 13:04:46,742 saving best model\n",
            "2022-09-12 13:04:49,787 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:05:34,614 epoch 5 - iter 384/3843 - loss 0.14420492 - samples/sec: 349.51 - lr: 0.100000\n",
            "2022-09-12 13:06:21,124 epoch 5 - iter 768/3843 - loss 0.14366103 - samples/sec: 379.27 - lr: 0.100000\n",
            "2022-09-12 13:07:05,752 epoch 5 - iter 1152/3843 - loss 0.14359733 - samples/sec: 366.16 - lr: 0.100000\n",
            "2022-09-12 13:07:52,013 epoch 5 - iter 1536/3843 - loss 0.14368566 - samples/sec: 365.74 - lr: 0.100000\n",
            "2022-09-12 13:08:39,650 epoch 5 - iter 1920/3843 - loss 0.14362921 - samples/sec: 351.86 - lr: 0.100000\n",
            "2022-09-12 13:09:23,605 epoch 5 - iter 2304/3843 - loss 0.14361823 - samples/sec: 358.08 - lr: 0.100000\n",
            "2022-09-12 13:10:09,530 epoch 5 - iter 2688/3843 - loss 0.14335331 - samples/sec: 353.87 - lr: 0.100000\n",
            "2022-09-12 13:10:53,910 epoch 5 - iter 3072/3843 - loss 0.14313580 - samples/sec: 387.60 - lr: 0.100000\n",
            "2022-09-12 13:11:40,740 epoch 5 - iter 3456/3843 - loss 0.14306114 - samples/sec: 345.12 - lr: 0.100000\n",
            "2022-09-12 13:12:25,972 epoch 5 - iter 3840/3843 - loss 0.14297648 - samples/sec: 361.01 - lr: 0.100000\n",
            "2022-09-12 13:12:26,210 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:12:26,211 EPOCH 5 done: loss 0.1430 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 13:13:42,690 Evaluating as a multi-label problem: False\n",
            "2022-09-12 13:13:42,963 DEV : loss 0.10525735467672348 - f1-score (micro avg)  0.727\n",
            "2022-09-12 13:13:53,352 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 13:13:53,355 saving best model\n",
            "2022-09-12 13:13:56,543 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:14:42,895 epoch 6 - iter 384/3843 - loss 0.13934774 - samples/sec: 378.54 - lr: 0.100000\n",
            "2022-09-12 13:15:27,857 epoch 6 - iter 768/3843 - loss 0.14026609 - samples/sec: 398.95 - lr: 0.100000\n",
            "2022-09-12 13:16:10,854 epoch 6 - iter 1152/3843 - loss 0.13990406 - samples/sec: 405.30 - lr: 0.100000\n",
            "2022-09-12 13:16:55,943 epoch 6 - iter 1536/3843 - loss 0.13948541 - samples/sec: 378.90 - lr: 0.100000\n",
            "2022-09-12 13:17:40,001 epoch 6 - iter 1920/3843 - loss 0.13973439 - samples/sec: 374.99 - lr: 0.100000\n",
            "2022-09-12 13:18:26,363 epoch 6 - iter 2304/3843 - loss 0.13977179 - samples/sec: 365.26 - lr: 0.100000\n",
            "2022-09-12 13:19:12,800 epoch 6 - iter 2688/3843 - loss 0.13970997 - samples/sec: 382.60 - lr: 0.100000\n",
            "2022-09-12 13:19:56,210 epoch 6 - iter 3072/3843 - loss 0.13957313 - samples/sec: 381.20 - lr: 0.100000\n",
            "2022-09-12 13:20:41,556 epoch 6 - iter 3456/3843 - loss 0.13960192 - samples/sec: 376.96 - lr: 0.100000\n",
            "2022-09-12 13:21:25,691 epoch 6 - iter 3840/3843 - loss 0.13931589 - samples/sec: 356.83 - lr: 0.100000\n",
            "2022-09-12 13:21:26,090 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:21:26,091 EPOCH 6 done: loss 0.1393 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 13:22:42,526 Evaluating as a multi-label problem: False\n",
            "2022-09-12 13:22:42,789 DEV : loss 0.09947327524423599 - f1-score (micro avg)  0.7366\n",
            "2022-09-12 13:22:53,231 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 13:22:53,234 saving best model\n",
            "2022-09-12 13:22:56,349 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:23:42,363 epoch 7 - iter 384/3843 - loss 0.13691647 - samples/sec: 403.26 - lr: 0.100000\n",
            "2022-09-12 13:24:25,732 epoch 7 - iter 768/3843 - loss 0.13603408 - samples/sec: 364.65 - lr: 0.100000\n",
            "2022-09-12 13:25:12,099 epoch 7 - iter 1152/3843 - loss 0.13657139 - samples/sec: 382.50 - lr: 0.100000\n",
            "2022-09-12 13:25:55,834 epoch 7 - iter 1536/3843 - loss 0.13668222 - samples/sec: 360.86 - lr: 0.100000\n",
            "2022-09-12 13:26:41,033 epoch 7 - iter 1920/3843 - loss 0.13657572 - samples/sec: 346.07 - lr: 0.100000\n",
            "2022-09-12 13:27:26,147 epoch 7 - iter 2304/3843 - loss 0.13631414 - samples/sec: 379.66 - lr: 0.100000\n",
            "2022-09-12 13:28:09,644 epoch 7 - iter 2688/3843 - loss 0.13633413 - samples/sec: 399.22 - lr: 0.100000\n",
            "2022-09-12 13:28:56,323 epoch 7 - iter 3072/3843 - loss 0.13660670 - samples/sec: 332.51 - lr: 0.100000\n",
            "2022-09-12 13:29:40,600 epoch 7 - iter 3456/3843 - loss 0.13651470 - samples/sec: 390.15 - lr: 0.100000\n",
            "2022-09-12 13:30:27,505 epoch 7 - iter 3840/3843 - loss 0.13641648 - samples/sec: 376.41 - lr: 0.100000\n",
            "2022-09-12 13:30:27,767 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:30:27,768 EPOCH 7 done: loss 0.1364 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 13:31:42,561 Evaluating as a multi-label problem: False\n",
            "2022-09-12 13:31:42,828 DEV : loss 0.09771141409873962 - f1-score (micro avg)  0.7463\n",
            "2022-09-12 13:31:54,886 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 13:31:54,889 saving best model\n",
            "2022-09-12 13:31:58,086 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:32:44,232 epoch 8 - iter 384/3843 - loss 0.13635905 - samples/sec: 387.04 - lr: 0.100000\n",
            "2022-09-12 13:33:28,046 epoch 8 - iter 768/3843 - loss 0.13509414 - samples/sec: 376.19 - lr: 0.100000\n",
            "2022-09-12 13:34:13,187 epoch 8 - iter 1152/3843 - loss 0.13462502 - samples/sec: 362.29 - lr: 0.100000\n",
            "2022-09-12 13:34:57,012 epoch 8 - iter 1536/3843 - loss 0.13421888 - samples/sec: 377.57 - lr: 0.100000\n",
            "2022-09-12 13:35:42,740 epoch 8 - iter 1920/3843 - loss 0.13423948 - samples/sec: 356.44 - lr: 0.100000\n",
            "2022-09-12 13:36:26,239 epoch 8 - iter 2304/3843 - loss 0.13428845 - samples/sec: 363.09 - lr: 0.100000\n",
            "2022-09-12 13:37:11,485 epoch 8 - iter 2688/3843 - loss 0.13417595 - samples/sec: 360.98 - lr: 0.100000\n",
            "2022-09-12 13:37:57,358 epoch 8 - iter 3072/3843 - loss 0.13436517 - samples/sec: 354.64 - lr: 0.100000\n",
            "2022-09-12 13:38:40,510 epoch 8 - iter 3456/3843 - loss 0.13450378 - samples/sec: 367.30 - lr: 0.100000\n",
            "2022-09-12 13:39:26,819 epoch 8 - iter 3840/3843 - loss 0.13462855 - samples/sec: 350.51 - lr: 0.100000\n",
            "2022-09-12 13:39:27,069 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:39:27,071 EPOCH 8 done: loss 0.1346 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 13:40:41,665 Evaluating as a multi-label problem: False\n",
            "2022-09-12 13:40:41,935 DEV : loss 0.0960039347410202 - f1-score (micro avg)  0.7469\n",
            "2022-09-12 13:40:53,897 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 13:40:53,899 saving best model\n",
            "2022-09-12 13:40:57,004 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:41:42,200 epoch 9 - iter 384/3843 - loss 0.13146401 - samples/sec: 361.83 - lr: 0.100000\n",
            "2022-09-12 13:42:27,458 epoch 9 - iter 768/3843 - loss 0.13286799 - samples/sec: 376.89 - lr: 0.100000\n",
            "2022-09-12 13:43:10,163 epoch 9 - iter 1152/3843 - loss 0.13322813 - samples/sec: 389.41 - lr: 0.100000\n",
            "2022-09-12 13:43:55,911 epoch 9 - iter 1536/3843 - loss 0.13333221 - samples/sec: 326.86 - lr: 0.100000\n",
            "2022-09-12 13:44:40,823 epoch 9 - iter 1920/3843 - loss 0.13313602 - samples/sec: 381.98 - lr: 0.100000\n",
            "2022-09-12 13:45:25,904 epoch 9 - iter 2304/3843 - loss 0.13316493 - samples/sec: 379.76 - lr: 0.100000\n",
            "2022-09-12 13:46:09,308 epoch 9 - iter 2688/3843 - loss 0.13313208 - samples/sec: 400.31 - lr: 0.100000\n",
            "2022-09-12 13:46:55,504 epoch 9 - iter 3072/3843 - loss 0.13287930 - samples/sec: 351.27 - lr: 0.100000\n",
            "2022-09-12 13:47:40,825 epoch 9 - iter 3456/3843 - loss 0.13281168 - samples/sec: 395.57 - lr: 0.100000\n",
            "2022-09-12 13:48:24,678 epoch 9 - iter 3840/3843 - loss 0.13292842 - samples/sec: 375.83 - lr: 0.100000\n",
            "2022-09-12 13:48:24,941 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:48:24,943 EPOCH 9 done: loss 0.1329 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 13:49:41,438 Evaluating as a multi-label problem: False\n",
            "2022-09-12 13:49:41,710 DEV : loss 0.09306784719228745 - f1-score (micro avg)  0.7558\n",
            "2022-09-12 13:49:52,166 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 13:49:52,170 saving best model\n",
            "2022-09-12 13:49:55,376 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:50:41,884 epoch 10 - iter 384/3843 - loss 0.13047355 - samples/sec: 378.48 - lr: 0.100000\n",
            "2022-09-12 13:51:25,479 epoch 10 - iter 768/3843 - loss 0.13141452 - samples/sec: 379.31 - lr: 0.100000\n",
            "2022-09-12 13:52:10,226 epoch 10 - iter 1152/3843 - loss 0.13085199 - samples/sec: 365.45 - lr: 0.100000\n",
            "2022-09-12 13:52:53,619 epoch 10 - iter 1536/3843 - loss 0.13137237 - samples/sec: 401.03 - lr: 0.100000\n",
            "2022-09-12 13:53:38,850 epoch 10 - iter 1920/3843 - loss 0.13145027 - samples/sec: 378.01 - lr: 0.100000\n",
            "2022-09-12 13:54:23,843 epoch 10 - iter 2304/3843 - loss 0.13145464 - samples/sec: 348.06 - lr: 0.100000\n",
            "2022-09-12 13:55:08,036 epoch 10 - iter 2688/3843 - loss 0.13135004 - samples/sec: 390.75 - lr: 0.100000\n",
            "2022-09-12 13:55:54,310 epoch 10 - iter 3072/3843 - loss 0.13146189 - samples/sec: 335.56 - lr: 0.100000\n",
            "2022-09-12 13:56:38,032 epoch 10 - iter 3456/3843 - loss 0.13133802 - samples/sec: 398.09 - lr: 0.100000\n",
            "2022-09-12 13:57:23,512 epoch 10 - iter 3840/3843 - loss 0.13124275 - samples/sec: 394.22 - lr: 0.100000\n",
            "2022-09-12 13:57:23,786 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:57:23,787 EPOCH 10 done: loss 0.1312 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 13:58:38,663 Evaluating as a multi-label problem: False\n",
            "2022-09-12 13:58:38,948 DEV : loss 0.09258154779672623 - f1-score (micro avg)  0.7575\n",
            "2022-09-12 13:58:50,992 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 13:58:50,994 saving best model\n",
            "2022-09-12 13:58:54,147 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 13:59:39,788 epoch 11 - iter 384/3843 - loss 0.13040048 - samples/sec: 393.37 - lr: 0.100000\n",
            "2022-09-12 14:00:22,610 epoch 11 - iter 768/3843 - loss 0.13080014 - samples/sec: 388.25 - lr: 0.100000\n",
            "2022-09-12 14:01:07,474 epoch 11 - iter 1152/3843 - loss 0.13103499 - samples/sec: 382.51 - lr: 0.100000\n",
            "2022-09-12 14:01:50,733 epoch 11 - iter 1536/3843 - loss 0.13097018 - samples/sec: 349.31 - lr: 0.100000\n",
            "2022-09-12 14:02:37,256 epoch 11 - iter 1920/3843 - loss 0.13065024 - samples/sec: 380.62 - lr: 0.100000\n",
            "2022-09-12 14:03:23,944 epoch 11 - iter 2304/3843 - loss 0.13035823 - samples/sec: 379.77 - lr: 0.100000\n",
            "2022-09-12 14:04:08,071 epoch 11 - iter 2688/3843 - loss 0.13020226 - samples/sec: 356.96 - lr: 0.100000\n",
            "2022-09-12 14:04:54,068 epoch 11 - iter 3072/3843 - loss 0.13039496 - samples/sec: 370.52 - lr: 0.100000\n",
            "2022-09-12 14:05:37,709 epoch 11 - iter 3456/3843 - loss 0.13045105 - samples/sec: 332.00 - lr: 0.100000\n",
            "2022-09-12 14:06:22,589 epoch 11 - iter 3840/3843 - loss 0.13042119 - samples/sec: 365.35 - lr: 0.100000\n",
            "2022-09-12 14:06:22,842 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 14:06:22,843 EPOCH 11 done: loss 0.1305 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 14:07:37,667 Evaluating as a multi-label problem: False\n",
            "2022-09-12 14:07:37,933 DEV : loss 0.09122157096862793 - f1-score (micro avg)  0.7572\n",
            "2022-09-12 14:07:49,838 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 14:07:49,840 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 14:08:34,730 epoch 12 - iter 384/3843 - loss 0.12929755 - samples/sec: 381.69 - lr: 0.100000\n",
            "2022-09-12 14:09:19,086 epoch 12 - iter 768/3843 - loss 0.12864941 - samples/sec: 387.62 - lr: 0.100000\n",
            "2022-09-12 14:10:03,983 epoch 12 - iter 1152/3843 - loss 0.12982715 - samples/sec: 349.04 - lr: 0.100000\n",
            "2022-09-12 14:10:50,852 epoch 12 - iter 1536/3843 - loss 0.12924404 - samples/sec: 360.11 - lr: 0.100000\n",
            "2022-09-12 14:11:36,402 epoch 12 - iter 1920/3843 - loss 0.12893036 - samples/sec: 343.03 - lr: 0.100000\n",
            "2022-09-12 14:12:20,809 epoch 12 - iter 2304/3843 - loss 0.12924232 - samples/sec: 388.40 - lr: 0.100000\n",
            "2022-09-12 14:13:04,999 epoch 12 - iter 2688/3843 - loss 0.12940640 - samples/sec: 373.05 - lr: 0.100000\n",
            "2022-09-12 14:13:50,568 epoch 12 - iter 3072/3843 - loss 0.12924088 - samples/sec: 392.64 - lr: 0.100000\n",
            "2022-09-12 14:14:35,151 epoch 12 - iter 3456/3843 - loss 0.12905261 - samples/sec: 386.19 - lr: 0.100000\n",
            "2022-09-12 14:15:18,143 epoch 12 - iter 3840/3843 - loss 0.12893282 - samples/sec: 369.44 - lr: 0.100000\n",
            "2022-09-12 14:15:18,450 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 14:15:18,452 EPOCH 12 done: loss 0.1289 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 14:16:34,823 Evaluating as a multi-label problem: False\n",
            "2022-09-12 14:16:35,091 DEV : loss 0.08981698006391525 - f1-score (micro avg)  0.7594\n",
            "2022-09-12 14:16:45,569 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 14:16:45,571 saving best model\n",
            "2022-09-12 14:16:48,695 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 14:17:35,303 epoch 13 - iter 384/3843 - loss 0.12801917 - samples/sec: 347.51 - lr: 0.100000\n",
            "2022-09-12 14:18:20,275 epoch 13 - iter 768/3843 - loss 0.12850060 - samples/sec: 363.74 - lr: 0.100000\n",
            "2022-09-12 14:19:05,335 epoch 13 - iter 1152/3843 - loss 0.12872461 - samples/sec: 380.06 - lr: 0.100000\n",
            "2022-09-12 14:19:51,504 epoch 13 - iter 1536/3843 - loss 0.12845362 - samples/sec: 351.92 - lr: 0.100000\n",
            "2022-09-12 14:20:34,960 epoch 13 - iter 1920/3843 - loss 0.12842498 - samples/sec: 381.21 - lr: 0.100000\n",
            "2022-09-12 14:21:19,662 epoch 13 - iter 2304/3843 - loss 0.12864815 - samples/sec: 385.08 - lr: 0.100000\n",
            "2022-09-12 14:22:03,101 epoch 13 - iter 2688/3843 - loss 0.12879073 - samples/sec: 400.60 - lr: 0.100000\n",
            "2022-09-12 14:22:48,801 epoch 13 - iter 3072/3843 - loss 0.12880930 - samples/sec: 391.94 - lr: 0.100000\n",
            "2022-09-12 14:23:32,086 epoch 13 - iter 3456/3843 - loss 0.12858495 - samples/sec: 382.99 - lr: 0.100000\n",
            "2022-09-12 14:24:16,932 epoch 13 - iter 3840/3843 - loss 0.12856458 - samples/sec: 383.12 - lr: 0.100000\n",
            "2022-09-12 14:24:17,245 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 14:24:17,247 EPOCH 13 done: loss 0.1286 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 14:25:33,664 Evaluating as a multi-label problem: False\n",
            "2022-09-12 14:25:33,923 DEV : loss 0.09164556115865707 - f1-score (micro avg)  0.7579\n",
            "2022-09-12 14:25:44,309 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 14:25:44,312 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 14:26:29,600 epoch 14 - iter 384/3843 - loss 0.12835649 - samples/sec: 377.07 - lr: 0.100000\n",
            "2022-09-12 14:27:14,598 epoch 14 - iter 768/3843 - loss 0.12849200 - samples/sec: 363.46 - lr: 0.100000\n",
            "2022-09-12 14:27:59,148 epoch 14 - iter 1152/3843 - loss 0.12791160 - samples/sec: 368.91 - lr: 0.100000\n",
            "2022-09-12 14:28:45,270 epoch 14 - iter 1536/3843 - loss 0.12769314 - samples/sec: 352.73 - lr: 0.100000\n",
            "2022-09-12 14:29:28,797 epoch 14 - iter 1920/3843 - loss 0.12757608 - samples/sec: 346.78 - lr: 0.100000\n",
            "2022-09-12 14:30:13,849 epoch 14 - iter 2304/3843 - loss 0.12728227 - samples/sec: 347.12 - lr: 0.100000\n",
            "2022-09-12 14:30:59,673 epoch 14 - iter 2688/3843 - loss 0.12727616 - samples/sec: 355.95 - lr: 0.100000\n",
            "2022-09-12 14:31:43,385 epoch 14 - iter 3072/3843 - loss 0.12736939 - samples/sec: 378.53 - lr: 0.100000\n",
            "2022-09-12 14:32:28,717 epoch 14 - iter 3456/3843 - loss 0.12747284 - samples/sec: 360.38 - lr: 0.100000\n",
            "2022-09-12 14:33:12,250 epoch 14 - iter 3840/3843 - loss 0.12745658 - samples/sec: 400.67 - lr: 0.100000\n",
            "2022-09-12 14:33:12,553 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 14:33:12,555 EPOCH 14 done: loss 0.1275 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 14:34:28,983 Evaluating as a multi-label problem: False\n",
            "2022-09-12 14:34:29,261 DEV : loss 0.09336325526237488 - f1-score (micro avg)  0.7587\n",
            "2022-09-12 14:34:39,668 BAD EPOCHS (no improvement): 2\n",
            "2022-09-12 14:34:39,671 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 14:35:25,352 epoch 15 - iter 384/3843 - loss 0.12680828 - samples/sec: 386.44 - lr: 0.100000\n",
            "2022-09-12 14:36:10,703 epoch 15 - iter 768/3843 - loss 0.12585607 - samples/sec: 377.38 - lr: 0.100000\n",
            "2022-09-12 14:36:54,418 epoch 15 - iter 1152/3843 - loss 0.12546644 - samples/sec: 378.68 - lr: 0.100000\n",
            "2022-09-12 14:37:38,713 epoch 15 - iter 1536/3843 - loss 0.12559947 - samples/sec: 372.04 - lr: 0.100000\n",
            "2022-09-12 14:38:22,542 epoch 15 - iter 1920/3843 - loss 0.12599829 - samples/sec: 377.36 - lr: 0.100000\n",
            "2022-09-12 14:39:08,741 epoch 15 - iter 2304/3843 - loss 0.12586708 - samples/sec: 385.56 - lr: 0.100000\n",
            "2022-09-12 14:39:53,828 epoch 15 - iter 2688/3843 - loss 0.12613074 - samples/sec: 400.69 - lr: 0.100000\n",
            "2022-09-12 14:40:38,298 epoch 15 - iter 3072/3843 - loss 0.12621383 - samples/sec: 353.29 - lr: 0.100000\n",
            "2022-09-12 14:41:23,191 epoch 15 - iter 3456/3843 - loss 0.12669221 - samples/sec: 383.16 - lr: 0.100000\n",
            "2022-09-12 14:42:08,590 epoch 15 - iter 3840/3843 - loss 0.12683131 - samples/sec: 377.13 - lr: 0.100000\n",
            "2022-09-12 14:42:08,845 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 14:42:08,847 EPOCH 15 done: loss 0.1268 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 14:43:25,222 Evaluating as a multi-label problem: False\n",
            "2022-09-12 14:43:25,479 DEV : loss 0.08979874104261398 - f1-score (micro avg)  0.764\n",
            "2022-09-12 14:43:36,001 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 14:43:36,004 saving best model\n",
            "2022-09-12 14:43:39,098 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 14:44:24,978 epoch 16 - iter 384/3843 - loss 0.12447805 - samples/sec: 386.17 - lr: 0.100000\n",
            "2022-09-12 14:45:08,262 epoch 16 - iter 768/3843 - loss 0.12457879 - samples/sec: 366.23 - lr: 0.100000\n",
            "2022-09-12 14:45:53,522 epoch 16 - iter 1152/3843 - loss 0.12546470 - samples/sec: 397.20 - lr: 0.100000\n",
            "2022-09-12 14:46:38,545 epoch 16 - iter 1536/3843 - loss 0.12555707 - samples/sec: 364.61 - lr: 0.100000\n",
            "2022-09-12 14:47:23,548 epoch 16 - iter 1920/3843 - loss 0.12571445 - samples/sec: 400.11 - lr: 0.100000\n",
            "2022-09-12 14:48:10,023 epoch 16 - iter 2304/3843 - loss 0.12592284 - samples/sec: 365.35 - lr: 0.100000\n",
            "2022-09-12 14:48:53,141 epoch 16 - iter 2688/3843 - loss 0.12593061 - samples/sec: 385.66 - lr: 0.100000\n",
            "2022-09-12 14:49:37,549 epoch 16 - iter 3072/3843 - loss 0.12605665 - samples/sec: 388.60 - lr: 0.100000\n",
            "2022-09-12 14:50:22,073 epoch 16 - iter 3456/3843 - loss 0.12583007 - samples/sec: 370.01 - lr: 0.100000\n",
            "2022-09-12 14:51:08,562 epoch 16 - iter 3840/3843 - loss 0.12583856 - samples/sec: 365.52 - lr: 0.100000\n",
            "2022-09-12 14:51:08,827 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 14:51:08,828 EPOCH 16 done: loss 0.1258 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 14:52:23,600 Evaluating as a multi-label problem: False\n",
            "2022-09-12 14:52:23,850 DEV : loss 0.08890406042337418 - f1-score (micro avg)  0.7665\n",
            "2022-09-12 14:52:35,975 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 14:52:35,977 saving best model\n",
            "2022-09-12 14:52:39,083 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 14:53:23,499 epoch 17 - iter 384/3843 - loss 0.12408889 - samples/sec: 389.35 - lr: 0.100000\n",
            "2022-09-12 14:54:08,497 epoch 17 - iter 768/3843 - loss 0.12492066 - samples/sec: 363.76 - lr: 0.100000\n",
            "2022-09-12 14:54:53,961 epoch 17 - iter 1152/3843 - loss 0.12467471 - samples/sec: 358.77 - lr: 0.100000\n",
            "2022-09-12 14:55:37,461 epoch 17 - iter 1536/3843 - loss 0.12457937 - samples/sec: 380.90 - lr: 0.100000\n",
            "2022-09-12 14:56:22,983 epoch 17 - iter 1920/3843 - loss 0.12483282 - samples/sec: 358.79 - lr: 0.100000\n",
            "2022-09-12 14:57:07,016 epoch 17 - iter 2304/3843 - loss 0.12507025 - samples/sec: 374.62 - lr: 0.100000\n",
            "2022-09-12 14:57:53,126 epoch 17 - iter 2688/3843 - loss 0.12501923 - samples/sec: 387.56 - lr: 0.100000\n",
            "2022-09-12 14:58:38,021 epoch 17 - iter 3072/3843 - loss 0.12526594 - samples/sec: 382.86 - lr: 0.100000\n",
            "2022-09-12 14:59:21,350 epoch 17 - iter 3456/3843 - loss 0.12541065 - samples/sec: 383.17 - lr: 0.100000\n",
            "2022-09-12 15:00:07,125 epoch 17 - iter 3840/3843 - loss 0.12549077 - samples/sec: 391.62 - lr: 0.100000\n",
            "2022-09-12 15:00:07,424 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:00:07,425 EPOCH 17 done: loss 0.1255 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 15:01:22,049 Evaluating as a multi-label problem: False\n",
            "2022-09-12 15:01:22,309 DEV : loss 0.08813448250293732 - f1-score (micro avg)  0.7666\n",
            "2022-09-12 15:01:34,396 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 15:01:34,400 saving best model\n",
            "2022-09-12 15:01:37,522 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:02:22,297 epoch 18 - iter 384/3843 - loss 0.12477241 - samples/sec: 403.87 - lr: 0.100000\n",
            "2022-09-12 15:03:05,913 epoch 18 - iter 768/3843 - loss 0.12493508 - samples/sec: 362.13 - lr: 0.100000\n",
            "2022-09-12 15:03:50,530 epoch 18 - iter 1152/3843 - loss 0.12448681 - samples/sec: 405.15 - lr: 0.100000\n",
            "2022-09-12 15:04:33,618 epoch 18 - iter 1536/3843 - loss 0.12446072 - samples/sec: 405.25 - lr: 0.100000\n",
            "2022-09-12 15:05:18,753 epoch 18 - iter 1920/3843 - loss 0.12448040 - samples/sec: 380.00 - lr: 0.100000\n",
            "2022-09-12 15:06:04,537 epoch 18 - iter 2304/3843 - loss 0.12439240 - samples/sec: 373.06 - lr: 0.100000\n",
            "2022-09-12 15:06:50,471 epoch 18 - iter 2688/3843 - loss 0.12465016 - samples/sec: 354.54 - lr: 0.100000\n",
            "2022-09-12 15:07:35,404 epoch 18 - iter 3072/3843 - loss 0.12486239 - samples/sec: 383.07 - lr: 0.100000\n",
            "2022-09-12 15:08:19,189 epoch 18 - iter 3456/3843 - loss 0.12470297 - samples/sec: 360.04 - lr: 0.100000\n",
            "2022-09-12 15:09:04,130 epoch 18 - iter 3840/3843 - loss 0.12476382 - samples/sec: 364.75 - lr: 0.100000\n",
            "2022-09-12 15:09:04,356 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:09:04,358 EPOCH 18 done: loss 0.1248 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 15:10:19,075 Evaluating as a multi-label problem: False\n",
            "2022-09-12 15:10:19,332 DEV : loss 0.08759693801403046 - f1-score (micro avg)  0.7691\n",
            "2022-09-12 15:10:31,367 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 15:10:31,369 saving best model\n",
            "2022-09-12 15:10:34,488 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:11:18,516 epoch 19 - iter 384/3843 - loss 0.12321354 - samples/sec: 411.91 - lr: 0.100000\n",
            "2022-09-12 15:12:04,228 epoch 19 - iter 768/3843 - loss 0.12344498 - samples/sec: 391.84 - lr: 0.100000\n",
            "2022-09-12 15:12:47,636 epoch 19 - iter 1152/3843 - loss 0.12390183 - samples/sec: 363.66 - lr: 0.100000\n",
            "2022-09-12 15:13:33,367 epoch 19 - iter 1536/3843 - loss 0.12392149 - samples/sec: 390.92 - lr: 0.100000\n",
            "2022-09-12 15:14:16,673 epoch 19 - iter 1920/3843 - loss 0.12369727 - samples/sec: 383.47 - lr: 0.100000\n",
            "2022-09-12 15:15:02,059 epoch 19 - iter 2304/3843 - loss 0.12390044 - samples/sec: 395.75 - lr: 0.100000\n",
            "2022-09-12 15:15:48,152 epoch 19 - iter 2688/3843 - loss 0.12376412 - samples/sec: 352.51 - lr: 0.100000\n",
            "2022-09-12 15:16:32,774 epoch 19 - iter 3072/3843 - loss 0.12409606 - samples/sec: 351.86 - lr: 0.100000\n",
            "2022-09-12 15:17:17,806 epoch 19 - iter 3456/3843 - loss 0.12431067 - samples/sec: 400.27 - lr: 0.100000\n",
            "2022-09-12 15:18:02,723 epoch 19 - iter 3840/3843 - loss 0.12430984 - samples/sec: 348.56 - lr: 0.100000\n",
            "2022-09-12 15:18:03,019 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:18:03,020 EPOCH 19 done: loss 0.1243 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 15:19:20,044 Evaluating as a multi-label problem: False\n",
            "2022-09-12 15:19:20,321 DEV : loss 0.08586442470550537 - f1-score (micro avg)  0.7733\n",
            "2022-09-12 15:19:30,891 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 15:19:30,893 saving best model\n",
            "2022-09-12 15:19:34,011 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:20:20,482 epoch 20 - iter 384/3843 - loss 0.12383776 - samples/sec: 320.84 - lr: 0.100000\n",
            "2022-09-12 15:21:05,822 epoch 20 - iter 768/3843 - loss 0.12303198 - samples/sec: 378.44 - lr: 0.100000\n",
            "2022-09-12 15:21:49,215 epoch 20 - iter 1152/3843 - loss 0.12340661 - samples/sec: 401.60 - lr: 0.100000\n",
            "2022-09-12 15:22:35,390 epoch 20 - iter 1536/3843 - loss 0.12335636 - samples/sec: 352.14 - lr: 0.100000\n",
            "2022-09-12 15:23:19,210 epoch 20 - iter 1920/3843 - loss 0.12380609 - samples/sec: 379.89 - lr: 0.100000\n",
            "2022-09-12 15:24:04,507 epoch 20 - iter 2304/3843 - loss 0.12415851 - samples/sec: 379.51 - lr: 0.100000\n",
            "2022-09-12 15:24:49,210 epoch 20 - iter 2688/3843 - loss 0.12407873 - samples/sec: 350.87 - lr: 0.100000\n",
            "2022-09-12 15:25:34,398 epoch 20 - iter 3072/3843 - loss 0.12403980 - samples/sec: 379.55 - lr: 0.100000\n",
            "2022-09-12 15:26:19,431 epoch 20 - iter 3456/3843 - loss 0.12388587 - samples/sec: 364.29 - lr: 0.100000\n",
            "2022-09-12 15:27:03,631 epoch 20 - iter 3840/3843 - loss 0.12377144 - samples/sec: 373.66 - lr: 0.100000\n",
            "2022-09-12 15:27:03,906 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:27:03,908 EPOCH 20 done: loss 0.1238 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 15:28:20,616 Evaluating as a multi-label problem: False\n",
            "2022-09-12 15:28:20,878 DEV : loss 0.08775848150253296 - f1-score (micro avg)  0.7723\n",
            "2022-09-12 15:28:31,361 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 15:28:31,363 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:29:16,150 epoch 21 - iter 384/3843 - loss 0.12339082 - samples/sec: 382.67 - lr: 0.100000\n",
            "2022-09-12 15:30:02,663 epoch 21 - iter 768/3843 - loss 0.12301962 - samples/sec: 348.01 - lr: 0.100000\n",
            "2022-09-12 15:30:47,938 epoch 21 - iter 1152/3843 - loss 0.12292144 - samples/sec: 378.88 - lr: 0.100000\n",
            "2022-09-12 15:31:31,430 epoch 21 - iter 1536/3843 - loss 0.12311519 - samples/sec: 381.14 - lr: 0.100000\n",
            "2022-09-12 15:32:17,964 epoch 21 - iter 1920/3843 - loss 0.12334159 - samples/sec: 382.47 - lr: 0.100000\n",
            "2022-09-12 15:33:02,046 epoch 21 - iter 2304/3843 - loss 0.12327226 - samples/sec: 374.55 - lr: 0.100000\n",
            "2022-09-12 15:33:48,071 epoch 21 - iter 2688/3843 - loss 0.12303581 - samples/sec: 371.22 - lr: 0.100000\n",
            "2022-09-12 15:34:31,642 epoch 21 - iter 3072/3843 - loss 0.12319942 - samples/sec: 380.69 - lr: 0.100000\n",
            "2022-09-12 15:35:16,953 epoch 21 - iter 3456/3843 - loss 0.12327671 - samples/sec: 397.93 - lr: 0.100000\n",
            "2022-09-12 15:36:01,600 epoch 21 - iter 3840/3843 - loss 0.12333279 - samples/sec: 406.26 - lr: 0.100000\n",
            "2022-09-12 15:36:01,865 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:36:01,867 EPOCH 21 done: loss 0.1233 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 15:37:17,117 Evaluating as a multi-label problem: False\n",
            "2022-09-12 15:37:17,654 DEV : loss 0.08684515953063965 - f1-score (micro avg)  0.7739\n",
            "2022-09-12 15:37:29,947 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 15:37:29,950 saving best model\n",
            "2022-09-12 15:37:33,085 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:38:17,205 epoch 22 - iter 384/3843 - loss 0.12167259 - samples/sec: 396.42 - lr: 0.100000\n",
            "2022-09-12 15:39:02,476 epoch 22 - iter 768/3843 - loss 0.12174153 - samples/sec: 379.03 - lr: 0.100000\n",
            "2022-09-12 15:39:48,217 epoch 22 - iter 1152/3843 - loss 0.12252048 - samples/sec: 372.26 - lr: 0.100000\n",
            "2022-09-12 15:40:31,995 epoch 22 - iter 1536/3843 - loss 0.12254601 - samples/sec: 397.37 - lr: 0.100000\n",
            "2022-09-12 15:41:17,736 epoch 22 - iter 1920/3843 - loss 0.12310396 - samples/sec: 372.62 - lr: 0.100000\n",
            "2022-09-12 15:42:03,870 epoch 22 - iter 2304/3843 - loss 0.12269389 - samples/sec: 337.27 - lr: 0.100000\n",
            "2022-09-12 15:42:49,297 epoch 22 - iter 2688/3843 - loss 0.12276453 - samples/sec: 376.89 - lr: 0.100000\n",
            "2022-09-12 15:43:34,791 epoch 22 - iter 3072/3843 - loss 0.12290617 - samples/sec: 376.90 - lr: 0.100000\n",
            "2022-09-12 15:44:18,801 epoch 22 - iter 3456/3843 - loss 0.12296864 - samples/sec: 375.49 - lr: 0.100000\n",
            "2022-09-12 15:45:03,738 epoch 22 - iter 3840/3843 - loss 0.12305817 - samples/sec: 382.67 - lr: 0.100000\n",
            "2022-09-12 15:45:04,047 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:45:04,049 EPOCH 22 done: loss 0.1231 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 15:46:18,818 Evaluating as a multi-label problem: False\n",
            "2022-09-12 15:46:19,078 DEV : loss 0.08911196887493134 - f1-score (micro avg)  0.7704\n",
            "2022-09-12 15:46:31,261 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 15:46:31,264 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:47:15,530 epoch 23 - iter 384/3843 - loss 0.12015296 - samples/sec: 373.62 - lr: 0.100000\n",
            "2022-09-12 15:48:01,199 epoch 23 - iter 768/3843 - loss 0.12182876 - samples/sec: 372.99 - lr: 0.100000\n",
            "2022-09-12 15:48:46,884 epoch 23 - iter 1152/3843 - loss 0.12276377 - samples/sec: 357.19 - lr: 0.100000\n",
            "2022-09-12 15:49:30,243 epoch 23 - iter 1536/3843 - loss 0.12276597 - samples/sec: 382.24 - lr: 0.100000\n",
            "2022-09-12 15:50:14,907 epoch 23 - iter 1920/3843 - loss 0.12293685 - samples/sec: 385.79 - lr: 0.100000\n",
            "2022-09-12 15:51:00,630 epoch 23 - iter 2304/3843 - loss 0.12303242 - samples/sec: 372.17 - lr: 0.100000\n",
            "2022-09-12 15:51:45,657 epoch 23 - iter 2688/3843 - loss 0.12291668 - samples/sec: 381.68 - lr: 0.100000\n",
            "2022-09-12 15:52:30,660 epoch 23 - iter 3072/3843 - loss 0.12302500 - samples/sec: 364.18 - lr: 0.100000\n",
            "2022-09-12 15:53:14,912 epoch 23 - iter 3456/3843 - loss 0.12289761 - samples/sec: 372.24 - lr: 0.100000\n",
            "2022-09-12 15:54:00,015 epoch 23 - iter 3840/3843 - loss 0.12277624 - samples/sec: 363.36 - lr: 0.100000\n",
            "2022-09-12 15:54:00,417 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:54:00,419 EPOCH 23 done: loss 0.1228 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 15:55:15,437 Evaluating as a multi-label problem: False\n",
            "2022-09-12 15:55:15,707 DEV : loss 0.08540176600217819 - f1-score (micro avg)  0.7706\n",
            "2022-09-12 15:55:27,831 BAD EPOCHS (no improvement): 2\n",
            "2022-09-12 15:55:27,834 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 15:56:10,842 epoch 24 - iter 384/3843 - loss 0.12082534 - samples/sec: 408.38 - lr: 0.100000\n",
            "2022-09-12 15:56:57,942 epoch 24 - iter 768/3843 - loss 0.12146416 - samples/sec: 357.95 - lr: 0.100000\n",
            "2022-09-12 15:57:43,237 epoch 24 - iter 1152/3843 - loss 0.12162082 - samples/sec: 360.93 - lr: 0.100000\n",
            "2022-09-12 15:58:27,109 epoch 24 - iter 1536/3843 - loss 0.12175284 - samples/sec: 395.93 - lr: 0.100000\n",
            "2022-09-12 15:59:13,576 epoch 24 - iter 1920/3843 - loss 0.12228896 - samples/sec: 348.95 - lr: 0.100000\n",
            "2022-09-12 15:59:57,359 epoch 24 - iter 2304/3843 - loss 0.12212675 - samples/sec: 396.91 - lr: 0.100000\n",
            "2022-09-12 16:00:43,214 epoch 24 - iter 2688/3843 - loss 0.12216954 - samples/sec: 371.80 - lr: 0.100000\n",
            "2022-09-12 16:01:27,170 epoch 24 - iter 3072/3843 - loss 0.12230183 - samples/sec: 375.96 - lr: 0.100000\n",
            "2022-09-12 16:02:12,557 epoch 24 - iter 3456/3843 - loss 0.12237652 - samples/sec: 377.50 - lr: 0.100000\n",
            "2022-09-12 16:02:57,621 epoch 24 - iter 3840/3843 - loss 0.12225026 - samples/sec: 381.22 - lr: 0.100000\n",
            "2022-09-12 16:02:57,957 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:02:57,959 EPOCH 24 done: loss 0.1222 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 16:04:13,086 Evaluating as a multi-label problem: False\n",
            "2022-09-12 16:04:13,360 DEV : loss 0.08646155893802643 - f1-score (micro avg)  0.7735\n",
            "2022-09-12 16:04:25,566 BAD EPOCHS (no improvement): 3\n",
            "2022-09-12 16:04:25,568 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:05:08,495 epoch 25 - iter 384/3843 - loss 0.12189373 - samples/sec: 409.79 - lr: 0.100000\n",
            "2022-09-12 16:05:53,988 epoch 25 - iter 768/3843 - loss 0.12192631 - samples/sec: 375.20 - lr: 0.100000\n",
            "2022-09-12 16:06:39,031 epoch 25 - iter 1152/3843 - loss 0.12212767 - samples/sec: 399.81 - lr: 0.100000\n",
            "2022-09-12 16:07:23,092 epoch 25 - iter 1536/3843 - loss 0.12215908 - samples/sec: 375.39 - lr: 0.100000\n",
            "2022-09-12 16:08:08,677 epoch 25 - iter 1920/3843 - loss 0.12193955 - samples/sec: 357.73 - lr: 0.100000\n",
            "2022-09-12 16:08:52,652 epoch 25 - iter 2304/3843 - loss 0.12202063 - samples/sec: 358.45 - lr: 0.100000\n",
            "2022-09-12 16:09:38,408 epoch 25 - iter 2688/3843 - loss 0.12174164 - samples/sec: 355.70 - lr: 0.100000\n",
            "2022-09-12 16:10:23,161 epoch 25 - iter 3072/3843 - loss 0.12201417 - samples/sec: 366.69 - lr: 0.100000\n",
            "2022-09-12 16:11:07,096 epoch 25 - iter 3456/3843 - loss 0.12203307 - samples/sec: 376.20 - lr: 0.100000\n",
            "2022-09-12 16:11:52,751 epoch 25 - iter 3840/3843 - loss 0.12204233 - samples/sec: 356.93 - lr: 0.100000\n",
            "2022-09-12 16:11:53,040 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:11:53,042 EPOCH 25 done: loss 0.1220 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 16:13:07,789 Evaluating as a multi-label problem: False\n",
            "2022-09-12 16:13:08,049 DEV : loss 0.08870924264192581 - f1-score (micro avg)  0.7721\n",
            "2022-09-12 16:13:20,200 Epoch    25: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2022-09-12 16:13:20,202 BAD EPOCHS (no improvement): 4\n",
            "2022-09-12 16:13:20,205 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:14:05,433 epoch 26 - iter 384/3843 - loss 0.11791259 - samples/sec: 400.06 - lr: 0.050000\n",
            "2022-09-12 16:14:50,329 epoch 26 - iter 768/3843 - loss 0.11767300 - samples/sec: 348.82 - lr: 0.050000\n",
            "2022-09-12 16:15:35,136 epoch 26 - iter 1152/3843 - loss 0.11775818 - samples/sec: 403.19 - lr: 0.050000\n",
            "2022-09-12 16:16:19,565 epoch 26 - iter 1536/3843 - loss 0.11720475 - samples/sec: 369.45 - lr: 0.050000\n",
            "2022-09-12 16:17:04,022 epoch 26 - iter 1920/3843 - loss 0.11725493 - samples/sec: 407.47 - lr: 0.050000\n",
            "2022-09-12 16:17:47,169 epoch 26 - iter 2304/3843 - loss 0.11724672 - samples/sec: 404.81 - lr: 0.050000\n",
            "2022-09-12 16:18:33,135 epoch 26 - iter 2688/3843 - loss 0.11703845 - samples/sec: 371.19 - lr: 0.050000\n",
            "2022-09-12 16:19:19,279 epoch 26 - iter 3072/3843 - loss 0.11697203 - samples/sec: 368.90 - lr: 0.050000\n",
            "2022-09-12 16:20:04,293 epoch 26 - iter 3456/3843 - loss 0.11694289 - samples/sec: 382.33 - lr: 0.050000\n",
            "2022-09-12 16:20:49,253 epoch 26 - iter 3840/3843 - loss 0.11686638 - samples/sec: 402.56 - lr: 0.050000\n",
            "2022-09-12 16:20:49,521 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:20:49,522 EPOCH 26 done: loss 0.1169 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 16:22:04,532 Evaluating as a multi-label problem: False\n",
            "2022-09-12 16:22:04,781 DEV : loss 0.08330924808979034 - f1-score (micro avg)  0.7794\n",
            "2022-09-12 16:22:16,926 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 16:22:16,929 saving best model\n",
            "2022-09-12 16:22:20,090 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:23:06,347 epoch 27 - iter 384/3843 - loss 0.11521148 - samples/sec: 386.51 - lr: 0.050000\n",
            "2022-09-12 16:23:49,908 epoch 27 - iter 768/3843 - loss 0.11570222 - samples/sec: 399.30 - lr: 0.050000\n",
            "2022-09-12 16:24:34,930 epoch 27 - iter 1152/3843 - loss 0.11551808 - samples/sec: 381.33 - lr: 0.050000\n",
            "2022-09-12 16:25:18,734 epoch 27 - iter 1536/3843 - loss 0.11528444 - samples/sec: 378.02 - lr: 0.050000\n",
            "2022-09-12 16:26:04,974 epoch 27 - iter 1920/3843 - loss 0.11511057 - samples/sec: 385.15 - lr: 0.050000\n",
            "2022-09-12 16:26:50,866 epoch 27 - iter 2304/3843 - loss 0.11505913 - samples/sec: 389.25 - lr: 0.050000\n",
            "2022-09-12 16:27:34,520 epoch 27 - iter 2688/3843 - loss 0.11510417 - samples/sec: 362.75 - lr: 0.050000\n",
            "2022-09-12 16:28:19,841 epoch 27 - iter 3072/3843 - loss 0.11510113 - samples/sec: 377.60 - lr: 0.050000\n",
            "2022-09-12 16:29:03,108 epoch 27 - iter 3456/3843 - loss 0.11514233 - samples/sec: 383.71 - lr: 0.050000\n",
            "2022-09-12 16:29:48,250 epoch 27 - iter 3840/3843 - loss 0.11488350 - samples/sec: 398.33 - lr: 0.050000\n",
            "2022-09-12 16:29:48,523 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:29:48,525 EPOCH 27 done: loss 0.1149 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 16:31:03,165 Evaluating as a multi-label problem: False\n",
            "2022-09-12 16:31:03,431 DEV : loss 0.0815466046333313 - f1-score (micro avg)  0.7816\n",
            "2022-09-12 16:31:15,467 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 16:31:15,470 saving best model\n",
            "2022-09-12 16:31:18,666 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:32:03,276 epoch 28 - iter 384/3843 - loss 0.11281822 - samples/sec: 386.70 - lr: 0.050000\n",
            "2022-09-12 16:32:48,684 epoch 28 - iter 768/3843 - loss 0.11461629 - samples/sec: 359.26 - lr: 0.050000\n",
            "2022-09-12 16:33:32,424 epoch 28 - iter 1152/3843 - loss 0.11444539 - samples/sec: 345.32 - lr: 0.050000\n",
            "2022-09-12 16:34:17,636 epoch 28 - iter 1536/3843 - loss 0.11453635 - samples/sec: 396.87 - lr: 0.050000\n",
            "2022-09-12 16:35:02,444 epoch 28 - iter 1920/3843 - loss 0.11455770 - samples/sec: 349.96 - lr: 0.050000\n",
            "2022-09-12 16:35:48,343 epoch 28 - iter 2304/3843 - loss 0.11476255 - samples/sec: 339.88 - lr: 0.050000\n",
            "2022-09-12 16:36:34,464 epoch 28 - iter 2688/3843 - loss 0.11435874 - samples/sec: 386.31 - lr: 0.050000\n",
            "2022-09-12 16:37:19,014 epoch 28 - iter 3072/3843 - loss 0.11426143 - samples/sec: 369.08 - lr: 0.050000\n",
            "2022-09-12 16:38:04,052 epoch 28 - iter 3456/3843 - loss 0.11409350 - samples/sec: 348.23 - lr: 0.050000\n",
            "2022-09-12 16:38:47,432 epoch 28 - iter 3840/3843 - loss 0.11399869 - samples/sec: 365.39 - lr: 0.050000\n",
            "2022-09-12 16:38:47,709 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:38:47,711 EPOCH 28 done: loss 0.1140 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 16:40:04,646 Evaluating as a multi-label problem: False\n",
            "2022-09-12 16:40:04,908 DEV : loss 0.08123621344566345 - f1-score (micro avg)  0.7824\n",
            "2022-09-12 16:40:15,405 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 16:40:15,408 saving best model\n",
            "2022-09-12 16:40:18,541 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:41:05,088 epoch 29 - iter 384/3843 - loss 0.11208028 - samples/sec: 361.73 - lr: 0.050000\n",
            "2022-09-12 16:41:48,343 epoch 29 - iter 768/3843 - loss 0.11313912 - samples/sec: 383.60 - lr: 0.050000\n",
            "2022-09-12 16:42:35,596 epoch 29 - iter 1152/3843 - loss 0.11354928 - samples/sec: 356.98 - lr: 0.050000\n",
            "2022-09-12 16:43:19,230 epoch 29 - iter 1536/3843 - loss 0.11356093 - samples/sec: 379.40 - lr: 0.050000\n",
            "2022-09-12 16:44:05,305 epoch 29 - iter 1920/3843 - loss 0.11328021 - samples/sec: 388.05 - lr: 0.050000\n",
            "2022-09-12 16:44:51,744 epoch 29 - iter 2304/3843 - loss 0.11366598 - samples/sec: 350.29 - lr: 0.050000\n",
            "2022-09-12 16:45:36,764 epoch 29 - iter 2688/3843 - loss 0.11330951 - samples/sec: 383.12 - lr: 0.050000\n",
            "2022-09-12 16:46:22,429 epoch 29 - iter 3072/3843 - loss 0.11354978 - samples/sec: 394.21 - lr: 0.050000\n",
            "2022-09-12 16:47:06,485 epoch 29 - iter 3456/3843 - loss 0.11352837 - samples/sec: 393.93 - lr: 0.050000\n",
            "2022-09-12 16:47:51,756 epoch 29 - iter 3840/3843 - loss 0.11336744 - samples/sec: 400.62 - lr: 0.050000\n",
            "2022-09-12 16:47:52,013 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:47:52,016 EPOCH 29 done: loss 0.1134 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 16:49:07,299 Evaluating as a multi-label problem: False\n",
            "2022-09-12 16:49:07,557 DEV : loss 0.08110686391592026 - f1-score (micro avg)  0.7839\n",
            "2022-09-12 16:49:19,722 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 16:49:19,725 saving best model\n",
            "2022-09-12 16:49:22,885 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:50:07,858 epoch 30 - iter 384/3843 - loss 0.11129687 - samples/sec: 381.98 - lr: 0.050000\n",
            "2022-09-12 16:50:52,974 epoch 30 - iter 768/3843 - loss 0.11195948 - samples/sec: 333.09 - lr: 0.050000\n",
            "2022-09-12 16:51:38,221 epoch 30 - iter 1152/3843 - loss 0.11138328 - samples/sec: 378.71 - lr: 0.050000\n",
            "2022-09-12 16:52:24,210 epoch 30 - iter 1536/3843 - loss 0.11187044 - samples/sec: 369.61 - lr: 0.050000\n",
            "2022-09-12 16:53:07,362 epoch 30 - iter 1920/3843 - loss 0.11225767 - samples/sec: 404.80 - lr: 0.050000\n",
            "2022-09-12 16:53:53,028 epoch 30 - iter 2304/3843 - loss 0.11253410 - samples/sec: 392.00 - lr: 0.050000\n",
            "2022-09-12 16:54:36,550 epoch 30 - iter 2688/3843 - loss 0.11283886 - samples/sec: 362.95 - lr: 0.050000\n",
            "2022-09-12 16:55:22,303 epoch 30 - iter 3072/3843 - loss 0.11297735 - samples/sec: 373.22 - lr: 0.050000\n",
            "2022-09-12 16:56:05,089 epoch 30 - iter 3456/3843 - loss 0.11275225 - samples/sec: 372.62 - lr: 0.050000\n",
            "2022-09-12 16:56:50,696 epoch 30 - iter 3840/3843 - loss 0.11287949 - samples/sec: 394.43 - lr: 0.050000\n",
            "2022-09-12 16:56:51,050 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:56:51,052 EPOCH 30 done: loss 0.1129 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 16:58:07,696 Evaluating as a multi-label problem: False\n",
            "2022-09-12 16:58:07,953 DEV : loss 0.08105611801147461 - f1-score (micro avg)  0.7829\n",
            "2022-09-12 16:58:18,382 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 16:58:18,385 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 16:59:03,531 epoch 31 - iter 384/3843 - loss 0.11133950 - samples/sec: 399.24 - lr: 0.050000\n",
            "2022-09-12 16:59:49,805 epoch 31 - iter 768/3843 - loss 0.11212200 - samples/sec: 367.47 - lr: 0.050000\n",
            "2022-09-12 17:00:33,704 epoch 31 - iter 1152/3843 - loss 0.11193428 - samples/sec: 359.24 - lr: 0.050000\n",
            "2022-09-12 17:01:20,594 epoch 31 - iter 1536/3843 - loss 0.11177187 - samples/sec: 361.11 - lr: 0.050000\n",
            "2022-09-12 17:02:05,238 epoch 31 - iter 1920/3843 - loss 0.11157411 - samples/sec: 385.33 - lr: 0.050000\n",
            "2022-09-12 17:02:49,309 epoch 31 - iter 2304/3843 - loss 0.11177090 - samples/sec: 375.48 - lr: 0.050000\n",
            "2022-09-12 17:03:34,449 epoch 31 - iter 2688/3843 - loss 0.11203840 - samples/sec: 380.85 - lr: 0.050000\n",
            "2022-09-12 17:04:19,237 epoch 31 - iter 3072/3843 - loss 0.11179751 - samples/sec: 384.82 - lr: 0.050000\n",
            "2022-09-12 17:05:03,479 epoch 31 - iter 3456/3843 - loss 0.11183351 - samples/sec: 372.37 - lr: 0.050000\n",
            "2022-09-12 17:05:47,414 epoch 31 - iter 3840/3843 - loss 0.11199953 - samples/sec: 377.43 - lr: 0.050000\n",
            "2022-09-12 17:05:47,662 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 17:05:47,663 EPOCH 31 done: loss 0.1120 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 17:07:04,427 Evaluating as a multi-label problem: False\n",
            "2022-09-12 17:07:04,691 DEV : loss 0.08050858974456787 - f1-score (micro avg)  0.7845\n",
            "2022-09-12 17:07:15,187 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 17:07:15,190 saving best model\n",
            "2022-09-12 17:07:18,310 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 17:08:04,839 epoch 32 - iter 384/3843 - loss 0.11107254 - samples/sec: 349.68 - lr: 0.050000\n",
            "2022-09-12 17:08:50,628 epoch 32 - iter 768/3843 - loss 0.11112530 - samples/sec: 374.64 - lr: 0.050000\n",
            "2022-09-12 17:09:34,567 epoch 32 - iter 1152/3843 - loss 0.11069016 - samples/sec: 376.63 - lr: 0.050000\n",
            "2022-09-12 17:10:19,792 epoch 32 - iter 1536/3843 - loss 0.11083053 - samples/sec: 378.90 - lr: 0.050000\n",
            "2022-09-12 17:11:03,682 epoch 32 - iter 1920/3843 - loss 0.11077200 - samples/sec: 396.13 - lr: 0.050000\n",
            "2022-09-12 17:11:49,847 epoch 32 - iter 2304/3843 - loss 0.11128153 - samples/sec: 353.19 - lr: 0.050000\n",
            "2022-09-12 17:12:34,022 epoch 32 - iter 2688/3843 - loss 0.11137590 - samples/sec: 358.91 - lr: 0.050000\n",
            "2022-09-12 17:13:19,516 epoch 32 - iter 3072/3843 - loss 0.11165049 - samples/sec: 360.24 - lr: 0.050000\n",
            "2022-09-12 17:14:05,645 epoch 32 - iter 3456/3843 - loss 0.11152850 - samples/sec: 370.15 - lr: 0.050000\n",
            "2022-09-12 17:14:50,000 epoch 32 - iter 3840/3843 - loss 0.11162480 - samples/sec: 390.63 - lr: 0.050000\n",
            "2022-09-12 17:14:50,293 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 17:14:50,295 EPOCH 32 done: loss 0.1116 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 17:16:07,172 Evaluating as a multi-label problem: False\n",
            "2022-09-12 17:16:07,442 DEV : loss 0.08035611361265182 - f1-score (micro avg)  0.7847\n",
            "2022-09-12 17:16:17,898 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 17:16:17,900 saving best model\n",
            "2022-09-12 17:16:21,128 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 17:17:08,006 epoch 33 - iter 384/3843 - loss 0.11142192 - samples/sec: 358.20 - lr: 0.050000\n",
            "2022-09-12 17:17:52,215 epoch 33 - iter 768/3843 - loss 0.11093382 - samples/sec: 373.69 - lr: 0.050000\n",
            "2022-09-12 17:18:37,643 epoch 33 - iter 1152/3843 - loss 0.11092865 - samples/sec: 344.64 - lr: 0.050000\n",
            "2022-09-12 17:19:21,588 epoch 33 - iter 1536/3843 - loss 0.11125200 - samples/sec: 376.16 - lr: 0.050000\n",
            "2022-09-12 17:20:06,412 epoch 33 - iter 1920/3843 - loss 0.11146861 - samples/sec: 403.88 - lr: 0.050000\n",
            "2022-09-12 17:20:50,713 epoch 33 - iter 2304/3843 - loss 0.11144081 - samples/sec: 391.05 - lr: 0.050000\n",
            "2022-09-12 17:21:37,708 epoch 33 - iter 2688/3843 - loss 0.11141085 - samples/sec: 360.88 - lr: 0.050000\n",
            "2022-09-12 17:22:22,863 epoch 33 - iter 3072/3843 - loss 0.11135237 - samples/sec: 363.60 - lr: 0.050000\n",
            "2022-09-12 17:23:06,631 epoch 33 - iter 3456/3843 - loss 0.11131279 - samples/sec: 379.07 - lr: 0.050000\n",
            "2022-09-12 17:23:52,349 epoch 33 - iter 3840/3843 - loss 0.11161031 - samples/sec: 342.56 - lr: 0.050000\n",
            "2022-09-12 17:23:52,619 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 17:23:52,621 EPOCH 33 done: loss 0.1116 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 17:25:07,982 Evaluating as a multi-label problem: False\n",
            "2022-09-12 17:25:08,242 DEV : loss 0.07982528209686279 - f1-score (micro avg)  0.7862\n",
            "2022-09-12 17:25:20,499 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 17:25:20,501 saving best model\n",
            "2022-09-12 17:25:23,650 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 17:26:09,042 epoch 34 - iter 384/3843 - loss 0.11061473 - samples/sec: 396.15 - lr: 0.050000\n",
            "2022-09-12 17:26:53,567 epoch 34 - iter 768/3843 - loss 0.11105618 - samples/sec: 353.72 - lr: 0.050000\n",
            "2022-09-12 17:27:38,590 epoch 34 - iter 1152/3843 - loss 0.11075720 - samples/sec: 381.03 - lr: 0.050000\n",
            "2022-09-12 17:28:23,632 epoch 34 - iter 1536/3843 - loss 0.11068563 - samples/sec: 381.56 - lr: 0.050000\n",
            "2022-09-12 17:29:06,922 epoch 34 - iter 1920/3843 - loss 0.11114820 - samples/sec: 384.25 - lr: 0.050000\n",
            "2022-09-12 17:29:52,593 epoch 34 - iter 2304/3843 - loss 0.11109671 - samples/sec: 393.28 - lr: 0.050000\n",
            "2022-09-12 17:30:36,262 epoch 34 - iter 2688/3843 - loss 0.11083577 - samples/sec: 398.08 - lr: 0.050000\n",
            "2022-09-12 17:31:21,901 epoch 34 - iter 3072/3843 - loss 0.11088383 - samples/sec: 376.32 - lr: 0.050000\n",
            "2022-09-12 17:32:09,048 epoch 34 - iter 3456/3843 - loss 0.11083887 - samples/sec: 359.45 - lr: 0.050000\n",
            "2022-09-12 17:32:53,324 epoch 34 - iter 3840/3843 - loss 0.11102506 - samples/sec: 391.30 - lr: 0.050000\n",
            "2022-09-12 17:32:53,621 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 17:32:53,623 EPOCH 34 done: loss 0.1110 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 17:34:10,149 Evaluating as a multi-label problem: False\n",
            "2022-09-12 17:34:10,414 DEV : loss 0.07969542592763901 - f1-score (micro avg)  0.7873\n",
            "2022-09-12 17:34:20,981 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 17:34:20,984 saving best model\n",
            "2022-09-12 17:34:24,142 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 17:35:11,370 epoch 35 - iter 384/3843 - loss 0.11024826 - samples/sec: 390.30 - lr: 0.050000\n",
            "2022-09-12 17:35:54,309 epoch 35 - iter 768/3843 - loss 0.11088845 - samples/sec: 387.50 - lr: 0.050000\n",
            "2022-09-12 17:36:40,382 epoch 35 - iter 1152/3843 - loss 0.11045451 - samples/sec: 370.31 - lr: 0.050000\n",
            "2022-09-12 17:37:24,052 epoch 35 - iter 1536/3843 - loss 0.11035853 - samples/sec: 399.02 - lr: 0.050000\n",
            "2022-09-12 17:38:09,765 epoch 35 - iter 1920/3843 - loss 0.11032863 - samples/sec: 358.68 - lr: 0.050000\n",
            "2022-09-12 17:38:54,541 epoch 35 - iter 2304/3843 - loss 0.11054155 - samples/sec: 351.72 - lr: 0.050000\n",
            "2022-09-12 17:39:40,471 epoch 35 - iter 2688/3843 - loss 0.11073286 - samples/sec: 339.34 - lr: 0.050000\n",
            "2022-09-12 17:40:25,689 epoch 35 - iter 3072/3843 - loss 0.11061794 - samples/sec: 400.23 - lr: 0.050000\n",
            "2022-09-12 17:41:09,658 epoch 35 - iter 3456/3843 - loss 0.11068668 - samples/sec: 359.39 - lr: 0.050000\n",
            "2022-09-12 17:41:54,819 epoch 35 - iter 3840/3843 - loss 0.11087609 - samples/sec: 362.77 - lr: 0.050000\n",
            "2022-09-12 17:41:55,067 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 17:41:55,068 EPOCH 35 done: loss 0.1109 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 17:43:10,102 Evaluating as a multi-label problem: False\n",
            "2022-09-12 17:43:10,360 DEV : loss 0.07963600009679794 - f1-score (micro avg)  0.7872\n",
            "2022-09-12 17:43:22,476 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 17:43:22,480 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 17:44:08,165 epoch 36 - iter 384/3843 - loss 0.10893179 - samples/sec: 358.04 - lr: 0.050000\n",
            "2022-09-12 17:44:51,409 epoch 36 - iter 768/3843 - loss 0.10978731 - samples/sec: 403.90 - lr: 0.050000\n",
            "2022-09-12 17:45:36,419 epoch 36 - iter 1152/3843 - loss 0.11004305 - samples/sec: 348.44 - lr: 0.050000\n",
            "2022-09-12 17:46:20,207 epoch 36 - iter 1536/3843 - loss 0.11010531 - samples/sec: 360.22 - lr: 0.050000\n",
            "2022-09-12 17:47:06,890 epoch 36 - iter 1920/3843 - loss 0.11042877 - samples/sec: 380.70 - lr: 0.050000\n",
            "2022-09-12 17:47:52,453 epoch 36 - iter 2304/3843 - loss 0.11034480 - samples/sec: 395.89 - lr: 0.050000\n",
            "2022-09-12 17:48:36,540 epoch 36 - iter 2688/3843 - loss 0.11016028 - samples/sec: 357.72 - lr: 0.050000\n",
            "2022-09-12 17:49:21,837 epoch 36 - iter 3072/3843 - loss 0.11019021 - samples/sec: 345.45 - lr: 0.050000\n",
            "2022-09-12 17:50:05,915 epoch 36 - iter 3456/3843 - loss 0.11052159 - samples/sec: 374.62 - lr: 0.050000\n",
            "2022-09-12 17:50:52,143 epoch 36 - iter 3840/3843 - loss 0.11062667 - samples/sec: 368.29 - lr: 0.050000\n",
            "2022-09-12 17:50:52,448 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 17:50:52,450 EPOCH 36 done: loss 0.1106 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 17:52:09,277 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 17:52:09,524 DEV : loss 0.08008643984794617 - f1-score (micro avg)  0.7874\n",
            "2022-09-12 17:52:20,110 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 17:52:20,112 saving best model\n",
            "2022-09-12 17:52:23,238 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 17:53:10,445 epoch 37 - iter 384/3843 - loss 0.10887745 - samples/sec: 373.19 - lr: 0.050000\n",
            "2022-09-12 17:53:54,782 epoch 37 - iter 768/3843 - loss 0.10962912 - samples/sec: 371.90 - lr: 0.050000\n",
            "2022-09-12 17:54:38,518 epoch 37 - iter 1152/3843 - loss 0.10998888 - samples/sec: 399.18 - lr: 0.050000\n",
            "2022-09-12 17:55:23,902 epoch 37 - iter 1536/3843 - loss 0.11007389 - samples/sec: 377.62 - lr: 0.050000\n",
            "2022-09-12 17:56:08,626 epoch 37 - iter 1920/3843 - loss 0.11058982 - samples/sec: 350.80 - lr: 0.050000\n",
            "2022-09-12 17:56:52,136 epoch 37 - iter 2304/3843 - loss 0.11092037 - samples/sec: 381.75 - lr: 0.050000\n",
            "2022-09-12 17:57:38,107 epoch 37 - iter 2688/3843 - loss 0.11063998 - samples/sec: 391.04 - lr: 0.050000\n",
            "2022-09-12 17:58:22,294 epoch 37 - iter 3072/3843 - loss 0.11066258 - samples/sec: 392.40 - lr: 0.050000\n",
            "2022-09-12 17:59:08,304 epoch 37 - iter 3456/3843 - loss 0.11043994 - samples/sec: 354.58 - lr: 0.050000\n",
            "2022-09-12 17:59:51,963 epoch 37 - iter 3840/3843 - loss 0.11034141 - samples/sec: 362.30 - lr: 0.050000\n",
            "2022-09-12 17:59:53,947 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 17:59:53,949 EPOCH 37 done: loss 0.1103 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 18:01:09,347 Evaluating as a multi-label problem: False\n",
            "2022-09-12 18:01:09,601 DEV : loss 0.07923725992441177 - f1-score (micro avg)  0.7883\n",
            "2022-09-12 18:01:21,820 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 18:01:21,822 saving best model\n",
            "2022-09-12 18:01:24,968 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 18:02:08,678 epoch 38 - iter 384/3843 - loss 0.10855218 - samples/sec: 402.95 - lr: 0.050000\n",
            "2022-09-12 18:02:54,554 epoch 38 - iter 768/3843 - loss 0.10878520 - samples/sec: 354.62 - lr: 0.050000\n",
            "2022-09-12 18:03:39,049 epoch 38 - iter 1152/3843 - loss 0.10899003 - samples/sec: 338.58 - lr: 0.050000\n",
            "2022-09-12 18:04:24,545 epoch 38 - iter 1536/3843 - loss 0.10963870 - samples/sec: 376.03 - lr: 0.050000\n",
            "2022-09-12 18:05:07,744 epoch 38 - iter 1920/3843 - loss 0.11009842 - samples/sec: 404.97 - lr: 0.050000\n",
            "2022-09-12 18:05:53,753 epoch 38 - iter 2304/3843 - loss 0.11060899 - samples/sec: 338.46 - lr: 0.050000\n",
            "2022-09-12 18:06:40,394 epoch 38 - iter 2688/3843 - loss 0.11037261 - samples/sec: 364.12 - lr: 0.050000\n",
            "2022-09-12 18:07:24,555 epoch 38 - iter 3072/3843 - loss 0.11068853 - samples/sec: 393.96 - lr: 0.050000\n",
            "2022-09-12 18:08:09,587 epoch 38 - iter 3456/3843 - loss 0.11057893 - samples/sec: 364.04 - lr: 0.050000\n",
            "2022-09-12 18:08:54,024 epoch 38 - iter 3840/3843 - loss 0.11029502 - samples/sec: 371.22 - lr: 0.050000\n",
            "2022-09-12 18:08:54,371 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 18:08:54,373 EPOCH 38 done: loss 0.1103 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:17<00:00,  5.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 18:10:11,667 Evaluating as a multi-label problem: False\n",
            "2022-09-12 18:10:11,931 DEV : loss 0.07896864414215088 - f1-score (micro avg)  0.7889\n",
            "2022-09-12 18:10:22,404 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 18:10:22,406 saving best model\n",
            "2022-09-12 18:10:25,528 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 18:11:11,069 epoch 39 - iter 384/3843 - loss 0.10958459 - samples/sec: 392.13 - lr: 0.050000\n",
            "2022-09-12 18:11:57,562 epoch 39 - iter 768/3843 - loss 0.11027334 - samples/sec: 383.21 - lr: 0.050000\n",
            "2022-09-12 18:12:43,438 epoch 39 - iter 1152/3843 - loss 0.10998219 - samples/sec: 372.35 - lr: 0.050000\n",
            "2022-09-12 18:13:28,146 epoch 39 - iter 1536/3843 - loss 0.11000468 - samples/sec: 368.51 - lr: 0.050000\n",
            "2022-09-12 18:14:13,785 epoch 39 - iter 1920/3843 - loss 0.10979929 - samples/sec: 342.35 - lr: 0.050000\n",
            "2022-09-12 18:14:58,244 epoch 39 - iter 2304/3843 - loss 0.10984500 - samples/sec: 388.20 - lr: 0.050000\n",
            "2022-09-12 18:15:44,146 epoch 39 - iter 2688/3843 - loss 0.10949897 - samples/sec: 372.17 - lr: 0.050000\n",
            "2022-09-12 18:16:28,529 epoch 39 - iter 3072/3843 - loss 0.10945776 - samples/sec: 372.91 - lr: 0.050000\n",
            "2022-09-12 18:17:13,400 epoch 39 - iter 3456/3843 - loss 0.10966161 - samples/sec: 365.83 - lr: 0.050000\n",
            "2022-09-12 18:17:58,285 epoch 39 - iter 3840/3843 - loss 0.10977009 - samples/sec: 366.31 - lr: 0.050000\n",
            "2022-09-12 18:17:58,581 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 18:17:58,583 EPOCH 39 done: loss 0.1098 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 18:19:13,438 Evaluating as a multi-label problem: False\n",
            "2022-09-12 18:19:13,694 DEV : loss 0.07918812334537506 - f1-score (micro avg)  0.7884\n",
            "2022-09-12 18:19:25,946 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 18:19:25,948 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 18:20:11,245 epoch 40 - iter 384/3843 - loss 0.10851256 - samples/sec: 382.78 - lr: 0.050000\n",
            "2022-09-12 18:20:57,575 epoch 40 - iter 768/3843 - loss 0.10879674 - samples/sec: 351.46 - lr: 0.050000\n",
            "2022-09-12 18:21:41,221 epoch 40 - iter 1152/3843 - loss 0.10885793 - samples/sec: 379.54 - lr: 0.050000\n",
            "2022-09-12 18:22:27,477 epoch 40 - iter 1536/3843 - loss 0.10898868 - samples/sec: 336.67 - lr: 0.050000\n",
            "2022-09-12 18:23:10,408 epoch 40 - iter 1920/3843 - loss 0.10915605 - samples/sec: 408.27 - lr: 0.050000\n",
            "2022-09-12 18:23:56,234 epoch 40 - iter 2304/3843 - loss 0.10936617 - samples/sec: 373.66 - lr: 0.050000\n",
            "2022-09-12 18:24:42,538 epoch 40 - iter 2688/3843 - loss 0.10968344 - samples/sec: 387.61 - lr: 0.050000\n",
            "2022-09-12 18:25:26,533 epoch 40 - iter 3072/3843 - loss 0.10985070 - samples/sec: 375.25 - lr: 0.050000\n",
            "2022-09-12 18:26:12,202 epoch 40 - iter 3456/3843 - loss 0.10975784 - samples/sec: 375.01 - lr: 0.050000\n",
            "2022-09-12 18:26:55,773 epoch 40 - iter 3840/3843 - loss 0.10978870 - samples/sec: 363.79 - lr: 0.050000\n",
            "2022-09-12 18:26:56,058 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 18:26:56,059 EPOCH 40 done: loss 0.1098 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 18:28:12,912 Evaluating as a multi-label problem: False\n",
            "2022-09-12 18:28:13,182 DEV : loss 0.07944537699222565 - f1-score (micro avg)  0.7882\n",
            "2022-09-12 18:28:23,747 BAD EPOCHS (no improvement): 2\n",
            "2022-09-12 18:28:23,750 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 18:29:11,913 epoch 41 - iter 384/3843 - loss 0.10771189 - samples/sec: 335.71 - lr: 0.050000\n",
            "2022-09-12 18:29:58,483 epoch 41 - iter 768/3843 - loss 0.10837143 - samples/sec: 364.05 - lr: 0.050000\n",
            "2022-09-12 18:30:41,705 epoch 41 - iter 1152/3843 - loss 0.10863430 - samples/sec: 405.68 - lr: 0.050000\n",
            "2022-09-12 18:31:27,076 epoch 41 - iter 1536/3843 - loss 0.10855931 - samples/sec: 378.33 - lr: 0.050000\n",
            "2022-09-12 18:32:10,596 epoch 41 - iter 1920/3843 - loss 0.10855481 - samples/sec: 401.10 - lr: 0.050000\n",
            "2022-09-12 18:32:56,606 epoch 41 - iter 2304/3843 - loss 0.10875451 - samples/sec: 371.40 - lr: 0.050000\n",
            "2022-09-12 18:33:41,736 epoch 41 - iter 2688/3843 - loss 0.10868439 - samples/sec: 384.59 - lr: 0.050000\n",
            "2022-09-12 18:34:26,993 epoch 41 - iter 3072/3843 - loss 0.10891836 - samples/sec: 362.77 - lr: 0.050000\n",
            "2022-09-12 18:35:12,592 epoch 41 - iter 3456/3843 - loss 0.10908097 - samples/sec: 375.96 - lr: 0.050000\n",
            "2022-09-12 18:35:56,944 epoch 41 - iter 3840/3843 - loss 0.10918920 - samples/sec: 373.06 - lr: 0.050000\n",
            "2022-09-12 18:35:57,245 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 18:35:57,247 EPOCH 41 done: loss 0.1092 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 18:37:14,283 Evaluating as a multi-label problem: False\n",
            "2022-09-12 18:37:14,549 DEV : loss 0.0789596363902092 - f1-score (micro avg)  0.7875\n",
            "2022-09-12 18:37:24,964 BAD EPOCHS (no improvement): 3\n",
            "2022-09-12 18:37:24,966 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 18:38:12,708 epoch 42 - iter 384/3843 - loss 0.11040025 - samples/sec: 369.20 - lr: 0.050000\n",
            "2022-09-12 18:38:57,299 epoch 42 - iter 768/3843 - loss 0.11013960 - samples/sec: 387.71 - lr: 0.050000\n",
            "2022-09-12 18:39:41,737 epoch 42 - iter 1152/3843 - loss 0.11019757 - samples/sec: 389.24 - lr: 0.050000\n",
            "2022-09-12 18:40:24,675 epoch 42 - iter 1536/3843 - loss 0.10988065 - samples/sec: 407.75 - lr: 0.050000\n",
            "2022-09-12 18:41:10,188 epoch 42 - iter 1920/3843 - loss 0.10905846 - samples/sec: 376.15 - lr: 0.050000\n",
            "2022-09-12 18:41:53,510 epoch 42 - iter 2304/3843 - loss 0.10902121 - samples/sec: 384.06 - lr: 0.050000\n",
            "2022-09-12 18:42:41,544 epoch 42 - iter 2688/3843 - loss 0.10917925 - samples/sec: 352.17 - lr: 0.050000\n",
            "2022-09-12 18:43:26,847 epoch 42 - iter 3072/3843 - loss 0.10943408 - samples/sec: 379.53 - lr: 0.050000\n",
            "2022-09-12 18:44:11,720 epoch 42 - iter 3456/3843 - loss 0.10941591 - samples/sec: 366.61 - lr: 0.050000\n",
            "2022-09-12 18:44:57,302 epoch 42 - iter 3840/3843 - loss 0.10939340 - samples/sec: 359.09 - lr: 0.050000\n",
            "2022-09-12 18:44:57,524 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 18:44:57,526 EPOCH 42 done: loss 0.1094 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 18:46:12,618 Evaluating as a multi-label problem: False\n",
            "2022-09-12 18:46:12,873 DEV : loss 0.07964200526475906 - f1-score (micro avg)  0.7902\n",
            "2022-09-12 18:46:25,084 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 18:46:25,086 saving best model\n",
            "2022-09-12 18:46:28,221 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 18:47:14,468 epoch 43 - iter 384/3843 - loss 0.10766226 - samples/sec: 389.31 - lr: 0.050000\n",
            "2022-09-12 18:47:57,878 epoch 43 - iter 768/3843 - loss 0.10857585 - samples/sec: 401.62 - lr: 0.050000\n",
            "2022-09-12 18:48:43,882 epoch 43 - iter 1152/3843 - loss 0.10846478 - samples/sec: 369.98 - lr: 0.050000\n",
            "2022-09-12 18:49:28,017 epoch 43 - iter 1536/3843 - loss 0.10832415 - samples/sec: 341.88 - lr: 0.050000\n",
            "2022-09-12 18:50:14,323 epoch 43 - iter 1920/3843 - loss 0.10818987 - samples/sec: 385.34 - lr: 0.050000\n",
            "2022-09-12 18:50:59,148 epoch 43 - iter 2304/3843 - loss 0.10844267 - samples/sec: 370.03 - lr: 0.050000\n",
            "2022-09-12 18:51:44,913 epoch 43 - iter 2688/3843 - loss 0.10835888 - samples/sec: 392.63 - lr: 0.050000\n",
            "2022-09-12 18:52:30,772 epoch 43 - iter 3072/3843 - loss 0.10839570 - samples/sec: 373.11 - lr: 0.050000\n",
            "2022-09-12 18:53:13,808 epoch 43 - iter 3456/3843 - loss 0.10874289 - samples/sec: 388.31 - lr: 0.050000\n",
            "2022-09-12 18:53:59,155 epoch 43 - iter 3840/3843 - loss 0.10895731 - samples/sec: 378.59 - lr: 0.050000\n",
            "2022-09-12 18:53:59,446 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 18:53:59,448 EPOCH 43 done: loss 0.1090 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 18:55:15,944 Evaluating as a multi-label problem: False\n",
            "2022-09-12 18:55:16,201 DEV : loss 0.0776829868555069 - f1-score (micro avg)  0.7915\n",
            "2022-09-12 18:55:28,243 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 18:55:28,246 saving best model\n",
            "2022-09-12 18:55:31,343 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 18:56:17,958 epoch 44 - iter 384/3843 - loss 0.10805751 - samples/sec: 380.82 - lr: 0.050000\n",
            "2022-09-12 18:57:04,769 epoch 44 - iter 768/3843 - loss 0.10775377 - samples/sec: 361.36 - lr: 0.050000\n",
            "2022-09-12 18:57:49,426 epoch 44 - iter 1152/3843 - loss 0.10715942 - samples/sec: 385.70 - lr: 0.050000\n",
            "2022-09-12 18:58:34,397 epoch 44 - iter 1536/3843 - loss 0.10768897 - samples/sec: 401.97 - lr: 0.050000\n",
            "2022-09-12 18:59:18,662 epoch 44 - iter 1920/3843 - loss 0.10800460 - samples/sec: 390.90 - lr: 0.050000\n",
            "2022-09-12 19:00:05,244 epoch 44 - iter 2304/3843 - loss 0.10796137 - samples/sec: 352.13 - lr: 0.050000\n",
            "2022-09-12 19:00:48,519 epoch 44 - iter 2688/3843 - loss 0.10827479 - samples/sec: 365.70 - lr: 0.050000\n",
            "2022-09-12 19:01:33,386 epoch 44 - iter 3072/3843 - loss 0.10829913 - samples/sec: 403.93 - lr: 0.050000\n",
            "2022-09-12 19:02:18,280 epoch 44 - iter 3456/3843 - loss 0.10844207 - samples/sec: 402.29 - lr: 0.050000\n",
            "2022-09-12 19:03:01,059 epoch 44 - iter 3840/3843 - loss 0.10862816 - samples/sec: 389.87 - lr: 0.050000\n",
            "2022-09-12 19:03:01,330 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:03:01,332 EPOCH 44 done: loss 0.1086 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:17<00:00,  5.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 19:04:19,011 Evaluating as a multi-label problem: False\n",
            "2022-09-12 19:04:19,262 DEV : loss 0.07870158553123474 - f1-score (micro avg)  0.7904\n",
            "2022-09-12 19:04:29,764 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 19:04:29,767 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:05:16,270 epoch 45 - iter 384/3843 - loss 0.10718927 - samples/sec: 362.47 - lr: 0.050000\n",
            "2022-09-12 19:06:00,213 epoch 45 - iter 768/3843 - loss 0.10743436 - samples/sec: 376.30 - lr: 0.050000\n",
            "2022-09-12 19:06:45,695 epoch 45 - iter 1152/3843 - loss 0.10729300 - samples/sec: 395.85 - lr: 0.050000\n",
            "2022-09-12 19:07:30,467 epoch 45 - iter 1536/3843 - loss 0.10740650 - samples/sec: 367.15 - lr: 0.050000\n",
            "2022-09-12 19:08:16,329 epoch 45 - iter 1920/3843 - loss 0.10759717 - samples/sec: 393.45 - lr: 0.050000\n",
            "2022-09-12 19:09:01,175 epoch 45 - iter 2304/3843 - loss 0.10784895 - samples/sec: 384.82 - lr: 0.050000\n",
            "2022-09-12 19:09:45,564 epoch 45 - iter 2688/3843 - loss 0.10820749 - samples/sec: 390.10 - lr: 0.050000\n",
            "2022-09-12 19:10:31,268 epoch 45 - iter 3072/3843 - loss 0.10834556 - samples/sec: 393.01 - lr: 0.050000\n",
            "2022-09-12 19:11:16,380 epoch 45 - iter 3456/3843 - loss 0.10843454 - samples/sec: 381.80 - lr: 0.050000\n",
            "2022-09-12 19:12:01,706 epoch 45 - iter 3840/3843 - loss 0.10856525 - samples/sec: 397.81 - lr: 0.050000\n",
            "2022-09-12 19:12:01,981 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:12:01,982 EPOCH 45 done: loss 0.1086 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 19:13:18,307 Evaluating as a multi-label problem: False\n",
            "2022-09-12 19:13:18,572 DEV : loss 0.07803124189376831 - f1-score (micro avg)  0.7924\n",
            "2022-09-12 19:13:30,715 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 19:13:30,718 saving best model\n",
            "2022-09-12 19:13:33,844 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:14:19,266 epoch 46 - iter 384/3843 - loss 0.10772673 - samples/sec: 396.35 - lr: 0.050000\n",
            "2022-09-12 19:15:03,145 epoch 46 - iter 768/3843 - loss 0.10797170 - samples/sec: 377.05 - lr: 0.050000\n",
            "2022-09-12 19:15:48,642 epoch 46 - iter 1152/3843 - loss 0.10820069 - samples/sec: 375.64 - lr: 0.050000\n",
            "2022-09-12 19:16:36,263 epoch 46 - iter 1536/3843 - loss 0.10799947 - samples/sec: 356.37 - lr: 0.050000\n",
            "2022-09-12 19:17:19,670 epoch 46 - iter 1920/3843 - loss 0.10812456 - samples/sec: 365.22 - lr: 0.050000\n",
            "2022-09-12 19:18:04,888 epoch 46 - iter 2304/3843 - loss 0.10858058 - samples/sec: 398.66 - lr: 0.050000\n",
            "2022-09-12 19:18:49,325 epoch 46 - iter 2688/3843 - loss 0.10822699 - samples/sec: 370.22 - lr: 0.050000\n",
            "2022-09-12 19:19:35,044 epoch 46 - iter 3072/3843 - loss 0.10821077 - samples/sec: 341.24 - lr: 0.050000\n",
            "2022-09-12 19:20:18,927 epoch 46 - iter 3456/3843 - loss 0.10821735 - samples/sec: 396.99 - lr: 0.050000\n",
            "2022-09-12 19:21:07,333 epoch 46 - iter 3840/3843 - loss 0.10828487 - samples/sec: 350.25 - lr: 0.050000\n",
            "2022-09-12 19:21:07,588 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:21:07,589 EPOCH 46 done: loss 0.1083 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:17<00:00,  5.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 19:22:24,746 Evaluating as a multi-label problem: False\n",
            "2022-09-12 19:22:25,017 DEV : loss 0.0777747631072998 - f1-score (micro avg)  0.7925\n",
            "2022-09-12 19:22:35,507 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 19:22:35,509 saving best model\n",
            "2022-09-12 19:22:38,658 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:23:24,026 epoch 47 - iter 384/3843 - loss 0.10763671 - samples/sec: 376.04 - lr: 0.050000\n",
            "2022-09-12 19:24:09,920 epoch 47 - iter 768/3843 - loss 0.10762861 - samples/sec: 354.93 - lr: 0.050000\n",
            "2022-09-12 19:24:58,863 epoch 47 - iter 1152/3843 - loss 0.10786365 - samples/sec: 342.18 - lr: 0.050000\n",
            "2022-09-12 19:25:43,008 epoch 47 - iter 1536/3843 - loss 0.10803722 - samples/sec: 341.40 - lr: 0.050000\n",
            "2022-09-12 19:26:27,524 epoch 47 - iter 1920/3843 - loss 0.10811468 - samples/sec: 387.29 - lr: 0.050000\n",
            "2022-09-12 19:27:11,032 epoch 47 - iter 2304/3843 - loss 0.10827869 - samples/sec: 381.24 - lr: 0.050000\n",
            "2022-09-12 19:27:56,706 epoch 47 - iter 2688/3843 - loss 0.10804299 - samples/sec: 392.45 - lr: 0.050000\n",
            "2022-09-12 19:28:40,424 epoch 47 - iter 3072/3843 - loss 0.10816242 - samples/sec: 379.79 - lr: 0.050000\n",
            "2022-09-12 19:29:26,772 epoch 47 - iter 3456/3843 - loss 0.10824931 - samples/sec: 389.24 - lr: 0.050000\n",
            "2022-09-12 19:30:12,169 epoch 47 - iter 3840/3843 - loss 0.10843878 - samples/sec: 377.96 - lr: 0.050000\n",
            "2022-09-12 19:30:12,488 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:30:12,490 EPOCH 47 done: loss 0.1084 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 19:31:27,999 Evaluating as a multi-label problem: False\n",
            "2022-09-12 19:31:28,260 DEV : loss 0.07740466296672821 - f1-score (micro avg)  0.7916\n",
            "2022-09-12 19:31:40,437 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 19:31:40,440 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:32:25,223 epoch 48 - iter 384/3843 - loss 0.10745341 - samples/sec: 369.17 - lr: 0.050000\n",
            "2022-09-12 19:33:11,834 epoch 48 - iter 768/3843 - loss 0.10755033 - samples/sec: 384.53 - lr: 0.050000\n",
            "2022-09-12 19:33:58,707 epoch 48 - iter 1152/3843 - loss 0.10826063 - samples/sec: 362.58 - lr: 0.050000\n",
            "2022-09-12 19:34:43,358 epoch 48 - iter 1536/3843 - loss 0.10802613 - samples/sec: 368.12 - lr: 0.050000\n",
            "2022-09-12 19:35:29,461 epoch 48 - iter 1920/3843 - loss 0.10803762 - samples/sec: 370.15 - lr: 0.050000\n",
            "2022-09-12 19:36:14,915 epoch 48 - iter 2304/3843 - loss 0.10846073 - samples/sec: 378.29 - lr: 0.050000\n",
            "2022-09-12 19:36:59,471 epoch 48 - iter 2688/3843 - loss 0.10854552 - samples/sec: 372.07 - lr: 0.050000\n",
            "2022-09-12 19:37:46,715 epoch 48 - iter 3072/3843 - loss 0.10866113 - samples/sec: 358.01 - lr: 0.050000\n",
            "2022-09-12 19:38:31,535 epoch 48 - iter 3456/3843 - loss 0.10863787 - samples/sec: 350.59 - lr: 0.050000\n",
            "2022-09-12 19:39:17,203 epoch 48 - iter 3840/3843 - loss 0.10849994 - samples/sec: 374.82 - lr: 0.050000\n",
            "2022-09-12 19:39:17,490 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:39:17,492 EPOCH 48 done: loss 0.1085 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 19:40:33,191 Evaluating as a multi-label problem: False\n",
            "2022-09-12 19:40:33,456 DEV : loss 0.0776827484369278 - f1-score (micro avg)  0.7912\n",
            "2022-09-12 19:40:45,690 BAD EPOCHS (no improvement): 2\n",
            "2022-09-12 19:40:45,692 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:41:31,441 epoch 49 - iter 384/3843 - loss 0.10837748 - samples/sec: 378.97 - lr: 0.050000\n",
            "2022-09-12 19:42:16,457 epoch 49 - iter 768/3843 - loss 0.10790288 - samples/sec: 364.52 - lr: 0.050000\n",
            "2022-09-12 19:43:02,073 epoch 49 - iter 1152/3843 - loss 0.10783544 - samples/sec: 357.57 - lr: 0.050000\n",
            "2022-09-12 19:43:45,599 epoch 49 - iter 1536/3843 - loss 0.10793977 - samples/sec: 400.30 - lr: 0.050000\n",
            "2022-09-12 19:44:30,842 epoch 49 - iter 1920/3843 - loss 0.10808156 - samples/sec: 379.33 - lr: 0.050000\n",
            "2022-09-12 19:45:17,084 epoch 49 - iter 2304/3843 - loss 0.10815895 - samples/sec: 353.45 - lr: 0.050000\n",
            "2022-09-12 19:46:00,363 epoch 49 - iter 2688/3843 - loss 0.10811492 - samples/sec: 404.92 - lr: 0.050000\n",
            "2022-09-12 19:46:46,179 epoch 49 - iter 3072/3843 - loss 0.10813125 - samples/sec: 372.71 - lr: 0.050000\n",
            "2022-09-12 19:47:29,605 epoch 49 - iter 3456/3843 - loss 0.10810876 - samples/sec: 364.79 - lr: 0.050000\n",
            "2022-09-12 19:48:15,960 epoch 49 - iter 3840/3843 - loss 0.10806770 - samples/sec: 384.67 - lr: 0.050000\n",
            "2022-09-12 19:48:16,198 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:48:16,200 EPOCH 49 done: loss 0.1081 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 19:49:32,082 Evaluating as a multi-label problem: False\n",
            "2022-09-12 19:49:32,346 DEV : loss 0.07743784040212631 - f1-score (micro avg)  0.793\n",
            "2022-09-12 19:49:44,562 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 19:49:44,565 saving best model\n",
            "2022-09-12 19:49:47,667 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:50:32,978 epoch 50 - iter 384/3843 - loss 0.10675868 - samples/sec: 360.41 - lr: 0.050000\n",
            "2022-09-12 19:51:18,470 epoch 50 - iter 768/3843 - loss 0.10753493 - samples/sec: 358.71 - lr: 0.050000\n",
            "2022-09-12 19:52:01,743 epoch 50 - iter 1152/3843 - loss 0.10787601 - samples/sec: 403.29 - lr: 0.050000\n",
            "2022-09-12 19:52:47,236 epoch 50 - iter 1536/3843 - loss 0.10775681 - samples/sec: 395.03 - lr: 0.050000\n",
            "2022-09-12 19:53:32,548 epoch 50 - iter 1920/3843 - loss 0.10811932 - samples/sec: 349.79 - lr: 0.050000\n",
            "2022-09-12 19:54:18,837 epoch 50 - iter 2304/3843 - loss 0.10793775 - samples/sec: 367.72 - lr: 0.050000\n",
            "2022-09-12 19:55:02,574 epoch 50 - iter 2688/3843 - loss 0.10774368 - samples/sec: 345.64 - lr: 0.050000\n",
            "2022-09-12 19:55:47,646 epoch 50 - iter 3072/3843 - loss 0.10760701 - samples/sec: 347.89 - lr: 0.050000\n",
            "2022-09-12 19:56:33,102 epoch 50 - iter 3456/3843 - loss 0.10771513 - samples/sec: 376.93 - lr: 0.050000\n",
            "2022-09-12 19:57:17,919 epoch 50 - iter 3840/3843 - loss 0.10778335 - samples/sec: 389.12 - lr: 0.050000\n",
            "2022-09-12 19:57:18,181 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:57:18,183 EPOCH 50 done: loss 0.1078 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 19:58:34,952 Evaluating as a multi-label problem: False\n",
            "2022-09-12 19:58:35,207 DEV : loss 0.0777691900730133 - f1-score (micro avg)  0.7913\n",
            "2022-09-12 19:58:45,686 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 19:58:45,688 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 19:59:32,172 epoch 51 - iter 384/3843 - loss 0.10817004 - samples/sec: 348.97 - lr: 0.050000\n",
            "2022-09-12 20:00:15,948 epoch 51 - iter 768/3843 - loss 0.10740287 - samples/sec: 377.46 - lr: 0.050000\n",
            "2022-09-12 20:01:01,225 epoch 51 - iter 1152/3843 - loss 0.10781658 - samples/sec: 399.18 - lr: 0.050000\n",
            "2022-09-12 20:01:46,202 epoch 51 - iter 1536/3843 - loss 0.10734450 - samples/sec: 353.15 - lr: 0.050000\n",
            "2022-09-12 20:02:30,829 epoch 51 - iter 1920/3843 - loss 0.10762260 - samples/sec: 407.74 - lr: 0.050000\n",
            "2022-09-12 20:03:17,959 epoch 51 - iter 2304/3843 - loss 0.10780040 - samples/sec: 329.53 - lr: 0.050000\n",
            "2022-09-12 20:04:02,598 epoch 51 - iter 2688/3843 - loss 0.10792121 - samples/sec: 352.41 - lr: 0.050000\n",
            "2022-09-12 20:04:47,999 epoch 51 - iter 3072/3843 - loss 0.10776008 - samples/sec: 377.82 - lr: 0.050000\n",
            "2022-09-12 20:05:33,767 epoch 51 - iter 3456/3843 - loss 0.10780860 - samples/sec: 358.87 - lr: 0.050000\n",
            "2022-09-12 20:06:18,340 epoch 51 - iter 3840/3843 - loss 0.10781699 - samples/sec: 408.33 - lr: 0.050000\n",
            "2022-09-12 20:06:18,579 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 20:06:18,580 EPOCH 51 done: loss 0.1078 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 20:07:35,391 Evaluating as a multi-label problem: False\n",
            "2022-09-12 20:07:35,649 DEV : loss 0.07719560712575912 - f1-score (micro avg)  0.7931\n",
            "2022-09-12 20:07:46,150 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 20:07:46,152 saving best model\n",
            "2022-09-12 20:07:49,269 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 20:08:36,828 epoch 52 - iter 384/3843 - loss 0.10747304 - samples/sec: 353.30 - lr: 0.050000\n",
            "2022-09-12 20:09:22,470 epoch 52 - iter 768/3843 - loss 0.10734201 - samples/sec: 377.22 - lr: 0.050000\n",
            "2022-09-12 20:10:07,411 epoch 52 - iter 1152/3843 - loss 0.10733692 - samples/sec: 349.65 - lr: 0.050000\n",
            "2022-09-12 20:10:51,906 epoch 52 - iter 1536/3843 - loss 0.10706719 - samples/sec: 388.06 - lr: 0.050000\n",
            "2022-09-12 20:11:36,997 epoch 52 - iter 1920/3843 - loss 0.10677388 - samples/sec: 401.62 - lr: 0.050000\n",
            "2022-09-12 20:12:20,386 epoch 52 - iter 2304/3843 - loss 0.10730700 - samples/sec: 366.06 - lr: 0.050000\n",
            "2022-09-12 20:13:05,532 epoch 52 - iter 2688/3843 - loss 0.10736328 - samples/sec: 381.42 - lr: 0.050000\n",
            "2022-09-12 20:13:50,328 epoch 52 - iter 3072/3843 - loss 0.10753462 - samples/sec: 389.09 - lr: 0.050000\n",
            "2022-09-12 20:14:35,148 epoch 52 - iter 3456/3843 - loss 0.10744572 - samples/sec: 405.18 - lr: 0.050000\n",
            "2022-09-12 20:15:19,455 epoch 52 - iter 3840/3843 - loss 0.10751980 - samples/sec: 372.98 - lr: 0.050000\n",
            "2022-09-12 20:15:21,411 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 20:15:21,413 EPOCH 52 done: loss 0.1075 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 20:16:36,767 Evaluating as a multi-label problem: False\n",
            "2022-09-12 20:16:37,039 DEV : loss 0.07834067940711975 - f1-score (micro avg)  0.7921\n",
            "2022-09-12 20:16:47,583 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 20:16:47,586 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 20:17:35,846 epoch 53 - iter 384/3843 - loss 0.10678781 - samples/sec: 380.97 - lr: 0.050000\n",
            "2022-09-12 20:18:21,452 epoch 53 - iter 768/3843 - loss 0.10639046 - samples/sec: 395.11 - lr: 0.050000\n",
            "2022-09-12 20:19:05,992 epoch 53 - iter 1152/3843 - loss 0.10712580 - samples/sec: 339.01 - lr: 0.050000\n",
            "2022-09-12 20:19:53,890 epoch 53 - iter 1536/3843 - loss 0.10715950 - samples/sec: 338.03 - lr: 0.050000\n",
            "2022-09-12 20:20:39,260 epoch 53 - iter 1920/3843 - loss 0.10725195 - samples/sec: 364.42 - lr: 0.050000\n",
            "2022-09-12 20:21:27,587 epoch 53 - iter 2304/3843 - loss 0.10720148 - samples/sec: 353.15 - lr: 0.050000\n",
            "2022-09-12 20:22:14,719 epoch 53 - iter 2688/3843 - loss 0.10706257 - samples/sec: 379.24 - lr: 0.050000\n",
            "2022-09-12 20:22:59,165 epoch 53 - iter 3072/3843 - loss 0.10708948 - samples/sec: 325.44 - lr: 0.050000\n",
            "2022-09-12 20:23:45,171 epoch 53 - iter 3456/3843 - loss 0.10725387 - samples/sec: 391.63 - lr: 0.050000\n",
            "2022-09-12 20:24:29,927 epoch 53 - iter 3840/3843 - loss 0.10731455 - samples/sec: 351.97 - lr: 0.050000\n",
            "2022-09-12 20:24:30,186 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 20:24:30,188 EPOCH 53 done: loss 0.1073 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:18<00:00,  5.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 20:25:48,922 Evaluating as a multi-label problem: False\n",
            "2022-09-12 20:25:49,195 DEV : loss 0.0773114264011383 - f1-score (micro avg)  0.792\n",
            "2022-09-12 20:25:59,777 BAD EPOCHS (no improvement): 2\n",
            "2022-09-12 20:25:59,779 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 20:26:46,933 epoch 54 - iter 384/3843 - loss 0.10800180 - samples/sec: 391.39 - lr: 0.050000\n",
            "2022-09-12 20:27:30,986 epoch 54 - iter 768/3843 - loss 0.10728076 - samples/sec: 375.15 - lr: 0.050000\n",
            "2022-09-12 20:28:16,498 epoch 54 - iter 1152/3843 - loss 0.10760243 - samples/sec: 359.56 - lr: 0.050000\n",
            "2022-09-12 20:29:01,585 epoch 54 - iter 1536/3843 - loss 0.10710656 - samples/sec: 335.43 - lr: 0.050000\n",
            "2022-09-12 20:29:46,957 epoch 54 - iter 1920/3843 - loss 0.10721509 - samples/sec: 360.95 - lr: 0.050000\n",
            "2022-09-12 20:30:33,008 epoch 54 - iter 2304/3843 - loss 0.10723325 - samples/sec: 371.03 - lr: 0.050000\n",
            "2022-09-12 20:31:17,549 epoch 54 - iter 2688/3843 - loss 0.10718405 - samples/sec: 370.18 - lr: 0.050000\n",
            "2022-09-12 20:32:03,694 epoch 54 - iter 3072/3843 - loss 0.10730021 - samples/sec: 369.97 - lr: 0.050000\n",
            "2022-09-12 20:32:50,517 epoch 54 - iter 3456/3843 - loss 0.10723916 - samples/sec: 364.86 - lr: 0.050000\n",
            "2022-09-12 20:33:38,042 epoch 54 - iter 3840/3843 - loss 0.10724343 - samples/sec: 339.53 - lr: 0.050000\n",
            "2022-09-12 20:33:38,303 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 20:33:38,305 EPOCH 54 done: loss 0.1073 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:17<00:00,  5.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 20:34:55,525 Evaluating as a multi-label problem: False\n",
            "2022-09-12 20:34:55,799 DEV : loss 0.07632597535848618 - f1-score (micro avg)  0.7942\n",
            "2022-09-12 20:35:06,277 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 20:35:06,279 saving best model\n",
            "2022-09-12 20:35:09,543 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 20:35:56,387 epoch 55 - iter 384/3843 - loss 0.10739708 - samples/sec: 360.90 - lr: 0.050000\n",
            "2022-09-12 20:36:43,085 epoch 55 - iter 768/3843 - loss 0.10756331 - samples/sec: 349.37 - lr: 0.050000\n",
            "2022-09-12 20:37:27,063 epoch 55 - iter 1152/3843 - loss 0.10720278 - samples/sec: 375.98 - lr: 0.050000\n",
            "2022-09-12 20:38:13,488 epoch 55 - iter 1536/3843 - loss 0.10728294 - samples/sec: 366.27 - lr: 0.050000\n",
            "2022-09-12 20:38:58,411 epoch 55 - iter 1920/3843 - loss 0.10693625 - samples/sec: 403.23 - lr: 0.050000\n",
            "2022-09-12 20:39:42,169 epoch 55 - iter 2304/3843 - loss 0.10694378 - samples/sec: 379.90 - lr: 0.050000\n",
            "2022-09-12 20:40:27,907 epoch 55 - iter 2688/3843 - loss 0.10689412 - samples/sec: 357.04 - lr: 0.050000\n",
            "2022-09-12 20:41:12,931 epoch 55 - iter 3072/3843 - loss 0.10672309 - samples/sec: 383.12 - lr: 0.050000\n",
            "2022-09-12 20:41:58,523 epoch 55 - iter 3456/3843 - loss 0.10689263 - samples/sec: 375.99 - lr: 0.050000\n",
            "2022-09-12 20:42:42,741 epoch 55 - iter 3840/3843 - loss 0.10708896 - samples/sec: 374.28 - lr: 0.050000\n",
            "2022-09-12 20:42:44,730 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 20:42:44,732 EPOCH 55 done: loss 0.1071 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 20:44:00,656 Evaluating as a multi-label problem: False\n",
            "2022-09-12 20:44:00,924 DEV : loss 0.07641249895095825 - f1-score (micro avg)  0.7946\n",
            "2022-09-12 20:44:13,253 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 20:44:13,256 saving best model\n",
            "2022-09-12 20:44:16,837 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 20:45:03,027 epoch 56 - iter 384/3843 - loss 0.10513534 - samples/sec: 356.65 - lr: 0.050000\n",
            "2022-09-12 20:45:49,260 epoch 56 - iter 768/3843 - loss 0.10658369 - samples/sec: 367.69 - lr: 0.050000\n",
            "2022-09-12 20:46:34,770 epoch 56 - iter 1152/3843 - loss 0.10690086 - samples/sec: 359.67 - lr: 0.050000\n",
            "2022-09-12 20:47:21,359 epoch 56 - iter 1536/3843 - loss 0.10693860 - samples/sec: 363.95 - lr: 0.050000\n",
            "2022-09-12 20:48:05,356 epoch 56 - iter 1920/3843 - loss 0.10719269 - samples/sec: 376.59 - lr: 0.050000\n",
            "2022-09-12 20:48:51,682 epoch 56 - iter 2304/3843 - loss 0.10698130 - samples/sec: 351.23 - lr: 0.050000\n",
            "2022-09-12 20:49:35,275 epoch 56 - iter 2688/3843 - loss 0.10688287 - samples/sec: 381.06 - lr: 0.050000\n",
            "2022-09-12 20:50:20,404 epoch 56 - iter 3072/3843 - loss 0.10662273 - samples/sec: 363.14 - lr: 0.050000\n",
            "2022-09-12 20:51:05,794 epoch 56 - iter 3456/3843 - loss 0.10657343 - samples/sec: 377.94 - lr: 0.050000\n",
            "2022-09-12 20:51:50,612 epoch 56 - iter 3840/3843 - loss 0.10670548 - samples/sec: 385.27 - lr: 0.050000\n",
            "2022-09-12 20:51:50,898 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 20:51:50,900 EPOCH 56 done: loss 0.1067 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 20:53:07,461 Evaluating as a multi-label problem: False\n",
            "2022-09-12 20:53:07,723 DEV : loss 0.07685336470603943 - f1-score (micro avg)  0.7944\n",
            "2022-09-12 20:53:18,237 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 20:53:18,240 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 20:54:05,891 epoch 57 - iter 384/3843 - loss 0.10525378 - samples/sec: 352.91 - lr: 0.050000\n",
            "2022-09-12 20:54:49,238 epoch 57 - iter 768/3843 - loss 0.10572477 - samples/sec: 365.38 - lr: 0.050000\n",
            "2022-09-12 20:55:35,031 epoch 57 - iter 1152/3843 - loss 0.10631390 - samples/sec: 391.28 - lr: 0.050000\n",
            "2022-09-12 20:56:18,638 epoch 57 - iter 1536/3843 - loss 0.10642755 - samples/sec: 380.08 - lr: 0.050000\n",
            "2022-09-12 20:57:03,253 epoch 57 - iter 1920/3843 - loss 0.10634291 - samples/sec: 407.32 - lr: 0.050000\n",
            "2022-09-12 20:57:46,617 epoch 57 - iter 2304/3843 - loss 0.10650427 - samples/sec: 365.89 - lr: 0.050000\n",
            "2022-09-12 20:58:31,509 epoch 57 - iter 2688/3843 - loss 0.10656364 - samples/sec: 402.27 - lr: 0.050000\n",
            "2022-09-12 20:59:14,985 epoch 57 - iter 3072/3843 - loss 0.10655739 - samples/sec: 401.35 - lr: 0.050000\n",
            "2022-09-12 21:00:01,180 epoch 57 - iter 3456/3843 - loss 0.10635468 - samples/sec: 353.31 - lr: 0.050000\n",
            "2022-09-12 21:00:47,715 epoch 57 - iter 3840/3843 - loss 0.10662593 - samples/sec: 349.37 - lr: 0.050000\n",
            "2022-09-12 21:00:48,001 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:00:48,003 EPOCH 57 done: loss 0.1066 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 21:02:03,437 Evaluating as a multi-label problem: False\n",
            "2022-09-12 21:02:03,693 DEV : loss 0.07704223692417145 - f1-score (micro avg)  0.7955\n",
            "2022-09-12 21:02:15,935 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 21:02:15,938 saving best model\n",
            "2022-09-12 21:02:19,174 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:03:05,167 epoch 58 - iter 384/3843 - loss 0.10467307 - samples/sec: 390.58 - lr: 0.050000\n",
            "2022-09-12 21:03:48,898 epoch 58 - iter 768/3843 - loss 0.10504245 - samples/sec: 379.45 - lr: 0.050000\n",
            "2022-09-12 21:04:33,351 epoch 58 - iter 1152/3843 - loss 0.10526001 - samples/sec: 370.56 - lr: 0.050000\n",
            "2022-09-12 21:05:16,895 epoch 58 - iter 1536/3843 - loss 0.10572905 - samples/sec: 399.84 - lr: 0.050000\n",
            "2022-09-12 21:06:02,356 epoch 58 - iter 1920/3843 - loss 0.10588121 - samples/sec: 396.04 - lr: 0.050000\n",
            "2022-09-12 21:06:48,774 epoch 58 - iter 2304/3843 - loss 0.10613810 - samples/sec: 368.09 - lr: 0.050000\n",
            "2022-09-12 21:07:32,976 epoch 58 - iter 2688/3843 - loss 0.10645156 - samples/sec: 392.25 - lr: 0.050000\n",
            "2022-09-12 21:08:17,485 epoch 58 - iter 3072/3843 - loss 0.10633944 - samples/sec: 387.20 - lr: 0.050000\n",
            "2022-09-12 21:09:01,882 epoch 58 - iter 3456/3843 - loss 0.10647889 - samples/sec: 371.91 - lr: 0.050000\n",
            "2022-09-12 21:09:48,959 epoch 58 - iter 3840/3843 - loss 0.10668114 - samples/sec: 343.25 - lr: 0.050000\n",
            "2022-09-12 21:09:49,271 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:09:49,272 EPOCH 58 done: loss 0.1067 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 21:11:04,340 Evaluating as a multi-label problem: False\n",
            "2022-09-12 21:11:04,592 DEV : loss 0.07782962918281555 - f1-score (micro avg)  0.7935\n",
            "2022-09-12 21:11:16,743 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 21:11:16,746 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:12:01,710 epoch 59 - iter 384/3843 - loss 0.10606809 - samples/sec: 382.90 - lr: 0.050000\n",
            "2022-09-12 21:12:45,111 epoch 59 - iter 768/3843 - loss 0.10548497 - samples/sec: 347.65 - lr: 0.050000\n",
            "2022-09-12 21:13:28,916 epoch 59 - iter 1152/3843 - loss 0.10562983 - samples/sec: 395.78 - lr: 0.050000\n",
            "2022-09-12 21:14:15,585 epoch 59 - iter 1536/3843 - loss 0.10540154 - samples/sec: 379.89 - lr: 0.050000\n",
            "2022-09-12 21:14:58,811 epoch 59 - iter 1920/3843 - loss 0.10564608 - samples/sec: 383.25 - lr: 0.050000\n",
            "2022-09-12 21:15:43,586 epoch 59 - iter 2304/3843 - loss 0.10572243 - samples/sec: 383.83 - lr: 0.050000\n",
            "2022-09-12 21:16:27,440 epoch 59 - iter 2688/3843 - loss 0.10577081 - samples/sec: 396.27 - lr: 0.050000\n",
            "2022-09-12 21:17:12,173 epoch 59 - iter 3072/3843 - loss 0.10577261 - samples/sec: 403.42 - lr: 0.050000\n",
            "2022-09-12 21:17:56,267 epoch 59 - iter 3456/3843 - loss 0.10579062 - samples/sec: 373.14 - lr: 0.050000\n",
            "2022-09-12 21:18:40,837 epoch 59 - iter 3840/3843 - loss 0.10603821 - samples/sec: 406.04 - lr: 0.050000\n",
            "2022-09-12 21:18:41,117 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:18:41,119 EPOCH 59 done: loss 0.1061 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 21:19:57,687 Evaluating as a multi-label problem: False\n",
            "2022-09-12 21:19:57,938 DEV : loss 0.07680345326662064 - f1-score (micro avg)  0.7948\n",
            "2022-09-12 21:20:08,421 BAD EPOCHS (no improvement): 2\n",
            "2022-09-12 21:20:08,424 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:20:52,926 epoch 60 - iter 384/3843 - loss 0.10479571 - samples/sec: 367.43 - lr: 0.050000\n",
            "2022-09-12 21:21:38,324 epoch 60 - iter 768/3843 - loss 0.10514693 - samples/sec: 359.83 - lr: 0.050000\n",
            "2022-09-12 21:22:23,655 epoch 60 - iter 1152/3843 - loss 0.10516690 - samples/sec: 359.83 - lr: 0.050000\n",
            "2022-09-12 21:23:07,199 epoch 60 - iter 1536/3843 - loss 0.10513557 - samples/sec: 362.38 - lr: 0.050000\n",
            "2022-09-12 21:23:52,683 epoch 60 - iter 1920/3843 - loss 0.10553294 - samples/sec: 374.73 - lr: 0.050000\n",
            "2022-09-12 21:24:35,437 epoch 60 - iter 2304/3843 - loss 0.10585533 - samples/sec: 371.62 - lr: 0.050000\n",
            "2022-09-12 21:25:20,366 epoch 60 - iter 2688/3843 - loss 0.10598000 - samples/sec: 402.21 - lr: 0.050000\n",
            "2022-09-12 21:26:04,440 epoch 60 - iter 3072/3843 - loss 0.10597451 - samples/sec: 373.84 - lr: 0.050000\n",
            "2022-09-12 21:26:49,053 epoch 60 - iter 3456/3843 - loss 0.10611796 - samples/sec: 386.31 - lr: 0.050000\n",
            "2022-09-12 21:27:34,221 epoch 60 - iter 3840/3843 - loss 0.10612315 - samples/sec: 379.12 - lr: 0.050000\n",
            "2022-09-12 21:27:34,515 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:27:34,517 EPOCH 60 done: loss 0.1061 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 21:28:49,278 Evaluating as a multi-label problem: False\n",
            "2022-09-12 21:28:49,534 DEV : loss 0.07708876579999924 - f1-score (micro avg)  0.7962\n",
            "2022-09-12 21:29:01,984 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 21:29:01,988 saving best model\n",
            "2022-09-12 21:29:05,143 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:29:49,556 epoch 61 - iter 384/3843 - loss 0.10639145 - samples/sec: 393.21 - lr: 0.050000\n",
            "2022-09-12 21:30:34,105 epoch 61 - iter 768/3843 - loss 0.10687203 - samples/sec: 386.79 - lr: 0.050000\n",
            "2022-09-12 21:31:18,057 epoch 61 - iter 1152/3843 - loss 0.10630863 - samples/sec: 394.70 - lr: 0.050000\n",
            "2022-09-12 21:32:04,075 epoch 61 - iter 1536/3843 - loss 0.10641660 - samples/sec: 369.54 - lr: 0.050000\n",
            "2022-09-12 21:32:49,770 epoch 61 - iter 1920/3843 - loss 0.10616239 - samples/sec: 372.64 - lr: 0.050000\n",
            "2022-09-12 21:33:34,084 epoch 61 - iter 2304/3843 - loss 0.10637678 - samples/sec: 354.83 - lr: 0.050000\n",
            "2022-09-12 21:34:18,523 epoch 61 - iter 2688/3843 - loss 0.10633973 - samples/sec: 388.24 - lr: 0.050000\n",
            "2022-09-12 21:35:01,448 epoch 61 - iter 3072/3843 - loss 0.10611290 - samples/sec: 407.19 - lr: 0.050000\n",
            "2022-09-12 21:35:46,192 epoch 61 - iter 3456/3843 - loss 0.10599686 - samples/sec: 383.92 - lr: 0.050000\n",
            "2022-09-12 21:36:29,116 epoch 61 - iter 3840/3843 - loss 0.10605936 - samples/sec: 369.25 - lr: 0.050000\n",
            "2022-09-12 21:36:29,354 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:36:29,356 EPOCH 61 done: loss 0.1061 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 21:37:45,431 Evaluating as a multi-label problem: False\n",
            "2022-09-12 21:37:45,675 DEV : loss 0.07743775844573975 - f1-score (micro avg)  0.7951\n",
            "2022-09-12 21:37:56,134 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 21:37:56,136 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:38:42,429 epoch 62 - iter 384/3843 - loss 0.10507799 - samples/sec: 366.06 - lr: 0.050000\n",
            "2022-09-12 21:39:28,398 epoch 62 - iter 768/3843 - loss 0.10521886 - samples/sec: 325.48 - lr: 0.050000\n",
            "2022-09-12 21:40:11,616 epoch 62 - iter 1152/3843 - loss 0.10465357 - samples/sec: 349.80 - lr: 0.050000\n",
            "2022-09-12 21:40:56,792 epoch 62 - iter 1536/3843 - loss 0.10523966 - samples/sec: 378.54 - lr: 0.050000\n",
            "2022-09-12 21:41:40,849 epoch 62 - iter 1920/3843 - loss 0.10537225 - samples/sec: 358.21 - lr: 0.050000\n",
            "2022-09-12 21:42:25,171 epoch 62 - iter 2304/3843 - loss 0.10573015 - samples/sec: 388.23 - lr: 0.050000\n",
            "2022-09-12 21:43:08,212 epoch 62 - iter 2688/3843 - loss 0.10582671 - samples/sec: 386.78 - lr: 0.050000\n",
            "2022-09-12 21:43:53,450 epoch 62 - iter 3072/3843 - loss 0.10625366 - samples/sec: 346.35 - lr: 0.050000\n",
            "2022-09-12 21:44:39,071 epoch 62 - iter 3456/3843 - loss 0.10612220 - samples/sec: 375.30 - lr: 0.050000\n",
            "2022-09-12 21:45:22,732 epoch 62 - iter 3840/3843 - loss 0.10609854 - samples/sec: 362.38 - lr: 0.050000\n",
            "2022-09-12 21:45:23,116 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:45:23,118 EPOCH 62 done: loss 0.1061 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 21:46:39,635 Evaluating as a multi-label problem: False\n",
            "2022-09-12 21:46:39,896 DEV : loss 0.07659641653299332 - f1-score (micro avg)  0.7922\n",
            "2022-09-12 21:46:50,424 BAD EPOCHS (no improvement): 2\n",
            "2022-09-12 21:46:50,426 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:47:36,570 epoch 63 - iter 384/3843 - loss 0.10565657 - samples/sec: 402.81 - lr: 0.050000\n",
            "2022-09-12 21:48:20,036 epoch 63 - iter 768/3843 - loss 0.10659324 - samples/sec: 400.42 - lr: 0.050000\n",
            "2022-09-12 21:49:05,535 epoch 63 - iter 1152/3843 - loss 0.10642065 - samples/sec: 376.02 - lr: 0.050000\n",
            "2022-09-12 21:49:50,050 epoch 63 - iter 1536/3843 - loss 0.10566789 - samples/sec: 353.00 - lr: 0.050000\n",
            "2022-09-12 21:50:34,682 epoch 63 - iter 1920/3843 - loss 0.10566701 - samples/sec: 352.01 - lr: 0.050000\n",
            "2022-09-12 21:51:20,331 epoch 63 - iter 2304/3843 - loss 0.10544572 - samples/sec: 357.30 - lr: 0.050000\n",
            "2022-09-12 21:52:04,321 epoch 63 - iter 2688/3843 - loss 0.10557360 - samples/sec: 393.93 - lr: 0.050000\n",
            "2022-09-12 21:52:50,185 epoch 63 - iter 3072/3843 - loss 0.10560698 - samples/sec: 372.31 - lr: 0.050000\n",
            "2022-09-12 21:53:34,644 epoch 63 - iter 3456/3843 - loss 0.10568253 - samples/sec: 354.35 - lr: 0.050000\n",
            "2022-09-12 21:54:19,967 epoch 63 - iter 3840/3843 - loss 0.10578996 - samples/sec: 377.35 - lr: 0.050000\n",
            "2022-09-12 21:54:20,255 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:54:20,257 EPOCH 63 done: loss 0.1058 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 21:55:35,548 Evaluating as a multi-label problem: False\n",
            "2022-09-12 21:55:35,806 DEV : loss 0.07676934450864792 - f1-score (micro avg)  0.7954\n",
            "2022-09-12 21:55:47,915 BAD EPOCHS (no improvement): 3\n",
            "2022-09-12 21:55:47,919 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 21:56:33,177 epoch 64 - iter 384/3843 - loss 0.10601447 - samples/sec: 379.33 - lr: 0.050000\n",
            "2022-09-12 21:57:17,079 epoch 64 - iter 768/3843 - loss 0.10531000 - samples/sec: 393.95 - lr: 0.050000\n",
            "2022-09-12 21:58:02,581 epoch 64 - iter 1152/3843 - loss 0.10599668 - samples/sec: 375.44 - lr: 0.050000\n",
            "2022-09-12 21:58:47,085 epoch 64 - iter 1536/3843 - loss 0.10552318 - samples/sec: 338.53 - lr: 0.050000\n",
            "2022-09-12 21:59:32,919 epoch 64 - iter 1920/3843 - loss 0.10572483 - samples/sec: 372.09 - lr: 0.050000\n",
            "2022-09-12 22:00:19,417 epoch 64 - iter 2304/3843 - loss 0.10595465 - samples/sec: 333.91 - lr: 0.050000\n",
            "2022-09-12 22:01:03,179 epoch 64 - iter 2688/3843 - loss 0.10585539 - samples/sec: 378.84 - lr: 0.050000\n",
            "2022-09-12 22:01:48,875 epoch 64 - iter 3072/3843 - loss 0.10572140 - samples/sec: 392.51 - lr: 0.050000\n",
            "2022-09-12 22:02:32,717 epoch 64 - iter 3456/3843 - loss 0.10574636 - samples/sec: 359.31 - lr: 0.050000\n",
            "2022-09-12 22:03:18,490 epoch 64 - iter 3840/3843 - loss 0.10591660 - samples/sec: 356.54 - lr: 0.050000\n",
            "2022-09-12 22:03:18,746 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:03:18,748 EPOCH 64 done: loss 0.1059 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 22:04:35,615 Evaluating as a multi-label problem: False\n",
            "2022-09-12 22:04:35,872 DEV : loss 0.07569903135299683 - f1-score (micro avg)  0.7963\n",
            "2022-09-12 22:04:46,347 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 22:04:46,349 saving best model\n",
            "2022-09-12 22:04:49,586 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:05:35,914 epoch 65 - iter 384/3843 - loss 0.10760012 - samples/sec: 351.49 - lr: 0.050000\n",
            "2022-09-12 22:06:21,321 epoch 65 - iter 768/3843 - loss 0.10606945 - samples/sec: 344.10 - lr: 0.050000\n",
            "2022-09-12 22:07:05,764 epoch 65 - iter 1152/3843 - loss 0.10573961 - samples/sec: 387.23 - lr: 0.050000\n",
            "2022-09-12 22:07:49,095 epoch 65 - iter 1536/3843 - loss 0.10564595 - samples/sec: 401.35 - lr: 0.050000\n",
            "2022-09-12 22:08:35,241 epoch 65 - iter 1920/3843 - loss 0.10533855 - samples/sec: 351.84 - lr: 0.050000\n",
            "2022-09-12 22:09:18,454 epoch 65 - iter 2304/3843 - loss 0.10553404 - samples/sec: 383.70 - lr: 0.050000\n",
            "2022-09-12 22:10:03,474 epoch 65 - iter 2688/3843 - loss 0.10560763 - samples/sec: 400.09 - lr: 0.050000\n",
            "2022-09-12 22:10:46,379 epoch 65 - iter 3072/3843 - loss 0.10575290 - samples/sec: 388.30 - lr: 0.050000\n",
            "2022-09-12 22:11:31,216 epoch 65 - iter 3456/3843 - loss 0.10582036 - samples/sec: 349.59 - lr: 0.050000\n",
            "2022-09-12 22:12:16,993 epoch 65 - iter 3840/3843 - loss 0.10579554 - samples/sec: 372.23 - lr: 0.050000\n",
            "2022-09-12 22:12:17,269 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:12:17,271 EPOCH 65 done: loss 0.1058 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 22:13:32,551 Evaluating as a multi-label problem: False\n",
            "2022-09-12 22:13:32,823 DEV : loss 0.07577285915613174 - f1-score (micro avg)  0.7969\n",
            "2022-09-12 22:13:45,229 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 22:13:45,232 saving best model\n",
            "2022-09-12 22:13:48,497 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:14:31,987 epoch 66 - iter 384/3843 - loss 0.10304705 - samples/sec: 403.57 - lr: 0.050000\n",
            "2022-09-12 22:15:17,053 epoch 66 - iter 768/3843 - loss 0.10364437 - samples/sec: 363.20 - lr: 0.050000\n",
            "2022-09-12 22:16:01,326 epoch 66 - iter 1152/3843 - loss 0.10451545 - samples/sec: 388.65 - lr: 0.050000\n",
            "2022-09-12 22:16:46,414 epoch 66 - iter 1536/3843 - loss 0.10479967 - samples/sec: 381.34 - lr: 0.050000\n",
            "2022-09-12 22:17:33,954 epoch 66 - iter 1920/3843 - loss 0.10493665 - samples/sec: 372.64 - lr: 0.050000\n",
            "2022-09-12 22:18:18,333 epoch 66 - iter 2304/3843 - loss 0.10500771 - samples/sec: 388.40 - lr: 0.050000\n",
            "2022-09-12 22:19:03,158 epoch 66 - iter 2688/3843 - loss 0.10522220 - samples/sec: 384.20 - lr: 0.050000\n",
            "2022-09-12 22:19:46,496 epoch 66 - iter 3072/3843 - loss 0.10506271 - samples/sec: 405.58 - lr: 0.050000\n",
            "2022-09-12 22:20:30,440 epoch 66 - iter 3456/3843 - loss 0.10529809 - samples/sec: 413.91 - lr: 0.050000\n",
            "2022-09-12 22:21:14,071 epoch 66 - iter 3840/3843 - loss 0.10542780 - samples/sec: 380.26 - lr: 0.050000\n",
            "2022-09-12 22:21:14,379 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:21:14,381 EPOCH 66 done: loss 0.1054 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:17<00:00,  5.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 22:22:32,076 Evaluating as a multi-label problem: False\n",
            "2022-09-12 22:22:32,349 DEV : loss 0.07596691697835922 - f1-score (micro avg)  0.7956\n",
            "2022-09-12 22:22:42,933 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 22:22:42,939 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:23:29,714 epoch 67 - iter 384/3843 - loss 0.10599922 - samples/sec: 394.26 - lr: 0.050000\n",
            "2022-09-12 22:24:17,185 epoch 67 - iter 768/3843 - loss 0.10597725 - samples/sec: 373.85 - lr: 0.050000\n",
            "2022-09-12 22:25:00,753 epoch 67 - iter 1152/3843 - loss 0.10547422 - samples/sec: 380.05 - lr: 0.050000\n",
            "2022-09-12 22:25:46,021 epoch 67 - iter 1536/3843 - loss 0.10552626 - samples/sec: 396.68 - lr: 0.050000\n",
            "2022-09-12 22:26:29,003 epoch 67 - iter 1920/3843 - loss 0.10534160 - samples/sec: 387.49 - lr: 0.050000\n",
            "2022-09-12 22:27:14,325 epoch 67 - iter 2304/3843 - loss 0.10542279 - samples/sec: 360.63 - lr: 0.050000\n",
            "2022-09-12 22:27:59,883 epoch 67 - iter 2688/3843 - loss 0.10535032 - samples/sec: 392.74 - lr: 0.050000\n",
            "2022-09-12 22:28:43,474 epoch 67 - iter 3072/3843 - loss 0.10531010 - samples/sec: 398.82 - lr: 0.050000\n",
            "2022-09-12 22:29:27,992 epoch 67 - iter 3456/3843 - loss 0.10530749 - samples/sec: 369.32 - lr: 0.050000\n",
            "2022-09-12 22:30:10,369 epoch 67 - iter 3840/3843 - loss 0.10548190 - samples/sec: 375.65 - lr: 0.050000\n",
            "2022-09-12 22:30:10,764 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:30:10,765 EPOCH 67 done: loss 0.1055 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 22:31:27,666 Evaluating as a multi-label problem: False\n",
            "2022-09-12 22:31:27,915 DEV : loss 0.07591041922569275 - f1-score (micro avg)  0.7957\n",
            "2022-09-12 22:31:38,446 BAD EPOCHS (no improvement): 2\n",
            "2022-09-12 22:31:38,448 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:32:25,458 epoch 68 - iter 384/3843 - loss 0.10560354 - samples/sec: 370.63 - lr: 0.050000\n",
            "2022-09-12 22:33:08,271 epoch 68 - iter 768/3843 - loss 0.10475658 - samples/sec: 408.49 - lr: 0.050000\n",
            "2022-09-12 22:33:53,302 epoch 68 - iter 1152/3843 - loss 0.10495075 - samples/sec: 362.82 - lr: 0.050000\n",
            "2022-09-12 22:34:37,348 epoch 68 - iter 1536/3843 - loss 0.10534712 - samples/sec: 392.72 - lr: 0.050000\n",
            "2022-09-12 22:35:20,664 epoch 68 - iter 1920/3843 - loss 0.10551557 - samples/sec: 349.18 - lr: 0.050000\n",
            "2022-09-12 22:36:06,121 epoch 68 - iter 2304/3843 - loss 0.10559846 - samples/sec: 394.79 - lr: 0.050000\n",
            "2022-09-12 22:36:50,065 epoch 68 - iter 2688/3843 - loss 0.10534326 - samples/sec: 375.92 - lr: 0.050000\n",
            "2022-09-12 22:37:35,690 epoch 68 - iter 3072/3843 - loss 0.10544238 - samples/sec: 391.58 - lr: 0.050000\n",
            "2022-09-12 22:38:20,544 epoch 68 - iter 3456/3843 - loss 0.10547073 - samples/sec: 402.61 - lr: 0.050000\n",
            "2022-09-12 22:39:03,318 epoch 68 - iter 3840/3843 - loss 0.10539683 - samples/sec: 409.37 - lr: 0.050000\n",
            "2022-09-12 22:39:03,574 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:39:03,576 EPOCH 68 done: loss 0.1054 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 22:40:19,690 Evaluating as a multi-label problem: False\n",
            "2022-09-12 22:40:19,948 DEV : loss 0.07555901259183884 - f1-score (micro avg)  0.7975\n",
            "2022-09-12 22:40:30,438 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 22:40:30,441 saving best model\n",
            "2022-09-12 22:40:33,587 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:41:18,753 epoch 69 - iter 384/3843 - loss 0.10411513 - samples/sec: 359.59 - lr: 0.050000\n",
            "2022-09-12 22:42:03,133 epoch 69 - iter 768/3843 - loss 0.10434888 - samples/sec: 407.78 - lr: 0.050000\n",
            "2022-09-12 22:42:49,336 epoch 69 - iter 1152/3843 - loss 0.10437317 - samples/sec: 350.53 - lr: 0.050000\n",
            "2022-09-12 22:43:32,441 epoch 69 - iter 1536/3843 - loss 0.10429664 - samples/sec: 384.66 - lr: 0.050000\n",
            "2022-09-12 22:44:17,029 epoch 69 - iter 1920/3843 - loss 0.10452857 - samples/sec: 385.77 - lr: 0.050000\n",
            "2022-09-12 22:44:59,691 epoch 69 - iter 2304/3843 - loss 0.10480990 - samples/sec: 390.95 - lr: 0.050000\n",
            "2022-09-12 22:45:44,099 epoch 69 - iter 2688/3843 - loss 0.10487000 - samples/sec: 388.16 - lr: 0.050000\n",
            "2022-09-12 22:46:28,667 epoch 69 - iter 3072/3843 - loss 0.10485576 - samples/sec: 408.50 - lr: 0.050000\n",
            "2022-09-12 22:47:12,008 epoch 69 - iter 3456/3843 - loss 0.10500621 - samples/sec: 383.42 - lr: 0.050000\n",
            "2022-09-12 22:47:57,761 epoch 69 - iter 3840/3843 - loss 0.10508102 - samples/sec: 372.96 - lr: 0.050000\n",
            "2022-09-12 22:47:58,031 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:47:58,032 EPOCH 69 done: loss 0.1051 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 22:49:12,802 Evaluating as a multi-label problem: False\n",
            "2022-09-12 22:49:13,068 DEV : loss 0.07618027925491333 - f1-score (micro avg)  0.7966\n",
            "2022-09-12 22:49:25,455 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 22:49:25,457 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:50:08,556 epoch 70 - iter 384/3843 - loss 0.10375329 - samples/sec: 408.84 - lr: 0.050000\n",
            "2022-09-12 22:50:53,553 epoch 70 - iter 768/3843 - loss 0.10475028 - samples/sec: 363.70 - lr: 0.050000\n",
            "2022-09-12 22:51:39,004 epoch 70 - iter 1152/3843 - loss 0.10449819 - samples/sec: 376.59 - lr: 0.050000\n",
            "2022-09-12 22:52:23,078 epoch 70 - iter 1536/3843 - loss 0.10412675 - samples/sec: 392.61 - lr: 0.050000\n",
            "2022-09-12 22:53:07,220 epoch 70 - iter 1920/3843 - loss 0.10463740 - samples/sec: 391.75 - lr: 0.050000\n",
            "2022-09-12 22:53:51,421 epoch 70 - iter 2304/3843 - loss 0.10454599 - samples/sec: 372.95 - lr: 0.050000\n",
            "2022-09-12 22:54:37,764 epoch 70 - iter 2688/3843 - loss 0.10483849 - samples/sec: 367.83 - lr: 0.050000\n",
            "2022-09-12 22:55:21,431 epoch 70 - iter 3072/3843 - loss 0.10502465 - samples/sec: 398.07 - lr: 0.050000\n",
            "2022-09-12 22:56:07,071 epoch 70 - iter 3456/3843 - loss 0.10501838 - samples/sec: 393.74 - lr: 0.050000\n",
            "2022-09-12 22:56:53,379 epoch 70 - iter 3840/3843 - loss 0.10509577 - samples/sec: 385.84 - lr: 0.050000\n",
            "2022-09-12 22:56:53,668 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:56:53,670 EPOCH 70 done: loss 0.1051 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 22:58:08,675 Evaluating as a multi-label problem: False\n",
            "2022-09-12 22:58:08,937 DEV : loss 0.07614801824092865 - f1-score (micro avg)  0.7972\n",
            "2022-09-12 22:58:21,319 BAD EPOCHS (no improvement): 2\n",
            "2022-09-12 22:58:21,323 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 22:59:04,817 epoch 71 - iter 384/3843 - loss 0.10292011 - samples/sec: 404.41 - lr: 0.050000\n",
            "2022-09-12 22:59:50,001 epoch 71 - iter 768/3843 - loss 0.10436805 - samples/sec: 346.73 - lr: 0.050000\n",
            "2022-09-12 23:00:33,513 epoch 71 - iter 1152/3843 - loss 0.10440896 - samples/sec: 400.27 - lr: 0.050000\n",
            "2022-09-12 23:01:18,482 epoch 71 - iter 1536/3843 - loss 0.10456335 - samples/sec: 401.94 - lr: 0.050000\n",
            "2022-09-12 23:02:00,868 epoch 71 - iter 1920/3843 - loss 0.10468566 - samples/sec: 413.90 - lr: 0.050000\n",
            "2022-09-12 23:02:45,215 epoch 71 - iter 2304/3843 - loss 0.10482605 - samples/sec: 339.10 - lr: 0.050000\n",
            "2022-09-12 23:03:31,974 epoch 71 - iter 2688/3843 - loss 0.10495184 - samples/sec: 379.58 - lr: 0.050000\n",
            "2022-09-12 23:04:15,656 epoch 71 - iter 3072/3843 - loss 0.10513746 - samples/sec: 361.41 - lr: 0.050000\n",
            "2022-09-12 23:05:01,497 epoch 71 - iter 3456/3843 - loss 0.10533598 - samples/sec: 390.74 - lr: 0.050000\n",
            "2022-09-12 23:05:44,920 epoch 71 - iter 3840/3843 - loss 0.10528125 - samples/sec: 382.85 - lr: 0.050000\n",
            "2022-09-12 23:05:45,180 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 23:05:45,183 EPOCH 71 done: loss 0.1053 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 23:07:01,545 Evaluating as a multi-label problem: False\n",
            "2022-09-12 23:07:01,807 DEV : loss 0.07566295564174652 - f1-score (micro avg)  0.7975\n",
            "2022-09-12 23:07:12,335 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 23:07:12,338 saving best model\n",
            "2022-09-12 23:07:15,456 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 23:08:01,715 epoch 72 - iter 384/3843 - loss 0.10544709 - samples/sec: 382.25 - lr: 0.050000\n",
            "2022-09-12 23:08:45,216 epoch 72 - iter 768/3843 - loss 0.10479525 - samples/sec: 380.49 - lr: 0.050000\n",
            "2022-09-12 23:09:29,020 epoch 72 - iter 1152/3843 - loss 0.10472975 - samples/sec: 376.58 - lr: 0.050000\n",
            "2022-09-12 23:10:15,199 epoch 72 - iter 1536/3843 - loss 0.10455425 - samples/sec: 352.20 - lr: 0.050000\n",
            "2022-09-12 23:10:59,609 epoch 72 - iter 1920/3843 - loss 0.10467966 - samples/sec: 370.94 - lr: 0.050000\n",
            "2022-09-12 23:11:45,084 epoch 72 - iter 2304/3843 - loss 0.10497499 - samples/sec: 378.44 - lr: 0.050000\n",
            "2022-09-12 23:12:28,920 epoch 72 - iter 2688/3843 - loss 0.10519398 - samples/sec: 398.95 - lr: 0.050000\n",
            "2022-09-12 23:13:13,671 epoch 72 - iter 3072/3843 - loss 0.10518337 - samples/sec: 351.09 - lr: 0.050000\n",
            "2022-09-12 23:13:57,244 epoch 72 - iter 3456/3843 - loss 0.10514480 - samples/sec: 379.76 - lr: 0.050000\n",
            "2022-09-12 23:14:43,426 epoch 72 - iter 3840/3843 - loss 0.10505062 - samples/sec: 353.00 - lr: 0.050000\n",
            "2022-09-12 23:14:43,691 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 23:14:43,693 EPOCH 72 done: loss 0.1051 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 23:16:00,396 Evaluating as a multi-label problem: False\n",
            "2022-09-12 23:16:00,644 DEV : loss 0.07543926686048508 - f1-score (micro avg)  0.797\n",
            "2022-09-12 23:16:11,129 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 23:16:11,132 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 23:16:56,088 epoch 73 - iter 384/3843 - loss 0.10375639 - samples/sec: 380.23 - lr: 0.050000\n",
            "2022-09-12 23:17:41,490 epoch 73 - iter 768/3843 - loss 0.10389531 - samples/sec: 344.39 - lr: 0.050000\n",
            "2022-09-12 23:18:28,595 epoch 73 - iter 1152/3843 - loss 0.10427330 - samples/sec: 359.24 - lr: 0.050000\n",
            "2022-09-12 23:19:12,694 epoch 73 - iter 1536/3843 - loss 0.10454082 - samples/sec: 373.99 - lr: 0.050000\n",
            "2022-09-12 23:19:58,646 epoch 73 - iter 1920/3843 - loss 0.10457514 - samples/sec: 389.34 - lr: 0.050000\n",
            "2022-09-12 23:20:41,307 epoch 73 - iter 2304/3843 - loss 0.10472016 - samples/sec: 391.29 - lr: 0.050000\n",
            "2022-09-12 23:21:26,475 epoch 73 - iter 2688/3843 - loss 0.10503674 - samples/sec: 380.18 - lr: 0.050000\n",
            "2022-09-12 23:22:09,525 epoch 73 - iter 3072/3843 - loss 0.10502540 - samples/sec: 386.24 - lr: 0.050000\n",
            "2022-09-12 23:22:53,818 epoch 73 - iter 3456/3843 - loss 0.10511585 - samples/sec: 411.00 - lr: 0.050000\n",
            "2022-09-12 23:23:38,997 epoch 73 - iter 3840/3843 - loss 0.10494050 - samples/sec: 379.94 - lr: 0.050000\n",
            "2022-09-12 23:23:39,302 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 23:23:39,303 EPOCH 73 done: loss 0.1049 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 23:24:53,998 Evaluating as a multi-label problem: False\n",
            "2022-09-12 23:24:54,254 DEV : loss 0.07530052214860916 - f1-score (micro avg)  0.798\n",
            "2022-09-12 23:25:06,545 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 23:25:06,547 saving best model\n",
            "2022-09-12 23:25:09,750 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 23:25:53,397 epoch 74 - iter 384/3843 - loss 0.10206898 - samples/sec: 384.40 - lr: 0.050000\n",
            "2022-09-12 23:26:36,258 epoch 74 - iter 768/3843 - loss 0.10368903 - samples/sec: 388.89 - lr: 0.050000\n",
            "2022-09-12 23:27:22,080 epoch 74 - iter 1152/3843 - loss 0.10438162 - samples/sec: 371.61 - lr: 0.050000\n",
            "2022-09-12 23:28:07,966 epoch 74 - iter 1536/3843 - loss 0.10484761 - samples/sec: 354.69 - lr: 0.050000\n",
            "2022-09-12 23:28:52,279 epoch 74 - iter 1920/3843 - loss 0.10479015 - samples/sec: 392.55 - lr: 0.050000\n",
            "2022-09-12 23:29:37,323 epoch 74 - iter 2304/3843 - loss 0.10480758 - samples/sec: 364.78 - lr: 0.050000\n",
            "2022-09-12 23:30:22,351 epoch 74 - iter 2688/3843 - loss 0.10471369 - samples/sec: 366.25 - lr: 0.050000\n",
            "2022-09-12 23:31:07,975 epoch 74 - iter 3072/3843 - loss 0.10472758 - samples/sec: 377.17 - lr: 0.050000\n",
            "2022-09-12 23:31:54,222 epoch 74 - iter 3456/3843 - loss 0.10491085 - samples/sec: 388.06 - lr: 0.050000\n",
            "2022-09-12 23:32:39,506 epoch 74 - iter 3840/3843 - loss 0.10486252 - samples/sec: 347.59 - lr: 0.050000\n",
            "2022-09-12 23:32:39,763 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 23:32:39,764 EPOCH 74 done: loss 0.1049 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:17<00:00,  5.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 23:33:57,146 Evaluating as a multi-label problem: False\n",
            "2022-09-12 23:33:57,406 DEV : loss 0.07519487291574478 - f1-score (micro avg)  0.7974\n",
            "2022-09-12 23:34:07,856 BAD EPOCHS (no improvement): 1\n",
            "2022-09-12 23:34:07,860 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 23:34:54,121 epoch 75 - iter 384/3843 - loss 0.10363034 - samples/sec: 384.35 - lr: 0.050000\n",
            "2022-09-12 23:35:39,463 epoch 75 - iter 768/3843 - loss 0.10476998 - samples/sec: 360.26 - lr: 0.050000\n",
            "2022-09-12 23:36:25,780 epoch 75 - iter 1152/3843 - loss 0.10422125 - samples/sec: 350.26 - lr: 0.050000\n",
            "2022-09-12 23:37:09,496 epoch 75 - iter 1536/3843 - loss 0.10413703 - samples/sec: 379.28 - lr: 0.050000\n",
            "2022-09-12 23:37:54,770 epoch 75 - iter 1920/3843 - loss 0.10412827 - samples/sec: 362.22 - lr: 0.050000\n",
            "2022-09-12 23:38:38,361 epoch 75 - iter 2304/3843 - loss 0.10406735 - samples/sec: 363.68 - lr: 0.050000\n",
            "2022-09-12 23:39:24,790 epoch 75 - iter 2688/3843 - loss 0.10418975 - samples/sec: 351.18 - lr: 0.050000\n",
            "2022-09-12 23:40:07,975 epoch 75 - iter 3072/3843 - loss 0.10424829 - samples/sec: 385.31 - lr: 0.050000\n",
            "2022-09-12 23:40:55,572 epoch 75 - iter 3456/3843 - loss 0.10449014 - samples/sec: 370.79 - lr: 0.050000\n",
            "2022-09-12 23:41:39,962 epoch 75 - iter 3840/3843 - loss 0.10455517 - samples/sec: 371.82 - lr: 0.050000\n",
            "2022-09-12 23:41:40,250 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 23:41:40,252 EPOCH 75 done: loss 0.1046 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 23:42:55,597 Evaluating as a multi-label problem: False\n",
            "2022-09-12 23:42:55,845 DEV : loss 0.07575573772192001 - f1-score (micro avg)  0.7969\n",
            "2022-09-12 23:43:08,125 BAD EPOCHS (no improvement): 2\n",
            "2022-09-12 23:43:08,128 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 23:43:51,879 epoch 76 - iter 384/3843 - loss 0.10459719 - samples/sec: 382.14 - lr: 0.050000\n",
            "2022-09-12 23:44:36,559 epoch 76 - iter 768/3843 - loss 0.10414644 - samples/sec: 385.09 - lr: 0.050000\n",
            "2022-09-12 23:45:19,163 epoch 76 - iter 1152/3843 - loss 0.10406370 - samples/sec: 391.71 - lr: 0.050000\n",
            "2022-09-12 23:46:05,115 epoch 76 - iter 1536/3843 - loss 0.10387455 - samples/sec: 339.04 - lr: 0.050000\n",
            "2022-09-12 23:46:50,420 epoch 76 - iter 1920/3843 - loss 0.10382673 - samples/sec: 378.75 - lr: 0.050000\n",
            "2022-09-12 23:47:34,178 epoch 76 - iter 2304/3843 - loss 0.10386095 - samples/sec: 378.52 - lr: 0.050000\n",
            "2022-09-12 23:48:19,462 epoch 76 - iter 2688/3843 - loss 0.10393336 - samples/sec: 362.60 - lr: 0.050000\n",
            "2022-09-12 23:49:03,595 epoch 76 - iter 3072/3843 - loss 0.10399072 - samples/sec: 391.69 - lr: 0.050000\n",
            "2022-09-12 23:49:49,340 epoch 76 - iter 3456/3843 - loss 0.10427558 - samples/sec: 392.26 - lr: 0.050000\n",
            "2022-09-12 23:50:35,065 epoch 76 - iter 3840/3843 - loss 0.10437288 - samples/sec: 392.84 - lr: 0.050000\n",
            "2022-09-12 23:50:35,325 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 23:50:35,327 EPOCH 76 done: loss 0.1044 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-12 23:51:50,351 Evaluating as a multi-label problem: False\n",
            "2022-09-12 23:51:50,599 DEV : loss 0.07576281577348709 - f1-score (micro avg)  0.7986\n",
            "2022-09-12 23:52:02,915 BAD EPOCHS (no improvement): 0\n",
            "2022-09-12 23:52:02,918 saving best model\n",
            "2022-09-12 23:52:06,459 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 23:52:51,464 epoch 77 - iter 384/3843 - loss 0.10477688 - samples/sec: 368.93 - lr: 0.050000\n",
            "2022-09-12 23:53:35,884 epoch 77 - iter 768/3843 - loss 0.10477396 - samples/sec: 388.35 - lr: 0.050000\n",
            "2022-09-12 23:54:20,114 epoch 77 - iter 1152/3843 - loss 0.10428728 - samples/sec: 372.40 - lr: 0.050000\n",
            "2022-09-12 23:55:06,262 epoch 77 - iter 1536/3843 - loss 0.10407936 - samples/sec: 387.74 - lr: 0.050000\n",
            "2022-09-12 23:55:49,971 epoch 77 - iter 1920/3843 - loss 0.10406922 - samples/sec: 345.66 - lr: 0.050000\n",
            "2022-09-12 23:56:36,190 epoch 77 - iter 2304/3843 - loss 0.10434182 - samples/sec: 336.40 - lr: 0.050000\n",
            "2022-09-12 23:57:21,082 epoch 77 - iter 2688/3843 - loss 0.10425544 - samples/sec: 349.49 - lr: 0.050000\n",
            "2022-09-12 23:58:04,778 epoch 77 - iter 3072/3843 - loss 0.10448282 - samples/sec: 398.68 - lr: 0.050000\n",
            "2022-09-12 23:58:49,439 epoch 77 - iter 3456/3843 - loss 0.10447316 - samples/sec: 405.80 - lr: 0.050000\n",
            "2022-09-12 23:59:33,189 epoch 77 - iter 3840/3843 - loss 0.10452599 - samples/sec: 361.56 - lr: 0.050000\n",
            "2022-09-12 23:59:33,523 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-12 23:59:33,525 EPOCH 77 done: loss 0.1045 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 00:00:50,049 Evaluating as a multi-label problem: False\n",
            "2022-09-13 00:00:50,297 DEV : loss 0.07592209428548813 - f1-score (micro avg)  0.7987\n",
            "2022-09-13 00:01:00,793 BAD EPOCHS (no improvement): 0\n",
            "2022-09-13 00:01:00,797 saving best model\n",
            "2022-09-13 00:01:04,021 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 00:01:50,761 epoch 78 - iter 384/3843 - loss 0.10438369 - samples/sec: 377.41 - lr: 0.050000\n",
            "2022-09-13 00:02:34,780 epoch 78 - iter 768/3843 - loss 0.10320214 - samples/sec: 393.64 - lr: 0.050000\n",
            "2022-09-13 00:03:20,788 epoch 78 - iter 1152/3843 - loss 0.10376070 - samples/sec: 388.40 - lr: 0.050000\n",
            "2022-09-13 00:04:05,114 epoch 78 - iter 1536/3843 - loss 0.10408710 - samples/sec: 371.85 - lr: 0.050000\n",
            "2022-09-13 00:04:50,409 epoch 78 - iter 1920/3843 - loss 0.10424229 - samples/sec: 397.36 - lr: 0.050000\n",
            "2022-09-13 00:05:36,171 epoch 78 - iter 2304/3843 - loss 0.10402311 - samples/sec: 373.09 - lr: 0.050000\n",
            "2022-09-13 00:06:20,843 epoch 78 - iter 2688/3843 - loss 0.10417911 - samples/sec: 351.65 - lr: 0.050000\n",
            "2022-09-13 00:07:05,574 epoch 78 - iter 3072/3843 - loss 0.10426022 - samples/sec: 405.43 - lr: 0.050000\n",
            "2022-09-13 00:07:48,516 epoch 78 - iter 3456/3843 - loss 0.10432484 - samples/sec: 408.68 - lr: 0.050000\n",
            "2022-09-13 00:08:33,639 epoch 78 - iter 3840/3843 - loss 0.10426516 - samples/sec: 400.75 - lr: 0.050000\n",
            "2022-09-13 00:08:33,867 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 00:08:33,869 EPOCH 78 done: loss 0.1043 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 00:09:48,593 Evaluating as a multi-label problem: False\n",
            "2022-09-13 00:09:48,867 DEV : loss 0.07491117715835571 - f1-score (micro avg)  0.797\n",
            "2022-09-13 00:10:01,079 BAD EPOCHS (no improvement): 1\n",
            "2022-09-13 00:10:01,082 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 00:10:45,308 epoch 79 - iter 384/3843 - loss 0.10292995 - samples/sec: 413.27 - lr: 0.050000\n",
            "2022-09-13 00:11:28,652 epoch 79 - iter 768/3843 - loss 0.10285530 - samples/sec: 382.20 - lr: 0.050000\n",
            "2022-09-13 00:12:13,387 epoch 79 - iter 1152/3843 - loss 0.10355197 - samples/sec: 405.26 - lr: 0.050000\n",
            "2022-09-13 00:12:56,973 epoch 79 - iter 1536/3843 - loss 0.10332981 - samples/sec: 399.07 - lr: 0.050000\n",
            "2022-09-13 00:13:43,734 epoch 79 - iter 1920/3843 - loss 0.10356278 - samples/sec: 346.50 - lr: 0.050000\n",
            "2022-09-13 00:14:30,300 epoch 79 - iter 2304/3843 - loss 0.10374773 - samples/sec: 348.34 - lr: 0.050000\n",
            "2022-09-13 00:15:14,379 epoch 79 - iter 2688/3843 - loss 0.10379173 - samples/sec: 393.34 - lr: 0.050000\n",
            "2022-09-13 00:16:00,763 epoch 79 - iter 3072/3843 - loss 0.10413241 - samples/sec: 335.08 - lr: 0.050000\n",
            "2022-09-13 00:16:43,524 epoch 79 - iter 3456/3843 - loss 0.10405055 - samples/sec: 390.25 - lr: 0.050000\n",
            "2022-09-13 00:17:27,931 epoch 79 - iter 3840/3843 - loss 0.10421876 - samples/sec: 369.56 - lr: 0.050000\n",
            "2022-09-13 00:17:28,203 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 00:17:28,204 EPOCH 79 done: loss 0.1042 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 00:18:43,058 Evaluating as a multi-label problem: False\n",
            "2022-09-13 00:18:43,309 DEV : loss 0.07510808110237122 - f1-score (micro avg)  0.7987\n",
            "2022-09-13 00:18:55,345 BAD EPOCHS (no improvement): 2\n",
            "2022-09-13 00:18:55,347 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 00:19:40,600 epoch 80 - iter 384/3843 - loss 0.10184416 - samples/sec: 360.81 - lr: 0.050000\n",
            "2022-09-13 00:20:25,296 epoch 80 - iter 768/3843 - loss 0.10328729 - samples/sec: 384.03 - lr: 0.050000\n",
            "2022-09-13 00:21:08,405 epoch 80 - iter 1152/3843 - loss 0.10322113 - samples/sec: 367.64 - lr: 0.050000\n",
            "2022-09-13 00:21:52,668 epoch 80 - iter 1536/3843 - loss 0.10332543 - samples/sec: 388.78 - lr: 0.050000\n",
            "2022-09-13 00:22:34,932 epoch 80 - iter 1920/3843 - loss 0.10346650 - samples/sec: 395.21 - lr: 0.050000\n",
            "2022-09-13 00:23:20,330 epoch 80 - iter 2304/3843 - loss 0.10328410 - samples/sec: 359.10 - lr: 0.050000\n",
            "2022-09-13 00:24:05,041 epoch 80 - iter 2688/3843 - loss 0.10353067 - samples/sec: 366.01 - lr: 0.050000\n",
            "2022-09-13 00:24:49,772 epoch 80 - iter 3072/3843 - loss 0.10360030 - samples/sec: 368.49 - lr: 0.050000\n",
            "2022-09-13 00:25:37,058 epoch 80 - iter 3456/3843 - loss 0.10374484 - samples/sec: 327.29 - lr: 0.050000\n",
            "2022-09-13 00:26:20,797 epoch 80 - iter 3840/3843 - loss 0.10385589 - samples/sec: 377.83 - lr: 0.050000\n",
            "2022-09-13 00:26:21,048 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 00:26:21,050 EPOCH 80 done: loss 0.1039 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 00:27:37,395 Evaluating as a multi-label problem: False\n",
            "2022-09-13 00:27:37,639 DEV : loss 0.07541114091873169 - f1-score (micro avg)  0.7968\n",
            "2022-09-13 00:27:48,126 BAD EPOCHS (no improvement): 3\n",
            "2022-09-13 00:27:48,129 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 00:28:34,387 epoch 81 - iter 384/3843 - loss 0.10261744 - samples/sec: 401.07 - lr: 0.050000\n",
            "2022-09-13 00:29:17,979 epoch 81 - iter 768/3843 - loss 0.10340282 - samples/sec: 362.97 - lr: 0.050000\n",
            "2022-09-13 00:30:04,633 epoch 81 - iter 1152/3843 - loss 0.10388564 - samples/sec: 348.08 - lr: 0.050000\n",
            "2022-09-13 00:30:48,695 epoch 81 - iter 1536/3843 - loss 0.10387556 - samples/sec: 358.41 - lr: 0.050000\n",
            "2022-09-13 00:31:36,137 epoch 81 - iter 1920/3843 - loss 0.10334819 - samples/sec: 341.85 - lr: 0.050000\n",
            "2022-09-13 00:32:21,526 epoch 81 - iter 2304/3843 - loss 0.10353708 - samples/sec: 361.82 - lr: 0.050000\n",
            "2022-09-13 00:33:03,895 epoch 81 - iter 2688/3843 - loss 0.10375548 - samples/sec: 416.26 - lr: 0.050000\n",
            "2022-09-13 00:33:49,067 epoch 81 - iter 3072/3843 - loss 0.10353292 - samples/sec: 380.12 - lr: 0.050000\n",
            "2022-09-13 00:34:32,432 epoch 81 - iter 3456/3843 - loss 0.10381656 - samples/sec: 401.70 - lr: 0.050000\n",
            "2022-09-13 00:35:16,904 epoch 81 - iter 3840/3843 - loss 0.10369038 - samples/sec: 407.08 - lr: 0.050000\n",
            "2022-09-13 00:35:17,175 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 00:35:17,177 EPOCH 81 done: loss 0.1037 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 00:36:33,757 Evaluating as a multi-label problem: False\n",
            "2022-09-13 00:36:34,026 DEV : loss 0.07514344900846481 - f1-score (micro avg)  0.8013\n",
            "2022-09-13 00:36:46,279 BAD EPOCHS (no improvement): 0\n",
            "2022-09-13 00:36:46,281 saving best model\n",
            "2022-09-13 00:36:49,516 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 00:37:34,681 epoch 82 - iter 384/3843 - loss 0.10185944 - samples/sec: 399.93 - lr: 0.050000\n",
            "2022-09-13 00:38:20,345 epoch 82 - iter 768/3843 - loss 0.10296950 - samples/sec: 342.56 - lr: 0.050000\n",
            "2022-09-13 00:39:03,737 epoch 82 - iter 1152/3843 - loss 0.10318619 - samples/sec: 403.53 - lr: 0.050000\n",
            "2022-09-13 00:39:50,379 epoch 82 - iter 1536/3843 - loss 0.10349536 - samples/sec: 381.18 - lr: 0.050000\n",
            "2022-09-13 00:40:34,398 epoch 82 - iter 1920/3843 - loss 0.10376236 - samples/sec: 358.68 - lr: 0.050000\n",
            "2022-09-13 00:41:20,329 epoch 82 - iter 2304/3843 - loss 0.10395344 - samples/sec: 387.81 - lr: 0.050000\n",
            "2022-09-13 00:42:03,796 epoch 82 - iter 2688/3843 - loss 0.10385015 - samples/sec: 402.07 - lr: 0.050000\n",
            "2022-09-13 00:42:48,544 epoch 82 - iter 3072/3843 - loss 0.10385145 - samples/sec: 349.84 - lr: 0.050000\n",
            "2022-09-13 00:43:34,605 epoch 82 - iter 3456/3843 - loss 0.10402475 - samples/sec: 390.58 - lr: 0.050000\n",
            "2022-09-13 00:44:18,012 epoch 82 - iter 3840/3843 - loss 0.10408427 - samples/sec: 365.18 - lr: 0.050000\n",
            "2022-09-13 00:44:18,268 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 00:44:18,270 EPOCH 82 done: loss 0.1041 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 00:45:34,402 Evaluating as a multi-label problem: False\n",
            "2022-09-13 00:45:34,649 DEV : loss 0.0748961791396141 - f1-score (micro avg)  0.7989\n",
            "2022-09-13 00:45:45,139 BAD EPOCHS (no improvement): 1\n",
            "2022-09-13 00:45:45,141 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 00:46:31,735 epoch 83 - iter 384/3843 - loss 0.10500663 - samples/sec: 397.65 - lr: 0.050000\n",
            "2022-09-13 00:47:14,539 epoch 83 - iter 768/3843 - loss 0.10295875 - samples/sec: 408.18 - lr: 0.050000\n",
            "2022-09-13 00:47:59,879 epoch 83 - iter 1152/3843 - loss 0.10310885 - samples/sec: 396.15 - lr: 0.050000\n",
            "2022-09-13 00:48:42,215 epoch 83 - iter 1536/3843 - loss 0.10345141 - samples/sec: 376.77 - lr: 0.050000\n",
            "2022-09-13 00:49:27,836 epoch 83 - iter 1920/3843 - loss 0.10350116 - samples/sec: 356.65 - lr: 0.050000\n",
            "2022-09-13 00:50:13,074 epoch 83 - iter 2304/3843 - loss 0.10381873 - samples/sec: 397.45 - lr: 0.050000\n",
            "2022-09-13 00:50:56,249 epoch 83 - iter 2688/3843 - loss 0.10388047 - samples/sec: 384.87 - lr: 0.050000\n",
            "2022-09-13 00:51:40,805 epoch 83 - iter 3072/3843 - loss 0.10387376 - samples/sec: 407.52 - lr: 0.050000\n",
            "2022-09-13 00:52:23,815 epoch 83 - iter 3456/3843 - loss 0.10408200 - samples/sec: 368.83 - lr: 0.050000\n",
            "2022-09-13 00:53:08,916 epoch 83 - iter 3840/3843 - loss 0.10400738 - samples/sec: 399.84 - lr: 0.050000\n",
            "2022-09-13 00:53:09,215 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 00:53:09,217 EPOCH 83 done: loss 0.1040 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 00:54:23,593 Evaluating as a multi-label problem: False\n",
            "2022-09-13 00:54:23,844 DEV : loss 0.07490020245313644 - f1-score (micro avg)  0.7996\n",
            "2022-09-13 00:54:35,910 BAD EPOCHS (no improvement): 2\n",
            "2022-09-13 00:54:35,915 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 00:55:21,582 epoch 84 - iter 384/3843 - loss 0.10489330 - samples/sec: 389.78 - lr: 0.050000\n",
            "2022-09-13 00:56:06,141 epoch 84 - iter 768/3843 - loss 0.10380505 - samples/sec: 385.50 - lr: 0.050000\n",
            "2022-09-13 00:56:50,031 epoch 84 - iter 1152/3843 - loss 0.10431349 - samples/sec: 358.13 - lr: 0.050000\n",
            "2022-09-13 00:57:34,143 epoch 84 - iter 1536/3843 - loss 0.10399647 - samples/sec: 411.11 - lr: 0.050000\n",
            "2022-09-13 00:58:17,543 epoch 84 - iter 1920/3843 - loss 0.10354648 - samples/sec: 348.32 - lr: 0.050000\n",
            "2022-09-13 00:59:01,680 epoch 84 - iter 2304/3843 - loss 0.10365028 - samples/sec: 409.94 - lr: 0.050000\n",
            "2022-09-13 00:59:46,307 epoch 84 - iter 2688/3843 - loss 0.10371191 - samples/sec: 385.13 - lr: 0.050000\n",
            "2022-09-13 01:00:29,910 epoch 84 - iter 3072/3843 - loss 0.10371683 - samples/sec: 361.78 - lr: 0.050000\n",
            "2022-09-13 01:01:13,996 epoch 84 - iter 3456/3843 - loss 0.10371924 - samples/sec: 413.42 - lr: 0.050000\n",
            "2022-09-13 01:01:56,718 epoch 84 - iter 3840/3843 - loss 0.10382367 - samples/sec: 388.62 - lr: 0.050000\n",
            "2022-09-13 01:01:56,966 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:01:56,967 EPOCH 84 done: loss 0.1038 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 01:03:13,059 Evaluating as a multi-label problem: False\n",
            "2022-09-13 01:03:13,307 DEV : loss 0.07492812722921371 - f1-score (micro avg)  0.8002\n",
            "2022-09-13 01:03:23,789 BAD EPOCHS (no improvement): 3\n",
            "2022-09-13 01:03:23,791 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:04:08,985 epoch 85 - iter 384/3843 - loss 0.10211104 - samples/sec: 392.73 - lr: 0.050000\n",
            "2022-09-13 01:04:53,758 epoch 85 - iter 768/3843 - loss 0.10291858 - samples/sec: 366.10 - lr: 0.050000\n",
            "2022-09-13 01:05:38,128 epoch 85 - iter 1152/3843 - loss 0.10332817 - samples/sec: 371.58 - lr: 0.050000\n",
            "2022-09-13 01:06:24,258 epoch 85 - iter 1536/3843 - loss 0.10311451 - samples/sec: 369.95 - lr: 0.050000\n",
            "2022-09-13 01:07:07,385 epoch 85 - iter 1920/3843 - loss 0.10342271 - samples/sec: 408.83 - lr: 0.050000\n",
            "2022-09-13 01:07:53,769 epoch 85 - iter 2304/3843 - loss 0.10365176 - samples/sec: 351.68 - lr: 0.050000\n",
            "2022-09-13 01:08:37,572 epoch 85 - iter 2688/3843 - loss 0.10349090 - samples/sec: 360.95 - lr: 0.050000\n",
            "2022-09-13 01:09:23,285 epoch 85 - iter 3072/3843 - loss 0.10359982 - samples/sec: 358.25 - lr: 0.050000\n",
            "2022-09-13 01:10:07,992 epoch 85 - iter 3456/3843 - loss 0.10386822 - samples/sec: 386.06 - lr: 0.050000\n",
            "2022-09-13 01:10:51,335 epoch 85 - iter 3840/3843 - loss 0.10388710 - samples/sec: 349.61 - lr: 0.050000\n",
            "2022-09-13 01:10:51,634 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:10:51,636 EPOCH 85 done: loss 0.1039 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 01:12:07,860 Evaluating as a multi-label problem: False\n",
            "2022-09-13 01:12:08,104 DEV : loss 0.07438882440328598 - f1-score (micro avg)  0.8003\n",
            "2022-09-13 01:12:18,587 Epoch    85: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2022-09-13 01:12:18,589 BAD EPOCHS (no improvement): 4\n",
            "2022-09-13 01:12:18,593 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:13:02,790 epoch 86 - iter 384/3843 - loss 0.10446651 - samples/sec: 355.90 - lr: 0.025000\n",
            "2022-09-13 01:13:48,115 epoch 86 - iter 768/3843 - loss 0.10363589 - samples/sec: 359.86 - lr: 0.025000\n",
            "2022-09-13 01:14:33,161 epoch 86 - iter 1152/3843 - loss 0.10232125 - samples/sec: 362.62 - lr: 0.025000\n",
            "2022-09-13 01:15:17,155 epoch 86 - iter 1536/3843 - loss 0.10230613 - samples/sec: 375.51 - lr: 0.025000\n",
            "2022-09-13 01:16:02,327 epoch 86 - iter 1920/3843 - loss 0.10212337 - samples/sec: 361.22 - lr: 0.025000\n",
            "2022-09-13 01:16:44,860 epoch 86 - iter 2304/3843 - loss 0.10180244 - samples/sec: 412.51 - lr: 0.025000\n",
            "2022-09-13 01:17:29,568 epoch 86 - iter 2688/3843 - loss 0.10187084 - samples/sec: 385.15 - lr: 0.025000\n",
            "2022-09-13 01:18:12,472 epoch 86 - iter 3072/3843 - loss 0.10186763 - samples/sec: 369.72 - lr: 0.025000\n",
            "2022-09-13 01:18:58,265 epoch 86 - iter 3456/3843 - loss 0.10165122 - samples/sec: 371.88 - lr: 0.025000\n",
            "2022-09-13 01:19:43,228 epoch 86 - iter 3840/3843 - loss 0.10162881 - samples/sec: 401.31 - lr: 0.025000\n",
            "2022-09-13 01:19:43,517 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:19:43,520 EPOCH 86 done: loss 0.1016 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 01:20:58,073 Evaluating as a multi-label problem: False\n",
            "2022-09-13 01:20:58,323 DEV : loss 0.07389696687459946 - f1-score (micro avg)  0.8015\n",
            "2022-09-13 01:21:10,632 BAD EPOCHS (no improvement): 0\n",
            "2022-09-13 01:21:10,634 saving best model\n",
            "2022-09-13 01:21:13,788 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:21:59,511 epoch 87 - iter 384/3843 - loss 0.09860389 - samples/sec: 358.78 - lr: 0.025000\n",
            "2022-09-13 01:22:43,776 epoch 87 - iter 768/3843 - loss 0.09870138 - samples/sec: 389.79 - lr: 0.025000\n",
            "2022-09-13 01:23:28,463 epoch 87 - iter 1152/3843 - loss 0.09886908 - samples/sec: 384.68 - lr: 0.025000\n",
            "2022-09-13 01:24:11,912 epoch 87 - iter 1536/3843 - loss 0.09988086 - samples/sec: 381.45 - lr: 0.025000\n",
            "2022-09-13 01:24:57,006 epoch 87 - iter 1920/3843 - loss 0.09973244 - samples/sec: 380.93 - lr: 0.025000\n",
            "2022-09-13 01:25:41,911 epoch 87 - iter 2304/3843 - loss 0.09995884 - samples/sec: 349.67 - lr: 0.025000\n",
            "2022-09-13 01:26:26,049 epoch 87 - iter 2688/3843 - loss 0.10051129 - samples/sec: 392.09 - lr: 0.025000\n",
            "2022-09-13 01:27:11,553 epoch 87 - iter 3072/3843 - loss 0.10044252 - samples/sec: 359.14 - lr: 0.025000\n",
            "2022-09-13 01:27:54,848 epoch 87 - iter 3456/3843 - loss 0.10039088 - samples/sec: 384.58 - lr: 0.025000\n",
            "2022-09-13 01:28:40,157 epoch 87 - iter 3840/3843 - loss 0.10066240 - samples/sec: 344.87 - lr: 0.025000\n",
            "2022-09-13 01:28:40,460 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:28:40,462 EPOCH 87 done: loss 0.1007 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 01:29:55,552 Evaluating as a multi-label problem: False\n",
            "2022-09-13 01:29:55,796 DEV : loss 0.07317440956830978 - f1-score (micro avg)  0.8022\n",
            "2022-09-13 01:30:08,043 BAD EPOCHS (no improvement): 0\n",
            "2022-09-13 01:30:08,046 saving best model\n",
            "2022-09-13 01:30:11,250 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:30:56,140 epoch 88 - iter 384/3843 - loss 0.10002071 - samples/sec: 404.70 - lr: 0.025000\n",
            "2022-09-13 01:31:39,881 epoch 88 - iter 768/3843 - loss 0.10028325 - samples/sec: 396.22 - lr: 0.025000\n",
            "2022-09-13 01:32:24,416 epoch 88 - iter 1152/3843 - loss 0.10005449 - samples/sec: 368.41 - lr: 0.025000\n",
            "2022-09-13 01:33:08,138 epoch 88 - iter 1536/3843 - loss 0.10033241 - samples/sec: 378.29 - lr: 0.025000\n",
            "2022-09-13 01:33:53,030 epoch 88 - iter 1920/3843 - loss 0.10039106 - samples/sec: 382.03 - lr: 0.025000\n",
            "2022-09-13 01:34:37,741 epoch 88 - iter 2304/3843 - loss 0.10019572 - samples/sec: 384.67 - lr: 0.025000\n",
            "2022-09-13 01:35:20,902 epoch 88 - iter 2688/3843 - loss 0.10027224 - samples/sec: 384.77 - lr: 0.025000\n",
            "2022-09-13 01:36:05,333 epoch 88 - iter 3072/3843 - loss 0.10017363 - samples/sec: 407.94 - lr: 0.025000\n",
            "2022-09-13 01:36:48,412 epoch 88 - iter 3456/3843 - loss 0.10016779 - samples/sec: 404.75 - lr: 0.025000\n",
            "2022-09-13 01:37:34,814 epoch 88 - iter 3840/3843 - loss 0.10001642 - samples/sec: 365.39 - lr: 0.025000\n",
            "2022-09-13 01:37:35,082 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:37:35,084 EPOCH 88 done: loss 0.1000 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 01:38:49,942 Evaluating as a multi-label problem: False\n",
            "2022-09-13 01:38:50,191 DEV : loss 0.07374802231788635 - f1-score (micro avg)  0.8017\n",
            "2022-09-13 01:39:02,318 BAD EPOCHS (no improvement): 1\n",
            "2022-09-13 01:39:02,320 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:39:47,749 epoch 89 - iter 384/3843 - loss 0.09787488 - samples/sec: 376.32 - lr: 0.025000\n",
            "2022-09-13 01:40:30,207 epoch 89 - iter 768/3843 - loss 0.09925327 - samples/sec: 374.60 - lr: 0.025000\n",
            "2022-09-13 01:41:15,853 epoch 89 - iter 1152/3843 - loss 0.09917876 - samples/sec: 373.20 - lr: 0.025000\n",
            "2022-09-13 01:42:01,051 epoch 89 - iter 1536/3843 - loss 0.09965593 - samples/sec: 361.47 - lr: 0.025000\n",
            "2022-09-13 01:42:44,007 epoch 89 - iter 1920/3843 - loss 0.09984383 - samples/sec: 368.96 - lr: 0.025000\n",
            "2022-09-13 01:43:28,627 epoch 89 - iter 2304/3843 - loss 0.10020559 - samples/sec: 405.86 - lr: 0.025000\n",
            "2022-09-13 01:44:10,983 epoch 89 - iter 2688/3843 - loss 0.10035917 - samples/sec: 375.67 - lr: 0.025000\n",
            "2022-09-13 01:44:55,820 epoch 89 - iter 3072/3843 - loss 0.10049336 - samples/sec: 382.87 - lr: 0.025000\n",
            "2022-09-13 01:45:40,580 epoch 89 - iter 3456/3843 - loss 0.10048689 - samples/sec: 367.02 - lr: 0.025000\n",
            "2022-09-13 01:46:24,947 epoch 89 - iter 3840/3843 - loss 0.09999805 - samples/sec: 370.27 - lr: 0.025000\n",
            "2022-09-13 01:46:25,206 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:46:25,207 EPOCH 89 done: loss 0.1000 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 01:47:41,688 Evaluating as a multi-label problem: False\n",
            "2022-09-13 01:47:41,943 DEV : loss 0.07374890893697739 - f1-score (micro avg)  0.8036\n",
            "2022-09-13 01:47:52,430 BAD EPOCHS (no improvement): 0\n",
            "2022-09-13 01:47:52,432 saving best model\n",
            "2022-09-13 01:47:55,603 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:48:40,464 epoch 90 - iter 384/3843 - loss 0.10007855 - samples/sec: 364.82 - lr: 0.025000\n",
            "2022-09-13 01:49:25,863 epoch 90 - iter 768/3843 - loss 0.10000025 - samples/sec: 344.09 - lr: 0.025000\n",
            "2022-09-13 01:50:10,181 epoch 90 - iter 1152/3843 - loss 0.09984503 - samples/sec: 388.50 - lr: 0.025000\n",
            "2022-09-13 01:50:53,073 epoch 90 - iter 1536/3843 - loss 0.09976040 - samples/sec: 369.70 - lr: 0.025000\n",
            "2022-09-13 01:51:39,063 epoch 90 - iter 1920/3843 - loss 0.09957627 - samples/sec: 338.64 - lr: 0.025000\n",
            "2022-09-13 01:52:23,495 epoch 90 - iter 2304/3843 - loss 0.09964515 - samples/sec: 353.63 - lr: 0.025000\n",
            "2022-09-13 01:53:08,372 epoch 90 - iter 2688/3843 - loss 0.09941495 - samples/sec: 383.52 - lr: 0.025000\n",
            "2022-09-13 01:53:52,298 epoch 90 - iter 3072/3843 - loss 0.09949530 - samples/sec: 396.12 - lr: 0.025000\n",
            "2022-09-13 01:54:37,189 epoch 90 - iter 3456/3843 - loss 0.09961977 - samples/sec: 364.89 - lr: 0.025000\n",
            "2022-09-13 01:55:22,736 epoch 90 - iter 3840/3843 - loss 0.09959903 - samples/sec: 398.44 - lr: 0.025000\n",
            "2022-09-13 01:55:23,008 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:55:23,010 EPOCH 90 done: loss 0.0996 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 01:56:38,449 Evaluating as a multi-label problem: False\n",
            "2022-09-13 01:56:38,708 DEV : loss 0.07305771112442017 - f1-score (micro avg)  0.8034\n",
            "2022-09-13 01:56:51,018 BAD EPOCHS (no improvement): 1\n",
            "2022-09-13 01:56:51,022 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 01:57:33,745 epoch 91 - iter 384/3843 - loss 0.10033689 - samples/sec: 395.19 - lr: 0.025000\n",
            "2022-09-13 01:58:18,190 epoch 91 - iter 768/3843 - loss 0.09979543 - samples/sec: 386.88 - lr: 0.025000\n",
            "2022-09-13 01:59:04,766 epoch 91 - iter 1152/3843 - loss 0.09996031 - samples/sec: 349.46 - lr: 0.025000\n",
            "2022-09-13 01:59:50,869 epoch 91 - iter 1536/3843 - loss 0.10006912 - samples/sec: 370.67 - lr: 0.025000\n",
            "2022-09-13 02:00:37,957 epoch 91 - iter 1920/3843 - loss 0.09972960 - samples/sec: 380.65 - lr: 0.025000\n",
            "2022-09-13 02:01:23,926 epoch 91 - iter 2304/3843 - loss 0.09970117 - samples/sec: 327.22 - lr: 0.025000\n",
            "2022-09-13 02:02:10,440 epoch 91 - iter 2688/3843 - loss 0.09955106 - samples/sec: 389.65 - lr: 0.025000\n",
            "2022-09-13 02:02:55,889 epoch 91 - iter 3072/3843 - loss 0.09966724 - samples/sec: 347.27 - lr: 0.025000\n",
            "2022-09-13 02:03:42,510 epoch 91 - iter 3456/3843 - loss 0.09953428 - samples/sec: 387.61 - lr: 0.025000\n",
            "2022-09-13 02:04:27,581 epoch 91 - iter 3840/3843 - loss 0.09959041 - samples/sec: 386.41 - lr: 0.025000\n",
            "2022-09-13 02:04:27,886 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 02:04:27,888 EPOCH 91 done: loss 0.0996 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:18<00:00,  5.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 02:05:46,517 Evaluating as a multi-label problem: False\n",
            "2022-09-13 02:05:46,783 DEV : loss 0.07329285889863968 - f1-score (micro avg)  0.8027\n",
            "2022-09-13 02:05:57,448 BAD EPOCHS (no improvement): 2\n",
            "2022-09-13 02:05:57,450 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 02:06:44,883 epoch 92 - iter 384/3843 - loss 0.09795358 - samples/sec: 389.43 - lr: 0.025000\n",
            "2022-09-13 02:07:31,795 epoch 92 - iter 768/3843 - loss 0.09780673 - samples/sec: 362.88 - lr: 0.025000\n",
            "2022-09-13 02:08:15,293 epoch 92 - iter 1152/3843 - loss 0.09767197 - samples/sec: 383.24 - lr: 0.025000\n",
            "2022-09-13 02:09:01,412 epoch 92 - iter 1536/3843 - loss 0.09795490 - samples/sec: 388.78 - lr: 0.025000\n",
            "2022-09-13 02:09:46,314 epoch 92 - iter 1920/3843 - loss 0.09814022 - samples/sec: 367.24 - lr: 0.025000\n",
            "2022-09-13 02:10:33,177 epoch 92 - iter 2304/3843 - loss 0.09837766 - samples/sec: 380.07 - lr: 0.025000\n",
            "2022-09-13 02:11:17,863 epoch 92 - iter 2688/3843 - loss 0.09853119 - samples/sec: 369.94 - lr: 0.025000\n",
            "2022-09-13 02:12:03,032 epoch 92 - iter 3072/3843 - loss 0.09873575 - samples/sec: 403.22 - lr: 0.025000\n",
            "2022-09-13 02:12:49,780 epoch 92 - iter 3456/3843 - loss 0.09898892 - samples/sec: 365.55 - lr: 0.025000\n",
            "2022-09-13 02:13:34,284 epoch 92 - iter 3840/3843 - loss 0.09922295 - samples/sec: 391.27 - lr: 0.025000\n",
            "2022-09-13 02:13:34,605 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 02:13:34,606 EPOCH 92 done: loss 0.0992 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:17<00:00,  5.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 02:14:52,627 Evaluating as a multi-label problem: False\n",
            "2022-09-13 02:14:52,886 DEV : loss 0.07269760966300964 - f1-score (micro avg)  0.8033\n",
            "2022-09-13 02:15:03,577 BAD EPOCHS (no improvement): 3\n",
            "2022-09-13 02:15:03,580 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 02:15:51,308 epoch 93 - iter 384/3843 - loss 0.09899813 - samples/sec: 355.04 - lr: 0.025000\n",
            "2022-09-13 02:16:35,542 epoch 93 - iter 768/3843 - loss 0.09939327 - samples/sec: 357.55 - lr: 0.025000\n",
            "2022-09-13 02:17:22,524 epoch 93 - iter 1152/3843 - loss 0.09943765 - samples/sec: 362.13 - lr: 0.025000\n",
            "2022-09-13 02:18:06,448 epoch 93 - iter 1536/3843 - loss 0.09917142 - samples/sec: 399.01 - lr: 0.025000\n",
            "2022-09-13 02:18:52,984 epoch 93 - iter 1920/3843 - loss 0.09919087 - samples/sec: 366.78 - lr: 0.025000\n",
            "2022-09-13 02:19:39,264 epoch 93 - iter 2304/3843 - loss 0.09897873 - samples/sec: 338.78 - lr: 0.025000\n",
            "2022-09-13 02:20:23,395 epoch 93 - iter 2688/3843 - loss 0.09921457 - samples/sec: 377.20 - lr: 0.025000\n",
            "2022-09-13 02:21:09,454 epoch 93 - iter 3072/3843 - loss 0.09905191 - samples/sec: 356.39 - lr: 0.025000\n",
            "2022-09-13 02:21:53,517 epoch 93 - iter 3456/3843 - loss 0.09898412 - samples/sec: 344.29 - lr: 0.025000\n",
            "2022-09-13 02:22:40,535 epoch 93 - iter 3840/3843 - loss 0.09898009 - samples/sec: 362.80 - lr: 0.025000\n",
            "2022-09-13 02:22:40,769 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 02:22:40,771 EPOCH 93 done: loss 0.0990 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 02:23:56,863 Evaluating as a multi-label problem: False\n",
            "2022-09-13 02:23:57,127 DEV : loss 0.07312982529401779 - f1-score (micro avg)  0.8041\n",
            "2022-09-13 02:24:09,442 BAD EPOCHS (no improvement): 0\n",
            "2022-09-13 02:24:09,444 saving best model\n",
            "2022-09-13 02:24:12,649 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 02:24:58,589 epoch 94 - iter 384/3843 - loss 0.09934074 - samples/sec: 374.30 - lr: 0.025000\n",
            "2022-09-13 02:25:43,388 epoch 94 - iter 768/3843 - loss 0.09942218 - samples/sec: 350.89 - lr: 0.025000\n",
            "2022-09-13 02:26:29,790 epoch 94 - iter 1152/3843 - loss 0.09899972 - samples/sec: 369.36 - lr: 0.025000\n",
            "2022-09-13 02:27:15,842 epoch 94 - iter 1536/3843 - loss 0.09867741 - samples/sec: 355.33 - lr: 0.025000\n",
            "2022-09-13 02:28:00,078 epoch 94 - iter 1920/3843 - loss 0.09842030 - samples/sec: 375.10 - lr: 0.025000\n",
            "2022-09-13 02:28:46,639 epoch 94 - iter 2304/3843 - loss 0.09864497 - samples/sec: 366.67 - lr: 0.025000\n",
            "2022-09-13 02:29:31,638 epoch 94 - iter 2688/3843 - loss 0.09874698 - samples/sec: 366.37 - lr: 0.025000\n",
            "2022-09-13 02:30:16,975 epoch 94 - iter 3072/3843 - loss 0.09873850 - samples/sec: 363.21 - lr: 0.025000\n",
            "2022-09-13 02:31:02,739 epoch 94 - iter 3456/3843 - loss 0.09859941 - samples/sec: 395.70 - lr: 0.025000\n",
            "2022-09-13 02:31:46,710 epoch 94 - iter 3840/3843 - loss 0.09865336 - samples/sec: 378.98 - lr: 0.025000\n",
            "2022-09-13 02:31:47,054 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 02:31:47,056 EPOCH 94 done: loss 0.0987 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:17<00:00,  5.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 02:33:05,039 Evaluating as a multi-label problem: False\n",
            "2022-09-13 02:33:05,299 DEV : loss 0.07313618063926697 - f1-score (micro avg)  0.8034\n",
            "2022-09-13 02:33:15,965 BAD EPOCHS (no improvement): 1\n",
            "2022-09-13 02:33:15,968 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 02:34:00,937 epoch 95 - iter 384/3843 - loss 0.09774735 - samples/sec: 404.34 - lr: 0.025000\n",
            "2022-09-13 02:34:46,739 epoch 95 - iter 768/3843 - loss 0.09790924 - samples/sec: 376.39 - lr: 0.025000\n",
            "2022-09-13 02:35:32,641 epoch 95 - iter 1152/3843 - loss 0.09813597 - samples/sec: 374.30 - lr: 0.025000\n",
            "2022-09-13 02:36:17,205 epoch 95 - iter 1536/3843 - loss 0.09834461 - samples/sec: 354.39 - lr: 0.025000\n",
            "2022-09-13 02:37:03,648 epoch 95 - iter 1920/3843 - loss 0.09853026 - samples/sec: 352.54 - lr: 0.025000\n",
            "2022-09-13 02:37:48,261 epoch 95 - iter 2304/3843 - loss 0.09883706 - samples/sec: 371.11 - lr: 0.025000\n",
            "2022-09-13 02:38:34,249 epoch 95 - iter 2688/3843 - loss 0.09899366 - samples/sec: 387.56 - lr: 0.025000\n",
            "2022-09-13 02:39:18,567 epoch 95 - iter 3072/3843 - loss 0.09911316 - samples/sec: 410.31 - lr: 0.025000\n",
            "2022-09-13 02:40:03,145 epoch 95 - iter 3456/3843 - loss 0.09903802 - samples/sec: 352.36 - lr: 0.025000\n",
            "2022-09-13 02:40:48,072 epoch 95 - iter 3840/3843 - loss 0.09892100 - samples/sec: 382.81 - lr: 0.025000\n",
            "2022-09-13 02:40:48,335 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 02:40:48,337 EPOCH 95 done: loss 0.0989 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:14<00:00,  5.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 02:42:02,942 Evaluating as a multi-label problem: False\n",
            "2022-09-13 02:42:03,208 DEV : loss 0.07273318618535995 - f1-score (micro avg)  0.8044\n",
            "2022-09-13 02:42:15,595 BAD EPOCHS (no improvement): 0\n",
            "2022-09-13 02:42:15,598 saving best model\n",
            "2022-09-13 02:42:18,747 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 02:43:03,474 epoch 96 - iter 384/3843 - loss 0.09847818 - samples/sec: 335.07 - lr: 0.025000\n",
            "2022-09-13 02:43:49,425 epoch 96 - iter 768/3843 - loss 0.09783336 - samples/sec: 388.12 - lr: 0.025000\n",
            "2022-09-13 02:44:33,891 epoch 96 - iter 1152/3843 - loss 0.09829738 - samples/sec: 387.43 - lr: 0.025000\n",
            "2022-09-13 02:45:17,642 epoch 96 - iter 1536/3843 - loss 0.09847414 - samples/sec: 378.14 - lr: 0.025000\n",
            "2022-09-13 02:46:02,529 epoch 96 - iter 1920/3843 - loss 0.09827329 - samples/sec: 384.01 - lr: 0.025000\n",
            "2022-09-13 02:46:45,113 epoch 96 - iter 2304/3843 - loss 0.09852080 - samples/sec: 412.58 - lr: 0.025000\n",
            "2022-09-13 02:47:31,168 epoch 96 - iter 2688/3843 - loss 0.09840889 - samples/sec: 352.98 - lr: 0.025000\n",
            "2022-09-13 02:48:15,553 epoch 96 - iter 3072/3843 - loss 0.09858224 - samples/sec: 371.32 - lr: 0.025000\n",
            "2022-09-13 02:49:01,072 epoch 96 - iter 3456/3843 - loss 0.09867857 - samples/sec: 378.05 - lr: 0.025000\n",
            "2022-09-13 02:49:46,675 epoch 96 - iter 3840/3843 - loss 0.09885148 - samples/sec: 343.32 - lr: 0.025000\n",
            "2022-09-13 02:49:46,978 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 02:49:46,979 EPOCH 96 done: loss 0.0988 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 02:51:03,491 Evaluating as a multi-label problem: False\n",
            "2022-09-13 02:51:03,754 DEV : loss 0.07304920256137848 - f1-score (micro avg)  0.8034\n",
            "2022-09-13 02:51:16,217 BAD EPOCHS (no improvement): 1\n",
            "2022-09-13 02:51:16,221 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 02:52:00,738 epoch 97 - iter 384/3843 - loss 0.09804693 - samples/sec: 393.64 - lr: 0.025000\n",
            "2022-09-13 02:52:47,279 epoch 97 - iter 768/3843 - loss 0.09846846 - samples/sec: 349.88 - lr: 0.025000\n",
            "2022-09-13 02:53:30,969 epoch 97 - iter 1152/3843 - loss 0.09823257 - samples/sec: 400.11 - lr: 0.025000\n",
            "2022-09-13 02:54:17,059 epoch 97 - iter 1536/3843 - loss 0.09812310 - samples/sec: 354.52 - lr: 0.025000\n",
            "2022-09-13 02:55:00,582 epoch 97 - iter 1920/3843 - loss 0.09872425 - samples/sec: 382.40 - lr: 0.025000\n",
            "2022-09-13 02:55:47,183 epoch 97 - iter 2304/3843 - loss 0.09878287 - samples/sec: 366.51 - lr: 0.025000\n",
            "2022-09-13 02:56:32,794 epoch 97 - iter 2688/3843 - loss 0.09862365 - samples/sec: 377.26 - lr: 0.025000\n",
            "2022-09-13 02:57:16,780 epoch 97 - iter 3072/3843 - loss 0.09871539 - samples/sec: 396.75 - lr: 0.025000\n",
            "2022-09-13 02:58:02,179 epoch 97 - iter 3456/3843 - loss 0.09892036 - samples/sec: 397.45 - lr: 0.025000\n",
            "2022-09-13 02:58:47,429 epoch 97 - iter 3840/3843 - loss 0.09876096 - samples/sec: 364.14 - lr: 0.025000\n",
            "2022-09-13 02:58:47,784 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 02:58:47,786 EPOCH 97 done: loss 0.0988 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:17<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 03:00:05,524 Evaluating as a multi-label problem: False\n",
            "2022-09-13 03:00:05,784 DEV : loss 0.07284247875213623 - f1-score (micro avg)  0.8044\n",
            "2022-09-13 03:00:16,396 BAD EPOCHS (no improvement): 0\n",
            "2022-09-13 03:00:16,399 saving best model\n",
            "2022-09-13 03:00:19,511 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 03:01:06,445 epoch 98 - iter 384/3843 - loss 0.09790410 - samples/sec: 395.33 - lr: 0.025000\n",
            "2022-09-13 03:01:50,677 epoch 98 - iter 768/3843 - loss 0.09834697 - samples/sec: 392.37 - lr: 0.025000\n",
            "2022-09-13 03:02:36,426 epoch 98 - iter 1152/3843 - loss 0.09803247 - samples/sec: 356.66 - lr: 0.025000\n",
            "2022-09-13 03:03:22,006 epoch 98 - iter 1536/3843 - loss 0.09821077 - samples/sec: 358.79 - lr: 0.025000\n",
            "2022-09-13 03:04:05,228 epoch 98 - iter 1920/3843 - loss 0.09840711 - samples/sec: 407.37 - lr: 0.025000\n",
            "2022-09-13 03:04:51,019 epoch 98 - iter 2304/3843 - loss 0.09830985 - samples/sec: 374.86 - lr: 0.025000\n",
            "2022-09-13 03:05:35,615 epoch 98 - iter 2688/3843 - loss 0.09835074 - samples/sec: 390.86 - lr: 0.025000\n",
            "2022-09-13 03:06:22,310 epoch 98 - iter 3072/3843 - loss 0.09847578 - samples/sec: 367.56 - lr: 0.025000\n",
            "2022-09-13 03:07:07,120 epoch 98 - iter 3456/3843 - loss 0.09846108 - samples/sec: 388.99 - lr: 0.025000\n",
            "2022-09-13 03:07:52,943 epoch 98 - iter 3840/3843 - loss 0.09844370 - samples/sec: 376.69 - lr: 0.025000\n",
            "2022-09-13 03:07:53,183 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 03:07:53,185 EPOCH 98 done: loss 0.0985 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:16<00:00,  5.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 03:09:09,474 Evaluating as a multi-label problem: False\n",
            "2022-09-13 03:09:09,742 DEV : loss 0.07316860556602478 - f1-score (micro avg)  0.804\n",
            "2022-09-13 03:09:22,019 BAD EPOCHS (no improvement): 1\n",
            "2022-09-13 03:09:22,022 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 03:10:08,616 epoch 99 - iter 384/3843 - loss 0.09876164 - samples/sec: 382.65 - lr: 0.025000\n",
            "2022-09-13 03:10:54,980 epoch 99 - iter 768/3843 - loss 0.09901816 - samples/sec: 367.58 - lr: 0.025000\n",
            "2022-09-13 03:11:38,870 epoch 99 - iter 1152/3843 - loss 0.09887431 - samples/sec: 397.79 - lr: 0.025000\n",
            "2022-09-13 03:12:24,755 epoch 99 - iter 1536/3843 - loss 0.09830056 - samples/sec: 340.67 - lr: 0.025000\n",
            "2022-09-13 03:13:08,315 epoch 99 - iter 1920/3843 - loss 0.09848687 - samples/sec: 364.51 - lr: 0.025000\n",
            "2022-09-13 03:13:53,473 epoch 99 - iter 2304/3843 - loss 0.09848300 - samples/sec: 380.40 - lr: 0.025000\n",
            "2022-09-13 03:14:40,053 epoch 99 - iter 2688/3843 - loss 0.09869028 - samples/sec: 366.04 - lr: 0.025000\n",
            "2022-09-13 03:15:24,215 epoch 99 - iter 3072/3843 - loss 0.09843751 - samples/sec: 374.93 - lr: 0.025000\n",
            "2022-09-13 03:16:10,209 epoch 99 - iter 3456/3843 - loss 0.09850910 - samples/sec: 372.30 - lr: 0.025000\n",
            "2022-09-13 03:16:53,731 epoch 99 - iter 3840/3843 - loss 0.09847281 - samples/sec: 401.52 - lr: 0.025000\n",
            "2022-09-13 03:16:53,978 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 03:16:53,980 EPOCH 99 done: loss 0.0985 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:17<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 03:18:11,853 Evaluating as a multi-label problem: False\n",
            "2022-09-13 03:18:12,106 DEV : loss 0.07289396226406097 - f1-score (micro avg)  0.8048\n",
            "2022-09-13 03:18:22,698 BAD EPOCHS (no improvement): 0\n",
            "2022-09-13 03:18:22,700 saving best model\n",
            "2022-09-13 03:18:25,823 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 03:19:12,699 epoch 100 - iter 384/3843 - loss 0.09942264 - samples/sec: 331.17 - lr: 0.025000\n",
            "2022-09-13 03:19:56,852 epoch 100 - iter 768/3843 - loss 0.09886207 - samples/sec: 374.61 - lr: 0.025000\n",
            "2022-09-13 03:20:42,650 epoch 100 - iter 1152/3843 - loss 0.09800157 - samples/sec: 373.41 - lr: 0.025000\n",
            "2022-09-13 03:21:26,816 epoch 100 - iter 1536/3843 - loss 0.09799267 - samples/sec: 374.66 - lr: 0.025000\n",
            "2022-09-13 03:22:12,679 epoch 100 - iter 1920/3843 - loss 0.09819870 - samples/sec: 392.34 - lr: 0.025000\n",
            "2022-09-13 03:22:58,318 epoch 100 - iter 2304/3843 - loss 0.09821611 - samples/sec: 376.98 - lr: 0.025000\n",
            "2022-09-13 03:23:42,614 epoch 100 - iter 2688/3843 - loss 0.09817798 - samples/sec: 374.87 - lr: 0.025000\n",
            "2022-09-13 03:24:29,160 epoch 100 - iter 3072/3843 - loss 0.09829323 - samples/sec: 387.52 - lr: 0.025000\n",
            "2022-09-13 03:25:13,527 epoch 100 - iter 3456/3843 - loss 0.09814445 - samples/sec: 371.93 - lr: 0.025000\n",
            "2022-09-13 03:25:58,790 epoch 100 - iter 3840/3843 - loss 0.09824437 - samples/sec: 400.83 - lr: 0.025000\n",
            "2022-09-13 03:25:59,091 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 03:25:59,092 EPOCH 100 done: loss 0.0982 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [01:15<00:00,  5.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 03:27:14,900 Evaluating as a multi-label problem: False\n",
            "2022-09-13 03:27:15,162 DEV : loss 0.0730525404214859 - f1-score (micro avg)  0.8048\n",
            "2022-09-13 03:27:27,481 BAD EPOCHS (no improvement): 1\n",
            "2022-09-13 03:27:30,135 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 03:27:30,137 loading file resources/taggers/sota-ner-flair/best-model.pt\n",
            "2022-09-13 03:27:31,847 SequenceTagger predicts: Dictionary with 31 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, S-LEGISLACAO, B-LEGISLACAO, E-LEGISLACAO, I-LEGISLACAO, S-TEMPO, B-TEMPO, E-TEMPO, I-TEMPO, S-JURISPRUDENCIA, B-JURISPRUDENCIA, E-JURISPRUDENCIA, I-JURISPRUDENCIA, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 488/488 [01:16<00:00,  6.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 03:28:49,113 Evaluating as a multi-label problem: False\n",
            "2022-09-13 03:28:49,404 0.8346\t0.7826\t0.8078\t0.7082\n",
            "2022-09-13 03:28:49,405 \n",
            "Results:\n",
            "- F-score (micro) 0.8078\n",
            "- F-score (macro) 0.8074\n",
            "- Accuracy 0.7082\n",
            "\n",
            "By class:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "           PER     0.9089    0.9166    0.9127      9881\n",
            "           LOC     0.8210    0.8153    0.8181      8661\n",
            "          MISC     0.7578    0.6267    0.6860      7500\n",
            "           ORG     0.7981    0.6974    0.7444      5470\n",
            "    LEGISLACAO     0.8883    0.8836    0.8859       378\n",
            "         TEMPO     0.8909    0.7656    0.8235       192\n",
            "JURISPRUDENCIA     0.8129    0.7514    0.7809       185\n",
            "\n",
            "     micro avg     0.8346    0.7826    0.8078     32267\n",
            "     macro avg     0.8397    0.7795    0.8074     32267\n",
            "  weighted avg     0.8305    0.7826    0.8045     32267\n",
            "\n",
            "2022-09-13 03:28:49,406 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-13 03:28:49,408 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44/44 [00:08<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 03:28:58,370 Evaluating as a multi-label problem: False\n",
            "2022-09-13 03:28:58,392 /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/Alter\n",
            "2022-09-13 03:28:58,393 0.8511\t0.804\t0.8269\t0.7102\n",
            "2022-09-13 03:28:58,394 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 445/445 [01:06<00:00,  6.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 03:30:05,016 Evaluating as a multi-label problem: False\n",
            "2022-09-13 03:30:05,297 wikiner\n",
            "2022-09-13 03:30:05,299 0.8337\t0.7816\t0.8068\t0.7081\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_score': 0.8077599718517097,\n",
              " 'dev_score_history': [0.5974741170423673,\n",
              "  0.6812849111516839,\n",
              "  0.7061810194270898,\n",
              "  0.7135397239835881,\n",
              "  0.7270060834298957,\n",
              "  0.736639781566042,\n",
              "  0.7463443587114875,\n",
              "  0.7469422483780622,\n",
              "  0.755821215095013,\n",
              "  0.7574586821206267,\n",
              "  0.7571674566402158,\n",
              "  0.7593519565100383,\n",
              "  0.7579241431180832,\n",
              "  0.7586885715308351,\n",
              "  0.7639560597616009,\n",
              "  0.7664550378421033,\n",
              "  0.7665886026541764,\n",
              "  0.7691345225753405,\n",
              "  0.7733040723501406,\n",
              "  0.772286341428875,\n",
              "  0.7738903764651641,\n",
              "  0.7703573730573658,\n",
              "  0.7706201509287242,\n",
              "  0.7735093681607088,\n",
              "  0.7721336302895323,\n",
              "  0.7794086213038831,\n",
              "  0.7815958066394875,\n",
              "  0.7823682671345775,\n",
              "  0.7838953160270881,\n",
              "  0.7828912325556621,\n",
              "  0.784470887327425,\n",
              "  0.7847087421086687,\n",
              "  0.7862398302087018,\n",
              "  0.787283563141376,\n",
              "  0.7872216227690022,\n",
              "  0.7874043764454722,\n",
              "  0.7882946447470542,\n",
              "  0.7889229468343728,\n",
              "  0.7883554864253393,\n",
              "  0.788220640569395,\n",
              "  0.7874965054514957,\n",
              "  0.7902077996014802,\n",
              "  0.7914659325533381,\n",
              "  0.7904128018126461,\n",
              "  0.792406398312533,\n",
              "  0.7925048612338695,\n",
              "  0.7915889494985043,\n",
              "  0.7911842804036113,\n",
              "  0.7930164888457808,\n",
              "  0.7913075925300733,\n",
              "  0.7931393114632728,\n",
              "  0.7921443170710033,\n",
              "  0.792036325532658,\n",
              "  0.794170836625406,\n",
              "  0.7946499374416268,\n",
              "  0.794389723891248,\n",
              "  0.7955030044582284,\n",
              "  0.7935439536235971,\n",
              "  0.794782884199039,\n",
              "  0.7962248868698607,\n",
              "  0.7950883668109873,\n",
              "  0.7922292545710268,\n",
              "  0.7953648827952233,\n",
              "  0.7963168756945546,\n",
              "  0.7968953500651202,\n",
              "  0.7955738802551362,\n",
              "  0.7956727804499886,\n",
              "  0.7975317757502242,\n",
              "  0.796599707236204,\n",
              "  0.7971995827661192,\n",
              "  0.7975330768014337,\n",
              "  0.7969797473713922,\n",
              "  0.7979682984499518,\n",
              "  0.7974386787501312,\n",
              "  0.7969289286468971,\n",
              "  0.7986047494891128,\n",
              "  0.7987069193944426,\n",
              "  0.7970056014099498,\n",
              "  0.7986782523558928,\n",
              "  0.7968057412228243,\n",
              "  0.8012576186043245,\n",
              "  0.7988819941287113,\n",
              "  0.7996152164407521,\n",
              "  0.8002247230464017,\n",
              "  0.8003093798340599,\n",
              "  0.8015427769985974,\n",
              "  0.8021902806297057,\n",
              "  0.8017362575565865,\n",
              "  0.8036133312161471,\n",
              "  0.8033853255927818,\n",
              "  0.8026833380162968,\n",
              "  0.8032643032643034,\n",
              "  0.8041258851851201,\n",
              "  0.8034136899524899,\n",
              "  0.8043524043524043,\n",
              "  0.8034251022091207,\n",
              "  0.8044035537451276,\n",
              "  0.8039642168040695,\n",
              "  0.8048480590198489,\n",
              "  0.8047848070045629],\n",
              " 'train_loss_history': [0.24481820204355104,\n",
              "  0.17518286719983997,\n",
              "  0.15636731202824525,\n",
              "  0.14818625235693728,\n",
              "  0.14297246805669733,\n",
              "  0.13931621557110616,\n",
              "  0.13642237736743568,\n",
              "  0.13463035237561607,\n",
              "  0.13293552305336967,\n",
              "  0.13124115619264137,\n",
              "  0.13045181950859683,\n",
              "  0.12893064010249788,\n",
              "  0.1285627560299192,\n",
              "  0.1274590410028629,\n",
              "  0.1268254589987797,\n",
              "  0.1258468733691257,\n",
              "  0.12547224239588156,\n",
              "  0.12476058250835342,\n",
              "  0.12432974022233474,\n",
              "  0.1237701892047304,\n",
              "  0.12334365940026554,\n",
              "  0.12305229923840569,\n",
              "  0.12276434162002818,\n",
              "  0.1222391415616942,\n",
              "  0.1220244860866171,\n",
              "  0.11686678748051113,\n",
              "  0.11488363229234956,\n",
              "  0.11400317905197936,\n",
              "  0.1133592870733282,\n",
              "  0.11287302146049981,\n",
              "  0.11202136868469566,\n",
              "  0.11162781983112936,\n",
              "  0.11161576267343891,\n",
              "  0.11102973593319147,\n",
              "  0.11086593974726008,\n",
              "  0.11062873939273649,\n",
              "  0.11033383927207933,\n",
              "  0.11031589095085859,\n",
              "  0.1097645724178174,\n",
              "  0.10977116883117745,\n",
              "  0.10920496209801218,\n",
              "  0.10938298969625153,\n",
              "  0.10895270854933788,\n",
              "  0.10862292151779925,\n",
              "  0.10856482544717277,\n",
              "  0.10828698810008625,\n",
              "  0.10842597954635719,\n",
              "  0.10848737167156769,\n",
              "  0.10808184233869433,\n",
              "  0.10777710108156807,\n",
              "  0.1078090203317736,\n",
              "  0.10751775932574423,\n",
              "  0.10732521034018783,\n",
              "  0.10726080815003945,\n",
              "  0.10709297973327774,\n",
              "  0.10670622066288239,\n",
              "  0.10663076227880508,\n",
              "  0.1066845033042013,\n",
              "  0.106050808434639,\n",
              "  0.10612874523623507,\n",
              "  0.10605569225782706,\n",
              "  0.10609496848806027,\n",
              "  0.10578158855817776,\n",
              "  0.10592559741700325,\n",
              "  0.10580197289265536,\n",
              "  0.10543299396116379,\n",
              "  0.10547644908358435,\n",
              "  0.1054126330606204,\n",
              "  0.10507883611628402,\n",
              "  0.1050826279500205,\n",
              "  0.10527866333109599,\n",
              "  0.10507599487132122,\n",
              "  0.10494715526041588,\n",
              "  0.1048605169767433,\n",
              "  0.10455691792464192,\n",
              "  0.10438030273903628,\n",
              "  0.10450988298979445,\n",
              "  0.10426885764331452,\n",
              "  0.10421224651892765,\n",
              "  0.10385019111938804,\n",
              "  0.10367423575047438,\n",
              "  0.10407328583965876,\n",
              "  0.10402447215761414,\n",
              "  0.10382515490984678,\n",
              "  0.10388779620722406,\n",
              "  0.10163887262634078,\n",
              "  0.10067019094247619,\n",
              "  0.10001717583034712,\n",
              "  0.09999863560301926,\n",
              "  0.09959976915936015,\n",
              "  0.09958229509633187,\n",
              "  0.09922151756357236,\n",
              "  0.0989833028544677,\n",
              "  0.09865910967838241,\n",
              "  0.09892061883399947,\n",
              "  0.09884898336948973,\n",
              "  0.09877190900043863,\n",
              "  0.098450702455357,\n",
              "  0.09846826913822052,\n",
              "  0.09823334777365306],\n",
              " 'dev_loss_history': [0.23824256658554077,\n",
              "  0.12456756085157394,\n",
              "  0.11420633643865585,\n",
              "  0.11365457624197006,\n",
              "  0.10525735467672348,\n",
              "  0.09947327524423599,\n",
              "  0.09771141409873962,\n",
              "  0.0960039347410202,\n",
              "  0.09306784719228745,\n",
              "  0.09258154779672623,\n",
              "  0.09122157096862793,\n",
              "  0.08981698006391525,\n",
              "  0.09164556115865707,\n",
              "  0.09336325526237488,\n",
              "  0.08979874104261398,\n",
              "  0.08890406042337418,\n",
              "  0.08813448250293732,\n",
              "  0.08759693801403046,\n",
              "  0.08586442470550537,\n",
              "  0.08775848150253296,\n",
              "  0.08684515953063965,\n",
              "  0.08911196887493134,\n",
              "  0.08540176600217819,\n",
              "  0.08646155893802643,\n",
              "  0.08870924264192581,\n",
              "  0.08330924808979034,\n",
              "  0.0815466046333313,\n",
              "  0.08123621344566345,\n",
              "  0.08110686391592026,\n",
              "  0.08105611801147461,\n",
              "  0.08050858974456787,\n",
              "  0.08035611361265182,\n",
              "  0.07982528209686279,\n",
              "  0.07969542592763901,\n",
              "  0.07963600009679794,\n",
              "  0.08008643984794617,\n",
              "  0.07923725992441177,\n",
              "  0.07896864414215088,\n",
              "  0.07918812334537506,\n",
              "  0.07944537699222565,\n",
              "  0.0789596363902092,\n",
              "  0.07964200526475906,\n",
              "  0.0776829868555069,\n",
              "  0.07870158553123474,\n",
              "  0.07803124189376831,\n",
              "  0.0777747631072998,\n",
              "  0.07740466296672821,\n",
              "  0.0776827484369278,\n",
              "  0.07743784040212631,\n",
              "  0.0777691900730133,\n",
              "  0.07719560712575912,\n",
              "  0.07834067940711975,\n",
              "  0.0773114264011383,\n",
              "  0.07632597535848618,\n",
              "  0.07641249895095825,\n",
              "  0.07685336470603943,\n",
              "  0.07704223692417145,\n",
              "  0.07782962918281555,\n",
              "  0.07680345326662064,\n",
              "  0.07708876579999924,\n",
              "  0.07743775844573975,\n",
              "  0.07659641653299332,\n",
              "  0.07676934450864792,\n",
              "  0.07569903135299683,\n",
              "  0.07577285915613174,\n",
              "  0.07596691697835922,\n",
              "  0.07591041922569275,\n",
              "  0.07555901259183884,\n",
              "  0.07618027925491333,\n",
              "  0.07614801824092865,\n",
              "  0.07566295564174652,\n",
              "  0.07543926686048508,\n",
              "  0.07530052214860916,\n",
              "  0.07519487291574478,\n",
              "  0.07575573772192001,\n",
              "  0.07576281577348709,\n",
              "  0.07592209428548813,\n",
              "  0.07491117715835571,\n",
              "  0.07510808110237122,\n",
              "  0.07541114091873169,\n",
              "  0.07514344900846481,\n",
              "  0.0748961791396141,\n",
              "  0.07490020245313644,\n",
              "  0.07492812722921371,\n",
              "  0.07438882440328598,\n",
              "  0.07389696687459946,\n",
              "  0.07317440956830978,\n",
              "  0.07374802231788635,\n",
              "  0.07374890893697739,\n",
              "  0.07305771112442017,\n",
              "  0.07329285889863968,\n",
              "  0.07269760966300964,\n",
              "  0.07312982529401779,\n",
              "  0.07313618063926697,\n",
              "  0.07273318618535995,\n",
              "  0.07304920256137848,\n",
              "  0.07284247875213623,\n",
              "  0.07316860556602478,\n",
              "  0.07289396226406097,\n",
              "  0.0730525404214859]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# Initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# Start training\n",
        "trainer.train('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI4cHv1z0PrD"
      },
      "source": [
        "## Teste 3.2 NER Flair Staked Embeddings com Corpus Lener_br+Multi_Wikiner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0GrkbPf0PrD"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QIQ2ZRD0PrE"
      },
      "outputs": [],
      "source": [
        "## Importes\n",
        "## datasets\n",
        "from flair.data import MultiCorpus\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.datasets import NER_MULTI_WIKINER\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import FlairEmbeddings, StackedEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X_eM36m0PrE"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gB8m2b90PrE",
        "outputId": "186c5c72-fb7f-4959-c0fe-9abbe4e56589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F9E80vk0PrE",
        "outputId": "9bae4109-4a7e-46a8-c3b4-ad9a231e91f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:27:33,701 Reading data from /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br\n",
            "2022-08-13 04:27:33,702 Train: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/train.txt\n",
            "2022-08-13 04:27:33,706 Dev: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/dev.txt\n",
            "2022-08-13 04:27:33,707 Test: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/test.txt\n",
            "2022-08-13 04:27:41,809 https://raw.githubusercontent.com/dice-group/FOX/master/input/Wikiner/aij-wikiner-en-wp3.bz2 not found in cache, downloading to /tmp/tmpzlq2m41q\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6208404/6208404 [00:00<00:00, 36488075.11B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:27:42,039 copying /tmp/tmpzlq2m41q to cache at /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.bz2\n",
            "2022-08-13 04:27:42,054 removing temp file /tmp/tmpzlq2m41q\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:27:46,548 Read data for language en\n",
            "2022-08-13 04:27:46,551 Reading data from /root/.flair/datasets/ner_multi_wikiner/en\n",
            "2022-08-13 04:27:46,553 Train: /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.train\n",
            "2022-08-13 04:27:46,554 Dev: None\n",
            "2022-08-13 04:27:46,556 Test: None\n",
            "MultiCorpus: 122971 train + 13970 dev + 15604 test sentences\n",
            " - ColumnCorpus Corpus: 7827 train + 1176 dev + 1389 test sentences - /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br\n",
            " - NER_MULTI_WIKINER MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en - wikiner\n"
          ]
        }
      ],
      "source": [
        "## carregando um corpus e definindo as colunas\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/Flair_NLP/Corpus/Lener_br'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "le_corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')\n",
        "\n",
        "wiki_corpus = NER_MULTI_WIKINER()#.downsample(0.3)\n",
        "\n",
        "# make a multi corpus consisting of three UDs\n",
        "corpus = MultiCorpus([le_corpus, wiki_corpus])\n",
        "\n",
        "print(corpus)\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WErnHKf-0PrE",
        "outputId": "f9f2f589-cf83-4694-ebd3-214e7c62048f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:27:54,754 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "122971it [01:26, 1421.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:29:21,316 Dictionary created for label 'ner' with 8 values: PER (seen 79737 times), LOC (seen 70183 times), MISC (seen 59563 times), ORG (seen 42597 times), LEGISLACAO (seen 1920 times), TEMPO (seen 1334 times), JURISPRUDENCIA (seen 1104 times)\n",
            "Dictionary with 8 tags: <unk>, PER, LOC, MISC, ORG, LEGISLACAO, TEMPO, JURISPRUDENCIA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iHTmWVq0PrE"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B-oNLTN0PrE",
        "outputId": "2364a3e9-959b-404b-95df-229ed0ec91eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:29:22,758 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-forward.pt not found in cache, downloading to /tmp/tmpiyu7kayy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:08<00:00, 8408479.37B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:29:32,259 copying /tmp/tmpiyu7kayy to cache at /root/.flair/embeddings/lm-pt-forward.pt\n",
            "2022-08-13 04:29:32,356 removing temp file /tmp/tmpiyu7kayy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:29:43,460 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-backward.pt not found in cache, downloading to /tmp/tmp6cn9o2q3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:08<00:00, 8419872.00B/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:29:52,972 copying /tmp/tmp6cn9o2q3 to cache at /root/.flair/embeddings/lm-pt-backward.pt\n",
            "2022-08-13 04:29:53,071 removing temp file /tmp/tmp6cn9o2q3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Empilhando os Embeddings\n",
        "# init Flair embeddings\n",
        "flair_embedding_forward = FlairEmbeddings('pt-forward')\n",
        "flair_embedding_backward = FlairEmbeddings('pt-backward')\n",
        "\n",
        "# create a StackedEmbedding object that combines glove and forward/backward flair embeddings\n",
        "embeddings = StackedEmbeddings([\n",
        "                                        flair_embedding_forward,\n",
        "                                        flair_embedding_backward,\n",
        "                                       ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkP_b5NT0PrE"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ikyDbd40PrE",
        "outputId": "af11becc-be00-430c-da5b-c977778f32bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:29:53,311 SequenceTagger predicts: Dictionary with 29 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, S-LEGISLACAO, B-LEGISLACAO, E-LEGISLACAO, I-LEGISLACAO, S-TEMPO, B-TEMPO, E-TEMPO, I-TEMPO, S-JURISPRUDENCIA, B-JURISPRUDENCIA, E-JURISPRUDENCIA, I-JURISPRUDENCIA\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8YDeG7CdeUM"
      },
      "outputs": [],
      "source": [
        "## Treinando o modelo\n",
        "# Initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# Start training\n",
        "trainer.train('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbXtQ7rhqGqD"
      },
      "source": [
        "## Teste 3.3 NER Flair Staked Embeddings (Word e Flair Embeddings) com Corpus Lener_br+Multi_Wikiner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-1DOm4xqGqJ"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXsGuN3mqGqJ"
      },
      "outputs": [],
      "source": [
        "## Importes\n",
        "## datasets\n",
        "from flair.data import MultiCorpus\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.datasets import NER_MULTI_WIKINER\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJaVvL1oqGqJ"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3SAeEdrqGqJ",
        "outputId": "88d728fc-8853-4d47-e760-080b6a796f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNtu0e1gqGqJ",
        "outputId": "94af1e68-989e-4f83-cc2b-7480df5423ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 01:58:56,257 Reading data from /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br\n",
            "2022-08-13 01:58:56,260 Train: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/train.txt\n",
            "2022-08-13 01:58:56,262 Dev: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/dev.txt\n",
            "2022-08-13 01:58:56,264 Test: /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br/test.txt\n",
            "2022-08-13 01:59:03,664 https://raw.githubusercontent.com/dice-group/FOX/master/input/Wikiner/aij-wikiner-en-wp3.bz2 not found in cache, downloading to /tmp/tmpe8tjizzh\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6208404/6208404 [00:00<00:00, 33335040.71B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 01:59:03,930 copying /tmp/tmpe8tjizzh to cache at /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.bz2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 01:59:03,946 removing temp file /tmp/tmpe8tjizzh\n",
            "2022-08-13 01:59:08,400 Read data for language en\n",
            "2022-08-13 01:59:08,404 Reading data from /root/.flair/datasets/ner_multi_wikiner/en\n",
            "2022-08-13 01:59:08,405 Train: /root/.flair/datasets/ner_multi_wikiner/en/aij-wikiner-en-wp3.train\n",
            "2022-08-13 01:59:08,407 Dev: None\n",
            "2022-08-13 01:59:08,411 Test: None\n",
            "MultiCorpus: 122971 train + 13970 dev + 15604 test sentences\n",
            " - ColumnCorpus Corpus: 7827 train + 1176 dev + 1389 test sentences - /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br\n",
            " - NER_MULTI_WIKINER MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en - wikiner\n"
          ]
        }
      ],
      "source": [
        "## carregando um corpus e definindo as colunas\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/Flair_NLP/Corpus/Lener_br'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "le_corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')\n",
        "\n",
        "wiki_corpus = NER_MULTI_WIKINER()\n",
        "\n",
        "# make a multi corpus consisting of three UDs\n",
        "corpus = MultiCorpus([le_corpus, wiki_corpus])\n",
        "\n",
        "print(corpus)\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m--60dvpqGqJ",
        "outputId": "bac9a2da-4d65-48da-b53a-93b687a8ac9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:07:08,351 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "122971it [01:23, 1464.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:08:32,379 Dictionary created for label 'ner' with 8 values: PER (seen 79340 times), LOC (seen 70499 times), MISC (seen 59594 times), ORG (seen 42509 times), LEGISLACAO (seen 1920 times), TEMPO (seen 1334 times), JURISPRUDENCIA (seen 1104 times)\n",
            "Dictionary with 8 tags: <unk>, PER, LOC, MISC, ORG, LEGISLACAO, TEMPO, JURISPRUDENCIA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SATvGxbBqGqJ"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVOijwPbqGqK",
        "outputId": "1b2eaab6-d521-4546-cacf-c0c1f1d0348c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:08:32,994 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpldo17kew\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 710528528/710528528 [00:28<00:00, 25045175.32B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:09:01,717 copying /tmp/tmpldo17kew to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M.vectors.npy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:09:03,284 removing temp file /tmp/tmpldo17kew\n",
            "2022-08-13 02:09:04,051 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmp72woz9nz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23541010/23541010 [00:01<00:00, 13030519.94B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:09:06,213 copying /tmp/tmp72woz9nz to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M\n",
            "2022-08-13 02:09:06,250 removing temp file /tmp/tmp72woz9nz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:09:10,212 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-forward.pt not found in cache, downloading to /tmp/tmp0ddfan86\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:03<00:00, 20360426.86B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:09:14,141 copying /tmp/tmp0ddfan86 to cache at /root/.flair/embeddings/lm-pt-forward.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:09:14,240 removing temp file /tmp/tmp0ddfan86\n",
            "2022-08-13 02:09:26,159 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-backward.pt not found in cache, downloading to /tmp/tmpybb8qd45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:03<00:00, 20509360.70B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:09:30,064 copying /tmp/tmpybb8qd45 to cache at /root/.flair/embeddings/lm-pt-backward.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:09:30,158 removing temp file /tmp/tmpybb8qd45\n"
          ]
        }
      ],
      "source": [
        "## Stacked Embeddings\n",
        "# Initialize embedding stack with \n",
        "embedding_types = [\n",
        "    WordEmbeddings('pt'),\n",
        "    FlairEmbeddings('pt-forward'),\n",
        "    FlairEmbeddings('pt-backward')\n",
        "]\n",
        "\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIzOGdLeqGqK"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud7jJ4iFqGqK",
        "outputId": "768d4cde-f5dc-4982-9145-6ef46e70b1e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:09:30,391 SequenceTagger predicts: Dictionary with 29 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, S-LEGISLACAO, B-LEGISLACAO, E-LEGISLACAO, I-LEGISLACAO, S-TEMPO, B-TEMPO, E-TEMPO, I-TEMPO, S-JURISPRUDENCIA, B-JURISPRUDENCIA, E-JURISPRUDENCIA, I-JURISPRUDENCIA\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEPtwK9CqGqK",
        "outputId": "7e0e4feb-61f2-4ed9-db13-bcddf509d0d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:09:30,658 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 02:09:30,662 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'pt'\n",
            "      (embedding): Embedding(592108, 300)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4396, out_features=4396, bias=True)\n",
            "  (rnn): LSTM(4396, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=31, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-08-13 02:09:30,665 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 02:09:30,667 Corpus: \"MultiCorpus: 122971 train + 13970 dev + 15604 test sentences\n",
            " - ColumnCorpus Corpus: 7827 train + 1176 dev + 1389 test sentences - /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br\n",
            " - NER_MULTI_WIKINER MultiCorpus: 115144 train + 12794 dev + 14215 test sentences\n",
            " - ColumnCorpus Corpus: 115144 train + 12794 dev + 14215 test sentences - /root/.flair/datasets/ner_multi_wikiner/en - wikiner\"\n",
            "2022-08-13 02:09:30,669 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 02:09:30,671 Parameters:\n",
            "2022-08-13 02:09:30,674  - learning_rate: \"0.100000\"\n",
            "2022-08-13 02:09:30,675  - mini_batch_size: \"32\"\n",
            "2022-08-13 02:09:30,677  - patience: \"3\"\n",
            "2022-08-13 02:09:30,679  - anneal_factor: \"0.5\"\n",
            "2022-08-13 02:09:30,681  - max_epochs: \"60\"\n",
            "2022-08-13 02:09:30,683  - shuffle: \"True\"\n",
            "2022-08-13 02:09:30,686  - train_with_dev: \"False\"\n",
            "2022-08-13 02:09:30,687  - batch_growth_annealing: \"False\"\n",
            "2022-08-13 02:09:30,689 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 02:09:30,691 Model training base path: \"resources/taggers/sota-ner-flair\"\n",
            "2022-08-13 02:09:30,693 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 02:09:30,694 Device: cuda:0\n",
            "2022-08-13 02:09:30,696 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 02:09:30,697 Embeddings storage mode: cpu\n",
            "2022-08-13 02:09:30,699 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 02:13:08,950 epoch 1 - iter 384/3843 - loss 0.35371656 - samples/sec: 57.75 - lr: 0.100000\n",
            "2022-08-13 02:15:32,226 epoch 1 - iter 768/3843 - loss 0.27647136 - samples/sec: 95.82 - lr: 0.100000\n",
            "2022-08-13 02:17:52,776 epoch 1 - iter 1152/3843 - loss 0.23826062 - samples/sec: 99.23 - lr: 0.100000\n",
            "2022-08-13 02:20:18,016 epoch 1 - iter 1536/3843 - loss 0.21173305 - samples/sec: 94.65 - lr: 0.100000\n",
            "2022-08-13 02:22:44,304 epoch 1 - iter 1920/3843 - loss 0.19206533 - samples/sec: 94.05 - lr: 0.100000\n",
            "2022-08-13 02:25:08,005 epoch 1 - iter 2304/3843 - loss 0.17844763 - samples/sec: 97.17 - lr: 0.100000\n",
            "2022-08-13 02:27:32,720 epoch 1 - iter 2688/3843 - loss 0.16757019 - samples/sec: 96.57 - lr: 0.100000\n",
            "2022-08-13 02:29:57,435 epoch 1 - iter 3072/3843 - loss 0.15861984 - samples/sec: 96.49 - lr: 0.100000\n",
            "2022-08-13 02:32:21,596 epoch 1 - iter 3456/3843 - loss 0.15147774 - samples/sec: 93.32 - lr: 0.100000\n",
            "2022-08-13 02:34:45,303 epoch 1 - iter 3840/3843 - loss 0.14572214 - samples/sec: 93.62 - lr: 0.100000\n",
            "2022-08-13 02:34:46,215 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 02:34:46,219 EPOCH 1 done: loss 0.1457 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [03:26<00:00,  2.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:38:12,588 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 02:38:12,849 DEV : loss 0.16947884857654572 - f1-score (micro avg)  0.6879\n",
            "2022-08-13 02:38:26,641 BAD EPOCHS (no improvement): 0\n",
            "2022-08-13 02:38:26,646 saving best model\n",
            "2022-08-13 02:38:31,192 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 02:41:20,496 epoch 2 - iter 384/3843 - loss 0.10069588 - samples/sec: 80.60 - lr: 0.100000\n",
            "2022-08-13 02:44:00,460 epoch 2 - iter 768/3843 - loss 0.09665045 - samples/sec: 85.72 - lr: 0.100000\n",
            "2022-08-13 02:46:42,497 epoch 2 - iter 1152/3843 - loss 0.09473246 - samples/sec: 85.97 - lr: 0.100000\n",
            "2022-08-13 02:49:23,830 epoch 2 - iter 1536/3843 - loss 0.09270825 - samples/sec: 81.81 - lr: 0.100000\n",
            "2022-08-13 02:52:05,113 epoch 2 - iter 1920/3843 - loss 0.09110576 - samples/sec: 81.86 - lr: 0.100000\n",
            "2022-08-13 02:54:45,326 epoch 2 - iter 2304/3843 - loss 0.09000049 - samples/sec: 85.14 - lr: 0.100000\n",
            "2022-08-13 02:57:27,100 epoch 2 - iter 2688/3843 - loss 0.08892300 - samples/sec: 85.62 - lr: 0.100000\n",
            "2022-08-13 03:00:10,790 epoch 2 - iter 3072/3843 - loss 0.08832642 - samples/sec: 85.81 - lr: 0.100000\n",
            "2022-08-13 03:02:49,188 epoch 2 - iter 3456/3843 - loss 0.08760473 - samples/sec: 87.58 - lr: 0.100000\n",
            "2022-08-13 03:05:29,458 epoch 2 - iter 3840/3843 - loss 0.08696487 - samples/sec: 85.04 - lr: 0.100000\n",
            "2022-08-13 03:05:30,530 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 03:05:30,533 EPOCH 2 done: loss 0.0869 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [03:13<00:00,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 03:08:44,089 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 03:08:44,354 DEV : loss 0.06445777416229248 - f1-score (micro avg)  0.7968\n",
            "2022-08-13 03:08:59,217 BAD EPOCHS (no improvement): 0\n",
            "2022-08-13 03:08:59,220 saving best model\n",
            "2022-08-13 03:09:03,767 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 03:11:48,817 epoch 3 - iter 384/3843 - loss 0.07661063 - samples/sec: 84.83 - lr: 0.100000\n",
            "2022-08-13 03:14:34,178 epoch 3 - iter 768/3843 - loss 0.07668005 - samples/sec: 82.40 - lr: 0.100000\n",
            "2022-08-13 03:17:15,529 epoch 3 - iter 1152/3843 - loss 0.07696315 - samples/sec: 84.65 - lr: 0.100000\n",
            "2022-08-13 03:19:59,942 epoch 3 - iter 1536/3843 - loss 0.07660316 - samples/sec: 81.74 - lr: 0.100000\n",
            "2022-08-13 03:22:50,466 epoch 3 - iter 1920/3843 - loss 0.07675192 - samples/sec: 80.97 - lr: 0.100000\n",
            "2022-08-13 03:25:36,685 epoch 3 - iter 2304/3843 - loss 0.07641607 - samples/sec: 82.04 - lr: 0.100000\n",
            "2022-08-13 03:28:15,297 epoch 3 - iter 2688/3843 - loss 0.07606873 - samples/sec: 85.09 - lr: 0.100000\n",
            "2022-08-13 03:30:59,099 epoch 3 - iter 3072/3843 - loss 0.07625682 - samples/sec: 84.81 - lr: 0.100000\n",
            "2022-08-13 03:33:44,190 epoch 3 - iter 3456/3843 - loss 0.07588665 - samples/sec: 82.78 - lr: 0.100000\n",
            "2022-08-13 03:36:21,008 epoch 3 - iter 3840/3843 - loss 0.07568763 - samples/sec: 87.55 - lr: 0.100000\n",
            "2022-08-13 03:36:22,170 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 03:36:22,173 EPOCH 3 done: loss 0.0757 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [03:12<00:00,  2.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 03:39:35,135 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 03:39:35,388 DEV : loss 0.05549291521310806 - f1-score (micro avg)  0.8206\n",
            "2022-08-13 03:39:50,350 BAD EPOCHS (no improvement): 0\n",
            "2022-08-13 03:39:50,353 saving best model\n",
            "2022-08-13 03:39:54,902 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 03:42:35,023 epoch 4 - iter 384/3843 - loss 0.07208991 - samples/sec: 88.15 - lr: 0.100000\n",
            "2022-08-13 03:45:19,681 epoch 4 - iter 768/3843 - loss 0.07258020 - samples/sec: 85.71 - lr: 0.100000\n",
            "2022-08-13 03:48:01,033 epoch 4 - iter 1152/3843 - loss 0.07210691 - samples/sec: 83.50 - lr: 0.100000\n",
            "2022-08-13 03:50:44,038 epoch 4 - iter 1536/3843 - loss 0.07194431 - samples/sec: 82.65 - lr: 0.100000\n",
            "2022-08-13 03:53:26,925 epoch 4 - iter 1920/3843 - loss 0.07161851 - samples/sec: 84.09 - lr: 0.100000\n",
            "2022-08-13 03:56:07,329 epoch 4 - iter 2304/3843 - loss 0.07156275 - samples/sec: 87.08 - lr: 0.100000\n",
            "2022-08-13 03:58:52,446 epoch 4 - iter 2688/3843 - loss 0.07140719 - samples/sec: 84.11 - lr: 0.100000\n",
            "2022-08-13 04:01:36,233 epoch 4 - iter 3072/3843 - loss 0.07145064 - samples/sec: 83.57 - lr: 0.100000\n",
            "2022-08-13 04:04:21,596 epoch 4 - iter 3456/3843 - loss 0.07123707 - samples/sec: 80.04 - lr: 0.100000\n",
            "2022-08-13 04:07:11,235 epoch 4 - iter 3840/3843 - loss 0.07109754 - samples/sec: 79.17 - lr: 0.100000\n",
            "2022-08-13 04:07:12,391 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 04:07:12,394 EPOCH 4 done: loss 0.0711 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [03:17<00:00,  2.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:10:29,812 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:10:30,088 DEV : loss 0.05296389386057854 - f1-score (micro avg)  0.8259\n",
            "2022-08-13 04:10:45,415 BAD EPOCHS (no improvement): 0\n",
            "2022-08-13 04:10:45,418 saving best model\n",
            "2022-08-13 04:10:49,879 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 04:13:35,164 epoch 5 - iter 384/3843 - loss 0.06733412 - samples/sec: 84.06 - lr: 0.100000\n",
            "2022-08-13 04:16:17,366 epoch 5 - iter 768/3843 - loss 0.06756848 - samples/sec: 83.17 - lr: 0.100000\n",
            "2022-08-13 04:18:19,752 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 04:18:19,754 Exiting from training early.\n",
            "2022-08-13 04:18:19,755 Saving model ...\n",
            "2022-08-13 04:18:23,861 Done.\n",
            "2022-08-13 04:18:23,865 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 04:18:23,869 loading file resources/taggers/sota-ner-flair/best-model.pt\n",
            "2022-08-13 04:18:25,957 SequenceTagger predicts: Dictionary with 31 tags: O, S-PER, B-PER, E-PER, I-PER, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, S-LEGISLACAO, B-LEGISLACAO, E-LEGISLACAO, I-LEGISLACAO, S-TEMPO, B-TEMPO, E-TEMPO, I-TEMPO, S-JURISPRUDENCIA, B-JURISPRUDENCIA, E-JURISPRUDENCIA, I-JURISPRUDENCIA, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 488/488 [03:13<00:00,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:21:39,700 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:21:40,056 0.8297\t0.8244\t0.827\t0.7657\n",
            "2022-08-13 04:21:40,059 \n",
            "Results:\n",
            "- F-score (micro) 0.827\n",
            "- F-score (macro) 0.834\n",
            "- Accuracy 0.7657\n",
            "\n",
            "By class:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "           PER     0.8894    0.9421    0.9150      9825\n",
            "           LOC     0.7990    0.8834    0.8391      8626\n",
            "          MISC     0.7883    0.6709    0.7249      7439\n",
            "           ORG     0.8057    0.7222    0.7616      5442\n",
            "    LEGISLACAO     0.9149    0.9392    0.9269       378\n",
            "         TEMPO     0.9653    0.8698    0.9151       192\n",
            "JURISPRUDENCIA     0.7964    0.7189    0.7557       185\n",
            "\n",
            "     micro avg     0.8297    0.8244    0.8270     32087\n",
            "     macro avg     0.8513    0.8209    0.8340     32087\n",
            "  weighted avg     0.8277    0.8244    0.8237     32087\n",
            "\n",
            "2022-08-13 04:21:40,060 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-13 04:21:40,062 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44/44 [00:30<00:00,  1.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:22:10,575 Evaluating as a multi-label problem: False\n",
            "2022-08-13 04:22:10,602 /content/drive/MyDrive/Flair_NLP/Corpus/Lener_br\n",
            "2022-08-13 04:22:10,604 0.8747\t0.8314\t0.8525\t0.7503\n",
            "2022-08-13 04:22:10,606 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 445/445 [02:45<00:00,  2.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-13 04:24:56,698 Evaluating as a multi-label problem: False\n",
            "2022-08-13 04:24:57,024 wikiner\n",
            "2022-08-13 04:24:57,026 0.8276\t0.824\t0.8258\t0.7665\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.16947884857654572,\n",
              "  0.06445777416229248,\n",
              "  0.05549291521310806,\n",
              "  0.05296389386057854],\n",
              " 'dev_score_history': [0.6879221831937314,\n",
              "  0.7967838508254212,\n",
              "  0.8205565116635711,\n",
              "  0.8258713274275746],\n",
              " 'test_score': 0.8270385192596299,\n",
              " 'train_loss_history': [0.14565637319965274,\n",
              "  0.08694998087720668,\n",
              "  0.07568894388582262,\n",
              "  0.07107764085344594]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# Initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# Start training\n",
        "trainer.train('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MTdmN9sXiue"
      },
      "source": [
        "## Teste 4.1 NER Flair Classic Word Embeddings com Corpus Ulysses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imr7x0qBXiue"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZ1-KE5TXiuf"
      },
      "outputs": [],
      "source": [
        "## Importes\n",
        "## datasets\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import WordEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vahJdSIZXiuf"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxAT58P6Xiuf",
        "outputId": "c6656487-5818-46ec-b7fb-3917fd5cc3da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sFS3xnZXiuf",
        "outputId": "911db553-86ce-4031-a2dd-313c1d9d8f44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:40:31,812 Reading data from /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria\n",
            "2022-10-03 18:40:31,814 Train: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/train.txt\n",
            "2022-10-03 18:40:31,816 Dev: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/valid.txt\n",
            "2022-10-03 18:40:31,817 Test: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/test.txt\n"
          ]
        }
      ],
      "source": [
        "## carregando um corpus e definindo as colunas\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='valid.txt')\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G2H4mmPXiuf",
        "outputId": "85eb3687-8fda-40e4-9232-f725eba4215c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:40:37,873 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6667it [00:00, 50770.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:40:38,055 Dictionary created for label 'ner' with 8 values: PESSOA (seen 628 times), FUNDAMENTO (seen 490 times), ORGANIZACAO (seen 435 times), DATA (seen 433 times), LOCAL (seen 369 times), PRODUTODELEI (seen 230 times), EVENTO (seen 9 times)\n",
            "Dictionary with 8 tags: <unk>, PESSOA, FUNDAMENTO, ORGANIZACAO, DATA, LOCAL, PRODUTODELEI, EVENTO\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-QW-CsvXiuf"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8reOvhyiXiuf",
        "outputId": "6f3cae86-eefb-4a1a-dda7-d26a1bfa9888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:40:38,193 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpw2ulevpc\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 710528528/710528528 [00:18<00:00, 38731417.43B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:40:56,606 copying /tmp/tmpw2ulevpc to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M.vectors.npy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:40:58,842 removing temp file /tmp/tmpw2ulevpc\n",
            "2022-10-03 18:40:59,010 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmplmp3y9p2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23541010/23541010 [00:00<00:00, 36033178.74B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:40:59,731 copying /tmp/tmplmp3y9p2 to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M\n",
            "2022-10-03 18:40:59,760 removing temp file /tmp/tmplmp3y9p2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Embeddings\n",
        "# Initialize embedding\n",
        "embeddings = WordEmbeddings('pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJyzWvyRXiuf"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meHCeIcVXiuf",
        "outputId": "799578a8-d33a-49db-a676-826679c056d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:41:02,599 SequenceTagger predicts: Dictionary with 29 tags: O, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-FUNDAMENTO, B-FUNDAMENTO, E-FUNDAMENTO, I-FUNDAMENTO, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-DATA, B-DATA, E-DATA, I-DATA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL, S-PRODUTODELEI, B-PRODUTODELEI, E-PRODUTODELEI, I-PRODUTODELEI, S-EVENTO, B-EVENTO, E-EVENTO, I-EVENTO\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQPTkp5lXiug",
        "outputId": "8c806139-ddfc-486c-d926-f642dfca8889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:41:12,330 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:41:12,331 Model: \"SequenceTagger(\n",
            "  (embeddings): WordEmbeddings(\n",
            "    'pt'\n",
            "    (embedding): Embedding(592108, 300)\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=300, out_features=300, bias=True)\n",
            "  (rnn): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=31, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-10-03 18:41:12,335 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:41:12,336 Corpus: \"Corpus: 6667 train + 1429 dev + 1430 test sentences\"\n",
            "2022-10-03 18:41:12,338 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:41:12,339 Parameters:\n",
            "2022-10-03 18:41:12,341  - learning_rate: \"0.100000\"\n",
            "2022-10-03 18:41:12,343  - mini_batch_size: \"32\"\n",
            "2022-10-03 18:41:12,345  - patience: \"3\"\n",
            "2022-10-03 18:41:12,347  - anneal_factor: \"0.5\"\n",
            "2022-10-03 18:41:12,349  - max_epochs: \"100\"\n",
            "2022-10-03 18:41:12,351  - shuffle: \"True\"\n",
            "2022-10-03 18:41:12,352  - train_with_dev: \"False\"\n",
            "2022-10-03 18:41:12,356  - batch_growth_annealing: \"False\"\n",
            "2022-10-03 18:41:12,358 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:41:12,360 Model training base path: \"/content/drive/MyDrive/Flair_NLP/sota-ner-flair\"\n",
            "2022-10-03 18:41:12,362 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:41:12,363 Device: cuda:0\n",
            "2022-10-03 18:41:12,365 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:41:12,366 Embeddings storage mode: cpu\n",
            "2022-10-03 18:41:12,371 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:41:15,349 epoch 1 - iter 20/209 - loss 1.55967633 - samples/sec: 215.39 - lr: 0.100000\n",
            "2022-10-03 18:41:18,829 epoch 1 - iter 40/209 - loss 0.97199410 - samples/sec: 184.11 - lr: 0.100000\n",
            "2022-10-03 18:41:20,907 epoch 1 - iter 60/209 - loss 0.83369193 - samples/sec: 308.58 - lr: 0.100000\n",
            "2022-10-03 18:41:23,333 epoch 1 - iter 80/209 - loss 0.72425215 - samples/sec: 264.26 - lr: 0.100000\n",
            "2022-10-03 18:41:25,734 epoch 1 - iter 100/209 - loss 0.63585800 - samples/sec: 266.96 - lr: 0.100000\n",
            "2022-10-03 18:41:28,099 epoch 1 - iter 120/209 - loss 0.58896527 - samples/sec: 271.06 - lr: 0.100000\n",
            "2022-10-03 18:41:30,412 epoch 1 - iter 140/209 - loss 0.55236318 - samples/sec: 277.18 - lr: 0.100000\n",
            "2022-10-03 18:41:32,654 epoch 1 - iter 160/209 - loss 0.52883959 - samples/sec: 285.89 - lr: 0.100000\n",
            "2022-10-03 18:41:35,784 epoch 1 - iter 180/209 - loss 0.50425031 - samples/sec: 204.78 - lr: 0.100000\n",
            "2022-10-03 18:41:38,313 epoch 1 - iter 200/209 - loss 0.47843208 - samples/sec: 253.53 - lr: 0.100000\n",
            "2022-10-03 18:41:39,477 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:41:39,480 EPOCH 1 done: loss 0.4734 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:41:46,276 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:41:46,290 DEV : loss 0.24962784349918365 - f1-score (micro avg)  0.1874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:41:46,353 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:41:46,357 saving best model\n",
            "2022-10-03 18:41:49,663 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:41:52,203 epoch 2 - iter 20/209 - loss 0.24736338 - samples/sec: 254.61 - lr: 0.100000\n",
            "2022-10-03 18:41:54,315 epoch 2 - iter 40/209 - loss 0.24630332 - samples/sec: 303.57 - lr: 0.100000\n",
            "2022-10-03 18:41:56,747 epoch 2 - iter 60/209 - loss 0.24346197 - samples/sec: 263.62 - lr: 0.100000\n",
            "2022-10-03 18:41:59,049 epoch 2 - iter 80/209 - loss 0.23695731 - samples/sec: 278.51 - lr: 0.100000\n",
            "2022-10-03 18:42:01,515 epoch 2 - iter 100/209 - loss 0.23573205 - samples/sec: 259.97 - lr: 0.100000\n",
            "2022-10-03 18:42:04,165 epoch 2 - iter 120/209 - loss 0.23944936 - samples/sec: 241.86 - lr: 0.100000\n",
            "2022-10-03 18:42:06,665 epoch 2 - iter 140/209 - loss 0.23104741 - samples/sec: 256.42 - lr: 0.100000\n",
            "2022-10-03 18:42:09,093 epoch 2 - iter 160/209 - loss 0.23120208 - samples/sec: 264.23 - lr: 0.100000\n",
            "2022-10-03 18:42:11,750 epoch 2 - iter 180/209 - loss 0.22713715 - samples/sec: 241.23 - lr: 0.100000\n",
            "2022-10-03 18:42:14,644 epoch 2 - iter 200/209 - loss 0.22122600 - samples/sec: 221.51 - lr: 0.100000\n",
            "2022-10-03 18:42:15,501 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:42:15,502 EPOCH 2 done: loss 0.2208 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:42:22,172 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:42:22,185 DEV : loss 0.1606435775756836 - f1-score (micro avg)  0.3552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:42:22,247 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:42:22,251 saving best model\n",
            "2022-10-03 18:42:25,291 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:42:27,726 epoch 3 - iter 20/209 - loss 0.20009008 - samples/sec: 263.45 - lr: 0.100000\n",
            "2022-10-03 18:42:29,839 epoch 3 - iter 40/209 - loss 0.17856804 - samples/sec: 303.41 - lr: 0.100000\n",
            "2022-10-03 18:42:32,794 epoch 3 - iter 60/209 - loss 0.17350678 - samples/sec: 216.89 - lr: 0.100000\n",
            "2022-10-03 18:42:35,040 epoch 3 - iter 80/209 - loss 0.17399075 - samples/sec: 285.55 - lr: 0.100000\n",
            "2022-10-03 18:42:37,325 epoch 3 - iter 100/209 - loss 0.16954490 - samples/sec: 280.64 - lr: 0.100000\n",
            "2022-10-03 18:42:39,957 epoch 3 - iter 120/209 - loss 0.16822763 - samples/sec: 243.56 - lr: 0.100000\n",
            "2022-10-03 18:42:42,536 epoch 3 - iter 140/209 - loss 0.16445022 - samples/sec: 248.56 - lr: 0.100000\n",
            "2022-10-03 18:42:46,039 epoch 3 - iter 160/209 - loss 0.16189731 - samples/sec: 183.03 - lr: 0.100000\n",
            "2022-10-03 18:42:48,202 epoch 3 - iter 180/209 - loss 0.16207216 - samples/sec: 296.58 - lr: 0.100000\n",
            "2022-10-03 18:42:50,211 epoch 3 - iter 200/209 - loss 0.15948237 - samples/sec: 319.15 - lr: 0.100000\n",
            "2022-10-03 18:42:51,050 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:42:51,053 EPOCH 3 done: loss 0.1587 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:42:57,672 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:42:57,684 DEV : loss 0.14665403962135315 - f1-score (micro avg)  0.4476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:42:57,745 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:42:57,750 saving best model\n",
            "2022-10-03 18:43:00,664 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:43:03,278 epoch 4 - iter 20/209 - loss 0.15744090 - samples/sec: 245.42 - lr: 0.100000\n",
            "2022-10-03 18:43:05,179 epoch 4 - iter 40/209 - loss 0.15558899 - samples/sec: 337.28 - lr: 0.100000\n",
            "2022-10-03 18:43:07,429 epoch 4 - iter 60/209 - loss 0.15465018 - samples/sec: 285.05 - lr: 0.100000\n",
            "2022-10-03 18:43:10,228 epoch 4 - iter 80/209 - loss 0.14895647 - samples/sec: 228.98 - lr: 0.100000\n",
            "2022-10-03 18:43:12,708 epoch 4 - iter 100/209 - loss 0.14668958 - samples/sec: 258.66 - lr: 0.100000\n",
            "2022-10-03 18:43:14,831 epoch 4 - iter 120/209 - loss 0.14223313 - samples/sec: 302.42 - lr: 0.100000\n",
            "2022-10-03 18:43:17,404 epoch 4 - iter 140/209 - loss 0.13997978 - samples/sec: 249.23 - lr: 0.100000\n",
            "2022-10-03 18:43:20,467 epoch 4 - iter 160/209 - loss 0.13497334 - samples/sec: 209.19 - lr: 0.100000\n",
            "2022-10-03 18:43:22,877 epoch 4 - iter 180/209 - loss 0.13321618 - samples/sec: 266.03 - lr: 0.100000\n",
            "2022-10-03 18:43:25,940 epoch 4 - iter 200/209 - loss 0.13456255 - samples/sec: 209.25 - lr: 0.100000\n",
            "2022-10-03 18:43:26,961 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:43:26,963 EPOCH 4 done: loss 0.1339 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:07<00:00,  6.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:43:34,045 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:43:34,059 DEV : loss 0.1001163050532341 - f1-score (micro avg)  0.5943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:43:34,119 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:43:34,123 saving best model\n",
            "2022-10-03 18:43:36,983 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:43:39,342 epoch 5 - iter 20/209 - loss 0.10305595 - samples/sec: 272.04 - lr: 0.100000\n",
            "2022-10-03 18:43:41,180 epoch 5 - iter 40/209 - loss 0.09758076 - samples/sec: 349.12 - lr: 0.100000\n",
            "2022-10-03 18:43:43,898 epoch 5 - iter 60/209 - loss 0.10228892 - samples/sec: 235.81 - lr: 0.100000\n",
            "2022-10-03 18:43:46,853 epoch 5 - iter 80/209 - loss 0.09961444 - samples/sec: 216.97 - lr: 0.100000\n",
            "2022-10-03 18:43:49,238 epoch 5 - iter 100/209 - loss 0.09951898 - samples/sec: 268.86 - lr: 0.100000\n",
            "2022-10-03 18:43:51,799 epoch 5 - iter 120/209 - loss 0.10366967 - samples/sec: 250.50 - lr: 0.100000\n",
            "2022-10-03 18:43:55,212 epoch 5 - iter 140/209 - loss 0.10452159 - samples/sec: 187.76 - lr: 0.100000\n",
            "2022-10-03 18:43:57,851 epoch 5 - iter 160/209 - loss 0.10145469 - samples/sec: 242.86 - lr: 0.100000\n",
            "2022-10-03 18:44:00,039 epoch 5 - iter 180/209 - loss 0.10243843 - samples/sec: 293.19 - lr: 0.100000\n",
            "2022-10-03 18:44:02,424 epoch 5 - iter 200/209 - loss 0.10573841 - samples/sec: 268.76 - lr: 0.100000\n",
            "2022-10-03 18:44:03,472 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:44:03,474 EPOCH 5 done: loss 0.1074 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:44:10,362 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:44:10,376 DEV : loss 0.08253118395805359 - f1-score (micro avg)  0.6818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:44:10,437 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:44:10,441 saving best model\n",
            "2022-10-03 18:44:13,361 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:44:15,654 epoch 6 - iter 20/209 - loss 0.08688902 - samples/sec: 279.72 - lr: 0.100000\n",
            "2022-10-03 18:44:17,825 epoch 6 - iter 40/209 - loss 0.10515545 - samples/sec: 295.32 - lr: 0.100000\n",
            "2022-10-03 18:44:20,029 epoch 6 - iter 60/209 - loss 0.10382327 - samples/sec: 291.12 - lr: 0.100000\n",
            "2022-10-03 18:44:22,740 epoch 6 - iter 80/209 - loss 0.09891535 - samples/sec: 236.61 - lr: 0.100000\n",
            "2022-10-03 18:44:25,290 epoch 6 - iter 100/209 - loss 0.10043741 - samples/sec: 251.46 - lr: 0.100000\n",
            "2022-10-03 18:44:28,293 epoch 6 - iter 120/209 - loss 0.09609621 - samples/sec: 213.47 - lr: 0.100000\n",
            "2022-10-03 18:44:30,894 epoch 6 - iter 140/209 - loss 0.09879681 - samples/sec: 246.53 - lr: 0.100000\n",
            "2022-10-03 18:44:33,629 epoch 6 - iter 160/209 - loss 0.09772805 - samples/sec: 234.39 - lr: 0.100000\n",
            "2022-10-03 18:44:36,651 epoch 6 - iter 180/209 - loss 0.09700375 - samples/sec: 212.11 - lr: 0.100000\n",
            "2022-10-03 18:44:38,712 epoch 6 - iter 200/209 - loss 0.09698739 - samples/sec: 311.18 - lr: 0.100000\n",
            "2022-10-03 18:44:39,814 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:44:39,816 EPOCH 6 done: loss 0.0969 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:07<00:00,  6.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:44:46,962 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:44:46,978 DEV : loss 0.0795944556593895 - f1-score (micro avg)  0.666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:44:47,040 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 18:44:47,045 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:44:49,674 epoch 7 - iter 20/209 - loss 0.08401653 - samples/sec: 243.87 - lr: 0.100000\n",
            "2022-10-03 18:44:52,150 epoch 7 - iter 40/209 - loss 0.08378110 - samples/sec: 258.96 - lr: 0.100000\n",
            "2022-10-03 18:44:54,141 epoch 7 - iter 60/209 - loss 0.08726679 - samples/sec: 322.15 - lr: 0.100000\n",
            "2022-10-03 18:44:56,412 epoch 7 - iter 80/209 - loss 0.08403209 - samples/sec: 282.31 - lr: 0.100000\n",
            "2022-10-03 18:44:59,551 epoch 7 - iter 100/209 - loss 0.08381965 - samples/sec: 204.15 - lr: 0.100000\n",
            "2022-10-03 18:45:01,626 epoch 7 - iter 120/209 - loss 0.08758004 - samples/sec: 309.16 - lr: 0.100000\n",
            "2022-10-03 18:45:04,256 epoch 7 - iter 140/209 - loss 0.08665601 - samples/sec: 243.65 - lr: 0.100000\n",
            "2022-10-03 18:45:06,593 epoch 7 - iter 160/209 - loss 0.08763578 - samples/sec: 274.34 - lr: 0.100000\n",
            "2022-10-03 18:45:08,912 epoch 7 - iter 180/209 - loss 0.08732316 - samples/sec: 276.45 - lr: 0.100000\n",
            "2022-10-03 18:45:11,218 epoch 7 - iter 200/209 - loss 0.08871687 - samples/sec: 278.14 - lr: 0.100000\n",
            "2022-10-03 18:45:12,113 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:45:12,115 EPOCH 7 done: loss 0.0894 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:45:18,776 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:45:18,791 DEV : loss 0.0680016428232193 - f1-score (micro avg)  0.7221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:45:18,858 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:45:18,862 saving best model\n",
            "2022-10-03 18:45:21,664 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:45:23,858 epoch 8 - iter 20/209 - loss 0.10493936 - samples/sec: 292.51 - lr: 0.100000\n",
            "2022-10-03 18:45:26,041 epoch 8 - iter 40/209 - loss 0.09432833 - samples/sec: 293.82 - lr: 0.100000\n",
            "2022-10-03 18:45:28,474 epoch 8 - iter 60/209 - loss 0.10157386 - samples/sec: 263.42 - lr: 0.100000\n",
            "2022-10-03 18:45:31,567 epoch 8 - iter 80/209 - loss 0.09912179 - samples/sec: 207.28 - lr: 0.100000\n",
            "2022-10-03 18:45:34,127 epoch 8 - iter 100/209 - loss 0.09568934 - samples/sec: 250.43 - lr: 0.100000\n",
            "2022-10-03 18:45:36,618 epoch 8 - iter 120/209 - loss 0.09353830 - samples/sec: 257.44 - lr: 0.100000\n",
            "2022-10-03 18:45:39,838 epoch 8 - iter 140/209 - loss 0.09134120 - samples/sec: 199.17 - lr: 0.100000\n",
            "2022-10-03 18:45:42,554 epoch 8 - iter 160/209 - loss 0.08962821 - samples/sec: 235.91 - lr: 0.100000\n",
            "2022-10-03 18:45:44,821 epoch 8 - iter 180/209 - loss 0.08866747 - samples/sec: 283.55 - lr: 0.100000\n",
            "2022-10-03 18:45:47,116 epoch 8 - iter 200/209 - loss 0.08589699 - samples/sec: 279.28 - lr: 0.100000\n",
            "2022-10-03 18:45:48,044 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:45:48,045 EPOCH 8 done: loss 0.0850 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:07<00:00,  6.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:45:55,118 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:45:55,134 DEV : loss 0.0680040791630745 - f1-score (micro avg)  0.71\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:45:55,194 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 18:45:55,199 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:45:57,592 epoch 9 - iter 20/209 - loss 0.09681647 - samples/sec: 268.07 - lr: 0.100000\n",
            "2022-10-03 18:45:59,948 epoch 9 - iter 40/209 - loss 0.08881046 - samples/sec: 272.12 - lr: 0.100000\n",
            "2022-10-03 18:46:02,109 epoch 9 - iter 60/209 - loss 0.08340358 - samples/sec: 296.75 - lr: 0.100000\n",
            "2022-10-03 18:46:04,464 epoch 9 - iter 80/209 - loss 0.08372878 - samples/sec: 272.20 - lr: 0.100000\n",
            "2022-10-03 18:46:06,736 epoch 9 - iter 100/209 - loss 0.08179172 - samples/sec: 282.22 - lr: 0.100000\n",
            "2022-10-03 18:46:09,281 epoch 9 - iter 120/209 - loss 0.07877386 - samples/sec: 251.88 - lr: 0.100000\n",
            "2022-10-03 18:46:12,108 epoch 9 - iter 140/209 - loss 0.07729495 - samples/sec: 226.68 - lr: 0.100000\n",
            "2022-10-03 18:46:14,464 epoch 9 - iter 160/209 - loss 0.07978013 - samples/sec: 272.18 - lr: 0.100000\n",
            "2022-10-03 18:46:16,862 epoch 9 - iter 180/209 - loss 0.07947610 - samples/sec: 267.46 - lr: 0.100000\n",
            "2022-10-03 18:46:19,418 epoch 9 - iter 200/209 - loss 0.07818568 - samples/sec: 250.76 - lr: 0.100000\n",
            "2022-10-03 18:46:20,406 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:46:20,408 EPOCH 9 done: loss 0.0771 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:46:27,236 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:46:27,252 DEV : loss 0.060828354209661484 - f1-score (micro avg)  0.7586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:46:27,312 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:46:27,317 saving best model\n",
            "2022-10-03 18:46:30,197 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:46:32,510 epoch 10 - iter 20/209 - loss 0.09725881 - samples/sec: 277.42 - lr: 0.100000\n",
            "2022-10-03 18:46:35,720 epoch 10 - iter 40/209 - loss 0.08603662 - samples/sec: 199.64 - lr: 0.100000\n",
            "2022-10-03 18:46:37,765 epoch 10 - iter 60/209 - loss 0.08038356 - samples/sec: 313.50 - lr: 0.100000\n",
            "2022-10-03 18:46:40,044 epoch 10 - iter 80/209 - loss 0.07767378 - samples/sec: 281.50 - lr: 0.100000\n",
            "2022-10-03 18:46:42,407 epoch 10 - iter 100/209 - loss 0.07848740 - samples/sec: 271.28 - lr: 0.100000\n",
            "2022-10-03 18:46:44,573 epoch 10 - iter 120/209 - loss 0.07484399 - samples/sec: 296.27 - lr: 0.100000\n",
            "2022-10-03 18:46:47,284 epoch 10 - iter 140/209 - loss 0.07309283 - samples/sec: 236.40 - lr: 0.100000\n",
            "2022-10-03 18:46:49,977 epoch 10 - iter 160/209 - loss 0.07200830 - samples/sec: 238.00 - lr: 0.100000\n",
            "2022-10-03 18:46:52,704 epoch 10 - iter 180/209 - loss 0.07169746 - samples/sec: 235.12 - lr: 0.100000\n",
            "2022-10-03 18:46:55,365 epoch 10 - iter 200/209 - loss 0.07266485 - samples/sec: 240.81 - lr: 0.100000\n",
            "2022-10-03 18:46:56,402 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:46:56,404 EPOCH 10 done: loss 0.0731 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:47:03,182 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:47:03,200 DEV : loss 0.06503196060657501 - f1-score (micro avg)  0.7529\n",
            "2022-10-03 18:47:03,259 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 18:47:03,264 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:47:06,422 epoch 11 - iter 20/209 - loss 0.06452681 - samples/sec: 203.04 - lr: 0.100000\n",
            "2022-10-03 18:47:08,828 epoch 11 - iter 40/209 - loss 0.06678285 - samples/sec: 266.49 - lr: 0.100000\n",
            "2022-10-03 18:47:10,874 epoch 11 - iter 60/209 - loss 0.06875308 - samples/sec: 313.44 - lr: 0.100000\n",
            "2022-10-03 18:47:12,953 epoch 11 - iter 80/209 - loss 0.06696340 - samples/sec: 308.45 - lr: 0.100000\n",
            "2022-10-03 18:47:15,470 epoch 11 - iter 100/209 - loss 0.06618400 - samples/sec: 254.74 - lr: 0.100000\n",
            "2022-10-03 18:47:17,757 epoch 11 - iter 120/209 - loss 0.06667697 - samples/sec: 280.28 - lr: 0.100000\n",
            "2022-10-03 18:47:20,453 epoch 11 - iter 140/209 - loss 0.06836063 - samples/sec: 237.76 - lr: 0.100000\n",
            "2022-10-03 18:47:22,906 epoch 11 - iter 160/209 - loss 0.06806221 - samples/sec: 261.44 - lr: 0.100000\n",
            "2022-10-03 18:47:24,875 epoch 11 - iter 180/209 - loss 0.06805743 - samples/sec: 325.72 - lr: 0.100000\n",
            "2022-10-03 18:47:27,424 epoch 11 - iter 200/209 - loss 0.06935675 - samples/sec: 251.35 - lr: 0.100000\n",
            "2022-10-03 18:47:28,726 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:47:28,728 EPOCH 11 done: loss 0.0696 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:47:35,484 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:47:35,497 DEV : loss 0.05805245786905289 - f1-score (micro avg)  0.7755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:47:35,558 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:47:35,562 saving best model\n",
            "2022-10-03 18:47:38,361 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:47:40,650 epoch 12 - iter 20/209 - loss 0.06850431 - samples/sec: 280.25 - lr: 0.100000\n",
            "2022-10-03 18:47:42,928 epoch 12 - iter 40/209 - loss 0.06560530 - samples/sec: 281.49 - lr: 0.100000\n",
            "2022-10-03 18:47:44,791 epoch 12 - iter 60/209 - loss 0.06556213 - samples/sec: 344.36 - lr: 0.100000\n",
            "2022-10-03 18:47:47,940 epoch 12 - iter 80/209 - loss 0.06393704 - samples/sec: 203.48 - lr: 0.100000\n",
            "2022-10-03 18:47:50,463 epoch 12 - iter 100/209 - loss 0.06121776 - samples/sec: 254.26 - lr: 0.100000\n",
            "2022-10-03 18:47:53,051 epoch 12 - iter 120/209 - loss 0.05933833 - samples/sec: 247.72 - lr: 0.100000\n",
            "2022-10-03 18:47:55,178 epoch 12 - iter 140/209 - loss 0.06262313 - samples/sec: 301.59 - lr: 0.100000\n",
            "2022-10-03 18:47:58,136 epoch 12 - iter 160/209 - loss 0.06502163 - samples/sec: 216.70 - lr: 0.100000\n",
            "2022-10-03 18:48:00,659 epoch 12 - iter 180/209 - loss 0.06486847 - samples/sec: 254.11 - lr: 0.100000\n",
            "2022-10-03 18:48:02,939 epoch 12 - iter 200/209 - loss 0.06505891 - samples/sec: 281.21 - lr: 0.100000\n",
            "2022-10-03 18:48:04,416 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:48:04,418 EPOCH 12 done: loss 0.0651 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:48:10,988 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:48:11,001 DEV : loss 0.057785019278526306 - f1-score (micro avg)  0.7593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:48:11,063 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 18:48:11,068 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:48:13,400 epoch 13 - iter 20/209 - loss 0.04475673 - samples/sec: 275.03 - lr: 0.100000\n",
            "2022-10-03 18:48:15,393 epoch 13 - iter 40/209 - loss 0.05227686 - samples/sec: 321.86 - lr: 0.100000\n",
            "2022-10-03 18:48:18,197 epoch 13 - iter 60/209 - loss 0.05574324 - samples/sec: 228.60 - lr: 0.100000\n",
            "2022-10-03 18:48:20,124 epoch 13 - iter 80/209 - loss 0.05706818 - samples/sec: 332.72 - lr: 0.100000\n",
            "2022-10-03 18:48:22,327 epoch 13 - iter 100/209 - loss 0.05711975 - samples/sec: 291.21 - lr: 0.100000\n",
            "2022-10-03 18:48:24,690 epoch 13 - iter 120/209 - loss 0.05729657 - samples/sec: 271.33 - lr: 0.100000\n",
            "2022-10-03 18:48:26,726 epoch 13 - iter 140/209 - loss 0.05831103 - samples/sec: 315.02 - lr: 0.100000\n",
            "2022-10-03 18:48:29,486 epoch 13 - iter 160/209 - loss 0.05802068 - samples/sec: 232.30 - lr: 0.100000\n",
            "2022-10-03 18:48:32,114 epoch 13 - iter 180/209 - loss 0.05863303 - samples/sec: 243.87 - lr: 0.100000\n",
            "2022-10-03 18:48:35,321 epoch 13 - iter 200/209 - loss 0.05922420 - samples/sec: 199.87 - lr: 0.100000\n",
            "2022-10-03 18:48:36,119 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:48:36,121 EPOCH 13 done: loss 0.0608 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:48:42,760 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:48:42,774 DEV : loss 0.05335738882422447 - f1-score (micro avg)  0.8049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:48:42,834 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:48:42,838 saving best model\n",
            "2022-10-03 18:48:45,605 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:48:48,194 epoch 14 - iter 20/209 - loss 0.05677778 - samples/sec: 247.85 - lr: 0.100000\n",
            "2022-10-03 18:48:50,405 epoch 14 - iter 40/209 - loss 0.05327978 - samples/sec: 290.01 - lr: 0.100000\n",
            "2022-10-03 18:48:52,855 epoch 14 - iter 60/209 - loss 0.05756637 - samples/sec: 261.67 - lr: 0.100000\n",
            "2022-10-03 18:48:55,476 epoch 14 - iter 80/209 - loss 0.05683522 - samples/sec: 244.69 - lr: 0.100000\n",
            "2022-10-03 18:48:57,713 epoch 14 - iter 100/209 - loss 0.05683143 - samples/sec: 286.56 - lr: 0.100000\n",
            "2022-10-03 18:48:59,703 epoch 14 - iter 120/209 - loss 0.05793003 - samples/sec: 322.37 - lr: 0.100000\n",
            "2022-10-03 18:49:02,275 epoch 14 - iter 140/209 - loss 0.05719444 - samples/sec: 249.34 - lr: 0.100000\n",
            "2022-10-03 18:49:04,776 epoch 14 - iter 160/209 - loss 0.05799304 - samples/sec: 256.41 - lr: 0.100000\n",
            "2022-10-03 18:49:07,288 epoch 14 - iter 180/209 - loss 0.05823381 - samples/sec: 255.14 - lr: 0.100000\n",
            "2022-10-03 18:49:10,498 epoch 14 - iter 200/209 - loss 0.05959184 - samples/sec: 199.66 - lr: 0.100000\n",
            "2022-10-03 18:49:11,655 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:49:11,658 EPOCH 14 done: loss 0.0599 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:49:18,314 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:49:18,336 DEV : loss 0.05508466437458992 - f1-score (micro avg)  0.7892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:49:18,397 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 18:49:18,401 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:49:20,882 epoch 15 - iter 20/209 - loss 0.05638990 - samples/sec: 258.45 - lr: 0.100000\n",
            "2022-10-03 18:49:23,232 epoch 15 - iter 40/209 - loss 0.06361697 - samples/sec: 272.91 - lr: 0.100000\n",
            "2022-10-03 18:49:25,500 epoch 15 - iter 60/209 - loss 0.06034399 - samples/sec: 282.75 - lr: 0.100000\n",
            "2022-10-03 18:49:27,692 epoch 15 - iter 80/209 - loss 0.05990189 - samples/sec: 292.48 - lr: 0.100000\n",
            "2022-10-03 18:49:30,455 epoch 15 - iter 100/209 - loss 0.05913335 - samples/sec: 232.01 - lr: 0.100000\n",
            "2022-10-03 18:49:32,691 epoch 15 - iter 120/209 - loss 0.05894373 - samples/sec: 286.71 - lr: 0.100000\n",
            "2022-10-03 18:49:35,200 epoch 15 - iter 140/209 - loss 0.05997174 - samples/sec: 255.60 - lr: 0.100000\n",
            "2022-10-03 18:49:37,394 epoch 15 - iter 160/209 - loss 0.05885711 - samples/sec: 292.31 - lr: 0.100000\n",
            "2022-10-03 18:49:39,911 epoch 15 - iter 180/209 - loss 0.05821986 - samples/sec: 254.78 - lr: 0.100000\n",
            "2022-10-03 18:49:41,605 epoch 15 - iter 200/209 - loss 0.05880007 - samples/sec: 378.78 - lr: 0.100000\n",
            "2022-10-03 18:49:42,921 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:49:42,923 EPOCH 15 done: loss 0.0586 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:49:49,941 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:49:49,956 DEV : loss 0.05065612494945526 - f1-score (micro avg)  0.8052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:49:50,018 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:49:50,023 saving best model\n",
            "2022-10-03 18:49:52,820 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:49:55,412 epoch 16 - iter 20/209 - loss 0.06611578 - samples/sec: 247.60 - lr: 0.100000\n",
            "2022-10-03 18:49:57,872 epoch 16 - iter 40/209 - loss 0.05526306 - samples/sec: 260.54 - lr: 0.100000\n",
            "2022-10-03 18:50:00,128 epoch 16 - iter 60/209 - loss 0.05897922 - samples/sec: 284.20 - lr: 0.100000\n",
            "2022-10-03 18:50:03,099 epoch 16 - iter 80/209 - loss 0.05748477 - samples/sec: 215.75 - lr: 0.100000\n",
            "2022-10-03 18:50:05,836 epoch 16 - iter 100/209 - loss 0.05541908 - samples/sec: 234.41 - lr: 0.100000\n",
            "2022-10-03 18:50:08,133 epoch 16 - iter 120/209 - loss 0.05354911 - samples/sec: 279.13 - lr: 0.100000\n",
            "2022-10-03 18:50:10,347 epoch 16 - iter 140/209 - loss 0.05534813 - samples/sec: 289.57 - lr: 0.100000\n",
            "2022-10-03 18:50:13,033 epoch 16 - iter 160/209 - loss 0.05503030 - samples/sec: 238.79 - lr: 0.100000\n",
            "2022-10-03 18:50:15,891 epoch 16 - iter 180/209 - loss 0.05529817 - samples/sec: 224.24 - lr: 0.100000\n",
            "2022-10-03 18:50:18,355 epoch 16 - iter 200/209 - loss 0.05599974 - samples/sec: 260.20 - lr: 0.100000\n",
            "2022-10-03 18:50:19,057 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:50:19,059 EPOCH 16 done: loss 0.0560 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:50:25,724 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:50:25,738 DEV : loss 0.048684261739254 - f1-score (micro avg)  0.8129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:50:25,800 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:50:25,805 saving best model\n",
            "2022-10-03 18:50:28,933 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:50:31,509 epoch 17 - iter 20/209 - loss 0.06389245 - samples/sec: 249.04 - lr: 0.100000\n",
            "2022-10-03 18:50:33,906 epoch 17 - iter 40/209 - loss 0.05413621 - samples/sec: 267.48 - lr: 0.100000\n",
            "2022-10-03 18:50:36,040 epoch 17 - iter 60/209 - loss 0.05422989 - samples/sec: 300.60 - lr: 0.100000\n",
            "2022-10-03 18:50:38,383 epoch 17 - iter 80/209 - loss 0.05406084 - samples/sec: 273.61 - lr: 0.100000\n",
            "2022-10-03 18:50:40,730 epoch 17 - iter 100/209 - loss 0.05342149 - samples/sec: 273.14 - lr: 0.100000\n",
            "2022-10-03 18:50:43,591 epoch 17 - iter 120/209 - loss 0.05536332 - samples/sec: 224.00 - lr: 0.100000\n",
            "2022-10-03 18:50:46,277 epoch 17 - iter 140/209 - loss 0.05497211 - samples/sec: 238.71 - lr: 0.100000\n",
            "2022-10-03 18:50:49,424 epoch 17 - iter 160/209 - loss 0.05531508 - samples/sec: 203.69 - lr: 0.100000\n",
            "2022-10-03 18:50:52,191 epoch 17 - iter 180/209 - loss 0.05438025 - samples/sec: 231.62 - lr: 0.100000\n",
            "2022-10-03 18:50:54,194 epoch 17 - iter 200/209 - loss 0.05341291 - samples/sec: 320.12 - lr: 0.100000\n",
            "2022-10-03 18:50:55,132 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:50:55,134 EPOCH 17 done: loss 0.0546 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:07<00:00,  6.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:51:02,182 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:51:02,196 DEV : loss 0.05065369978547096 - f1-score (micro avg)  0.794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:51:02,258 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 18:51:02,262 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:51:04,376 epoch 18 - iter 20/209 - loss 0.04804430 - samples/sec: 303.63 - lr: 0.100000\n",
            "2022-10-03 18:51:06,242 epoch 18 - iter 40/209 - loss 0.05200816 - samples/sec: 343.60 - lr: 0.100000\n",
            "2022-10-03 18:51:08,434 epoch 18 - iter 60/209 - loss 0.05164329 - samples/sec: 292.50 - lr: 0.100000\n",
            "2022-10-03 18:51:10,505 epoch 18 - iter 80/209 - loss 0.05380102 - samples/sec: 309.69 - lr: 0.100000\n",
            "2022-10-03 18:51:13,061 epoch 18 - iter 100/209 - loss 0.05356022 - samples/sec: 250.80 - lr: 0.100000\n",
            "2022-10-03 18:51:15,430 epoch 18 - iter 120/209 - loss 0.05247331 - samples/sec: 270.59 - lr: 0.100000\n",
            "2022-10-03 18:51:17,660 epoch 18 - iter 140/209 - loss 0.05200027 - samples/sec: 287.55 - lr: 0.100000\n",
            "2022-10-03 18:51:20,506 epoch 18 - iter 160/209 - loss 0.05149652 - samples/sec: 225.15 - lr: 0.100000\n",
            "2022-10-03 18:51:22,745 epoch 18 - iter 180/209 - loss 0.05177796 - samples/sec: 286.48 - lr: 0.100000\n",
            "2022-10-03 18:51:25,302 epoch 18 - iter 200/209 - loss 0.05211152 - samples/sec: 250.61 - lr: 0.100000\n",
            "2022-10-03 18:51:26,502 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:51:26,504 EPOCH 18 done: loss 0.0524 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:51:33,217 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:51:33,232 DEV : loss 0.04896869510412216 - f1-score (micro avg)  0.8203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:51:33,290 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:51:33,294 saving best model\n",
            "2022-10-03 18:51:36,140 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:51:38,718 epoch 19 - iter 20/209 - loss 0.03978212 - samples/sec: 248.88 - lr: 0.100000\n",
            "2022-10-03 18:51:40,791 epoch 19 - iter 40/209 - loss 0.04558074 - samples/sec: 309.31 - lr: 0.100000\n",
            "2022-10-03 18:51:43,538 epoch 19 - iter 60/209 - loss 0.05048568 - samples/sec: 233.36 - lr: 0.100000\n",
            "2022-10-03 18:51:46,128 epoch 19 - iter 80/209 - loss 0.05190054 - samples/sec: 247.55 - lr: 0.100000\n",
            "2022-10-03 18:51:49,133 epoch 19 - iter 100/209 - loss 0.05070626 - samples/sec: 213.28 - lr: 0.100000\n",
            "2022-10-03 18:51:51,851 epoch 19 - iter 120/209 - loss 0.04981074 - samples/sec: 235.90 - lr: 0.100000\n",
            "2022-10-03 18:51:54,399 epoch 19 - iter 140/209 - loss 0.04984403 - samples/sec: 251.63 - lr: 0.100000\n",
            "2022-10-03 18:51:56,836 epoch 19 - iter 160/209 - loss 0.05034534 - samples/sec: 263.06 - lr: 0.100000\n",
            "2022-10-03 18:51:59,161 epoch 19 - iter 180/209 - loss 0.05047426 - samples/sec: 275.73 - lr: 0.100000\n",
            "2022-10-03 18:52:01,488 epoch 19 - iter 200/209 - loss 0.05214474 - samples/sec: 275.53 - lr: 0.100000\n",
            "2022-10-03 18:52:02,259 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:52:02,262 EPOCH 19 done: loss 0.0519 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:52:09,246 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:52:09,261 DEV : loss 0.046392813324928284 - f1-score (micro avg)  0.814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:52:09,320 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 18:52:09,324 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:52:11,635 epoch 20 - iter 20/209 - loss 0.04410483 - samples/sec: 277.63 - lr: 0.100000\n",
            "2022-10-03 18:52:14,206 epoch 20 - iter 40/209 - loss 0.04222022 - samples/sec: 249.35 - lr: 0.100000\n",
            "2022-10-03 18:52:16,431 epoch 20 - iter 60/209 - loss 0.04208644 - samples/sec: 288.20 - lr: 0.100000\n",
            "2022-10-03 18:52:18,566 epoch 20 - iter 80/209 - loss 0.04350335 - samples/sec: 300.26 - lr: 0.100000\n",
            "2022-10-03 18:52:21,437 epoch 20 - iter 100/209 - loss 0.04412048 - samples/sec: 223.28 - lr: 0.100000\n",
            "2022-10-03 18:52:23,731 epoch 20 - iter 120/209 - loss 0.04564095 - samples/sec: 279.41 - lr: 0.100000\n",
            "2022-10-03 18:52:26,117 epoch 20 - iter 140/209 - loss 0.04779393 - samples/sec: 268.75 - lr: 0.100000\n",
            "2022-10-03 18:52:28,677 epoch 20 - iter 160/209 - loss 0.04623421 - samples/sec: 250.53 - lr: 0.100000\n",
            "2022-10-03 18:52:31,046 epoch 20 - iter 180/209 - loss 0.04844623 - samples/sec: 270.70 - lr: 0.100000\n",
            "2022-10-03 18:52:33,032 epoch 20 - iter 200/209 - loss 0.04788235 - samples/sec: 322.83 - lr: 0.100000\n",
            "2022-10-03 18:52:33,830 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:52:33,832 EPOCH 20 done: loss 0.0476 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:52:40,403 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:52:40,416 DEV : loss 0.05078371241688728 - f1-score (micro avg)  0.8134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:52:40,482 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 18:52:40,486 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:52:42,835 epoch 21 - iter 20/209 - loss 0.03856598 - samples/sec: 273.04 - lr: 0.100000\n",
            "2022-10-03 18:52:45,169 epoch 21 - iter 40/209 - loss 0.04267619 - samples/sec: 274.62 - lr: 0.100000\n",
            "2022-10-03 18:52:47,526 epoch 21 - iter 60/209 - loss 0.04270275 - samples/sec: 271.94 - lr: 0.100000\n",
            "2022-10-03 18:52:50,276 epoch 21 - iter 80/209 - loss 0.04224218 - samples/sec: 233.13 - lr: 0.100000\n",
            "2022-10-03 18:52:52,573 epoch 21 - iter 100/209 - loss 0.04222561 - samples/sec: 279.04 - lr: 0.100000\n",
            "2022-10-03 18:52:54,581 epoch 21 - iter 120/209 - loss 0.04324073 - samples/sec: 319.45 - lr: 0.100000\n",
            "2022-10-03 18:52:56,456 epoch 21 - iter 140/209 - loss 0.04446012 - samples/sec: 342.16 - lr: 0.100000\n",
            "2022-10-03 18:52:59,262 epoch 21 - iter 160/209 - loss 0.04520011 - samples/sec: 228.46 - lr: 0.100000\n",
            "2022-10-03 18:53:01,442 epoch 21 - iter 180/209 - loss 0.04679123 - samples/sec: 294.23 - lr: 0.100000\n",
            "2022-10-03 18:53:03,719 epoch 21 - iter 200/209 - loss 0.04673049 - samples/sec: 281.52 - lr: 0.100000\n",
            "2022-10-03 18:53:04,866 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:53:04,869 EPOCH 21 done: loss 0.0466 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:53:11,519 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:53:11,533 DEV : loss 0.04473907873034477 - f1-score (micro avg)  0.8177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:53:11,593 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 18:53:11,598 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:53:14,353 epoch 22 - iter 20/209 - loss 0.05449680 - samples/sec: 232.75 - lr: 0.100000\n",
            "2022-10-03 18:53:16,424 epoch 22 - iter 40/209 - loss 0.04822891 - samples/sec: 309.70 - lr: 0.100000\n",
            "2022-10-03 18:53:18,803 epoch 22 - iter 60/209 - loss 0.04362862 - samples/sec: 269.52 - lr: 0.100000\n",
            "2022-10-03 18:53:21,473 epoch 22 - iter 80/209 - loss 0.04361282 - samples/sec: 240.01 - lr: 0.100000\n",
            "2022-10-03 18:53:23,803 epoch 22 - iter 100/209 - loss 0.04374349 - samples/sec: 275.22 - lr: 0.100000\n",
            "2022-10-03 18:53:26,462 epoch 22 - iter 120/209 - loss 0.04402134 - samples/sec: 241.06 - lr: 0.100000\n",
            "2022-10-03 18:53:28,921 epoch 22 - iter 140/209 - loss 0.04372993 - samples/sec: 260.60 - lr: 0.100000\n",
            "2022-10-03 18:53:31,015 epoch 22 - iter 160/209 - loss 0.04465147 - samples/sec: 306.26 - lr: 0.100000\n",
            "2022-10-03 18:53:33,607 epoch 22 - iter 180/209 - loss 0.04464847 - samples/sec: 247.33 - lr: 0.100000\n",
            "2022-10-03 18:53:36,040 epoch 22 - iter 200/209 - loss 0.04478017 - samples/sec: 263.45 - lr: 0.100000\n",
            "2022-10-03 18:53:36,835 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:53:36,837 EPOCH 22 done: loss 0.0455 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:53:43,510 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:53:43,523 DEV : loss 0.04734628647565842 - f1-score (micro avg)  0.8129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:53:43,583 Epoch    22: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2022-10-03 18:53:43,584 BAD EPOCHS (no improvement): 4\n",
            "2022-10-03 18:53:43,589 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:53:46,788 epoch 23 - iter 20/209 - loss 0.04490919 - samples/sec: 200.38 - lr: 0.050000\n",
            "2022-10-03 18:53:49,053 epoch 23 - iter 40/209 - loss 0.04070683 - samples/sec: 283.12 - lr: 0.050000\n",
            "2022-10-03 18:53:51,127 epoch 23 - iter 60/209 - loss 0.04136243 - samples/sec: 309.27 - lr: 0.050000\n",
            "2022-10-03 18:53:53,505 epoch 23 - iter 80/209 - loss 0.03796725 - samples/sec: 269.52 - lr: 0.050000\n",
            "2022-10-03 18:53:55,786 epoch 23 - iter 100/209 - loss 0.03771703 - samples/sec: 281.17 - lr: 0.050000\n",
            "2022-10-03 18:53:57,744 epoch 23 - iter 120/209 - loss 0.03845175 - samples/sec: 327.51 - lr: 0.050000\n",
            "2022-10-03 18:54:00,251 epoch 23 - iter 140/209 - loss 0.03796796 - samples/sec: 255.61 - lr: 0.050000\n",
            "2022-10-03 18:54:02,381 epoch 23 - iter 160/209 - loss 0.03825035 - samples/sec: 301.10 - lr: 0.050000\n",
            "2022-10-03 18:54:04,559 epoch 23 - iter 180/209 - loss 0.03804160 - samples/sec: 294.36 - lr: 0.050000\n",
            "2022-10-03 18:54:07,027 epoch 23 - iter 200/209 - loss 0.03945031 - samples/sec: 259.69 - lr: 0.050000\n",
            "2022-10-03 18:54:08,289 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:54:08,292 EPOCH 23 done: loss 0.0401 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:54:14,849 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:54:14,864 DEV : loss 0.038541991263628006 - f1-score (micro avg)  0.8447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:54:14,922 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:54:14,928 saving best model\n",
            "2022-10-03 18:54:17,719 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:54:20,002 epoch 24 - iter 20/209 - loss 0.03566420 - samples/sec: 281.09 - lr: 0.050000\n",
            "2022-10-03 18:54:22,826 epoch 24 - iter 40/209 - loss 0.03802126 - samples/sec: 226.99 - lr: 0.050000\n",
            "2022-10-03 18:54:25,600 epoch 24 - iter 60/209 - loss 0.03830815 - samples/sec: 231.09 - lr: 0.050000\n",
            "2022-10-03 18:54:28,097 epoch 24 - iter 80/209 - loss 0.03712500 - samples/sec: 256.77 - lr: 0.050000\n",
            "2022-10-03 18:54:30,394 epoch 24 - iter 100/209 - loss 0.03688358 - samples/sec: 279.20 - lr: 0.050000\n",
            "2022-10-03 18:54:33,114 epoch 24 - iter 120/209 - loss 0.03593417 - samples/sec: 235.62 - lr: 0.050000\n",
            "2022-10-03 18:54:35,451 epoch 24 - iter 140/209 - loss 0.03668622 - samples/sec: 274.55 - lr: 0.050000\n",
            "2022-10-03 18:54:37,896 epoch 24 - iter 160/209 - loss 0.03600764 - samples/sec: 262.18 - lr: 0.050000\n",
            "2022-10-03 18:54:40,697 epoch 24 - iter 180/209 - loss 0.03573732 - samples/sec: 228.85 - lr: 0.050000\n",
            "2022-10-03 18:54:43,068 epoch 24 - iter 200/209 - loss 0.03630266 - samples/sec: 270.36 - lr: 0.050000\n",
            "2022-10-03 18:54:44,019 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:54:44,022 EPOCH 24 done: loss 0.0368 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:54:50,678 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:54:50,691 DEV : loss 0.03912742808461189 - f1-score (micro avg)  0.8359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:54:50,751 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 18:54:50,757 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:54:52,890 epoch 25 - iter 20/209 - loss 0.03604788 - samples/sec: 300.82 - lr: 0.050000\n",
            "2022-10-03 18:54:55,195 epoch 25 - iter 40/209 - loss 0.03723479 - samples/sec: 278.12 - lr: 0.050000\n",
            "2022-10-03 18:54:57,304 epoch 25 - iter 60/209 - loss 0.03694517 - samples/sec: 304.11 - lr: 0.050000\n",
            "2022-10-03 18:55:00,247 epoch 25 - iter 80/209 - loss 0.03474352 - samples/sec: 217.73 - lr: 0.050000\n",
            "2022-10-03 18:55:02,679 epoch 25 - iter 100/209 - loss 0.03339952 - samples/sec: 263.57 - lr: 0.050000\n",
            "2022-10-03 18:55:05,339 epoch 25 - iter 120/209 - loss 0.03451474 - samples/sec: 241.00 - lr: 0.050000\n",
            "2022-10-03 18:55:07,993 epoch 25 - iter 140/209 - loss 0.03607590 - samples/sec: 241.63 - lr: 0.050000\n",
            "2022-10-03 18:55:10,306 epoch 25 - iter 160/209 - loss 0.03695701 - samples/sec: 277.23 - lr: 0.050000\n",
            "2022-10-03 18:55:12,211 epoch 25 - iter 180/209 - loss 0.03625311 - samples/sec: 336.67 - lr: 0.050000\n",
            "2022-10-03 18:55:14,489 epoch 25 - iter 200/209 - loss 0.03614369 - samples/sec: 281.47 - lr: 0.050000\n",
            "2022-10-03 18:55:15,385 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:55:15,387 EPOCH 25 done: loss 0.0359 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:55:22,032 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:55:22,046 DEV : loss 0.03847711160778999 - f1-score (micro avg)  0.8443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:55:22,106 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 18:55:22,111 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:55:24,048 epoch 26 - iter 20/209 - loss 0.03142486 - samples/sec: 331.33 - lr: 0.050000\n",
            "2022-10-03 18:55:26,178 epoch 26 - iter 40/209 - loss 0.03569151 - samples/sec: 301.04 - lr: 0.050000\n",
            "2022-10-03 18:55:29,198 epoch 26 - iter 60/209 - loss 0.03878296 - samples/sec: 212.13 - lr: 0.050000\n",
            "2022-10-03 18:55:31,438 epoch 26 - iter 80/209 - loss 0.03929280 - samples/sec: 286.30 - lr: 0.050000\n",
            "2022-10-03 18:55:33,650 epoch 26 - iter 100/209 - loss 0.03806674 - samples/sec: 289.91 - lr: 0.050000\n",
            "2022-10-03 18:55:35,809 epoch 26 - iter 120/209 - loss 0.03672993 - samples/sec: 296.93 - lr: 0.050000\n",
            "2022-10-03 18:55:37,934 epoch 26 - iter 140/209 - loss 0.03619345 - samples/sec: 301.77 - lr: 0.050000\n",
            "2022-10-03 18:55:40,277 epoch 26 - iter 160/209 - loss 0.03568538 - samples/sec: 273.57 - lr: 0.050000\n",
            "2022-10-03 18:55:43,067 epoch 26 - iter 180/209 - loss 0.03487082 - samples/sec: 229.77 - lr: 0.050000\n",
            "2022-10-03 18:55:45,327 epoch 26 - iter 200/209 - loss 0.03496334 - samples/sec: 283.68 - lr: 0.050000\n",
            "2022-10-03 18:55:46,386 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:55:46,388 EPOCH 26 done: loss 0.0349 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:07<00:00,  6.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:55:53,437 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:55:53,451 DEV : loss 0.03878262639045715 - f1-score (micro avg)  0.8464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:55:53,515 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:55:53,520 saving best model\n",
            "2022-10-03 18:55:56,326 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:55:58,480 epoch 27 - iter 20/209 - loss 0.04124344 - samples/sec: 297.94 - lr: 0.050000\n",
            "2022-10-03 18:56:00,995 epoch 27 - iter 40/209 - loss 0.03519492 - samples/sec: 254.86 - lr: 0.050000\n",
            "2022-10-03 18:56:03,294 epoch 27 - iter 60/209 - loss 0.03254257 - samples/sec: 278.94 - lr: 0.050000\n",
            "2022-10-03 18:56:05,719 epoch 27 - iter 80/209 - loss 0.03391869 - samples/sec: 264.39 - lr: 0.050000\n",
            "2022-10-03 18:56:09,097 epoch 27 - iter 100/209 - loss 0.03531802 - samples/sec: 189.71 - lr: 0.050000\n",
            "2022-10-03 18:56:11,949 epoch 27 - iter 120/209 - loss 0.03442961 - samples/sec: 224.72 - lr: 0.050000\n",
            "2022-10-03 18:56:14,821 epoch 27 - iter 140/209 - loss 0.03337365 - samples/sec: 223.19 - lr: 0.050000\n",
            "2022-10-03 18:56:17,244 epoch 27 - iter 160/209 - loss 0.03405620 - samples/sec: 264.60 - lr: 0.050000\n",
            "2022-10-03 18:56:19,543 epoch 27 - iter 180/209 - loss 0.03326931 - samples/sec: 278.92 - lr: 0.050000\n",
            "2022-10-03 18:56:21,631 epoch 27 - iter 200/209 - loss 0.03404483 - samples/sec: 307.02 - lr: 0.050000\n",
            "2022-10-03 18:56:22,487 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:56:22,489 EPOCH 27 done: loss 0.0342 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:56:29,135 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:56:29,150 DEV : loss 0.03771375119686127 - f1-score (micro avg)  0.8546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:56:29,211 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:56:29,216 saving best model\n",
            "2022-10-03 18:56:32,041 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:56:34,596 epoch 28 - iter 20/209 - loss 0.03651516 - samples/sec: 251.00 - lr: 0.050000\n",
            "2022-10-03 18:56:36,612 epoch 28 - iter 40/209 - loss 0.03021368 - samples/sec: 318.01 - lr: 0.050000\n",
            "2022-10-03 18:56:38,962 epoch 28 - iter 60/209 - loss 0.03062097 - samples/sec: 272.81 - lr: 0.050000\n",
            "2022-10-03 18:56:41,301 epoch 28 - iter 80/209 - loss 0.03287940 - samples/sec: 274.15 - lr: 0.050000\n",
            "2022-10-03 18:56:44,116 epoch 28 - iter 100/209 - loss 0.03227649 - samples/sec: 227.75 - lr: 0.050000\n",
            "2022-10-03 18:56:46,512 epoch 28 - iter 120/209 - loss 0.03255969 - samples/sec: 267.80 - lr: 0.050000\n",
            "2022-10-03 18:56:48,877 epoch 28 - iter 140/209 - loss 0.03340108 - samples/sec: 271.09 - lr: 0.050000\n",
            "2022-10-03 18:56:51,919 epoch 28 - iter 160/209 - loss 0.03311304 - samples/sec: 210.80 - lr: 0.050000\n",
            "2022-10-03 18:56:54,699 epoch 28 - iter 180/209 - loss 0.03345397 - samples/sec: 230.57 - lr: 0.050000\n",
            "2022-10-03 18:56:57,153 epoch 28 - iter 200/209 - loss 0.03394040 - samples/sec: 261.20 - lr: 0.050000\n",
            "2022-10-03 18:56:58,125 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:56:58,127 EPOCH 28 done: loss 0.0341 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:07<00:00,  6.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:57:05,208 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:57:05,223 DEV : loss 0.03745303675532341 - f1-score (micro avg)  0.8522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:57:05,285 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 18:57:05,289 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:57:08,284 epoch 29 - iter 20/209 - loss 0.03503674 - samples/sec: 214.06 - lr: 0.050000\n",
            "2022-10-03 18:57:10,623 epoch 29 - iter 40/209 - loss 0.03784537 - samples/sec: 274.15 - lr: 0.050000\n",
            "2022-10-03 18:57:13,379 epoch 29 - iter 60/209 - loss 0.03309820 - samples/sec: 232.64 - lr: 0.050000\n",
            "2022-10-03 18:57:15,238 epoch 29 - iter 80/209 - loss 0.03424924 - samples/sec: 344.87 - lr: 0.050000\n",
            "2022-10-03 18:57:17,673 epoch 29 - iter 100/209 - loss 0.03278384 - samples/sec: 263.23 - lr: 0.050000\n",
            "2022-10-03 18:57:20,253 epoch 29 - iter 120/209 - loss 0.03303552 - samples/sec: 248.42 - lr: 0.050000\n",
            "2022-10-03 18:57:22,476 epoch 29 - iter 140/209 - loss 0.03319139 - samples/sec: 288.42 - lr: 0.050000\n",
            "2022-10-03 18:57:24,905 epoch 29 - iter 160/209 - loss 0.03383625 - samples/sec: 263.77 - lr: 0.050000\n",
            "2022-10-03 18:57:26,962 epoch 29 - iter 180/209 - loss 0.03411469 - samples/sec: 311.86 - lr: 0.050000\n",
            "2022-10-03 18:57:29,258 epoch 29 - iter 200/209 - loss 0.03359481 - samples/sec: 279.17 - lr: 0.050000\n",
            "2022-10-03 18:57:30,155 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:57:30,157 EPOCH 29 done: loss 0.0332 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:57:36,800 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:57:36,815 DEV : loss 0.03784233704209328 - f1-score (micro avg)  0.8434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:57:36,875 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 18:57:36,879 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:57:39,190 epoch 30 - iter 20/209 - loss 0.03099233 - samples/sec: 277.69 - lr: 0.050000\n",
            "2022-10-03 18:57:42,306 epoch 30 - iter 40/209 - loss 0.03235507 - samples/sec: 205.57 - lr: 0.050000\n",
            "2022-10-03 18:57:44,282 epoch 30 - iter 60/209 - loss 0.03269074 - samples/sec: 324.68 - lr: 0.050000\n",
            "2022-10-03 18:57:46,802 epoch 30 - iter 80/209 - loss 0.03263476 - samples/sec: 254.32 - lr: 0.050000\n",
            "2022-10-03 18:57:48,874 epoch 30 - iter 100/209 - loss 0.03300115 - samples/sec: 309.64 - lr: 0.050000\n",
            "2022-10-03 18:57:51,254 epoch 30 - iter 120/209 - loss 0.03307002 - samples/sec: 269.37 - lr: 0.050000\n",
            "2022-10-03 18:57:53,486 epoch 30 - iter 140/209 - loss 0.03300142 - samples/sec: 287.25 - lr: 0.050000\n",
            "2022-10-03 18:57:55,816 epoch 30 - iter 160/209 - loss 0.03331140 - samples/sec: 275.15 - lr: 0.050000\n",
            "2022-10-03 18:57:58,131 epoch 30 - iter 180/209 - loss 0.03288845 - samples/sec: 276.83 - lr: 0.050000\n",
            "2022-10-03 18:58:00,350 epoch 30 - iter 200/209 - loss 0.03281468 - samples/sec: 288.99 - lr: 0.050000\n",
            "2022-10-03 18:58:01,302 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:58:01,303 EPOCH 30 done: loss 0.0329 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:07<00:00,  6.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:58:08,370 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:58:08,384 DEV : loss 0.035691067576408386 - f1-score (micro avg)  0.8594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:58:08,445 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 18:58:08,460 saving best model\n",
            "2022-10-03 18:58:11,237 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:58:13,027 epoch 31 - iter 20/209 - loss 0.03092145 - samples/sec: 358.70 - lr: 0.050000\n",
            "2022-10-03 18:58:15,687 epoch 31 - iter 40/209 - loss 0.03636770 - samples/sec: 241.11 - lr: 0.050000\n",
            "2022-10-03 18:58:18,281 epoch 31 - iter 60/209 - loss 0.03664451 - samples/sec: 247.11 - lr: 0.050000\n",
            "2022-10-03 18:58:21,368 epoch 31 - iter 80/209 - loss 0.03561756 - samples/sec: 207.62 - lr: 0.050000\n",
            "2022-10-03 18:58:24,074 epoch 31 - iter 100/209 - loss 0.03319419 - samples/sec: 236.86 - lr: 0.050000\n",
            "2022-10-03 18:58:26,786 epoch 31 - iter 120/209 - loss 0.03343126 - samples/sec: 236.35 - lr: 0.050000\n",
            "2022-10-03 18:58:29,313 epoch 31 - iter 140/209 - loss 0.03330487 - samples/sec: 253.69 - lr: 0.050000\n",
            "2022-10-03 18:58:31,667 epoch 31 - iter 160/209 - loss 0.03322221 - samples/sec: 272.35 - lr: 0.050000\n",
            "2022-10-03 18:58:33,849 epoch 31 - iter 180/209 - loss 0.03264382 - samples/sec: 293.96 - lr: 0.050000\n",
            "2022-10-03 18:58:36,087 epoch 31 - iter 200/209 - loss 0.03331545 - samples/sec: 286.43 - lr: 0.050000\n",
            "2022-10-03 18:58:37,104 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:58:37,105 EPOCH 31 done: loss 0.0329 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:58:43,704 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:58:43,720 DEV : loss 0.0346212238073349 - f1-score (micro avg)  0.8561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:58:43,783 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 18:58:43,787 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:58:46,446 epoch 32 - iter 20/209 - loss 0.04293188 - samples/sec: 241.22 - lr: 0.050000\n",
            "2022-10-03 18:58:48,550 epoch 32 - iter 40/209 - loss 0.04038174 - samples/sec: 304.72 - lr: 0.050000\n",
            "2022-10-03 18:58:50,872 epoch 32 - iter 60/209 - loss 0.03612782 - samples/sec: 276.16 - lr: 0.050000\n",
            "2022-10-03 18:58:53,029 epoch 32 - iter 80/209 - loss 0.03405726 - samples/sec: 297.28 - lr: 0.050000\n",
            "2022-10-03 18:58:55,904 epoch 32 - iter 100/209 - loss 0.03282160 - samples/sec: 222.97 - lr: 0.050000\n",
            "2022-10-03 18:58:58,277 epoch 32 - iter 120/209 - loss 0.03297007 - samples/sec: 270.07 - lr: 0.050000\n",
            "2022-10-03 18:59:00,929 epoch 32 - iter 140/209 - loss 0.03271107 - samples/sec: 242.29 - lr: 0.050000\n",
            "2022-10-03 18:59:03,032 epoch 32 - iter 160/209 - loss 0.03199546 - samples/sec: 304.78 - lr: 0.050000\n",
            "2022-10-03 18:59:05,548 epoch 32 - iter 180/209 - loss 0.03170911 - samples/sec: 254.75 - lr: 0.050000\n",
            "2022-10-03 18:59:07,910 epoch 32 - iter 200/209 - loss 0.03205250 - samples/sec: 271.50 - lr: 0.050000\n",
            "2022-10-03 18:59:08,921 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:59:08,923 EPOCH 32 done: loss 0.0320 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:07<00:00,  6.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:59:16,029 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:59:16,045 DEV : loss 0.03576216101646423 - f1-score (micro avg)  0.8592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:59:16,105 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 18:59:16,109 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:59:18,744 epoch 33 - iter 20/209 - loss 0.02933981 - samples/sec: 243.42 - lr: 0.050000\n",
            "2022-10-03 18:59:21,395 epoch 33 - iter 40/209 - loss 0.02843495 - samples/sec: 241.83 - lr: 0.050000\n",
            "2022-10-03 18:59:23,946 epoch 33 - iter 60/209 - loss 0.02835724 - samples/sec: 251.33 - lr: 0.050000\n",
            "2022-10-03 18:59:26,072 epoch 33 - iter 80/209 - loss 0.02894572 - samples/sec: 301.53 - lr: 0.050000\n",
            "2022-10-03 18:59:28,844 epoch 33 - iter 100/209 - loss 0.03014244 - samples/sec: 231.22 - lr: 0.050000\n",
            "2022-10-03 18:59:31,078 epoch 33 - iter 120/209 - loss 0.03044812 - samples/sec: 287.01 - lr: 0.050000\n",
            "2022-10-03 18:59:33,281 epoch 33 - iter 140/209 - loss 0.03243420 - samples/sec: 291.04 - lr: 0.050000\n",
            "2022-10-03 18:59:35,450 epoch 33 - iter 160/209 - loss 0.03204004 - samples/sec: 295.67 - lr: 0.050000\n",
            "2022-10-03 18:59:37,955 epoch 33 - iter 180/209 - loss 0.03140746 - samples/sec: 255.97 - lr: 0.050000\n",
            "2022-10-03 18:59:40,340 epoch 33 - iter 200/209 - loss 0.03116224 - samples/sec: 268.72 - lr: 0.050000\n",
            "2022-10-03 18:59:41,160 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:59:41,162 EPOCH 33 done: loss 0.0305 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:59:47,824 Evaluating as a multi-label problem: False\n",
            "2022-10-03 18:59:47,839 DEV : loss 0.035961270332336426 - f1-score (micro avg)  0.8577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 18:59:47,901 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 18:59:47,906 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 18:59:50,009 epoch 34 - iter 20/209 - loss 0.03336373 - samples/sec: 305.08 - lr: 0.050000\n",
            "2022-10-03 18:59:52,195 epoch 34 - iter 40/209 - loss 0.03099473 - samples/sec: 293.43 - lr: 0.050000\n",
            "2022-10-03 18:59:54,644 epoch 34 - iter 60/209 - loss 0.03257470 - samples/sec: 261.75 - lr: 0.050000\n",
            "2022-10-03 18:59:57,228 epoch 34 - iter 80/209 - loss 0.03216700 - samples/sec: 248.15 - lr: 0.050000\n",
            "2022-10-03 18:59:59,240 epoch 34 - iter 100/209 - loss 0.03195582 - samples/sec: 318.70 - lr: 0.050000\n",
            "2022-10-03 19:00:01,550 epoch 34 - iter 120/209 - loss 0.03222553 - samples/sec: 277.62 - lr: 0.050000\n",
            "2022-10-03 19:00:03,684 epoch 34 - iter 140/209 - loss 0.03343709 - samples/sec: 300.50 - lr: 0.050000\n",
            "2022-10-03 19:00:05,812 epoch 34 - iter 160/209 - loss 0.03318508 - samples/sec: 301.21 - lr: 0.050000\n",
            "2022-10-03 19:00:08,213 epoch 34 - iter 180/209 - loss 0.03328766 - samples/sec: 267.09 - lr: 0.050000\n",
            "2022-10-03 19:00:11,306 epoch 34 - iter 200/209 - loss 0.03268260 - samples/sec: 207.20 - lr: 0.050000\n",
            "2022-10-03 19:00:12,422 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:00:12,423 EPOCH 34 done: loss 0.0326 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:00:19,037 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:00:19,051 DEV : loss 0.03565596416592598 - f1-score (micro avg)  0.8669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:00:19,110 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 19:00:19,115 saving best model\n",
            "2022-10-03 19:00:21,891 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:00:24,336 epoch 35 - iter 20/209 - loss 0.02474612 - samples/sec: 262.31 - lr: 0.050000\n",
            "2022-10-03 19:00:26,943 epoch 35 - iter 40/209 - loss 0.02533335 - samples/sec: 245.92 - lr: 0.050000\n",
            "2022-10-03 19:00:29,217 epoch 35 - iter 60/209 - loss 0.02782840 - samples/sec: 281.92 - lr: 0.050000\n",
            "2022-10-03 19:00:31,844 epoch 35 - iter 80/209 - loss 0.02830117 - samples/sec: 244.04 - lr: 0.050000\n",
            "2022-10-03 19:00:34,242 epoch 35 - iter 100/209 - loss 0.02829926 - samples/sec: 267.40 - lr: 0.050000\n",
            "2022-10-03 19:00:37,315 epoch 35 - iter 120/209 - loss 0.02939050 - samples/sec: 208.57 - lr: 0.050000\n",
            "2022-10-03 19:00:39,347 epoch 35 - iter 140/209 - loss 0.03062654 - samples/sec: 315.75 - lr: 0.050000\n",
            "2022-10-03 19:00:42,089 epoch 35 - iter 160/209 - loss 0.03044770 - samples/sec: 233.73 - lr: 0.050000\n",
            "2022-10-03 19:00:44,218 epoch 35 - iter 180/209 - loss 0.02991385 - samples/sec: 301.17 - lr: 0.050000\n",
            "2022-10-03 19:00:46,313 epoch 35 - iter 200/209 - loss 0.03008819 - samples/sec: 306.13 - lr: 0.050000\n",
            "2022-10-03 19:00:47,464 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:00:47,466 EPOCH 35 done: loss 0.0308 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:00:54,096 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:00:54,110 DEV : loss 0.03467694669961929 - f1-score (micro avg)  0.8579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:00:54,173 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:00:54,178 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:00:56,374 epoch 36 - iter 20/209 - loss 0.02611639 - samples/sec: 292.20 - lr: 0.050000\n",
            "2022-10-03 19:00:58,472 epoch 36 - iter 40/209 - loss 0.02599810 - samples/sec: 305.74 - lr: 0.050000\n",
            "2022-10-03 19:01:01,227 epoch 36 - iter 60/209 - loss 0.02458949 - samples/sec: 232.65 - lr: 0.050000\n",
            "2022-10-03 19:01:03,628 epoch 36 - iter 80/209 - loss 0.02705213 - samples/sec: 267.13 - lr: 0.050000\n",
            "2022-10-03 19:01:06,670 epoch 36 - iter 100/209 - loss 0.02858279 - samples/sec: 210.61 - lr: 0.050000\n",
            "2022-10-03 19:01:08,615 epoch 36 - iter 120/209 - loss 0.02944707 - samples/sec: 329.81 - lr: 0.050000\n",
            "2022-10-03 19:01:11,000 epoch 36 - iter 140/209 - loss 0.02934770 - samples/sec: 268.83 - lr: 0.050000\n",
            "2022-10-03 19:01:13,184 epoch 36 - iter 160/209 - loss 0.02865872 - samples/sec: 293.57 - lr: 0.050000\n",
            "2022-10-03 19:01:15,173 epoch 36 - iter 180/209 - loss 0.03002189 - samples/sec: 322.38 - lr: 0.050000\n",
            "2022-10-03 19:01:17,934 epoch 36 - iter 200/209 - loss 0.02942180 - samples/sec: 232.10 - lr: 0.050000\n",
            "2022-10-03 19:01:18,955 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:01:18,956 EPOCH 36 done: loss 0.0297 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:01:25,552 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:01:25,568 DEV : loss 0.03771058842539787 - f1-score (micro avg)  0.8508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:01:25,629 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 19:01:25,633 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:01:27,808 epoch 37 - iter 20/209 - loss 0.02875593 - samples/sec: 295.03 - lr: 0.050000\n",
            "2022-10-03 19:01:29,857 epoch 37 - iter 40/209 - loss 0.02971880 - samples/sec: 313.14 - lr: 0.050000\n",
            "2022-10-03 19:01:32,550 epoch 37 - iter 60/209 - loss 0.02873274 - samples/sec: 237.93 - lr: 0.050000\n",
            "2022-10-03 19:01:34,330 epoch 37 - iter 80/209 - loss 0.02911321 - samples/sec: 360.47 - lr: 0.050000\n",
            "2022-10-03 19:01:36,346 epoch 37 - iter 100/209 - loss 0.02795122 - samples/sec: 318.18 - lr: 0.050000\n",
            "2022-10-03 19:01:38,738 epoch 37 - iter 120/209 - loss 0.02740457 - samples/sec: 268.05 - lr: 0.050000\n",
            "2022-10-03 19:01:41,163 epoch 37 - iter 140/209 - loss 0.02917642 - samples/sec: 264.30 - lr: 0.050000\n",
            "2022-10-03 19:01:44,265 epoch 37 - iter 160/209 - loss 0.02948369 - samples/sec: 206.65 - lr: 0.050000\n",
            "2022-10-03 19:01:46,500 epoch 37 - iter 180/209 - loss 0.02843702 - samples/sec: 286.81 - lr: 0.050000\n",
            "2022-10-03 19:01:49,073 epoch 37 - iter 200/209 - loss 0.02793815 - samples/sec: 249.15 - lr: 0.050000\n",
            "2022-10-03 19:01:49,877 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:01:49,879 EPOCH 37 done: loss 0.0280 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:01:56,684 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:01:56,702 DEV : loss 0.035229187458753586 - f1-score (micro avg)  0.8652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:01:56,762 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 19:01:56,766 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:01:59,030 epoch 38 - iter 20/209 - loss 0.02248741 - samples/sec: 283.35 - lr: 0.050000\n",
            "2022-10-03 19:02:01,403 epoch 38 - iter 40/209 - loss 0.02712813 - samples/sec: 270.11 - lr: 0.050000\n",
            "2022-10-03 19:02:04,070 epoch 38 - iter 60/209 - loss 0.02696268 - samples/sec: 240.36 - lr: 0.050000\n",
            "2022-10-03 19:02:05,859 epoch 38 - iter 80/209 - loss 0.02747135 - samples/sec: 358.51 - lr: 0.050000\n",
            "2022-10-03 19:02:08,089 epoch 38 - iter 100/209 - loss 0.02793577 - samples/sec: 287.54 - lr: 0.050000\n",
            "2022-10-03 19:02:10,160 epoch 38 - iter 120/209 - loss 0.02764095 - samples/sec: 310.27 - lr: 0.050000\n",
            "2022-10-03 19:02:12,677 epoch 38 - iter 140/209 - loss 0.02870037 - samples/sec: 254.63 - lr: 0.050000\n",
            "2022-10-03 19:02:15,054 epoch 38 - iter 160/209 - loss 0.02846173 - samples/sec: 269.66 - lr: 0.050000\n",
            "2022-10-03 19:02:17,272 epoch 38 - iter 180/209 - loss 0.02890232 - samples/sec: 289.17 - lr: 0.050000\n",
            "2022-10-03 19:02:20,052 epoch 38 - iter 200/209 - loss 0.02795848 - samples/sec: 230.53 - lr: 0.050000\n",
            "2022-10-03 19:02:20,898 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:02:20,900 EPOCH 38 done: loss 0.0278 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:02:27,518 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:02:27,532 DEV : loss 0.036679625511169434 - f1-score (micro avg)  0.8606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:02:27,592 Epoch    38: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2022-10-03 19:02:27,594 BAD EPOCHS (no improvement): 4\n",
            "2022-10-03 19:02:27,600 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:02:29,559 epoch 39 - iter 20/209 - loss 0.03323789 - samples/sec: 327.49 - lr: 0.025000\n",
            "2022-10-03 19:02:32,147 epoch 39 - iter 40/209 - loss 0.02909738 - samples/sec: 247.72 - lr: 0.025000\n",
            "2022-10-03 19:02:35,052 epoch 39 - iter 60/209 - loss 0.02853403 - samples/sec: 220.59 - lr: 0.025000\n",
            "2022-10-03 19:02:37,286 epoch 39 - iter 80/209 - loss 0.02781790 - samples/sec: 286.98 - lr: 0.025000\n",
            "2022-10-03 19:02:39,256 epoch 39 - iter 100/209 - loss 0.02665063 - samples/sec: 325.47 - lr: 0.025000\n",
            "2022-10-03 19:02:41,332 epoch 39 - iter 120/209 - loss 0.02809682 - samples/sec: 309.04 - lr: 0.025000\n",
            "2022-10-03 19:02:43,969 epoch 39 - iter 140/209 - loss 0.02734183 - samples/sec: 243.03 - lr: 0.025000\n",
            "2022-10-03 19:02:46,400 epoch 39 - iter 160/209 - loss 0.02809348 - samples/sec: 263.64 - lr: 0.025000\n",
            "2022-10-03 19:02:48,742 epoch 39 - iter 180/209 - loss 0.02823898 - samples/sec: 273.75 - lr: 0.025000\n",
            "2022-10-03 19:02:50,884 epoch 39 - iter 200/209 - loss 0.02804382 - samples/sec: 299.29 - lr: 0.025000\n",
            "2022-10-03 19:02:52,056 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:02:52,057 EPOCH 39 done: loss 0.0277 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:02:59,077 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:02:59,090 DEV : loss 0.03443046286702156 - f1-score (micro avg)  0.8646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:02:59,153 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:02:59,157 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:03:01,315 epoch 40 - iter 20/209 - loss 0.02333335 - samples/sec: 297.29 - lr: 0.025000\n",
            "2022-10-03 19:03:03,550 epoch 40 - iter 40/209 - loss 0.02482048 - samples/sec: 286.90 - lr: 0.025000\n",
            "2022-10-03 19:03:05,769 epoch 40 - iter 60/209 - loss 0.02556107 - samples/sec: 289.01 - lr: 0.025000\n",
            "2022-10-03 19:03:08,215 epoch 40 - iter 80/209 - loss 0.02564052 - samples/sec: 262.05 - lr: 0.025000\n",
            "2022-10-03 19:03:10,557 epoch 40 - iter 100/209 - loss 0.02677976 - samples/sec: 273.81 - lr: 0.025000\n",
            "2022-10-03 19:03:13,455 epoch 40 - iter 120/209 - loss 0.02664807 - samples/sec: 221.19 - lr: 0.025000\n",
            "2022-10-03 19:03:16,237 epoch 40 - iter 140/209 - loss 0.02614328 - samples/sec: 230.39 - lr: 0.025000\n",
            "2022-10-03 19:03:17,958 epoch 40 - iter 160/209 - loss 0.02552506 - samples/sec: 372.82 - lr: 0.025000\n",
            "2022-10-03 19:03:20,731 epoch 40 - iter 180/209 - loss 0.02547681 - samples/sec: 231.18 - lr: 0.025000\n",
            "2022-10-03 19:03:22,564 epoch 40 - iter 200/209 - loss 0.02553244 - samples/sec: 349.92 - lr: 0.025000\n",
            "2022-10-03 19:03:23,571 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:03:23,573 EPOCH 40 done: loss 0.0254 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:03:30,523 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:03:30,539 DEV : loss 0.03451847657561302 - f1-score (micro avg)  0.8627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:03:30,603 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 19:03:30,608 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:03:32,921 epoch 41 - iter 20/209 - loss 0.02145619 - samples/sec: 277.60 - lr: 0.025000\n",
            "2022-10-03 19:03:35,941 epoch 41 - iter 40/209 - loss 0.02499946 - samples/sec: 212.18 - lr: 0.025000\n",
            "2022-10-03 19:03:38,389 epoch 41 - iter 60/209 - loss 0.02378618 - samples/sec: 261.91 - lr: 0.025000\n",
            "2022-10-03 19:03:40,559 epoch 41 - iter 80/209 - loss 0.02492705 - samples/sec: 295.45 - lr: 0.025000\n",
            "2022-10-03 19:03:43,052 epoch 41 - iter 100/209 - loss 0.02410770 - samples/sec: 257.18 - lr: 0.025000\n",
            "2022-10-03 19:03:45,609 epoch 41 - iter 120/209 - loss 0.02370296 - samples/sec: 250.76 - lr: 0.025000\n",
            "2022-10-03 19:03:47,874 epoch 41 - iter 140/209 - loss 0.02348416 - samples/sec: 283.02 - lr: 0.025000\n",
            "2022-10-03 19:03:50,312 epoch 41 - iter 160/209 - loss 0.02338055 - samples/sec: 262.99 - lr: 0.025000\n",
            "2022-10-03 19:03:52,646 epoch 41 - iter 180/209 - loss 0.02408237 - samples/sec: 274.73 - lr: 0.025000\n",
            "2022-10-03 19:03:54,837 epoch 41 - iter 200/209 - loss 0.02415668 - samples/sec: 292.67 - lr: 0.025000\n",
            "2022-10-03 19:03:55,876 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:03:55,878 EPOCH 41 done: loss 0.0241 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:07<00:00,  6.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:04:02,970 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:04:02,985 DEV : loss 0.035778582096099854 - f1-score (micro avg)  0.8665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:04:03,046 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 19:04:03,050 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:04:05,204 epoch 42 - iter 20/209 - loss 0.02210304 - samples/sec: 297.84 - lr: 0.025000\n",
            "2022-10-03 19:04:07,508 epoch 42 - iter 40/209 - loss 0.01883916 - samples/sec: 278.25 - lr: 0.025000\n",
            "2022-10-03 19:04:09,556 epoch 42 - iter 60/209 - loss 0.02167392 - samples/sec: 313.16 - lr: 0.025000\n",
            "2022-10-03 19:04:12,724 epoch 42 - iter 80/209 - loss 0.02205374 - samples/sec: 202.25 - lr: 0.025000\n",
            "2022-10-03 19:04:15,008 epoch 42 - iter 100/209 - loss 0.02330793 - samples/sec: 280.80 - lr: 0.025000\n",
            "2022-10-03 19:04:17,355 epoch 42 - iter 120/209 - loss 0.02227605 - samples/sec: 273.16 - lr: 0.025000\n",
            "2022-10-03 19:04:19,747 epoch 42 - iter 140/209 - loss 0.02291935 - samples/sec: 267.92 - lr: 0.025000\n",
            "2022-10-03 19:04:21,988 epoch 42 - iter 160/209 - loss 0.02300133 - samples/sec: 286.11 - lr: 0.025000\n",
            "2022-10-03 19:04:24,270 epoch 42 - iter 180/209 - loss 0.02326016 - samples/sec: 281.01 - lr: 0.025000\n",
            "2022-10-03 19:04:26,701 epoch 42 - iter 200/209 - loss 0.02303277 - samples/sec: 263.62 - lr: 0.025000\n",
            "2022-10-03 19:04:27,572 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:04:27,574 EPOCH 42 done: loss 0.0234 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:04:34,240 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:04:34,253 DEV : loss 0.034299444407224655 - f1-score (micro avg)  0.873\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:04:34,315 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 19:04:34,320 saving best model\n",
            "2022-10-03 19:04:37,174 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:04:39,823 epoch 43 - iter 20/209 - loss 0.02188493 - samples/sec: 242.09 - lr: 0.025000\n",
            "2022-10-03 19:04:42,305 epoch 43 - iter 40/209 - loss 0.02090843 - samples/sec: 258.23 - lr: 0.025000\n",
            "2022-10-03 19:04:44,401 epoch 43 - iter 60/209 - loss 0.02145781 - samples/sec: 305.88 - lr: 0.025000\n",
            "2022-10-03 19:04:46,842 epoch 43 - iter 80/209 - loss 0.02260492 - samples/sec: 262.79 - lr: 0.025000\n",
            "2022-10-03 19:04:50,187 epoch 43 - iter 100/209 - loss 0.02342191 - samples/sec: 191.56 - lr: 0.025000\n",
            "2022-10-03 19:04:52,752 epoch 43 - iter 120/209 - loss 0.02299544 - samples/sec: 250.17 - lr: 0.025000\n",
            "2022-10-03 19:04:55,118 epoch 43 - iter 140/209 - loss 0.02302930 - samples/sec: 270.95 - lr: 0.025000\n",
            "2022-10-03 19:04:57,297 epoch 43 - iter 160/209 - loss 0.02333748 - samples/sec: 294.41 - lr: 0.025000\n",
            "2022-10-03 19:04:59,691 epoch 43 - iter 180/209 - loss 0.02363900 - samples/sec: 267.84 - lr: 0.025000\n",
            "2022-10-03 19:05:01,899 epoch 43 - iter 200/209 - loss 0.02419507 - samples/sec: 290.39 - lr: 0.025000\n",
            "2022-10-03 19:05:03,111 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:05:03,113 EPOCH 43 done: loss 0.0240 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:05:10,114 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:05:10,129 DEV : loss 0.034895509481430054 - f1-score (micro avg)  0.8718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:05:10,191 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:05:10,195 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:05:12,625 epoch 44 - iter 20/209 - loss 0.02495643 - samples/sec: 263.99 - lr: 0.025000\n",
            "2022-10-03 19:05:14,666 epoch 44 - iter 40/209 - loss 0.02376734 - samples/sec: 314.28 - lr: 0.025000\n",
            "2022-10-03 19:05:17,053 epoch 44 - iter 60/209 - loss 0.02244456 - samples/sec: 268.58 - lr: 0.025000\n",
            "2022-10-03 19:05:19,426 epoch 44 - iter 80/209 - loss 0.02170674 - samples/sec: 270.24 - lr: 0.025000\n",
            "2022-10-03 19:05:21,858 epoch 44 - iter 100/209 - loss 0.02234838 - samples/sec: 263.51 - lr: 0.025000\n",
            "2022-10-03 19:05:24,235 epoch 44 - iter 120/209 - loss 0.02189085 - samples/sec: 269.71 - lr: 0.025000\n",
            "2022-10-03 19:05:26,819 epoch 44 - iter 140/209 - loss 0.02157902 - samples/sec: 248.01 - lr: 0.025000\n",
            "2022-10-03 19:05:28,850 epoch 44 - iter 160/209 - loss 0.02396619 - samples/sec: 315.84 - lr: 0.025000\n",
            "2022-10-03 19:05:31,280 epoch 44 - iter 180/209 - loss 0.02352444 - samples/sec: 263.85 - lr: 0.025000\n",
            "2022-10-03 19:05:33,616 epoch 44 - iter 200/209 - loss 0.02340534 - samples/sec: 274.34 - lr: 0.025000\n",
            "2022-10-03 19:05:34,927 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:05:34,929 EPOCH 44 done: loss 0.0239 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:05:41,573 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:05:41,591 DEV : loss 0.035161375999450684 - f1-score (micro avg)  0.8664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:05:41,652 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 19:05:41,656 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:05:44,329 epoch 45 - iter 20/209 - loss 0.02446418 - samples/sec: 239.85 - lr: 0.025000\n",
            "2022-10-03 19:05:46,761 epoch 45 - iter 40/209 - loss 0.02323851 - samples/sec: 263.62 - lr: 0.025000\n",
            "2022-10-03 19:05:48,547 epoch 45 - iter 60/209 - loss 0.02438842 - samples/sec: 359.20 - lr: 0.025000\n",
            "2022-10-03 19:05:50,638 epoch 45 - iter 80/209 - loss 0.02397033 - samples/sec: 306.71 - lr: 0.025000\n",
            "2022-10-03 19:05:52,728 epoch 45 - iter 100/209 - loss 0.02333019 - samples/sec: 306.71 - lr: 0.025000\n",
            "2022-10-03 19:05:55,401 epoch 45 - iter 120/209 - loss 0.02303955 - samples/sec: 239.80 - lr: 0.025000\n",
            "2022-10-03 19:05:57,414 epoch 45 - iter 140/209 - loss 0.02262398 - samples/sec: 318.51 - lr: 0.025000\n",
            "2022-10-03 19:06:00,340 epoch 45 - iter 160/209 - loss 0.02377841 - samples/sec: 219.01 - lr: 0.025000\n",
            "2022-10-03 19:06:02,190 epoch 45 - iter 180/209 - loss 0.02379193 - samples/sec: 346.68 - lr: 0.025000\n",
            "2022-10-03 19:06:05,085 epoch 45 - iter 200/209 - loss 0.02420670 - samples/sec: 221.43 - lr: 0.025000\n",
            "2022-10-03 19:06:06,040 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:06:06,042 EPOCH 45 done: loss 0.0244 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:06:13,042 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:06:13,056 DEV : loss 0.033696189522743225 - f1-score (micro avg)  0.8731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:06:13,117 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 19:06:13,122 saving best model\n",
            "2022-10-03 19:06:16,017 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:06:18,535 epoch 46 - iter 20/209 - loss 0.02272263 - samples/sec: 254.77 - lr: 0.025000\n",
            "2022-10-03 19:06:20,706 epoch 46 - iter 40/209 - loss 0.02244563 - samples/sec: 295.42 - lr: 0.025000\n",
            "2022-10-03 19:06:22,920 epoch 46 - iter 60/209 - loss 0.02208276 - samples/sec: 289.53 - lr: 0.025000\n",
            "2022-10-03 19:06:25,255 epoch 46 - iter 80/209 - loss 0.02376052 - samples/sec: 274.59 - lr: 0.025000\n",
            "2022-10-03 19:06:28,101 epoch 46 - iter 100/209 - loss 0.02330807 - samples/sec: 225.26 - lr: 0.025000\n",
            "2022-10-03 19:06:30,729 epoch 46 - iter 120/209 - loss 0.02361636 - samples/sec: 243.88 - lr: 0.025000\n",
            "2022-10-03 19:06:33,152 epoch 46 - iter 140/209 - loss 0.02440889 - samples/sec: 264.93 - lr: 0.025000\n",
            "2022-10-03 19:06:35,379 epoch 46 - iter 160/209 - loss 0.02443082 - samples/sec: 287.90 - lr: 0.025000\n",
            "2022-10-03 19:06:37,859 epoch 46 - iter 180/209 - loss 0.02385427 - samples/sec: 258.50 - lr: 0.025000\n",
            "2022-10-03 19:06:40,122 epoch 46 - iter 200/209 - loss 0.02352633 - samples/sec: 283.25 - lr: 0.025000\n",
            "2022-10-03 19:06:40,940 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:06:40,942 EPOCH 46 done: loss 0.0239 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:06:47,617 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:06:47,631 DEV : loss 0.03433816879987717 - f1-score (micro avg)  0.8642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:06:47,693 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:06:47,697 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:06:50,593 epoch 47 - iter 20/209 - loss 0.03144695 - samples/sec: 221.45 - lr: 0.025000\n",
            "2022-10-03 19:06:53,354 epoch 47 - iter 40/209 - loss 0.02593703 - samples/sec: 232.12 - lr: 0.025000\n",
            "2022-10-03 19:06:55,886 epoch 47 - iter 60/209 - loss 0.02503758 - samples/sec: 253.23 - lr: 0.025000\n",
            "2022-10-03 19:06:57,935 epoch 47 - iter 80/209 - loss 0.02411605 - samples/sec: 313.04 - lr: 0.025000\n",
            "2022-10-03 19:07:00,063 epoch 47 - iter 100/209 - loss 0.02345332 - samples/sec: 301.34 - lr: 0.025000\n",
            "2022-10-03 19:07:02,523 epoch 47 - iter 120/209 - loss 0.02336255 - samples/sec: 260.55 - lr: 0.025000\n",
            "2022-10-03 19:07:04,509 epoch 47 - iter 140/209 - loss 0.02361644 - samples/sec: 323.08 - lr: 0.025000\n",
            "2022-10-03 19:07:06,662 epoch 47 - iter 160/209 - loss 0.02367686 - samples/sec: 297.77 - lr: 0.025000\n",
            "2022-10-03 19:07:08,762 epoch 47 - iter 180/209 - loss 0.02345965 - samples/sec: 305.33 - lr: 0.025000\n",
            "2022-10-03 19:07:10,850 epoch 47 - iter 200/209 - loss 0.02292910 - samples/sec: 307.08 - lr: 0.025000\n",
            "2022-10-03 19:07:11,845 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:07:11,847 EPOCH 47 done: loss 0.0233 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:07<00:00,  6.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:07:18,896 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:07:18,911 DEV : loss 0.03581185266375542 - f1-score (micro avg)  0.8684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:07:18,972 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 19:07:18,977 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:07:20,845 epoch 48 - iter 20/209 - loss 0.02008651 - samples/sec: 343.68 - lr: 0.025000\n",
            "2022-10-03 19:07:23,385 epoch 48 - iter 40/209 - loss 0.02344140 - samples/sec: 252.33 - lr: 0.025000\n",
            "2022-10-03 19:07:25,698 epoch 48 - iter 60/209 - loss 0.02315436 - samples/sec: 277.15 - lr: 0.025000\n",
            "2022-10-03 19:07:27,881 epoch 48 - iter 80/209 - loss 0.02390065 - samples/sec: 293.72 - lr: 0.025000\n",
            "2022-10-03 19:07:30,065 epoch 48 - iter 100/209 - loss 0.02355359 - samples/sec: 293.64 - lr: 0.025000\n",
            "2022-10-03 19:07:32,315 epoch 48 - iter 120/209 - loss 0.02334787 - samples/sec: 285.05 - lr: 0.025000\n",
            "2022-10-03 19:07:34,978 epoch 48 - iter 140/209 - loss 0.02361882 - samples/sec: 240.66 - lr: 0.025000\n",
            "2022-10-03 19:07:37,328 epoch 48 - iter 160/209 - loss 0.02322118 - samples/sec: 272.82 - lr: 0.025000\n",
            "2022-10-03 19:07:40,383 epoch 48 - iter 180/209 - loss 0.02333524 - samples/sec: 209.79 - lr: 0.025000\n",
            "2022-10-03 19:07:42,672 epoch 48 - iter 200/209 - loss 0.02309496 - samples/sec: 280.04 - lr: 0.025000\n",
            "2022-10-03 19:07:43,638 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:07:43,640 EPOCH 48 done: loss 0.0229 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:07:50,510 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:07:50,524 DEV : loss 0.03494102135300636 - f1-score (micro avg)  0.8774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:07:50,585 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 19:07:50,589 saving best model\n",
            "2022-10-03 19:07:53,373 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:07:56,031 epoch 49 - iter 20/209 - loss 0.02246136 - samples/sec: 241.25 - lr: 0.025000\n",
            "2022-10-03 19:07:58,059 epoch 49 - iter 40/209 - loss 0.02835828 - samples/sec: 316.27 - lr: 0.025000\n",
            "2022-10-03 19:08:00,822 epoch 49 - iter 60/209 - loss 0.02661774 - samples/sec: 232.01 - lr: 0.025000\n",
            "2022-10-03 19:08:03,338 epoch 49 - iter 80/209 - loss 0.02440317 - samples/sec: 254.81 - lr: 0.025000\n",
            "2022-10-03 19:08:06,415 epoch 49 - iter 100/209 - loss 0.02353666 - samples/sec: 208.48 - lr: 0.025000\n",
            "2022-10-03 19:08:08,837 epoch 49 - iter 120/209 - loss 0.02309499 - samples/sec: 264.74 - lr: 0.025000\n",
            "2022-10-03 19:08:11,197 epoch 49 - iter 140/209 - loss 0.02296278 - samples/sec: 271.71 - lr: 0.025000\n",
            "2022-10-03 19:08:13,291 epoch 49 - iter 160/209 - loss 0.02281397 - samples/sec: 306.28 - lr: 0.025000\n",
            "2022-10-03 19:08:15,684 epoch 49 - iter 180/209 - loss 0.02318597 - samples/sec: 267.96 - lr: 0.025000\n",
            "2022-10-03 19:08:18,449 epoch 49 - iter 200/209 - loss 0.02363920 - samples/sec: 231.82 - lr: 0.025000\n",
            "2022-10-03 19:08:19,663 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:08:19,666 EPOCH 49 done: loss 0.0235 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:08:26,275 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:08:26,289 DEV : loss 0.035118408501148224 - f1-score (micro avg)  0.8643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:08:26,350 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:08:26,357 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:08:28,849 epoch 50 - iter 20/209 - loss 0.01987740 - samples/sec: 257.28 - lr: 0.025000\n",
            "2022-10-03 19:08:31,090 epoch 50 - iter 40/209 - loss 0.01972687 - samples/sec: 286.14 - lr: 0.025000\n",
            "2022-10-03 19:08:33,703 epoch 50 - iter 60/209 - loss 0.01974508 - samples/sec: 245.41 - lr: 0.025000\n",
            "2022-10-03 19:08:36,085 epoch 50 - iter 80/209 - loss 0.02078722 - samples/sec: 269.09 - lr: 0.025000\n",
            "2022-10-03 19:08:38,525 epoch 50 - iter 100/209 - loss 0.02091209 - samples/sec: 262.72 - lr: 0.025000\n",
            "2022-10-03 19:08:40,719 epoch 50 - iter 120/209 - loss 0.02140482 - samples/sec: 292.32 - lr: 0.025000\n",
            "2022-10-03 19:08:43,369 epoch 50 - iter 140/209 - loss 0.02160555 - samples/sec: 241.93 - lr: 0.025000\n",
            "2022-10-03 19:08:45,364 epoch 50 - iter 160/209 - loss 0.02137551 - samples/sec: 321.43 - lr: 0.025000\n",
            "2022-10-03 19:08:48,388 epoch 50 - iter 180/209 - loss 0.02147997 - samples/sec: 211.92 - lr: 0.025000\n",
            "2022-10-03 19:08:50,780 epoch 50 - iter 200/209 - loss 0.02168030 - samples/sec: 267.99 - lr: 0.025000\n",
            "2022-10-03 19:08:51,483 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:08:51,484 EPOCH 50 done: loss 0.0215 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:08:58,312 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:08:58,327 DEV : loss 0.035399846732616425 - f1-score (micro avg)  0.8716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:08:58,392 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 19:08:58,398 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:09:00,569 epoch 51 - iter 20/209 - loss 0.02495955 - samples/sec: 295.67 - lr: 0.025000\n",
            "2022-10-03 19:09:02,996 epoch 51 - iter 40/209 - loss 0.02152705 - samples/sec: 264.19 - lr: 0.025000\n",
            "2022-10-03 19:09:05,367 epoch 51 - iter 60/209 - loss 0.02577160 - samples/sec: 270.39 - lr: 0.025000\n",
            "2022-10-03 19:09:07,621 epoch 51 - iter 80/209 - loss 0.02370978 - samples/sec: 284.41 - lr: 0.025000\n",
            "2022-10-03 19:09:10,065 epoch 51 - iter 100/209 - loss 0.02404241 - samples/sec: 262.34 - lr: 0.025000\n",
            "2022-10-03 19:09:12,613 epoch 51 - iter 120/209 - loss 0.02337208 - samples/sec: 251.53 - lr: 0.025000\n",
            "2022-10-03 19:09:14,722 epoch 51 - iter 140/209 - loss 0.02257906 - samples/sec: 304.03 - lr: 0.025000\n",
            "2022-10-03 19:09:17,627 epoch 51 - iter 160/209 - loss 0.02300082 - samples/sec: 220.55 - lr: 0.025000\n",
            "2022-10-03 19:09:20,219 epoch 51 - iter 180/209 - loss 0.02269472 - samples/sec: 247.27 - lr: 0.025000\n",
            "2022-10-03 19:09:22,475 epoch 51 - iter 200/209 - loss 0.02280801 - samples/sec: 284.24 - lr: 0.025000\n",
            "2022-10-03 19:09:23,354 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:09:23,356 EPOCH 51 done: loss 0.0235 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:09:29,918 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:09:29,932 DEV : loss 0.035587798804044724 - f1-score (micro avg)  0.8635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:09:29,994 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 19:09:29,998 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:09:31,961 epoch 52 - iter 20/209 - loss 0.02417430 - samples/sec: 326.84 - lr: 0.025000\n",
            "2022-10-03 19:09:34,691 epoch 52 - iter 40/209 - loss 0.02565059 - samples/sec: 234.78 - lr: 0.025000\n",
            "2022-10-03 19:09:37,103 epoch 52 - iter 60/209 - loss 0.02331609 - samples/sec: 265.82 - lr: 0.025000\n",
            "2022-10-03 19:09:39,697 epoch 52 - iter 80/209 - loss 0.02381603 - samples/sec: 247.11 - lr: 0.025000\n",
            "2022-10-03 19:09:42,219 epoch 52 - iter 100/209 - loss 0.02268180 - samples/sec: 254.14 - lr: 0.025000\n",
            "2022-10-03 19:09:44,640 epoch 52 - iter 120/209 - loss 0.02148553 - samples/sec: 264.78 - lr: 0.025000\n",
            "2022-10-03 19:09:47,042 epoch 52 - iter 140/209 - loss 0.02089275 - samples/sec: 267.01 - lr: 0.025000\n",
            "2022-10-03 19:09:49,412 epoch 52 - iter 160/209 - loss 0.02111722 - samples/sec: 270.51 - lr: 0.025000\n",
            "2022-10-03 19:09:51,221 epoch 52 - iter 180/209 - loss 0.02142116 - samples/sec: 354.63 - lr: 0.025000\n",
            "2022-10-03 19:09:53,471 epoch 52 - iter 200/209 - loss 0.02175667 - samples/sec: 284.98 - lr: 0.025000\n",
            "2022-10-03 19:09:55,036 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:09:55,038 EPOCH 52 done: loss 0.0214 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:10:01,708 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:10:01,726 DEV : loss 0.036509983241558075 - f1-score (micro avg)  0.8729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:10:01,788 Epoch    52: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2022-10-03 19:10:01,790 BAD EPOCHS (no improvement): 4\n",
            "2022-10-03 19:10:01,796 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:10:04,378 epoch 53 - iter 20/209 - loss 0.02399334 - samples/sec: 248.37 - lr: 0.012500\n",
            "2022-10-03 19:10:06,814 epoch 53 - iter 40/209 - loss 0.02144920 - samples/sec: 263.14 - lr: 0.012500\n",
            "2022-10-03 19:10:09,345 epoch 53 - iter 60/209 - loss 0.01876152 - samples/sec: 253.32 - lr: 0.012500\n",
            "2022-10-03 19:10:11,594 epoch 53 - iter 80/209 - loss 0.01835339 - samples/sec: 285.07 - lr: 0.012500\n",
            "2022-10-03 19:10:13,833 epoch 53 - iter 100/209 - loss 0.01876080 - samples/sec: 286.40 - lr: 0.012500\n",
            "2022-10-03 19:10:16,273 epoch 53 - iter 120/209 - loss 0.01943931 - samples/sec: 262.77 - lr: 0.012500\n",
            "2022-10-03 19:10:18,693 epoch 53 - iter 140/209 - loss 0.01932565 - samples/sec: 264.84 - lr: 0.012500\n",
            "2022-10-03 19:10:20,803 epoch 53 - iter 160/209 - loss 0.01951025 - samples/sec: 303.94 - lr: 0.012500\n",
            "2022-10-03 19:10:22,972 epoch 53 - iter 180/209 - loss 0.02013798 - samples/sec: 295.70 - lr: 0.012500\n",
            "2022-10-03 19:10:25,522 epoch 53 - iter 200/209 - loss 0.02053402 - samples/sec: 251.40 - lr: 0.012500\n",
            "2022-10-03 19:10:26,523 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:10:26,525 EPOCH 53 done: loss 0.0205 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:10:33,241 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:10:33,255 DEV : loss 0.034630678594112396 - f1-score (micro avg)  0.8679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:10:33,317 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:10:33,321 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:10:35,671 epoch 54 - iter 20/209 - loss 0.01341939 - samples/sec: 272.92 - lr: 0.012500\n",
            "2022-10-03 19:10:38,662 epoch 54 - iter 40/209 - loss 0.01637549 - samples/sec: 214.34 - lr: 0.012500\n",
            "2022-10-03 19:10:41,116 epoch 54 - iter 60/209 - loss 0.01717534 - samples/sec: 261.22 - lr: 0.012500\n",
            "2022-10-03 19:10:43,568 epoch 54 - iter 80/209 - loss 0.01802383 - samples/sec: 261.51 - lr: 0.012500\n",
            "2022-10-03 19:10:45,534 epoch 54 - iter 100/209 - loss 0.01855165 - samples/sec: 326.19 - lr: 0.012500\n",
            "2022-10-03 19:10:48,344 epoch 54 - iter 120/209 - loss 0.02037558 - samples/sec: 228.10 - lr: 0.012500\n",
            "2022-10-03 19:10:50,700 epoch 54 - iter 140/209 - loss 0.02030548 - samples/sec: 272.18 - lr: 0.012500\n",
            "2022-10-03 19:10:52,886 epoch 54 - iter 160/209 - loss 0.02062239 - samples/sec: 293.31 - lr: 0.012500\n",
            "2022-10-03 19:10:55,118 epoch 54 - iter 180/209 - loss 0.02014013 - samples/sec: 287.17 - lr: 0.012500\n",
            "2022-10-03 19:10:57,379 epoch 54 - iter 200/209 - loss 0.02114763 - samples/sec: 283.66 - lr: 0.012500\n",
            "2022-10-03 19:10:58,331 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:10:58,333 EPOCH 54 done: loss 0.0209 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:07<00:00,  6.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:11:05,357 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:11:05,371 DEV : loss 0.03396720439195633 - f1-score (micro avg)  0.8711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:11:05,431 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 19:11:05,442 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:11:08,161 epoch 55 - iter 20/209 - loss 0.01578634 - samples/sec: 235.83 - lr: 0.012500\n",
            "2022-10-03 19:11:10,985 epoch 55 - iter 40/209 - loss 0.01966757 - samples/sec: 226.93 - lr: 0.012500\n",
            "2022-10-03 19:11:13,273 epoch 55 - iter 60/209 - loss 0.01868557 - samples/sec: 280.17 - lr: 0.012500\n",
            "2022-10-03 19:11:15,623 epoch 55 - iter 80/209 - loss 0.01781036 - samples/sec: 272.84 - lr: 0.012500\n",
            "2022-10-03 19:11:17,593 epoch 55 - iter 100/209 - loss 0.01921116 - samples/sec: 325.53 - lr: 0.012500\n",
            "2022-10-03 19:11:19,901 epoch 55 - iter 120/209 - loss 0.01898954 - samples/sec: 277.90 - lr: 0.012500\n",
            "2022-10-03 19:11:22,213 epoch 55 - iter 140/209 - loss 0.02014739 - samples/sec: 277.34 - lr: 0.012500\n",
            "2022-10-03 19:11:24,302 epoch 55 - iter 160/209 - loss 0.01961584 - samples/sec: 306.88 - lr: 0.012500\n",
            "2022-10-03 19:11:26,865 epoch 55 - iter 180/209 - loss 0.01957830 - samples/sec: 250.13 - lr: 0.012500\n",
            "2022-10-03 19:11:28,952 epoch 55 - iter 200/209 - loss 0.01989057 - samples/sec: 307.22 - lr: 0.012500\n",
            "2022-10-03 19:11:29,686 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:11:29,688 EPOCH 55 done: loss 0.0200 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:11:36,346 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:11:36,362 DEV : loss 0.034209948033094406 - f1-score (micro avg)  0.8749\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:11:36,426 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 19:11:36,430 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:11:39,046 epoch 56 - iter 20/209 - loss 0.01643525 - samples/sec: 245.20 - lr: 0.012500\n",
            "2022-10-03 19:11:41,552 epoch 56 - iter 40/209 - loss 0.01650752 - samples/sec: 255.81 - lr: 0.012500\n",
            "2022-10-03 19:11:43,440 epoch 56 - iter 60/209 - loss 0.01781854 - samples/sec: 339.74 - lr: 0.012500\n",
            "2022-10-03 19:11:46,195 epoch 56 - iter 80/209 - loss 0.01813378 - samples/sec: 232.68 - lr: 0.012500\n",
            "2022-10-03 19:11:48,281 epoch 56 - iter 100/209 - loss 0.01822422 - samples/sec: 307.42 - lr: 0.012500\n",
            "2022-10-03 19:11:51,016 epoch 56 - iter 120/209 - loss 0.01825890 - samples/sec: 234.35 - lr: 0.012500\n",
            "2022-10-03 19:11:53,096 epoch 56 - iter 140/209 - loss 0.01777448 - samples/sec: 308.38 - lr: 0.012500\n",
            "2022-10-03 19:11:55,968 epoch 56 - iter 160/209 - loss 0.01860373 - samples/sec: 223.06 - lr: 0.012500\n",
            "2022-10-03 19:11:58,268 epoch 56 - iter 180/209 - loss 0.01954934 - samples/sec: 278.84 - lr: 0.012500\n",
            "2022-10-03 19:12:00,401 epoch 56 - iter 200/209 - loss 0.01997459 - samples/sec: 300.47 - lr: 0.012500\n",
            "2022-10-03 19:12:01,316 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:12:01,318 EPOCH 56 done: loss 0.0199 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:07<00:00,  6.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:12:08,503 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:12:08,518 DEV : loss 0.03512508049607277 - f1-score (micro avg)  0.8697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:12:08,581 Epoch    56: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2022-10-03 19:12:08,583 BAD EPOCHS (no improvement): 4\n",
            "2022-10-03 19:12:08,590 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:12:11,049 epoch 57 - iter 20/209 - loss 0.01980101 - samples/sec: 260.80 - lr: 0.006250\n",
            "2022-10-03 19:12:13,364 epoch 57 - iter 40/209 - loss 0.02146163 - samples/sec: 276.95 - lr: 0.006250\n",
            "2022-10-03 19:12:15,347 epoch 57 - iter 60/209 - loss 0.02256366 - samples/sec: 323.40 - lr: 0.006250\n",
            "2022-10-03 19:12:18,309 epoch 57 - iter 80/209 - loss 0.02139072 - samples/sec: 216.42 - lr: 0.006250\n",
            "2022-10-03 19:12:20,660 epoch 57 - iter 100/209 - loss 0.02158705 - samples/sec: 272.64 - lr: 0.006250\n",
            "2022-10-03 19:12:23,019 epoch 57 - iter 120/209 - loss 0.02139961 - samples/sec: 271.77 - lr: 0.006250\n",
            "2022-10-03 19:12:25,466 epoch 57 - iter 140/209 - loss 0.02058319 - samples/sec: 262.07 - lr: 0.006250\n",
            "2022-10-03 19:12:27,741 epoch 57 - iter 160/209 - loss 0.02099224 - samples/sec: 281.81 - lr: 0.006250\n",
            "2022-10-03 19:12:30,168 epoch 57 - iter 180/209 - loss 0.02065146 - samples/sec: 264.14 - lr: 0.006250\n",
            "2022-10-03 19:12:32,082 epoch 57 - iter 200/209 - loss 0.02076252 - samples/sec: 335.24 - lr: 0.006250\n",
            "2022-10-03 19:12:33,098 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:12:33,101 EPOCH 57 done: loss 0.0208 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:12:39,744 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:12:39,759 DEV : loss 0.035065241158008575 - f1-score (micro avg)  0.8704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:12:39,819 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:12:39,824 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:12:42,197 epoch 58 - iter 20/209 - loss 0.02111709 - samples/sec: 270.37 - lr: 0.006250\n",
            "2022-10-03 19:12:45,193 epoch 58 - iter 40/209 - loss 0.02369031 - samples/sec: 213.94 - lr: 0.006250\n",
            "2022-10-03 19:12:46,955 epoch 58 - iter 60/209 - loss 0.02213122 - samples/sec: 364.10 - lr: 0.006250\n",
            "2022-10-03 19:12:49,482 epoch 58 - iter 80/209 - loss 0.02033665 - samples/sec: 253.61 - lr: 0.006250\n",
            "2022-10-03 19:12:52,144 epoch 58 - iter 100/209 - loss 0.02028090 - samples/sec: 240.83 - lr: 0.006250\n",
            "2022-10-03 19:12:54,365 epoch 58 - iter 120/209 - loss 0.02112618 - samples/sec: 288.71 - lr: 0.006250\n",
            "2022-10-03 19:12:56,739 epoch 58 - iter 140/209 - loss 0.02171642 - samples/sec: 270.00 - lr: 0.006250\n",
            "2022-10-03 19:12:59,316 epoch 58 - iter 160/209 - loss 0.02095216 - samples/sec: 248.72 - lr: 0.006250\n",
            "2022-10-03 19:13:01,446 epoch 58 - iter 180/209 - loss 0.02051791 - samples/sec: 301.13 - lr: 0.006250\n",
            "2022-10-03 19:13:03,399 epoch 58 - iter 200/209 - loss 0.02076977 - samples/sec: 328.22 - lr: 0.006250\n",
            "2022-10-03 19:13:04,304 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:13:04,306 EPOCH 58 done: loss 0.0206 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:13:10,925 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:13:10,939 DEV : loss 0.03536901995539665 - f1-score (micro avg)  0.8754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:13:11,000 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 19:13:11,004 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:13:13,703 epoch 59 - iter 20/209 - loss 0.02152230 - samples/sec: 237.64 - lr: 0.006250\n",
            "2022-10-03 19:13:16,058 epoch 59 - iter 40/209 - loss 0.01760568 - samples/sec: 272.25 - lr: 0.006250\n",
            "2022-10-03 19:13:18,563 epoch 59 - iter 60/209 - loss 0.01822673 - samples/sec: 255.91 - lr: 0.006250\n",
            "2022-10-03 19:13:20,670 epoch 59 - iter 80/209 - loss 0.01938733 - samples/sec: 304.34 - lr: 0.006250\n",
            "2022-10-03 19:13:23,007 epoch 59 - iter 100/209 - loss 0.01913116 - samples/sec: 274.35 - lr: 0.006250\n",
            "2022-10-03 19:13:25,944 epoch 59 - iter 120/209 - loss 0.01930495 - samples/sec: 218.21 - lr: 0.006250\n",
            "2022-10-03 19:13:28,267 epoch 59 - iter 140/209 - loss 0.01980231 - samples/sec: 276.07 - lr: 0.006250\n",
            "2022-10-03 19:13:30,547 epoch 59 - iter 160/209 - loss 0.01962202 - samples/sec: 281.26 - lr: 0.006250\n",
            "2022-10-03 19:13:33,219 epoch 59 - iter 180/209 - loss 0.01954616 - samples/sec: 239.82 - lr: 0.006250\n",
            "2022-10-03 19:13:35,425 epoch 59 - iter 200/209 - loss 0.01985264 - samples/sec: 290.69 - lr: 0.006250\n",
            "2022-10-03 19:13:36,389 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:13:36,392 EPOCH 59 done: loss 0.0202 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:13:42,983 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:13:42,998 DEV : loss 0.03492897003889084 - f1-score (micro avg)  0.875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:13:43,059 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 19:13:43,064 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:13:45,392 epoch 60 - iter 20/209 - loss 0.02293606 - samples/sec: 275.53 - lr: 0.006250\n",
            "2022-10-03 19:13:47,709 epoch 60 - iter 40/209 - loss 0.02144036 - samples/sec: 276.75 - lr: 0.006250\n",
            "2022-10-03 19:13:49,835 epoch 60 - iter 60/209 - loss 0.02089450 - samples/sec: 301.64 - lr: 0.006250\n",
            "2022-10-03 19:13:52,647 epoch 60 - iter 80/209 - loss 0.02164286 - samples/sec: 227.91 - lr: 0.006250\n",
            "2022-10-03 19:13:54,923 epoch 60 - iter 100/209 - loss 0.02062991 - samples/sec: 281.67 - lr: 0.006250\n",
            "2022-10-03 19:13:57,095 epoch 60 - iter 120/209 - loss 0.01957764 - samples/sec: 295.18 - lr: 0.006250\n",
            "2022-10-03 19:13:59,496 epoch 60 - iter 140/209 - loss 0.01890808 - samples/sec: 267.00 - lr: 0.006250\n",
            "2022-10-03 19:14:01,749 epoch 60 - iter 160/209 - loss 0.01930005 - samples/sec: 284.52 - lr: 0.006250\n",
            "2022-10-03 19:14:03,701 epoch 60 - iter 180/209 - loss 0.01887521 - samples/sec: 328.58 - lr: 0.006250\n",
            "2022-10-03 19:14:06,142 epoch 60 - iter 200/209 - loss 0.01931444 - samples/sec: 262.52 - lr: 0.006250\n",
            "2022-10-03 19:14:07,305 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:14:07,308 EPOCH 60 done: loss 0.0193 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:14:13,834 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:14:13,847 DEV : loss 0.0348680317401886 - f1-score (micro avg)  0.874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:14:13,907 Epoch    60: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2022-10-03 19:14:13,909 BAD EPOCHS (no improvement): 4\n",
            "2022-10-03 19:14:13,914 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:14:15,973 epoch 61 - iter 20/209 - loss 0.02414530 - samples/sec: 311.61 - lr: 0.003125\n",
            "2022-10-03 19:14:17,981 epoch 61 - iter 40/209 - loss 0.01924958 - samples/sec: 319.48 - lr: 0.003125\n",
            "2022-10-03 19:14:20,711 epoch 61 - iter 60/209 - loss 0.01916045 - samples/sec: 234.76 - lr: 0.003125\n",
            "2022-10-03 19:14:23,246 epoch 61 - iter 80/209 - loss 0.01844401 - samples/sec: 252.88 - lr: 0.003125\n",
            "2022-10-03 19:14:25,427 epoch 61 - iter 100/209 - loss 0.01858065 - samples/sec: 293.96 - lr: 0.003125\n",
            "2022-10-03 19:14:27,737 epoch 61 - iter 120/209 - loss 0.01837066 - samples/sec: 277.63 - lr: 0.003125\n",
            "2022-10-03 19:14:30,600 epoch 61 - iter 140/209 - loss 0.01929522 - samples/sec: 223.88 - lr: 0.003125\n",
            "2022-10-03 19:14:32,491 epoch 61 - iter 160/209 - loss 0.01979341 - samples/sec: 339.03 - lr: 0.003125\n",
            "2022-10-03 19:14:35,181 epoch 61 - iter 180/209 - loss 0.01965928 - samples/sec: 238.28 - lr: 0.003125\n",
            "2022-10-03 19:14:37,352 epoch 61 - iter 200/209 - loss 0.01924573 - samples/sec: 295.31 - lr: 0.003125\n",
            "2022-10-03 19:14:38,302 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:14:38,303 EPOCH 61 done: loss 0.0194 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:14:44,941 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:14:44,957 DEV : loss 0.03488953039050102 - f1-score (micro avg)  0.8742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:14:45,015 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:14:45,021 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:14:47,415 epoch 62 - iter 20/209 - loss 0.01181098 - samples/sec: 268.11 - lr: 0.003125\n",
            "2022-10-03 19:14:49,787 epoch 62 - iter 40/209 - loss 0.01293157 - samples/sec: 270.34 - lr: 0.003125\n",
            "2022-10-03 19:14:52,062 epoch 62 - iter 60/209 - loss 0.01394274 - samples/sec: 281.79 - lr: 0.003125\n",
            "2022-10-03 19:14:54,249 epoch 62 - iter 80/209 - loss 0.01385399 - samples/sec: 293.17 - lr: 0.003125\n",
            "2022-10-03 19:14:56,250 epoch 62 - iter 100/209 - loss 0.01568637 - samples/sec: 320.49 - lr: 0.003125\n",
            "2022-10-03 19:14:58,237 epoch 62 - iter 120/209 - loss 0.01746889 - samples/sec: 322.95 - lr: 0.003125\n",
            "2022-10-03 19:15:00,900 epoch 62 - iter 140/209 - loss 0.01841341 - samples/sec: 240.72 - lr: 0.003125\n",
            "2022-10-03 19:15:03,099 epoch 62 - iter 160/209 - loss 0.01827288 - samples/sec: 291.61 - lr: 0.003125\n",
            "2022-10-03 19:15:05,483 epoch 62 - iter 180/209 - loss 0.01877228 - samples/sec: 268.95 - lr: 0.003125\n",
            "2022-10-03 19:15:08,345 epoch 62 - iter 200/209 - loss 0.01818892 - samples/sec: 223.90 - lr: 0.003125\n",
            "2022-10-03 19:15:09,391 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:15:09,393 EPOCH 62 done: loss 0.0184 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:15:15,945 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:15:15,959 DEV : loss 0.034764859825372696 - f1-score (micro avg)  0.8717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:15:16,021 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 19:15:16,025 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:15:18,188 epoch 63 - iter 20/209 - loss 0.01996152 - samples/sec: 296.63 - lr: 0.003125\n",
            "2022-10-03 19:15:20,645 epoch 63 - iter 40/209 - loss 0.01863588 - samples/sec: 260.96 - lr: 0.003125\n",
            "2022-10-03 19:15:23,793 epoch 63 - iter 60/209 - loss 0.01856509 - samples/sec: 203.57 - lr: 0.003125\n",
            "2022-10-03 19:15:25,943 epoch 63 - iter 80/209 - loss 0.01795568 - samples/sec: 298.12 - lr: 0.003125\n",
            "2022-10-03 19:15:28,079 epoch 63 - iter 100/209 - loss 0.01724804 - samples/sec: 300.21 - lr: 0.003125\n",
            "2022-10-03 19:15:29,886 epoch 63 - iter 120/209 - loss 0.01743796 - samples/sec: 354.84 - lr: 0.003125\n",
            "2022-10-03 19:15:32,655 epoch 63 - iter 140/209 - loss 0.01787550 - samples/sec: 231.53 - lr: 0.003125\n",
            "2022-10-03 19:15:34,635 epoch 63 - iter 160/209 - loss 0.01801099 - samples/sec: 323.87 - lr: 0.003125\n",
            "2022-10-03 19:15:36,661 epoch 63 - iter 180/209 - loss 0.01839998 - samples/sec: 316.59 - lr: 0.003125\n",
            "2022-10-03 19:15:39,000 epoch 63 - iter 200/209 - loss 0.01911775 - samples/sec: 274.12 - lr: 0.003125\n",
            "2022-10-03 19:15:40,085 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:15:40,087 EPOCH 63 done: loss 0.0189 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:15:47,048 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:15:47,062 DEV : loss 0.03489621728658676 - f1-score (micro avg)  0.8798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:15:47,122 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 19:15:47,130 saving best model\n",
            "2022-10-03 19:15:49,853 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:15:52,204 epoch 64 - iter 20/209 - loss 0.01578349 - samples/sec: 272.90 - lr: 0.003125\n",
            "2022-10-03 19:15:54,328 epoch 64 - iter 40/209 - loss 0.01531008 - samples/sec: 301.89 - lr: 0.003125\n",
            "2022-10-03 19:15:56,914 epoch 64 - iter 60/209 - loss 0.01537041 - samples/sec: 247.93 - lr: 0.003125\n",
            "2022-10-03 19:15:59,774 epoch 64 - iter 80/209 - loss 0.01761964 - samples/sec: 224.05 - lr: 0.003125\n",
            "2022-10-03 19:16:02,187 epoch 64 - iter 100/209 - loss 0.01901937 - samples/sec: 265.73 - lr: 0.003125\n",
            "2022-10-03 19:16:05,375 epoch 64 - iter 120/209 - loss 0.01905087 - samples/sec: 201.00 - lr: 0.003125\n",
            "2022-10-03 19:16:07,668 epoch 64 - iter 140/209 - loss 0.01832486 - samples/sec: 279.57 - lr: 0.003125\n",
            "2022-10-03 19:16:09,719 epoch 64 - iter 160/209 - loss 0.01858781 - samples/sec: 312.69 - lr: 0.003125\n",
            "2022-10-03 19:16:12,182 epoch 64 - iter 180/209 - loss 0.01879785 - samples/sec: 260.37 - lr: 0.003125\n",
            "2022-10-03 19:16:14,407 epoch 64 - iter 200/209 - loss 0.01990943 - samples/sec: 288.16 - lr: 0.003125\n",
            "2022-10-03 19:16:15,451 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:16:15,453 EPOCH 64 done: loss 0.0199 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:16:22,020 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:16:22,037 DEV : loss 0.034771960228681564 - f1-score (micro avg)  0.8778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:16:22,097 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:16:22,102 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:16:24,501 epoch 65 - iter 20/209 - loss 0.01821296 - samples/sec: 267.35 - lr: 0.003125\n",
            "2022-10-03 19:16:26,919 epoch 65 - iter 40/209 - loss 0.01808091 - samples/sec: 265.17 - lr: 0.003125\n",
            "2022-10-03 19:16:29,023 epoch 65 - iter 60/209 - loss 0.01987660 - samples/sec: 304.75 - lr: 0.003125\n",
            "2022-10-03 19:16:31,425 epoch 65 - iter 80/209 - loss 0.02063004 - samples/sec: 266.84 - lr: 0.003125\n",
            "2022-10-03 19:16:33,821 epoch 65 - iter 100/209 - loss 0.02091067 - samples/sec: 267.55 - lr: 0.003125\n",
            "2022-10-03 19:16:36,045 epoch 65 - iter 120/209 - loss 0.02004083 - samples/sec: 288.40 - lr: 0.003125\n",
            "2022-10-03 19:16:38,379 epoch 65 - iter 140/209 - loss 0.01931386 - samples/sec: 274.62 - lr: 0.003125\n",
            "2022-10-03 19:16:40,381 epoch 65 - iter 160/209 - loss 0.01928993 - samples/sec: 320.29 - lr: 0.003125\n",
            "2022-10-03 19:16:42,926 epoch 65 - iter 180/209 - loss 0.01951987 - samples/sec: 251.90 - lr: 0.003125\n",
            "2022-10-03 19:16:45,403 epoch 65 - iter 200/209 - loss 0.01962988 - samples/sec: 258.84 - lr: 0.003125\n",
            "2022-10-03 19:16:46,589 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:16:46,591 EPOCH 65 done: loss 0.0194 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:16:53,553 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:16:53,568 DEV : loss 0.034869417548179626 - f1-score (micro avg)  0.8752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:16:53,628 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 19:16:53,634 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:16:55,907 epoch 66 - iter 20/209 - loss 0.01491423 - samples/sec: 282.30 - lr: 0.003125\n",
            "2022-10-03 19:16:58,260 epoch 66 - iter 40/209 - loss 0.01778867 - samples/sec: 272.48 - lr: 0.003125\n",
            "2022-10-03 19:17:00,450 epoch 66 - iter 60/209 - loss 0.01876415 - samples/sec: 292.83 - lr: 0.003125\n",
            "2022-10-03 19:17:02,870 epoch 66 - iter 80/209 - loss 0.01845549 - samples/sec: 264.89 - lr: 0.003125\n",
            "2022-10-03 19:17:05,136 epoch 66 - iter 100/209 - loss 0.01966041 - samples/sec: 282.86 - lr: 0.003125\n",
            "2022-10-03 19:17:07,282 epoch 66 - iter 120/209 - loss 0.01956874 - samples/sec: 298.86 - lr: 0.003125\n",
            "2022-10-03 19:17:09,608 epoch 66 - iter 140/209 - loss 0.01902105 - samples/sec: 275.54 - lr: 0.003125\n",
            "2022-10-03 19:17:11,902 epoch 66 - iter 160/209 - loss 0.01868922 - samples/sec: 279.53 - lr: 0.003125\n",
            "2022-10-03 19:17:14,934 epoch 66 - iter 180/209 - loss 0.01852954 - samples/sec: 211.30 - lr: 0.003125\n",
            "2022-10-03 19:17:17,315 epoch 66 - iter 200/209 - loss 0.01846892 - samples/sec: 269.34 - lr: 0.003125\n",
            "2022-10-03 19:17:18,262 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:17:18,264 EPOCH 66 done: loss 0.0186 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:17:24,876 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:17:24,890 DEV : loss 0.03478711098432541 - f1-score (micro avg)  0.8762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:17:24,959 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 19:17:24,963 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:17:27,481 epoch 67 - iter 20/209 - loss 0.01396055 - samples/sec: 254.74 - lr: 0.003125\n",
            "2022-10-03 19:17:29,768 epoch 67 - iter 40/209 - loss 0.02044204 - samples/sec: 280.36 - lr: 0.003125\n",
            "2022-10-03 19:17:32,538 epoch 67 - iter 60/209 - loss 0.01863545 - samples/sec: 231.40 - lr: 0.003125\n",
            "2022-10-03 19:17:34,507 epoch 67 - iter 80/209 - loss 0.01711628 - samples/sec: 325.58 - lr: 0.003125\n",
            "2022-10-03 19:17:36,401 epoch 67 - iter 100/209 - loss 0.01870816 - samples/sec: 338.62 - lr: 0.003125\n",
            "2022-10-03 19:17:38,755 epoch 67 - iter 120/209 - loss 0.01784488 - samples/sec: 272.30 - lr: 0.003125\n",
            "2022-10-03 19:17:41,339 epoch 67 - iter 140/209 - loss 0.01762153 - samples/sec: 248.05 - lr: 0.003125\n",
            "2022-10-03 19:17:43,483 epoch 67 - iter 160/209 - loss 0.01878138 - samples/sec: 298.97 - lr: 0.003125\n",
            "2022-10-03 19:17:46,052 epoch 67 - iter 180/209 - loss 0.01891868 - samples/sec: 249.50 - lr: 0.003125\n",
            "2022-10-03 19:17:48,484 epoch 67 - iter 200/209 - loss 0.01936779 - samples/sec: 263.51 - lr: 0.003125\n",
            "2022-10-03 19:17:49,164 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:17:49,166 EPOCH 67 done: loss 0.0193 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:17:55,978 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:17:55,991 DEV : loss 0.035082440823316574 - f1-score (micro avg)  0.8762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:17:56,052 Epoch    67: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2022-10-03 19:17:56,053 BAD EPOCHS (no improvement): 4\n",
            "2022-10-03 19:17:56,061 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:17:58,786 epoch 68 - iter 20/209 - loss 0.01963565 - samples/sec: 235.47 - lr: 0.001563\n",
            "2022-10-03 19:18:00,899 epoch 68 - iter 40/209 - loss 0.01923029 - samples/sec: 303.38 - lr: 0.001563\n",
            "2022-10-03 19:18:02,951 epoch 68 - iter 60/209 - loss 0.01937616 - samples/sec: 312.40 - lr: 0.001563\n",
            "2022-10-03 19:18:05,141 epoch 68 - iter 80/209 - loss 0.01897040 - samples/sec: 292.69 - lr: 0.001563\n",
            "2022-10-03 19:18:07,378 epoch 68 - iter 100/209 - loss 0.01842393 - samples/sec: 286.60 - lr: 0.001563\n",
            "2022-10-03 19:18:09,745 epoch 68 - iter 120/209 - loss 0.01807717 - samples/sec: 270.67 - lr: 0.001563\n",
            "2022-10-03 19:18:11,845 epoch 68 - iter 140/209 - loss 0.01798271 - samples/sec: 305.26 - lr: 0.001563\n",
            "2022-10-03 19:18:14,229 epoch 68 - iter 160/209 - loss 0.01812361 - samples/sec: 268.89 - lr: 0.001563\n",
            "2022-10-03 19:18:16,275 epoch 68 - iter 180/209 - loss 0.01801524 - samples/sec: 313.24 - lr: 0.001563\n",
            "2022-10-03 19:18:18,940 epoch 68 - iter 200/209 - loss 0.01841856 - samples/sec: 240.48 - lr: 0.001563\n",
            "2022-10-03 19:18:19,764 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:18:19,766 EPOCH 68 done: loss 0.0183 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  7.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:18:26,214 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:18:26,228 DEV : loss 0.03492031991481781 - f1-score (micro avg)  0.8762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:18:26,288 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:18:26,292 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:18:28,589 epoch 69 - iter 20/209 - loss 0.01519404 - samples/sec: 279.37 - lr: 0.001563\n",
            "2022-10-03 19:18:30,567 epoch 69 - iter 40/209 - loss 0.01819276 - samples/sec: 324.08 - lr: 0.001563\n",
            "2022-10-03 19:18:32,976 epoch 69 - iter 60/209 - loss 0.01884177 - samples/sec: 266.12 - lr: 0.001563\n",
            "2022-10-03 19:18:35,591 epoch 69 - iter 80/209 - loss 0.01888207 - samples/sec: 245.01 - lr: 0.001563\n",
            "2022-10-03 19:18:38,326 epoch 69 - iter 100/209 - loss 0.02009867 - samples/sec: 234.34 - lr: 0.001563\n",
            "2022-10-03 19:18:40,521 epoch 69 - iter 120/209 - loss 0.02020916 - samples/sec: 292.01 - lr: 0.001563\n",
            "2022-10-03 19:18:42,624 epoch 69 - iter 140/209 - loss 0.01910118 - samples/sec: 304.89 - lr: 0.001563\n",
            "2022-10-03 19:18:44,702 epoch 69 - iter 160/209 - loss 0.01879652 - samples/sec: 308.62 - lr: 0.001563\n",
            "2022-10-03 19:18:46,796 epoch 69 - iter 180/209 - loss 0.01960069 - samples/sec: 306.04 - lr: 0.001563\n",
            "2022-10-03 19:18:49,087 epoch 69 - iter 200/209 - loss 0.01898844 - samples/sec: 279.86 - lr: 0.001563\n",
            "2022-10-03 19:18:50,208 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:18:50,210 EPOCH 69 done: loss 0.0189 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  7.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:18:56,572 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:18:56,586 DEV : loss 0.03477175906300545 - f1-score (micro avg)  0.8806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:18:56,645 BAD EPOCHS (no improvement): 0\n",
            "2022-10-03 19:18:56,649 saving best model\n",
            "2022-10-03 19:18:59,465 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:19:01,969 epoch 70 - iter 20/209 - loss 0.01711614 - samples/sec: 256.15 - lr: 0.001563\n",
            "2022-10-03 19:19:04,036 epoch 70 - iter 40/209 - loss 0.01608790 - samples/sec: 310.19 - lr: 0.001563\n",
            "2022-10-03 19:19:06,042 epoch 70 - iter 60/209 - loss 0.01877522 - samples/sec: 319.60 - lr: 0.001563\n",
            "2022-10-03 19:19:09,063 epoch 70 - iter 80/209 - loss 0.01951794 - samples/sec: 212.05 - lr: 0.001563\n",
            "2022-10-03 19:19:11,505 epoch 70 - iter 100/209 - loss 0.01906754 - samples/sec: 262.48 - lr: 0.001563\n",
            "2022-10-03 19:19:14,274 epoch 70 - iter 120/209 - loss 0.01811945 - samples/sec: 231.44 - lr: 0.001563\n",
            "2022-10-03 19:19:16,622 epoch 70 - iter 140/209 - loss 0.01745468 - samples/sec: 273.06 - lr: 0.001563\n",
            "2022-10-03 19:19:19,199 epoch 70 - iter 160/209 - loss 0.01677718 - samples/sec: 248.73 - lr: 0.001563\n",
            "2022-10-03 19:19:21,398 epoch 70 - iter 180/209 - loss 0.01717816 - samples/sec: 291.64 - lr: 0.001563\n",
            "2022-10-03 19:19:23,176 epoch 70 - iter 200/209 - loss 0.01731968 - samples/sec: 360.74 - lr: 0.001563\n",
            "2022-10-03 19:19:24,232 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:19:24,234 EPOCH 70 done: loss 0.0186 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  7.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:19:30,671 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:19:30,686 DEV : loss 0.0350797101855278 - f1-score (micro avg)  0.8742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:19:30,747 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:19:30,751 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:19:32,929 epoch 71 - iter 20/209 - loss 0.02151159 - samples/sec: 294.40 - lr: 0.001563\n",
            "2022-10-03 19:19:35,430 epoch 71 - iter 40/209 - loss 0.02354236 - samples/sec: 256.37 - lr: 0.001563\n",
            "2022-10-03 19:19:37,437 epoch 71 - iter 60/209 - loss 0.02103064 - samples/sec: 319.45 - lr: 0.001563\n",
            "2022-10-03 19:19:39,769 epoch 71 - iter 80/209 - loss 0.01849395 - samples/sec: 274.87 - lr: 0.001563\n",
            "2022-10-03 19:19:41,740 epoch 71 - iter 100/209 - loss 0.01906296 - samples/sec: 325.24 - lr: 0.001563\n",
            "2022-10-03 19:19:43,719 epoch 71 - iter 120/209 - loss 0.02003465 - samples/sec: 323.96 - lr: 0.001563\n",
            "2022-10-03 19:19:45,917 epoch 71 - iter 140/209 - loss 0.01985499 - samples/sec: 291.56 - lr: 0.001563\n",
            "2022-10-03 19:19:48,290 epoch 71 - iter 160/209 - loss 0.01919267 - samples/sec: 270.30 - lr: 0.001563\n",
            "2022-10-03 19:19:50,489 epoch 71 - iter 180/209 - loss 0.01965052 - samples/sec: 291.40 - lr: 0.001563\n",
            "2022-10-03 19:19:52,578 epoch 71 - iter 200/209 - loss 0.01941323 - samples/sec: 306.89 - lr: 0.001563\n",
            "2022-10-03 19:19:54,181 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:19:54,184 EPOCH 71 done: loss 0.0195 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  7.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:20:00,635 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:20:00,649 DEV : loss 0.034917108714580536 - f1-score (micro avg)  0.875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:20:00,712 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 19:20:00,723 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:20:03,041 epoch 72 - iter 20/209 - loss 0.01946228 - samples/sec: 276.79 - lr: 0.001563\n",
            "2022-10-03 19:20:04,925 epoch 72 - iter 40/209 - loss 0.02167901 - samples/sec: 340.38 - lr: 0.001563\n",
            "2022-10-03 19:20:07,172 epoch 72 - iter 60/209 - loss 0.01904927 - samples/sec: 285.31 - lr: 0.001563\n",
            "2022-10-03 19:20:09,920 epoch 72 - iter 80/209 - loss 0.01950831 - samples/sec: 233.21 - lr: 0.001563\n",
            "2022-10-03 19:20:12,057 epoch 72 - iter 100/209 - loss 0.01887816 - samples/sec: 299.86 - lr: 0.001563\n",
            "2022-10-03 19:20:13,954 epoch 72 - iter 120/209 - loss 0.01973675 - samples/sec: 338.09 - lr: 0.001563\n",
            "2022-10-03 19:20:15,986 epoch 72 - iter 140/209 - loss 0.02005957 - samples/sec: 315.49 - lr: 0.001563\n",
            "2022-10-03 19:20:18,487 epoch 72 - iter 160/209 - loss 0.02007449 - samples/sec: 256.24 - lr: 0.001563\n",
            "2022-10-03 19:20:20,886 epoch 72 - iter 180/209 - loss 0.01922265 - samples/sec: 267.26 - lr: 0.001563\n",
            "2022-10-03 19:20:23,129 epoch 72 - iter 200/209 - loss 0.01878528 - samples/sec: 285.74 - lr: 0.001563\n",
            "2022-10-03 19:20:24,014 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:20:24,015 EPOCH 72 done: loss 0.0188 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  7.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:20:30,457 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:20:30,470 DEV : loss 0.03500644117593765 - f1-score (micro avg)  0.875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:20:30,531 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 19:20:30,538 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:20:32,420 epoch 73 - iter 20/209 - loss 0.01748658 - samples/sec: 340.88 - lr: 0.001563\n",
            "2022-10-03 19:20:34,913 epoch 73 - iter 40/209 - loss 0.01785763 - samples/sec: 257.06 - lr: 0.001563\n",
            "2022-10-03 19:20:37,414 epoch 73 - iter 60/209 - loss 0.01636475 - samples/sec: 256.19 - lr: 0.001563\n",
            "2022-10-03 19:20:39,328 epoch 73 - iter 80/209 - loss 0.01625790 - samples/sec: 335.13 - lr: 0.001563\n",
            "2022-10-03 19:20:41,779 epoch 73 - iter 100/209 - loss 0.01624215 - samples/sec: 261.55 - lr: 0.001563\n",
            "2022-10-03 19:20:43,811 epoch 73 - iter 120/209 - loss 0.01735613 - samples/sec: 315.53 - lr: 0.001563\n",
            "2022-10-03 19:20:45,821 epoch 73 - iter 140/209 - loss 0.01772073 - samples/sec: 318.90 - lr: 0.001563\n",
            "2022-10-03 19:20:47,944 epoch 73 - iter 160/209 - loss 0.01784101 - samples/sec: 301.85 - lr: 0.001563\n",
            "2022-10-03 19:20:50,975 epoch 73 - iter 180/209 - loss 0.01837764 - samples/sec: 211.36 - lr: 0.001563\n",
            "2022-10-03 19:20:53,184 epoch 73 - iter 200/209 - loss 0.01869044 - samples/sec: 290.18 - lr: 0.001563\n",
            "2022-10-03 19:20:54,048 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:20:54,049 EPOCH 73 done: loss 0.0186 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:21:00,519 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:21:00,534 DEV : loss 0.035036664456129074 - f1-score (micro avg)  0.876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:21:00,596 Epoch    73: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2022-10-03 19:21:00,597 BAD EPOCHS (no improvement): 4\n",
            "2022-10-03 19:21:00,603 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:21:03,105 epoch 74 - iter 20/209 - loss 0.02677825 - samples/sec: 256.37 - lr: 0.000781\n",
            "2022-10-03 19:21:05,130 epoch 74 - iter 40/209 - loss 0.02413203 - samples/sec: 316.49 - lr: 0.000781\n",
            "2022-10-03 19:21:07,182 epoch 74 - iter 60/209 - loss 0.02215506 - samples/sec: 312.47 - lr: 0.000781\n",
            "2022-10-03 19:21:09,531 epoch 74 - iter 80/209 - loss 0.02063176 - samples/sec: 272.93 - lr: 0.000781\n",
            "2022-10-03 19:21:12,348 epoch 74 - iter 100/209 - loss 0.01961199 - samples/sec: 227.49 - lr: 0.000781\n",
            "2022-10-03 19:21:14,424 epoch 74 - iter 120/209 - loss 0.01876651 - samples/sec: 308.78 - lr: 0.000781\n",
            "2022-10-03 19:21:16,683 epoch 74 - iter 140/209 - loss 0.01855344 - samples/sec: 283.82 - lr: 0.000781\n",
            "2022-10-03 19:21:18,894 epoch 74 - iter 160/209 - loss 0.01898857 - samples/sec: 289.87 - lr: 0.000781\n",
            "2022-10-03 19:21:20,968 epoch 74 - iter 180/209 - loss 0.01933114 - samples/sec: 308.93 - lr: 0.000781\n",
            "2022-10-03 19:21:23,043 epoch 74 - iter 200/209 - loss 0.01939904 - samples/sec: 308.94 - lr: 0.000781\n",
            "2022-10-03 19:21:24,043 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:21:24,045 EPOCH 74 done: loss 0.0190 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:21:30,946 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:21:30,960 DEV : loss 0.03510430455207825 - f1-score (micro avg)  0.875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:21:31,021 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:21:31,024 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:21:33,165 epoch 75 - iter 20/209 - loss 0.01911324 - samples/sec: 299.84 - lr: 0.000781\n",
            "2022-10-03 19:21:35,875 epoch 75 - iter 40/209 - loss 0.01820434 - samples/sec: 236.46 - lr: 0.000781\n",
            "2022-10-03 19:21:37,846 epoch 75 - iter 60/209 - loss 0.01806888 - samples/sec: 325.36 - lr: 0.000781\n",
            "2022-10-03 19:21:39,765 epoch 75 - iter 80/209 - loss 0.01774210 - samples/sec: 334.03 - lr: 0.000781\n",
            "2022-10-03 19:21:42,404 epoch 75 - iter 100/209 - loss 0.01738705 - samples/sec: 242.81 - lr: 0.000781\n",
            "2022-10-03 19:21:44,592 epoch 75 - iter 120/209 - loss 0.01768008 - samples/sec: 293.07 - lr: 0.000781\n",
            "2022-10-03 19:21:46,938 epoch 75 - iter 140/209 - loss 0.01741865 - samples/sec: 273.23 - lr: 0.000781\n",
            "2022-10-03 19:21:49,432 epoch 75 - iter 160/209 - loss 0.01759304 - samples/sec: 257.00 - lr: 0.000781\n",
            "2022-10-03 19:21:51,582 epoch 75 - iter 180/209 - loss 0.01792954 - samples/sec: 298.27 - lr: 0.000781\n",
            "2022-10-03 19:21:53,594 epoch 75 - iter 200/209 - loss 0.01841444 - samples/sec: 318.49 - lr: 0.000781\n",
            "2022-10-03 19:21:54,486 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:21:54,488 EPOCH 75 done: loss 0.0190 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  7.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:22:00,914 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:22:00,927 DEV : loss 0.035137295722961426 - f1-score (micro avg)  0.875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:22:00,989 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 19:22:00,993 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:22:03,445 epoch 76 - iter 20/209 - loss 0.02154003 - samples/sec: 261.49 - lr: 0.000781\n",
            "2022-10-03 19:22:05,374 epoch 76 - iter 40/209 - loss 0.01879825 - samples/sec: 332.48 - lr: 0.000781\n",
            "2022-10-03 19:22:08,431 epoch 76 - iter 60/209 - loss 0.01864241 - samples/sec: 209.61 - lr: 0.000781\n",
            "2022-10-03 19:22:10,605 epoch 76 - iter 80/209 - loss 0.01749681 - samples/sec: 294.89 - lr: 0.000781\n",
            "2022-10-03 19:22:12,944 epoch 76 - iter 100/209 - loss 0.01804213 - samples/sec: 274.11 - lr: 0.000781\n",
            "2022-10-03 19:22:15,016 epoch 76 - iter 120/209 - loss 0.01735181 - samples/sec: 309.47 - lr: 0.000781\n",
            "2022-10-03 19:22:16,974 epoch 76 - iter 140/209 - loss 0.01834934 - samples/sec: 327.50 - lr: 0.000781\n",
            "2022-10-03 19:22:19,169 epoch 76 - iter 160/209 - loss 0.01756134 - samples/sec: 292.19 - lr: 0.000781\n",
            "2022-10-03 19:22:21,379 epoch 76 - iter 180/209 - loss 0.01741035 - samples/sec: 290.06 - lr: 0.000781\n",
            "2022-10-03 19:22:23,510 epoch 76 - iter 200/209 - loss 0.01720525 - samples/sec: 300.84 - lr: 0.000781\n",
            "2022-10-03 19:22:24,257 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:22:24,259 EPOCH 76 done: loss 0.0178 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:22:31,135 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:22:31,149 DEV : loss 0.03514198213815689 - f1-score (micro avg)  0.875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:22:31,209 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 19:22:31,213 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:22:33,616 epoch 77 - iter 20/209 - loss 0.02006788 - samples/sec: 266.90 - lr: 0.000781\n",
            "2022-10-03 19:22:35,743 epoch 77 - iter 40/209 - loss 0.01637534 - samples/sec: 301.45 - lr: 0.000781\n",
            "2022-10-03 19:22:38,187 epoch 77 - iter 60/209 - loss 0.01715055 - samples/sec: 262.15 - lr: 0.000781\n",
            "2022-10-03 19:22:40,384 epoch 77 - iter 80/209 - loss 0.01673623 - samples/sec: 291.92 - lr: 0.000781\n",
            "2022-10-03 19:22:42,835 epoch 77 - iter 100/209 - loss 0.01704461 - samples/sec: 261.49 - lr: 0.000781\n",
            "2022-10-03 19:22:44,779 epoch 77 - iter 120/209 - loss 0.01775368 - samples/sec: 329.83 - lr: 0.000781\n",
            "2022-10-03 19:22:46,889 epoch 77 - iter 140/209 - loss 0.01742609 - samples/sec: 303.99 - lr: 0.000781\n",
            "2022-10-03 19:22:49,270 epoch 77 - iter 160/209 - loss 0.01717592 - samples/sec: 269.15 - lr: 0.000781\n",
            "2022-10-03 19:22:51,344 epoch 77 - iter 180/209 - loss 0.01722612 - samples/sec: 309.12 - lr: 0.000781\n",
            "2022-10-03 19:22:53,798 epoch 77 - iter 200/209 - loss 0.01751355 - samples/sec: 261.16 - lr: 0.000781\n",
            "2022-10-03 19:22:54,755 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:22:54,757 EPOCH 77 done: loss 0.0178 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  7.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:23:01,100 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:23:01,115 DEV : loss 0.035096194595098495 - f1-score (micro avg)  0.8742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:23:01,175 Epoch    77: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2022-10-03 19:23:01,176 BAD EPOCHS (no improvement): 4\n",
            "2022-10-03 19:23:01,181 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:23:03,408 epoch 78 - iter 20/209 - loss 0.02037479 - samples/sec: 288.08 - lr: 0.000391\n",
            "2022-10-03 19:23:05,927 epoch 78 - iter 40/209 - loss 0.02077358 - samples/sec: 254.43 - lr: 0.000391\n",
            "2022-10-03 19:23:08,283 epoch 78 - iter 60/209 - loss 0.01807861 - samples/sec: 271.99 - lr: 0.000391\n",
            "2022-10-03 19:23:10,241 epoch 78 - iter 80/209 - loss 0.01734763 - samples/sec: 327.40 - lr: 0.000391\n",
            "2022-10-03 19:23:12,482 epoch 78 - iter 100/209 - loss 0.01788362 - samples/sec: 285.96 - lr: 0.000391\n",
            "2022-10-03 19:23:14,945 epoch 78 - iter 120/209 - loss 0.01872418 - samples/sec: 260.13 - lr: 0.000391\n",
            "2022-10-03 19:23:16,963 epoch 78 - iter 140/209 - loss 0.01849453 - samples/sec: 317.66 - lr: 0.000391\n",
            "2022-10-03 19:23:19,022 epoch 78 - iter 160/209 - loss 0.01854160 - samples/sec: 311.33 - lr: 0.000391\n",
            "2022-10-03 19:23:21,098 epoch 78 - iter 180/209 - loss 0.01865088 - samples/sec: 308.79 - lr: 0.000391\n",
            "2022-10-03 19:23:23,181 epoch 78 - iter 200/209 - loss 0.01920673 - samples/sec: 307.80 - lr: 0.000391\n",
            "2022-10-03 19:23:24,562 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:23:24,564 EPOCH 78 done: loss 0.0192 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  7.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:23:30,918 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:23:30,931 DEV : loss 0.035006631165742874 - f1-score (micro avg)  0.8752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:23:30,992 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:23:30,996 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:23:33,532 epoch 79 - iter 20/209 - loss 0.02130564 - samples/sec: 252.79 - lr: 0.000391\n",
            "2022-10-03 19:23:35,778 epoch 79 - iter 40/209 - loss 0.02098178 - samples/sec: 285.41 - lr: 0.000391\n",
            "2022-10-03 19:23:38,050 epoch 79 - iter 60/209 - loss 0.01951401 - samples/sec: 282.07 - lr: 0.000391\n",
            "2022-10-03 19:23:40,363 epoch 79 - iter 80/209 - loss 0.01854836 - samples/sec: 277.16 - lr: 0.000391\n",
            "2022-10-03 19:23:42,706 epoch 79 - iter 100/209 - loss 0.01982808 - samples/sec: 273.62 - lr: 0.000391\n",
            "2022-10-03 19:23:45,030 epoch 79 - iter 120/209 - loss 0.01904833 - samples/sec: 275.91 - lr: 0.000391\n",
            "2022-10-03 19:23:47,478 epoch 79 - iter 140/209 - loss 0.01941893 - samples/sec: 261.75 - lr: 0.000391\n",
            "2022-10-03 19:23:49,622 epoch 79 - iter 160/209 - loss 0.01960195 - samples/sec: 299.07 - lr: 0.000391\n",
            "2022-10-03 19:23:51,908 epoch 79 - iter 180/209 - loss 0.01984734 - samples/sec: 280.40 - lr: 0.000391\n",
            "2022-10-03 19:23:54,076 epoch 79 - iter 200/209 - loss 0.01978341 - samples/sec: 295.64 - lr: 0.000391\n",
            "2022-10-03 19:23:54,834 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:23:54,836 EPOCH 79 done: loss 0.0198 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  7.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:24:01,229 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:24:01,243 DEV : loss 0.035026099532842636 - f1-score (micro avg)  0.8752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:24:01,303 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 19:24:01,307 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:24:03,242 epoch 80 - iter 20/209 - loss 0.01574453 - samples/sec: 331.54 - lr: 0.000391\n",
            "2022-10-03 19:24:06,168 epoch 80 - iter 40/209 - loss 0.01918007 - samples/sec: 219.01 - lr: 0.000391\n",
            "2022-10-03 19:24:08,126 epoch 80 - iter 60/209 - loss 0.01884088 - samples/sec: 327.51 - lr: 0.000391\n",
            "2022-10-03 19:24:09,951 epoch 80 - iter 80/209 - loss 0.01980117 - samples/sec: 351.50 - lr: 0.000391\n",
            "2022-10-03 19:24:12,776 epoch 80 - iter 100/209 - loss 0.02004965 - samples/sec: 226.80 - lr: 0.000391\n",
            "2022-10-03 19:24:15,540 epoch 80 - iter 120/209 - loss 0.01968290 - samples/sec: 231.84 - lr: 0.000391\n",
            "2022-10-03 19:24:17,783 epoch 80 - iter 140/209 - loss 0.01923350 - samples/sec: 285.70 - lr: 0.000391\n",
            "2022-10-03 19:24:19,819 epoch 80 - iter 160/209 - loss 0.01960577 - samples/sec: 314.80 - lr: 0.000391\n",
            "2022-10-03 19:24:21,718 epoch 80 - iter 180/209 - loss 0.01947967 - samples/sec: 337.65 - lr: 0.000391\n",
            "2022-10-03 19:24:23,610 epoch 80 - iter 200/209 - loss 0.01904580 - samples/sec: 338.90 - lr: 0.000391\n",
            "2022-10-03 19:24:24,507 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:24:24,509 EPOCH 80 done: loss 0.0191 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  7.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:24:30,871 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:24:30,883 DEV : loss 0.03505483642220497 - f1-score (micro avg)  0.8752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:24:30,943 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 19:24:30,946 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:24:33,109 epoch 81 - iter 20/209 - loss 0.01944239 - samples/sec: 296.47 - lr: 0.000391\n",
            "2022-10-03 19:24:35,249 epoch 81 - iter 40/209 - loss 0.01654143 - samples/sec: 299.61 - lr: 0.000391\n",
            "2022-10-03 19:24:37,962 epoch 81 - iter 60/209 - loss 0.01729232 - samples/sec: 236.24 - lr: 0.000391\n",
            "2022-10-03 19:24:40,443 epoch 81 - iter 80/209 - loss 0.01821247 - samples/sec: 258.37 - lr: 0.000391\n",
            "2022-10-03 19:24:42,222 epoch 81 - iter 100/209 - loss 0.01836415 - samples/sec: 360.26 - lr: 0.000391\n",
            "2022-10-03 19:24:44,779 epoch 81 - iter 120/209 - loss 0.01860634 - samples/sec: 250.65 - lr: 0.000391\n",
            "2022-10-03 19:24:47,016 epoch 81 - iter 140/209 - loss 0.01881178 - samples/sec: 286.65 - lr: 0.000391\n",
            "2022-10-03 19:24:48,907 epoch 81 - iter 160/209 - loss 0.01869566 - samples/sec: 338.94 - lr: 0.000391\n",
            "2022-10-03 19:24:51,594 epoch 81 - iter 180/209 - loss 0.01868901 - samples/sec: 238.56 - lr: 0.000391\n",
            "2022-10-03 19:24:53,542 epoch 81 - iter 200/209 - loss 0.01830127 - samples/sec: 329.10 - lr: 0.000391\n",
            "2022-10-03 19:24:54,395 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:24:54,396 EPOCH 81 done: loss 0.0181 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  7.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:25:00,820 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:25:00,838 DEV : loss 0.03510748967528343 - f1-score (micro avg)  0.8742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:25:00,901 Epoch    81: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2022-10-03 19:25:00,902 BAD EPOCHS (no improvement): 4\n",
            "2022-10-03 19:25:00,907 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:25:03,640 epoch 82 - iter 20/209 - loss 0.01787978 - samples/sec: 234.63 - lr: 0.000195\n",
            "2022-10-03 19:25:06,157 epoch 82 - iter 40/209 - loss 0.01620613 - samples/sec: 254.67 - lr: 0.000195\n",
            "2022-10-03 19:25:08,395 epoch 82 - iter 60/209 - loss 0.01614408 - samples/sec: 286.42 - lr: 0.000195\n",
            "2022-10-03 19:25:10,629 epoch 82 - iter 80/209 - loss 0.01603924 - samples/sec: 287.01 - lr: 0.000195\n",
            "2022-10-03 19:25:12,606 epoch 82 - iter 100/209 - loss 0.01755991 - samples/sec: 324.30 - lr: 0.000195\n",
            "2022-10-03 19:25:14,736 epoch 82 - iter 120/209 - loss 0.01752979 - samples/sec: 300.89 - lr: 0.000195\n",
            "2022-10-03 19:25:17,137 epoch 82 - iter 140/209 - loss 0.01780406 - samples/sec: 266.91 - lr: 0.000195\n",
            "2022-10-03 19:25:19,837 epoch 82 - iter 160/209 - loss 0.01741333 - samples/sec: 237.33 - lr: 0.000195\n",
            "2022-10-03 19:25:21,657 epoch 82 - iter 180/209 - loss 0.01717415 - samples/sec: 352.39 - lr: 0.000195\n",
            "2022-10-03 19:25:23,846 epoch 82 - iter 200/209 - loss 0.01740924 - samples/sec: 292.76 - lr: 0.000195\n",
            "2022-10-03 19:25:24,702 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:25:24,704 EPOCH 82 done: loss 0.0177 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  7.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:25:31,153 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:25:31,166 DEV : loss 0.03514496609568596 - f1-score (micro avg)  0.8742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:25:31,228 BAD EPOCHS (no improvement): 1\n",
            "2022-10-03 19:25:31,234 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:25:33,837 epoch 83 - iter 20/209 - loss 0.01350827 - samples/sec: 246.38 - lr: 0.000195\n",
            "2022-10-03 19:25:36,413 epoch 83 - iter 40/209 - loss 0.01723518 - samples/sec: 248.79 - lr: 0.000195\n",
            "2022-10-03 19:25:38,676 epoch 83 - iter 60/209 - loss 0.01800993 - samples/sec: 283.25 - lr: 0.000195\n",
            "2022-10-03 19:25:40,834 epoch 83 - iter 80/209 - loss 0.01850703 - samples/sec: 297.04 - lr: 0.000195\n",
            "2022-10-03 19:25:43,231 epoch 83 - iter 100/209 - loss 0.01798957 - samples/sec: 267.44 - lr: 0.000195\n",
            "2022-10-03 19:25:45,174 epoch 83 - iter 120/209 - loss 0.01819250 - samples/sec: 330.08 - lr: 0.000195\n",
            "2022-10-03 19:25:47,269 epoch 83 - iter 140/209 - loss 0.01836390 - samples/sec: 306.07 - lr: 0.000195\n",
            "2022-10-03 19:25:49,307 epoch 83 - iter 160/209 - loss 0.01782714 - samples/sec: 314.49 - lr: 0.000195\n",
            "2022-10-03 19:25:51,448 epoch 83 - iter 180/209 - loss 0.01781987 - samples/sec: 299.46 - lr: 0.000195\n",
            "2022-10-03 19:25:54,122 epoch 83 - iter 200/209 - loss 0.01799337 - samples/sec: 239.64 - lr: 0.000195\n",
            "2022-10-03 19:25:54,886 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:25:54,888 EPOCH 83 done: loss 0.0181 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:26:01,659 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:26:01,672 DEV : loss 0.03508172556757927 - f1-score (micro avg)  0.8752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:26:01,734 BAD EPOCHS (no improvement): 2\n",
            "2022-10-03 19:26:01,738 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:26:03,922 epoch 84 - iter 20/209 - loss 0.01684332 - samples/sec: 293.81 - lr: 0.000195\n",
            "2022-10-03 19:26:05,731 epoch 84 - iter 40/209 - loss 0.01674248 - samples/sec: 354.41 - lr: 0.000195\n",
            "2022-10-03 19:26:08,919 epoch 84 - iter 60/209 - loss 0.01726975 - samples/sec: 200.98 - lr: 0.000195\n",
            "2022-10-03 19:26:11,119 epoch 84 - iter 80/209 - loss 0.01963823 - samples/sec: 291.26 - lr: 0.000195\n",
            "2022-10-03 19:26:13,631 epoch 84 - iter 100/209 - loss 0.01849264 - samples/sec: 255.16 - lr: 0.000195\n",
            "2022-10-03 19:26:15,754 epoch 84 - iter 120/209 - loss 0.01839022 - samples/sec: 301.99 - lr: 0.000195\n",
            "2022-10-03 19:26:18,091 epoch 84 - iter 140/209 - loss 0.01859170 - samples/sec: 274.28 - lr: 0.000195\n",
            "2022-10-03 19:26:20,302 epoch 84 - iter 160/209 - loss 0.01856816 - samples/sec: 290.01 - lr: 0.000195\n",
            "2022-10-03 19:26:22,263 epoch 84 - iter 180/209 - loss 0.01791436 - samples/sec: 326.93 - lr: 0.000195\n",
            "2022-10-03 19:26:24,399 epoch 84 - iter 200/209 - loss 0.01757670 - samples/sec: 300.11 - lr: 0.000195\n",
            "2022-10-03 19:26:25,440 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:26:25,442 EPOCH 84 done: loss 0.0173 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  7.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:26:31,796 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:26:31,810 DEV : loss 0.0350802019238472 - f1-score (micro avg)  0.8752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:26:31,870 BAD EPOCHS (no improvement): 3\n",
            "2022-10-03 19:26:31,874 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:26:34,082 epoch 85 - iter 20/209 - loss 0.02079547 - samples/sec: 290.54 - lr: 0.000195\n",
            "2022-10-03 19:26:36,603 epoch 85 - iter 40/209 - loss 0.02109484 - samples/sec: 254.18 - lr: 0.000195\n",
            "2022-10-03 19:26:38,713 epoch 85 - iter 60/209 - loss 0.02101884 - samples/sec: 304.06 - lr: 0.000195\n",
            "2022-10-03 19:26:40,533 epoch 85 - iter 80/209 - loss 0.02056094 - samples/sec: 352.09 - lr: 0.000195\n",
            "2022-10-03 19:26:42,821 epoch 85 - iter 100/209 - loss 0.01907542 - samples/sec: 280.13 - lr: 0.000195\n",
            "2022-10-03 19:26:45,036 epoch 85 - iter 120/209 - loss 0.01851257 - samples/sec: 289.42 - lr: 0.000195\n",
            "2022-10-03 19:26:46,928 epoch 85 - iter 140/209 - loss 0.01863915 - samples/sec: 338.82 - lr: 0.000195\n",
            "2022-10-03 19:26:49,198 epoch 85 - iter 160/209 - loss 0.01888991 - samples/sec: 282.44 - lr: 0.000195\n",
            "2022-10-03 19:26:51,441 epoch 85 - iter 180/209 - loss 0.01842544 - samples/sec: 285.60 - lr: 0.000195\n",
            "2022-10-03 19:26:54,169 epoch 85 - iter 200/209 - loss 0.01840742 - samples/sec: 234.85 - lr: 0.000195\n",
            "2022-10-03 19:26:55,234 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:26:55,236 EPOCH 85 done: loss 0.0192 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:06<00:00,  6.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:27:01,990 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:27:02,002 DEV : loss 0.035058941692113876 - f1-score (micro avg)  0.8752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:27:02,067 Epoch    85: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2022-10-03 19:27:02,069 BAD EPOCHS (no improvement): 4\n",
            "2022-10-03 19:27:02,073 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:27:02,075 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:27:02,077 learning rate too small - quitting training!\n",
            "2022-10-03 19:27:02,078 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:27:04,785 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-03 19:27:04,788 loading file /content/drive/MyDrive/Flair_NLP/sota-ner-flair/best-model.pt\n",
            "2022-10-03 19:27:06,385 SequenceTagger predicts: Dictionary with 31 tags: O, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-FUNDAMENTO, B-FUNDAMENTO, E-FUNDAMENTO, I-FUNDAMENTO, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-DATA, B-DATA, E-DATA, I-DATA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL, S-PRODUTODELEI, B-PRODUTODELEI, E-PRODUTODELEI, I-PRODUTODELEI, S-EVENTO, B-EVENTO, E-EVENTO, I-EVENTO, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:07<00:00,  6.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-03 19:27:14,029 Evaluating as a multi-label problem: False\n",
            "2022-10-03 19:27:14,043 0.8694\t0.8447\t0.8569\t0.7541\n",
            "2022-10-03 19:27:14,045 \n",
            "Results:\n",
            "- F-score (micro) 0.8569\n",
            "- F-score (macro) 0.8171\n",
            "- Accuracy 0.7541\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  FUNDAMENTO     0.9174    0.8952    0.9061       124\n",
            "      PESSOA     0.8926    0.9076    0.9000       119\n",
            "       LOCAL     0.8081    0.7921    0.8000       101\n",
            "        DATA     0.9216    0.9592    0.9400        98\n",
            " ORGANIZACAO     0.8391    0.7766    0.8066        94\n",
            "PRODUTODELEI     0.7609    0.6481    0.7000        54\n",
            "      EVENTO     0.8333    0.5556    0.6667         9\n",
            "\n",
            "   micro avg     0.8694    0.8447    0.8569       599\n",
            "   macro avg     0.8533    0.7906    0.8171       599\n",
            "weighted avg     0.8670    0.8447    0.8548       599\n",
            "\n",
            "2022-10-03 19:27:14,048 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_score': 0.8569009314140559,\n",
              " 'dev_score_history': [0.18742857142857144,\n",
              "  0.3552311435523115,\n",
              "  0.4476190476190477,\n",
              "  0.5943097997892519,\n",
              "  0.6818181818181818,\n",
              "  0.666,\n",
              "  0.7220630372492837,\n",
              "  0.7100478468899523,\n",
              "  0.7585551330798479,\n",
              "  0.7529411764705883,\n",
              "  0.7755491881566381,\n",
              "  0.7592592592592592,\n",
              "  0.8048780487804877,\n",
              "  0.7892204042348413,\n",
              "  0.8052434456928839,\n",
              "  0.8129032258064516,\n",
              "  0.7939793038570083,\n",
              "  0.8203198494825964,\n",
              "  0.8139754485363551,\n",
              "  0.8133704735376045,\n",
              "  0.8176991150442477,\n",
              "  0.8129032258064516,\n",
              "  0.8446866485013623,\n",
              "  0.8359020852221215,\n",
              "  0.8442844284428443,\n",
              "  0.8464285714285714,\n",
              "  0.8545618789521228,\n",
              "  0.8522212148685404,\n",
              "  0.8434389140271493,\n",
              "  0.8594306049822064,\n",
              "  0.8561085972850679,\n",
              "  0.8592057761732852,\n",
              "  0.8576642335766423,\n",
              "  0.8669064748201438,\n",
              "  0.8579234972677596,\n",
              "  0.8507596067917784,\n",
              "  0.8651583710407241,\n",
              "  0.8606485539000875,\n",
              "  0.8645739910313901,\n",
              "  0.8627450980392157,\n",
              "  0.8664898320070734,\n",
              "  0.8729874776386404,\n",
              "  0.871841155234657,\n",
              "  0.8663677130044842,\n",
              "  0.873114463176575,\n",
              "  0.8641542506573182,\n",
              "  0.8683974932855864,\n",
              "  0.8773500447627574,\n",
              "  0.8643306379155437,\n",
              "  0.8716094032549728,\n",
              "  0.863514719000892,\n",
              "  0.8728584310189359,\n",
              "  0.8678571428571429,\n",
              "  0.8711111111111112,\n",
              "  0.8748890860692103,\n",
              "  0.8697214734950585,\n",
              "  0.870420017873101,\n",
              "  0.8754448398576513,\n",
              "  0.875,\n",
              "  0.8739946380697051,\n",
              "  0.8742194469223907,\n",
              "  0.8717488789237668,\n",
              "  0.879786286731968,\n",
              "  0.8777876895628902,\n",
              "  0.875222816399287,\n",
              "  0.8762243989314338,\n",
              "  0.8762243989314338,\n",
              "  0.8762243989314338,\n",
              "  0.8805704099821747,\n",
              "  0.8742194469223907,\n",
              "  0.875,\n",
              "  0.875,\n",
              "  0.8760035682426405,\n",
              "  0.875,\n",
              "  0.875,\n",
              "  0.875,\n",
              "  0.8742194469223907,\n",
              "  0.875222816399287,\n",
              "  0.875222816399287,\n",
              "  0.875222816399287,\n",
              "  0.8742194469223907,\n",
              "  0.8742194469223907,\n",
              "  0.875222816399287,\n",
              "  0.875222816399287,\n",
              "  0.875222816399287],\n",
              " 'train_loss_history': [0.47341014457739256,\n",
              "  0.22080218110050945,\n",
              "  0.15866796908988035,\n",
              "  0.13390058130295235,\n",
              "  0.10739790772798241,\n",
              "  0.09693718111106096,\n",
              "  0.08937152682859284,\n",
              "  0.0849629361994047,\n",
              "  0.07714864041364515,\n",
              "  0.07307881157860972,\n",
              "  0.06961690187875309,\n",
              "  0.06513884820188479,\n",
              "  0.06075192557947267,\n",
              "  0.059869857427597165,\n",
              "  0.05856189002129132,\n",
              "  0.056015459473193974,\n",
              "  0.054583929070886016,\n",
              "  0.052427857452271465,\n",
              "  0.05191957462380622,\n",
              "  0.047559855111946645,\n",
              "  0.0465685617154141,\n",
              "  0.045549616261889116,\n",
              "  0.040054221417502776,\n",
              "  0.03680311236253818,\n",
              "  0.03585231989547188,\n",
              "  0.03494798070283118,\n",
              "  0.03417867990693082,\n",
              "  0.0341431490935604,\n",
              "  0.03324100644112842,\n",
              "  0.032869566672635034,\n",
              "  0.032895131255503016,\n",
              "  0.03200206962279652,\n",
              "  0.030539694444110765,\n",
              "  0.03256485632455859,\n",
              "  0.030779316435875392,\n",
              "  0.029656133608733145,\n",
              "  0.027998648716871508,\n",
              "  0.027802313278457908,\n",
              "  0.027719460466618596,\n",
              "  0.025396350969423998,\n",
              "  0.02405458322267776,\n",
              "  0.02342275578725949,\n",
              "  0.024000384988058936,\n",
              "  0.02390005497032104,\n",
              "  0.024387158687074043,\n",
              "  0.023888518695489278,\n",
              "  0.023278008606704006,\n",
              "  0.02287191102909319,\n",
              "  0.023529091414788605,\n",
              "  0.02153763729543058,\n",
              "  0.02354556927098484,\n",
              "  0.021388461524569757,\n",
              "  0.020505698393459622,\n",
              "  0.02085170674116465,\n",
              "  0.01999512517722478,\n",
              "  0.019904247130719893,\n",
              "  0.02081045693352679,\n",
              "  0.020586234819218552,\n",
              "  0.020169044364795878,\n",
              "  0.01928491790763241,\n",
              "  0.01943150399309704,\n",
              "  0.018444090685922794,\n",
              "  0.01891312684489086,\n",
              "  0.01991963305786318,\n",
              "  0.01939897439935938,\n",
              "  0.018647867982272165,\n",
              "  0.019334859394439127,\n",
              "  0.018287704505502694,\n",
              "  0.018897672434392335,\n",
              "  0.018607720249369505,\n",
              "  0.019454508059405323,\n",
              "  0.018832510521884154,\n",
              "  0.01864222729998964,\n",
              "  0.019010492421094188,\n",
              "  0.019045660526323907,\n",
              "  0.017751673236063567,\n",
              "  0.01779380571805782,\n",
              "  0.019159943393586242,\n",
              "  0.01975953038721118,\n",
              "  0.019098078827811702,\n",
              "  0.018118562666064528,\n",
              "  0.01767901620078776,\n",
              "  0.018126859931835625,\n",
              "  0.017324116430794435,\n",
              "  0.0191962681065933],\n",
              " 'dev_loss_history': [0.24962784349918365,\n",
              "  0.1606435775756836,\n",
              "  0.14665403962135315,\n",
              "  0.1001163050532341,\n",
              "  0.08253118395805359,\n",
              "  0.0795944556593895,\n",
              "  0.0680016428232193,\n",
              "  0.0680040791630745,\n",
              "  0.060828354209661484,\n",
              "  0.06503196060657501,\n",
              "  0.05805245786905289,\n",
              "  0.057785019278526306,\n",
              "  0.05335738882422447,\n",
              "  0.05508466437458992,\n",
              "  0.05065612494945526,\n",
              "  0.048684261739254,\n",
              "  0.05065369978547096,\n",
              "  0.04896869510412216,\n",
              "  0.046392813324928284,\n",
              "  0.05078371241688728,\n",
              "  0.04473907873034477,\n",
              "  0.04734628647565842,\n",
              "  0.038541991263628006,\n",
              "  0.03912742808461189,\n",
              "  0.03847711160778999,\n",
              "  0.03878262639045715,\n",
              "  0.03771375119686127,\n",
              "  0.03745303675532341,\n",
              "  0.03784233704209328,\n",
              "  0.035691067576408386,\n",
              "  0.0346212238073349,\n",
              "  0.03576216101646423,\n",
              "  0.035961270332336426,\n",
              "  0.03565596416592598,\n",
              "  0.03467694669961929,\n",
              "  0.03771058842539787,\n",
              "  0.035229187458753586,\n",
              "  0.036679625511169434,\n",
              "  0.03443046286702156,\n",
              "  0.03451847657561302,\n",
              "  0.035778582096099854,\n",
              "  0.034299444407224655,\n",
              "  0.034895509481430054,\n",
              "  0.035161375999450684,\n",
              "  0.033696189522743225,\n",
              "  0.03433816879987717,\n",
              "  0.03581185266375542,\n",
              "  0.03494102135300636,\n",
              "  0.035118408501148224,\n",
              "  0.035399846732616425,\n",
              "  0.035587798804044724,\n",
              "  0.036509983241558075,\n",
              "  0.034630678594112396,\n",
              "  0.03396720439195633,\n",
              "  0.034209948033094406,\n",
              "  0.03512508049607277,\n",
              "  0.035065241158008575,\n",
              "  0.03536901995539665,\n",
              "  0.03492897003889084,\n",
              "  0.0348680317401886,\n",
              "  0.03488953039050102,\n",
              "  0.034764859825372696,\n",
              "  0.03489621728658676,\n",
              "  0.034771960228681564,\n",
              "  0.034869417548179626,\n",
              "  0.03478711098432541,\n",
              "  0.035082440823316574,\n",
              "  0.03492031991481781,\n",
              "  0.03477175906300545,\n",
              "  0.0350797101855278,\n",
              "  0.034917108714580536,\n",
              "  0.03500644117593765,\n",
              "  0.035036664456129074,\n",
              "  0.03510430455207825,\n",
              "  0.035137295722961426,\n",
              "  0.03514198213815689,\n",
              "  0.035096194595098495,\n",
              "  0.035006631165742874,\n",
              "  0.035026099532842636,\n",
              "  0.03505483642220497,\n",
              "  0.03510748967528343,\n",
              "  0.03514496609568596,\n",
              "  0.03508172556757927,\n",
              "  0.0350802019238472,\n",
              "  0.035058941692113876]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# Initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "path = '/content/drive/MyDrive/Flair_NLP/sota-ner-flair'\n",
        "\n",
        "# Start training\n",
        "trainer.train(path,\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKd693ELYMLh"
      },
      "source": [
        "## Teste 4.2 NER Flair Stacked Embeddings com Corpus Ulysses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7PKxStLvY2j"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIFoJwD_vY2j"
      },
      "outputs": [],
      "source": [
        "## Importes\n",
        "## datasets\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import FlairEmbeddings, StackedEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BFtUmgOvY2k"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLXYTDeqvY2k",
        "outputId": "d8d11309-63a9-49ac-b6eb-77e4a98b87be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGpTljgpvY2k",
        "outputId": "13376338-3c3d-44ee-97de-96d2723e074b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:29:47,877 Reading data from /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria\n",
            "2022-10-04 05:29:47,880 Train: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/train.txt\n",
            "2022-10-04 05:29:47,882 Dev: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/valid.txt\n",
            "2022-10-04 05:29:47,884 Test: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/test.txt\n"
          ]
        }
      ],
      "source": [
        "## carregando um corpus e definindo as colunas\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='valid.txt')\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bdlc3GZBvY2k",
        "outputId": "fdf4bf5b-c6d0-48c5-e53c-cf3ea8fc794f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:29:52,038 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6667it [00:00, 44590.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:29:52,237 Dictionary created for label 'ner' with 8 values: PESSOA (seen 628 times), FUNDAMENTO (seen 490 times), ORGANIZACAO (seen 435 times), DATA (seen 433 times), LOCAL (seen 369 times), PRODUTODELEI (seen 230 times), EVENTO (seen 9 times)\n",
            "Dictionary with 8 tags: <unk>, PESSOA, FUNDAMENTO, ORGANIZACAO, DATA, LOCAL, PRODUTODELEI, EVENTO\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ayg1NWNvY2k"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCpCA9SrvY2k",
        "outputId": "29fe6166-68e2-4be2-878b-c3a383e29a7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:29:52,839 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-forward.pt not found in cache, downloading to /tmp/tmpgvcqwym7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:03<00:00, 20669355.30B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:29:56,714 copying /tmp/tmpgvcqwym7 to cache at /root/.flair/embeddings/lm-pt-forward.pt\n",
            "2022-10-04 05:29:56,796 removing temp file /tmp/tmpgvcqwym7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:30:08,058 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-backward.pt not found in cache, downloading to /tmp/tmp1wbxvwvz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:03<00:00, 20063950.90B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:30:12,039 copying /tmp/tmp1wbxvwvz to cache at /root/.flair/embeddings/lm-pt-backward.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:30:12,120 removing temp file /tmp/tmp1wbxvwvz\n"
          ]
        }
      ],
      "source": [
        "## Stacked Embeddings\n",
        "# Initialize embedding stack with \n",
        "embedding_types = [\n",
        "    FlairEmbeddings('pt-forward'),\n",
        "    FlairEmbeddings('pt-backward')\n",
        "]\n",
        "\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MBsE_USvY2k"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWhgHEXWvY2k",
        "outputId": "ee9ac12e-3c75-46c1-b7c5-407c289a5f3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:30:12,353 SequenceTagger predicts: Dictionary with 29 tags: O, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-FUNDAMENTO, B-FUNDAMENTO, E-FUNDAMENTO, I-FUNDAMENTO, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-DATA, B-DATA, E-DATA, I-DATA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL, S-PRODUTODELEI, B-PRODUTODELEI, E-PRODUTODELEI, I-PRODUTODELEI, S-EVENTO, B-EVENTO, E-EVENTO, I-EVENTO\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNFTHWaivY2k",
        "outputId": "b6117e29-38e7-4660-e42e-e0b75760cf2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:30:12,598 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:30:12,602 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (rnn): LSTM(4096, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=31, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-10-04 05:30:12,603 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:30:12,607 Corpus: \"Corpus: 6667 train + 1429 dev + 1430 test sentences\"\n",
            "2022-10-04 05:30:12,610 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:30:12,612 Parameters:\n",
            "2022-10-04 05:30:12,614  - learning_rate: \"0.100000\"\n",
            "2022-10-04 05:30:12,615  - mini_batch_size: \"32\"\n",
            "2022-10-04 05:30:12,618  - patience: \"3\"\n",
            "2022-10-04 05:30:12,621  - anneal_factor: \"0.5\"\n",
            "2022-10-04 05:30:12,626  - max_epochs: \"100\"\n",
            "2022-10-04 05:30:12,627  - shuffle: \"True\"\n",
            "2022-10-04 05:30:12,630  - train_with_dev: \"False\"\n",
            "2022-10-04 05:30:12,632  - batch_growth_annealing: \"False\"\n",
            "2022-10-04 05:30:12,637 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:30:12,638 Model training base path: \"/content/drive/MyDrive/Flair_NLP/sota-ner-flair\"\n",
            "2022-10-04 05:30:12,643 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:30:12,645 Device: cuda:0\n",
            "2022-10-04 05:30:12,648 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:30:12,651 Embeddings storage mode: cpu\n",
            "2022-10-04 05:30:12,653 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:30:24,503 epoch 1 - iter 20/209 - loss 1.00624512 - samples/sec: 54.03 - lr: 0.100000\n",
            "2022-10-04 05:30:42,856 epoch 1 - iter 40/209 - loss 0.64800049 - samples/sec: 34.88 - lr: 0.100000\n",
            "2022-10-04 05:30:56,324 epoch 1 - iter 60/209 - loss 0.56557114 - samples/sec: 47.53 - lr: 0.100000\n",
            "2022-10-04 05:31:10,301 epoch 1 - iter 80/209 - loss 0.49539024 - samples/sec: 45.80 - lr: 0.100000\n",
            "2022-10-04 05:31:25,336 epoch 1 - iter 100/209 - loss 0.43375978 - samples/sec: 42.58 - lr: 0.100000\n",
            "2022-10-04 05:31:39,943 epoch 1 - iter 120/209 - loss 0.40537658 - samples/sec: 43.83 - lr: 0.100000\n",
            "2022-10-04 05:31:53,763 epoch 1 - iter 140/209 - loss 0.37989238 - samples/sec: 46.32 - lr: 0.100000\n",
            "2022-10-04 05:32:08,824 epoch 1 - iter 160/209 - loss 0.36286938 - samples/sec: 42.50 - lr: 0.100000\n",
            "2022-10-04 05:32:26,418 epoch 1 - iter 180/209 - loss 0.34251788 - samples/sec: 36.39 - lr: 0.100000\n",
            "2022-10-04 05:32:42,051 epoch 1 - iter 200/209 - loss 0.32769472 - samples/sec: 40.95 - lr: 0.100000\n",
            "2022-10-04 05:32:48,637 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:32:48,639 EPOCH 1 done: loss 0.3242 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:34<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:33:22,677 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:33:22,698 DEV : loss 0.16018033027648926 - f1-score (micro avg)  0.5041\n",
            "2022-10-04 05:33:22,793 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:33:22,799 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:33:23,548 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:33:26,676 epoch 2 - iter 20/209 - loss 0.17530746 - samples/sec: 205.22 - lr: 0.100000\n",
            "2022-10-04 05:33:30,028 epoch 2 - iter 40/209 - loss 0.17048181 - samples/sec: 191.15 - lr: 0.100000\n",
            "2022-10-04 05:33:33,517 epoch 2 - iter 60/209 - loss 0.15783351 - samples/sec: 183.71 - lr: 0.100000\n",
            "2022-10-04 05:33:37,382 epoch 2 - iter 80/209 - loss 0.14285898 - samples/sec: 165.81 - lr: 0.100000\n",
            "2022-10-04 05:33:41,266 epoch 2 - iter 100/209 - loss 0.14534819 - samples/sec: 164.99 - lr: 0.100000\n",
            "2022-10-04 05:33:44,786 epoch 2 - iter 120/209 - loss 0.14638194 - samples/sec: 182.09 - lr: 0.100000\n",
            "2022-10-04 05:33:47,687 epoch 2 - iter 140/209 - loss 0.14734390 - samples/sec: 220.96 - lr: 0.100000\n",
            "2022-10-04 05:33:52,696 epoch 2 - iter 160/209 - loss 0.14241373 - samples/sec: 127.89 - lr: 0.100000\n",
            "2022-10-04 05:33:56,484 epoch 2 - iter 180/209 - loss 0.14281968 - samples/sec: 169.19 - lr: 0.100000\n",
            "2022-10-04 05:33:59,929 epoch 2 - iter 200/209 - loss 0.13930034 - samples/sec: 186.03 - lr: 0.100000\n",
            "2022-10-04 05:34:02,046 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:34:02,048 EPOCH 2 done: loss 0.1391 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:34:11,278 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:34:11,294 DEV : loss 0.08979383111000061 - f1-score (micro avg)  0.6182\n",
            "2022-10-04 05:34:11,385 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:34:11,391 saving best model\n",
            "2022-10-04 05:34:12,107 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:34:15,834 epoch 3 - iter 20/209 - loss 0.12845237 - samples/sec: 171.95 - lr: 0.100000\n",
            "2022-10-04 05:34:20,051 epoch 3 - iter 40/209 - loss 0.11445123 - samples/sec: 151.98 - lr: 0.100000\n",
            "2022-10-04 05:34:23,217 epoch 3 - iter 60/209 - loss 0.11535705 - samples/sec: 202.45 - lr: 0.100000\n",
            "2022-10-04 05:34:27,096 epoch 3 - iter 80/209 - loss 0.11145062 - samples/sec: 165.17 - lr: 0.100000\n",
            "2022-10-04 05:34:31,164 epoch 3 - iter 100/209 - loss 0.10570771 - samples/sec: 157.52 - lr: 0.100000\n",
            "2022-10-04 05:34:35,136 epoch 3 - iter 120/209 - loss 0.10768676 - samples/sec: 161.34 - lr: 0.100000\n",
            "2022-10-04 05:34:38,744 epoch 3 - iter 140/209 - loss 0.10637378 - samples/sec: 177.62 - lr: 0.100000\n",
            "2022-10-04 05:34:42,450 epoch 3 - iter 160/209 - loss 0.10560140 - samples/sec: 172.88 - lr: 0.100000\n",
            "2022-10-04 05:34:46,090 epoch 3 - iter 180/209 - loss 0.10232881 - samples/sec: 176.07 - lr: 0.100000\n",
            "2022-10-04 05:34:50,028 epoch 3 - iter 200/209 - loss 0.10366238 - samples/sec: 162.75 - lr: 0.100000\n",
            "2022-10-04 05:34:51,388 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:34:51,390 EPOCH 3 done: loss 0.1024 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:35:01,077 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:35:01,093 DEV : loss 0.06800028681755066 - f1-score (micro avg)  0.7527\n",
            "2022-10-04 05:35:01,185 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:35:01,190 saving best model\n",
            "2022-10-04 05:35:01,902 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:35:05,736 epoch 4 - iter 20/209 - loss 0.07889683 - samples/sec: 167.38 - lr: 0.100000\n",
            "2022-10-04 05:35:09,501 epoch 4 - iter 40/209 - loss 0.07485090 - samples/sec: 170.19 - lr: 0.100000\n",
            "2022-10-04 05:35:13,938 epoch 4 - iter 60/209 - loss 0.07727403 - samples/sec: 144.44 - lr: 0.100000\n",
            "2022-10-04 05:35:17,873 epoch 4 - iter 80/209 - loss 0.07242931 - samples/sec: 162.84 - lr: 0.100000\n",
            "2022-10-04 05:35:21,242 epoch 4 - iter 100/209 - loss 0.07723278 - samples/sec: 190.26 - lr: 0.100000\n",
            "2022-10-04 05:35:24,777 epoch 4 - iter 120/209 - loss 0.08153699 - samples/sec: 181.29 - lr: 0.100000\n",
            "2022-10-04 05:35:28,703 epoch 4 - iter 140/209 - loss 0.08155474 - samples/sec: 163.16 - lr: 0.100000\n",
            "2022-10-04 05:35:32,874 epoch 4 - iter 160/209 - loss 0.08272667 - samples/sec: 153.62 - lr: 0.100000\n",
            "2022-10-04 05:35:36,606 epoch 4 - iter 180/209 - loss 0.08130831 - samples/sec: 171.68 - lr: 0.100000\n",
            "2022-10-04 05:35:40,088 epoch 4 - iter 200/209 - loss 0.07979241 - samples/sec: 184.02 - lr: 0.100000\n",
            "2022-10-04 05:35:41,389 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:35:41,392 EPOCH 4 done: loss 0.0800 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:35:50,591 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:35:50,609 DEV : loss 0.07237409800291061 - f1-score (micro avg)  0.742\n",
            "2022-10-04 05:35:50,704 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 05:35:50,709 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:35:55,159 epoch 5 - iter 20/209 - loss 0.07737473 - samples/sec: 144.10 - lr: 0.100000\n",
            "2022-10-04 05:35:58,869 epoch 5 - iter 40/209 - loss 0.07132954 - samples/sec: 172.74 - lr: 0.100000\n",
            "2022-10-04 05:36:02,608 epoch 5 - iter 60/209 - loss 0.07167298 - samples/sec: 171.36 - lr: 0.100000\n",
            "2022-10-04 05:36:06,742 epoch 5 - iter 80/209 - loss 0.07410241 - samples/sec: 155.00 - lr: 0.100000\n",
            "2022-10-04 05:36:10,402 epoch 5 - iter 100/209 - loss 0.07098395 - samples/sec: 175.11 - lr: 0.100000\n",
            "2022-10-04 05:36:13,839 epoch 5 - iter 120/209 - loss 0.07312924 - samples/sec: 186.44 - lr: 0.100000\n",
            "2022-10-04 05:36:18,400 epoch 5 - iter 140/209 - loss 0.07316206 - samples/sec: 140.49 - lr: 0.100000\n",
            "2022-10-04 05:36:21,488 epoch 5 - iter 160/209 - loss 0.07481866 - samples/sec: 207.52 - lr: 0.100000\n",
            "2022-10-04 05:36:24,718 epoch 5 - iter 180/209 - loss 0.07565514 - samples/sec: 198.43 - lr: 0.100000\n",
            "2022-10-04 05:36:27,953 epoch 5 - iter 200/209 - loss 0.07439258 - samples/sec: 198.13 - lr: 0.100000\n",
            "2022-10-04 05:36:29,489 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:36:29,492 EPOCH 5 done: loss 0.0740 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:36:39,139 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:36:39,154 DEV : loss 0.06755087524652481 - f1-score (micro avg)  0.7792\n",
            "2022-10-04 05:36:39,244 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:36:39,250 saving best model\n",
            "2022-10-04 05:36:39,980 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:36:43,621 epoch 6 - iter 20/209 - loss 0.08050086 - samples/sec: 176.18 - lr: 0.100000\n",
            "2022-10-04 05:36:46,745 epoch 6 - iter 40/209 - loss 0.06803591 - samples/sec: 205.22 - lr: 0.100000\n",
            "2022-10-04 05:36:51,294 epoch 6 - iter 60/209 - loss 0.06693076 - samples/sec: 140.83 - lr: 0.100000\n",
            "2022-10-04 05:36:54,861 epoch 6 - iter 80/209 - loss 0.06388079 - samples/sec: 179.65 - lr: 0.100000\n",
            "2022-10-04 05:36:59,538 epoch 6 - iter 100/209 - loss 0.06616947 - samples/sec: 137.01 - lr: 0.100000\n",
            "2022-10-04 05:37:03,520 epoch 6 - iter 120/209 - loss 0.06668201 - samples/sec: 161.00 - lr: 0.100000\n",
            "2022-10-04 05:37:07,198 epoch 6 - iter 140/209 - loss 0.06631223 - samples/sec: 174.25 - lr: 0.100000\n",
            "2022-10-04 05:37:10,368 epoch 6 - iter 160/209 - loss 0.06496243 - samples/sec: 202.18 - lr: 0.100000\n",
            "2022-10-04 05:37:14,550 epoch 6 - iter 180/209 - loss 0.06357033 - samples/sec: 153.20 - lr: 0.100000\n",
            "2022-10-04 05:37:18,300 epoch 6 - iter 200/209 - loss 0.06265147 - samples/sec: 170.83 - lr: 0.100000\n",
            "2022-10-04 05:37:19,419 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:37:19,421 EPOCH 6 done: loss 0.0628 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:37:28,788 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:37:28,803 DEV : loss 0.05483702942728996 - f1-score (micro avg)  0.7723\n",
            "2022-10-04 05:37:28,897 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 05:37:28,902 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:37:32,912 epoch 7 - iter 20/209 - loss 0.05176174 - samples/sec: 159.87 - lr: 0.100000\n",
            "2022-10-04 05:37:36,517 epoch 7 - iter 40/209 - loss 0.05748387 - samples/sec: 177.76 - lr: 0.100000\n",
            "2022-10-04 05:37:40,222 epoch 7 - iter 60/209 - loss 0.05191996 - samples/sec: 172.94 - lr: 0.100000\n",
            "2022-10-04 05:37:44,149 epoch 7 - iter 80/209 - loss 0.05435278 - samples/sec: 163.18 - lr: 0.100000\n",
            "2022-10-04 05:37:47,465 epoch 7 - iter 100/209 - loss 0.05488853 - samples/sec: 193.25 - lr: 0.100000\n",
            "2022-10-04 05:37:51,411 epoch 7 - iter 120/209 - loss 0.05544098 - samples/sec: 162.37 - lr: 0.100000\n",
            "2022-10-04 05:37:55,800 epoch 7 - iter 140/209 - loss 0.05728433 - samples/sec: 146.00 - lr: 0.100000\n",
            "2022-10-04 05:37:59,639 epoch 7 - iter 160/209 - loss 0.05720070 - samples/sec: 166.94 - lr: 0.100000\n",
            "2022-10-04 05:38:02,790 epoch 7 - iter 180/209 - loss 0.06002783 - samples/sec: 203.39 - lr: 0.100000\n",
            "2022-10-04 05:38:06,886 epoch 7 - iter 200/209 - loss 0.05787514 - samples/sec: 156.44 - lr: 0.100000\n",
            "2022-10-04 05:38:08,030 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:38:08,033 EPOCH 7 done: loss 0.0575 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:38:17,839 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:38:17,854 DEV : loss 0.05141553282737732 - f1-score (micro avg)  0.8043\n",
            "2022-10-04 05:38:17,948 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:38:17,953 saving best model\n",
            "2022-10-04 05:38:18,690 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:38:22,586 epoch 8 - iter 20/209 - loss 0.05908982 - samples/sec: 164.56 - lr: 0.100000\n",
            "2022-10-04 05:38:26,121 epoch 8 - iter 40/209 - loss 0.05477516 - samples/sec: 181.32 - lr: 0.100000\n",
            "2022-10-04 05:38:29,793 epoch 8 - iter 60/209 - loss 0.05725141 - samples/sec: 174.59 - lr: 0.100000\n",
            "2022-10-04 05:38:33,106 epoch 8 - iter 80/209 - loss 0.05718671 - samples/sec: 193.44 - lr: 0.100000\n",
            "2022-10-04 05:38:36,775 epoch 8 - iter 100/209 - loss 0.05187066 - samples/sec: 174.73 - lr: 0.100000\n",
            "2022-10-04 05:38:41,263 epoch 8 - iter 120/209 - loss 0.05067641 - samples/sec: 142.73 - lr: 0.100000\n",
            "2022-10-04 05:38:44,838 epoch 8 - iter 140/209 - loss 0.04973056 - samples/sec: 179.30 - lr: 0.100000\n",
            "2022-10-04 05:38:48,682 epoch 8 - iter 160/209 - loss 0.04965004 - samples/sec: 166.70 - lr: 0.100000\n",
            "2022-10-04 05:38:52,571 epoch 8 - iter 180/209 - loss 0.05011778 - samples/sec: 164.79 - lr: 0.100000\n",
            "2022-10-04 05:38:55,974 epoch 8 - iter 200/209 - loss 0.05205238 - samples/sec: 188.35 - lr: 0.100000\n",
            "2022-10-04 05:38:58,224 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:38:58,226 EPOCH 8 done: loss 0.0519 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:39:07,689 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:39:07,704 DEV : loss 0.05836400017142296 - f1-score (micro avg)  0.8198\n",
            "2022-10-04 05:39:07,797 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:39:07,816 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:39:08,528 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:39:12,255 epoch 9 - iter 20/209 - loss 0.05137884 - samples/sec: 172.13 - lr: 0.100000\n",
            "2022-10-04 05:39:16,000 epoch 9 - iter 40/209 - loss 0.05079334 - samples/sec: 171.07 - lr: 0.100000\n",
            "2022-10-04 05:39:19,720 epoch 9 - iter 60/209 - loss 0.05468352 - samples/sec: 172.30 - lr: 0.100000\n",
            "2022-10-04 05:39:22,863 epoch 9 - iter 80/209 - loss 0.05142707 - samples/sec: 203.90 - lr: 0.100000\n",
            "2022-10-04 05:39:27,191 epoch 9 - iter 100/209 - loss 0.05268009 - samples/sec: 148.04 - lr: 0.100000\n",
            "2022-10-04 05:39:30,722 epoch 9 - iter 120/209 - loss 0.05137849 - samples/sec: 181.48 - lr: 0.100000\n",
            "2022-10-04 05:39:34,130 epoch 9 - iter 140/209 - loss 0.05259436 - samples/sec: 188.11 - lr: 0.100000\n",
            "2022-10-04 05:39:37,881 epoch 9 - iter 160/209 - loss 0.05178342 - samples/sec: 170.85 - lr: 0.100000\n",
            "2022-10-04 05:39:41,865 epoch 9 - iter 180/209 - loss 0.04971440 - samples/sec: 160.79 - lr: 0.100000\n",
            "2022-10-04 05:39:45,780 epoch 9 - iter 200/209 - loss 0.04785726 - samples/sec: 163.66 - lr: 0.100000\n",
            "2022-10-04 05:39:47,274 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:39:47,276 EPOCH 9 done: loss 0.0484 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:39:56,945 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:39:56,962 DEV : loss 0.04702908545732498 - f1-score (micro avg)  0.8284\n",
            "2022-10-04 05:39:57,054 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:39:57,059 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:39:57,771 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:40:02,101 epoch 10 - iter 20/209 - loss 0.04537652 - samples/sec: 148.01 - lr: 0.100000\n",
            "2022-10-04 05:40:06,304 epoch 10 - iter 40/209 - loss 0.04432074 - samples/sec: 152.45 - lr: 0.100000\n",
            "2022-10-04 05:40:10,056 epoch 10 - iter 60/209 - loss 0.04668812 - samples/sec: 170.77 - lr: 0.100000\n",
            "2022-10-04 05:40:13,794 epoch 10 - iter 80/209 - loss 0.04152727 - samples/sec: 171.44 - lr: 0.100000\n",
            "2022-10-04 05:40:17,347 epoch 10 - iter 100/209 - loss 0.04189730 - samples/sec: 180.37 - lr: 0.100000\n",
            "2022-10-04 05:40:20,988 epoch 10 - iter 120/209 - loss 0.04122967 - samples/sec: 176.00 - lr: 0.100000\n",
            "2022-10-04 05:40:24,621 epoch 10 - iter 140/209 - loss 0.04105762 - samples/sec: 176.43 - lr: 0.100000\n",
            "2022-10-04 05:40:28,249 epoch 10 - iter 160/209 - loss 0.04178446 - samples/sec: 176.61 - lr: 0.100000\n",
            "2022-10-04 05:40:32,256 epoch 10 - iter 180/209 - loss 0.04137126 - samples/sec: 159.94 - lr: 0.100000\n",
            "2022-10-04 05:40:35,466 epoch 10 - iter 200/209 - loss 0.04188418 - samples/sec: 199.72 - lr: 0.100000\n",
            "2022-10-04 05:40:37,005 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:40:37,007 EPOCH 10 done: loss 0.0421 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:40:46,142 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:40:46,157 DEV : loss 0.04637054726481438 - f1-score (micro avg)  0.845\n",
            "2022-10-04 05:40:46,250 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:40:46,255 saving best model\n",
            "2022-10-04 05:40:46,989 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:40:50,784 epoch 11 - iter 20/209 - loss 0.04803611 - samples/sec: 168.97 - lr: 0.100000\n",
            "2022-10-04 05:40:54,753 epoch 11 - iter 40/209 - loss 0.04129475 - samples/sec: 161.46 - lr: 0.100000\n",
            "2022-10-04 05:40:58,904 epoch 11 - iter 60/209 - loss 0.04004095 - samples/sec: 154.38 - lr: 0.100000\n",
            "2022-10-04 05:41:02,657 epoch 11 - iter 80/209 - loss 0.03931082 - samples/sec: 170.79 - lr: 0.100000\n",
            "2022-10-04 05:41:06,239 epoch 11 - iter 100/209 - loss 0.04074366 - samples/sec: 178.88 - lr: 0.100000\n",
            "2022-10-04 05:41:09,368 epoch 11 - iter 120/209 - loss 0.04208986 - samples/sec: 204.80 - lr: 0.100000\n",
            "2022-10-04 05:41:12,891 epoch 11 - iter 140/209 - loss 0.04090900 - samples/sec: 181.89 - lr: 0.100000\n",
            "2022-10-04 05:41:16,382 epoch 11 - iter 160/209 - loss 0.04133570 - samples/sec: 183.60 - lr: 0.100000\n",
            "2022-10-04 05:41:20,061 epoch 11 - iter 180/209 - loss 0.04088173 - samples/sec: 174.18 - lr: 0.100000\n",
            "2022-10-04 05:41:23,676 epoch 11 - iter 200/209 - loss 0.04012152 - samples/sec: 177.22 - lr: 0.100000\n",
            "2022-10-04 05:41:26,152 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:41:26,155 EPOCH 11 done: loss 0.0407 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:41:35,883 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:41:35,898 DEV : loss 0.04224751144647598 - f1-score (micro avg)  0.8389\n",
            "2022-10-04 05:41:35,990 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 05:41:35,996 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:41:39,667 epoch 12 - iter 20/209 - loss 0.02952437 - samples/sec: 174.65 - lr: 0.100000\n",
            "2022-10-04 05:41:43,577 epoch 12 - iter 40/209 - loss 0.03868607 - samples/sec: 163.87 - lr: 0.100000\n",
            "2022-10-04 05:41:47,099 epoch 12 - iter 60/209 - loss 0.04154795 - samples/sec: 181.93 - lr: 0.100000\n",
            "2022-10-04 05:41:51,116 epoch 12 - iter 80/209 - loss 0.04442386 - samples/sec: 159.52 - lr: 0.100000\n",
            "2022-10-04 05:41:55,025 epoch 12 - iter 100/209 - loss 0.04329236 - samples/sec: 163.92 - lr: 0.100000\n",
            "2022-10-04 05:41:58,869 epoch 12 - iter 120/209 - loss 0.04199310 - samples/sec: 166.68 - lr: 0.100000\n",
            "2022-10-04 05:42:02,462 epoch 12 - iter 140/209 - loss 0.04090710 - samples/sec: 178.39 - lr: 0.100000\n",
            "2022-10-04 05:42:05,924 epoch 12 - iter 160/209 - loss 0.03949522 - samples/sec: 185.11 - lr: 0.100000\n",
            "2022-10-04 05:42:09,338 epoch 12 - iter 180/209 - loss 0.03881091 - samples/sec: 187.70 - lr: 0.100000\n",
            "2022-10-04 05:42:12,569 epoch 12 - iter 200/209 - loss 0.03860072 - samples/sec: 198.39 - lr: 0.100000\n",
            "2022-10-04 05:42:14,062 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:42:14,064 EPOCH 12 done: loss 0.0387 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:42:23,388 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:42:23,403 DEV : loss 0.038745809346437454 - f1-score (micro avg)  0.8444\n",
            "2022-10-04 05:42:23,493 BAD EPOCHS (no improvement): 2\n",
            "2022-10-04 05:42:23,500 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:42:26,830 epoch 13 - iter 20/209 - loss 0.03649700 - samples/sec: 192.63 - lr: 0.100000\n",
            "2022-10-04 05:42:31,094 epoch 13 - iter 40/209 - loss 0.03491071 - samples/sec: 150.26 - lr: 0.100000\n",
            "2022-10-04 05:42:34,876 epoch 13 - iter 60/209 - loss 0.03224873 - samples/sec: 169.44 - lr: 0.100000\n",
            "2022-10-04 05:42:38,921 epoch 13 - iter 80/209 - loss 0.03186616 - samples/sec: 158.45 - lr: 0.100000\n",
            "2022-10-04 05:42:42,760 epoch 13 - iter 100/209 - loss 0.03034522 - samples/sec: 166.98 - lr: 0.100000\n",
            "2022-10-04 05:42:46,261 epoch 13 - iter 120/209 - loss 0.03315228 - samples/sec: 183.01 - lr: 0.100000\n",
            "2022-10-04 05:42:50,365 epoch 13 - iter 140/209 - loss 0.03388766 - samples/sec: 156.14 - lr: 0.100000\n",
            "2022-10-04 05:42:53,720 epoch 13 - iter 160/209 - loss 0.03317680 - samples/sec: 191.01 - lr: 0.100000\n",
            "2022-10-04 05:42:57,493 epoch 13 - iter 180/209 - loss 0.03358853 - samples/sec: 169.85 - lr: 0.100000\n",
            "2022-10-04 05:43:01,984 epoch 13 - iter 200/209 - loss 0.03466333 - samples/sec: 142.75 - lr: 0.100000\n",
            "2022-10-04 05:43:03,375 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:43:03,377 EPOCH 13 done: loss 0.0360 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:43:12,834 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:43:12,849 DEV : loss 0.04167303070425987 - f1-score (micro avg)  0.8363\n",
            "2022-10-04 05:43:12,942 BAD EPOCHS (no improvement): 3\n",
            "2022-10-04 05:43:12,949 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:43:17,315 epoch 14 - iter 20/209 - loss 0.02980401 - samples/sec: 146.82 - lr: 0.100000\n",
            "2022-10-04 05:43:21,131 epoch 14 - iter 40/209 - loss 0.03006117 - samples/sec: 167.93 - lr: 0.100000\n",
            "2022-10-04 05:43:24,700 epoch 14 - iter 60/209 - loss 0.02943008 - samples/sec: 179.55 - lr: 0.100000\n",
            "2022-10-04 05:43:28,553 epoch 14 - iter 80/209 - loss 0.02679424 - samples/sec: 166.32 - lr: 0.100000\n",
            "2022-10-04 05:43:32,978 epoch 14 - iter 100/209 - loss 0.02877195 - samples/sec: 144.79 - lr: 0.100000\n",
            "2022-10-04 05:43:36,575 epoch 14 - iter 120/209 - loss 0.02874556 - samples/sec: 178.15 - lr: 0.100000\n",
            "2022-10-04 05:43:40,024 epoch 14 - iter 140/209 - loss 0.03066637 - samples/sec: 185.87 - lr: 0.100000\n",
            "2022-10-04 05:43:43,236 epoch 14 - iter 160/209 - loss 0.03423040 - samples/sec: 199.53 - lr: 0.100000\n",
            "2022-10-04 05:43:47,486 epoch 14 - iter 180/209 - loss 0.03420059 - samples/sec: 150.81 - lr: 0.100000\n",
            "2022-10-04 05:43:50,810 epoch 14 - iter 200/209 - loss 0.03334038 - samples/sec: 192.78 - lr: 0.100000\n",
            "2022-10-04 05:43:52,067 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:43:52,069 EPOCH 14 done: loss 0.0330 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:44:01,572 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:44:01,591 DEV : loss 0.041958753019571304 - f1-score (micro avg)  0.8506\n",
            "2022-10-04 05:44:01,683 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:44:01,689 saving best model\n",
            "2022-10-04 05:44:02,416 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:44:07,097 epoch 15 - iter 20/209 - loss 0.03153648 - samples/sec: 136.92 - lr: 0.100000\n",
            "2022-10-04 05:44:11,126 epoch 15 - iter 40/209 - loss 0.03033912 - samples/sec: 159.08 - lr: 0.100000\n",
            "2022-10-04 05:44:15,248 epoch 15 - iter 60/209 - loss 0.02844562 - samples/sec: 155.42 - lr: 0.100000\n",
            "2022-10-04 05:44:18,658 epoch 15 - iter 80/209 - loss 0.02861322 - samples/sec: 187.97 - lr: 0.100000\n",
            "2022-10-04 05:44:22,858 epoch 15 - iter 100/209 - loss 0.02819313 - samples/sec: 152.54 - lr: 0.100000\n",
            "2022-10-04 05:44:26,402 epoch 15 - iter 120/209 - loss 0.02720257 - samples/sec: 180.84 - lr: 0.100000\n",
            "2022-10-04 05:44:30,063 epoch 15 - iter 140/209 - loss 0.02749227 - samples/sec: 175.05 - lr: 0.100000\n",
            "2022-10-04 05:44:33,376 epoch 15 - iter 160/209 - loss 0.02946278 - samples/sec: 193.43 - lr: 0.100000\n",
            "2022-10-04 05:44:37,255 epoch 15 - iter 180/209 - loss 0.02958335 - samples/sec: 165.16 - lr: 0.100000\n",
            "2022-10-04 05:44:40,375 epoch 15 - iter 200/209 - loss 0.03010790 - samples/sec: 205.44 - lr: 0.100000\n",
            "2022-10-04 05:44:42,043 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:44:42,046 EPOCH 15 done: loss 0.0299 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:44:51,192 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:44:51,207 DEV : loss 0.03923148289322853 - f1-score (micro avg)  0.8684\n",
            "2022-10-04 05:44:51,300 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:44:51,307 saving best model\n",
            "2022-10-04 05:44:52,025 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:44:56,392 epoch 16 - iter 20/209 - loss 0.02720362 - samples/sec: 146.76 - lr: 0.100000\n",
            "2022-10-04 05:45:00,269 epoch 16 - iter 40/209 - loss 0.02586910 - samples/sec: 165.29 - lr: 0.100000\n",
            "2022-10-04 05:45:05,358 epoch 16 - iter 60/209 - loss 0.02616053 - samples/sec: 125.89 - lr: 0.100000\n",
            "2022-10-04 05:45:08,757 epoch 16 - iter 80/209 - loss 0.02676294 - samples/sec: 188.55 - lr: 0.100000\n",
            "2022-10-04 05:45:12,199 epoch 16 - iter 100/209 - loss 0.02575664 - samples/sec: 186.21 - lr: 0.100000\n",
            "2022-10-04 05:45:15,858 epoch 16 - iter 120/209 - loss 0.02702852 - samples/sec: 175.14 - lr: 0.100000\n",
            "2022-10-04 05:45:20,091 epoch 16 - iter 140/209 - loss 0.02727540 - samples/sec: 151.36 - lr: 0.100000\n",
            "2022-10-04 05:45:23,495 epoch 16 - iter 160/209 - loss 0.02849544 - samples/sec: 188.26 - lr: 0.100000\n",
            "2022-10-04 05:45:27,019 epoch 16 - iter 180/209 - loss 0.02883596 - samples/sec: 181.84 - lr: 0.100000\n",
            "2022-10-04 05:45:30,530 epoch 16 - iter 200/209 - loss 0.02891081 - samples/sec: 182.49 - lr: 0.100000\n",
            "2022-10-04 05:45:32,257 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:45:32,260 EPOCH 16 done: loss 0.0292 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:45:41,411 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:45:41,426 DEV : loss 0.04206893965601921 - f1-score (micro avg)  0.8566\n",
            "2022-10-04 05:45:41,521 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 05:45:41,525 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:45:45,159 epoch 17 - iter 20/209 - loss 0.02986693 - samples/sec: 176.46 - lr: 0.100000\n",
            "2022-10-04 05:45:48,857 epoch 17 - iter 40/209 - loss 0.02741694 - samples/sec: 173.27 - lr: 0.100000\n",
            "2022-10-04 05:45:52,555 epoch 17 - iter 60/209 - loss 0.03001159 - samples/sec: 173.30 - lr: 0.100000\n",
            "2022-10-04 05:45:56,091 epoch 17 - iter 80/209 - loss 0.02903714 - samples/sec: 181.26 - lr: 0.100000\n",
            "2022-10-04 05:45:59,639 epoch 17 - iter 100/209 - loss 0.02638125 - samples/sec: 180.62 - lr: 0.100000\n",
            "2022-10-04 05:46:02,875 epoch 17 - iter 120/209 - loss 0.02739707 - samples/sec: 198.07 - lr: 0.100000\n",
            "2022-10-04 05:46:06,468 epoch 17 - iter 140/209 - loss 0.02828226 - samples/sec: 178.36 - lr: 0.100000\n",
            "2022-10-04 05:46:10,686 epoch 17 - iter 160/209 - loss 0.02710349 - samples/sec: 151.88 - lr: 0.100000\n",
            "2022-10-04 05:46:14,145 epoch 17 - iter 180/209 - loss 0.02596510 - samples/sec: 185.29 - lr: 0.100000\n",
            "2022-10-04 05:46:18,390 epoch 17 - iter 200/209 - loss 0.02678328 - samples/sec: 150.94 - lr: 0.100000\n",
            "2022-10-04 05:46:20,728 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:46:20,730 EPOCH 17 done: loss 0.0275 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:46:29,970 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:46:29,985 DEV : loss 0.03701391816139221 - f1-score (micro avg)  0.8631\n",
            "2022-10-04 05:46:30,076 BAD EPOCHS (no improvement): 2\n",
            "2022-10-04 05:46:30,081 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:46:33,410 epoch 18 - iter 20/209 - loss 0.02169776 - samples/sec: 192.60 - lr: 0.100000\n",
            "2022-10-04 05:46:37,212 epoch 18 - iter 40/209 - loss 0.01960079 - samples/sec: 168.56 - lr: 0.100000\n",
            "2022-10-04 05:46:41,077 epoch 18 - iter 60/209 - loss 0.01910406 - samples/sec: 165.79 - lr: 0.100000\n",
            "2022-10-04 05:46:45,173 epoch 18 - iter 80/209 - loss 0.02373642 - samples/sec: 156.42 - lr: 0.100000\n",
            "2022-10-04 05:46:48,448 epoch 18 - iter 100/209 - loss 0.02729723 - samples/sec: 195.67 - lr: 0.100000\n",
            "2022-10-04 05:46:52,246 epoch 18 - iter 120/209 - loss 0.02869175 - samples/sec: 168.72 - lr: 0.100000\n",
            "2022-10-04 05:46:55,701 epoch 18 - iter 140/209 - loss 0.02813674 - samples/sec: 185.45 - lr: 0.100000\n",
            "2022-10-04 05:46:58,895 epoch 18 - iter 160/209 - loss 0.02726586 - samples/sec: 200.60 - lr: 0.100000\n",
            "2022-10-04 05:47:02,981 epoch 18 - iter 180/209 - loss 0.02706907 - samples/sec: 156.81 - lr: 0.100000\n",
            "2022-10-04 05:47:07,570 epoch 18 - iter 200/209 - loss 0.02756986 - samples/sec: 139.64 - lr: 0.100000\n",
            "2022-10-04 05:47:09,078 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:47:09,081 EPOCH 18 done: loss 0.0272 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:47:18,189 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:47:18,204 DEV : loss 0.04064689949154854 - f1-score (micro avg)  0.8612\n",
            "2022-10-04 05:47:18,296 BAD EPOCHS (no improvement): 3\n",
            "2022-10-04 05:47:18,301 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:47:21,671 epoch 19 - iter 20/209 - loss 0.02606302 - samples/sec: 190.28 - lr: 0.100000\n",
            "2022-10-04 05:47:25,972 epoch 19 - iter 40/209 - loss 0.02666914 - samples/sec: 148.94 - lr: 0.100000\n",
            "2022-10-04 05:47:30,321 epoch 19 - iter 60/209 - loss 0.03160707 - samples/sec: 147.32 - lr: 0.100000\n",
            "2022-10-04 05:47:34,427 epoch 19 - iter 80/209 - loss 0.02834404 - samples/sec: 156.08 - lr: 0.100000\n",
            "2022-10-04 05:47:38,245 epoch 19 - iter 100/209 - loss 0.02676546 - samples/sec: 167.83 - lr: 0.100000\n",
            "2022-10-04 05:47:41,361 epoch 19 - iter 120/209 - loss 0.02596884 - samples/sec: 205.66 - lr: 0.100000\n",
            "2022-10-04 05:47:45,491 epoch 19 - iter 140/209 - loss 0.02564724 - samples/sec: 155.16 - lr: 0.100000\n",
            "2022-10-04 05:47:48,901 epoch 19 - iter 160/209 - loss 0.02579106 - samples/sec: 187.91 - lr: 0.100000\n",
            "2022-10-04 05:47:52,420 epoch 19 - iter 180/209 - loss 0.02626600 - samples/sec: 182.10 - lr: 0.100000\n",
            "2022-10-04 05:47:55,732 epoch 19 - iter 200/209 - loss 0.02628235 - samples/sec: 193.53 - lr: 0.100000\n",
            "2022-10-04 05:47:57,084 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:47:57,086 EPOCH 19 done: loss 0.0265 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:48:06,388 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:48:06,403 DEV : loss 0.03446009382605553 - f1-score (micro avg)  0.8603\n",
            "2022-10-04 05:48:06,496 Epoch    19: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2022-10-04 05:48:06,498 BAD EPOCHS (no improvement): 4\n",
            "2022-10-04 05:48:06,505 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:48:10,061 epoch 20 - iter 20/209 - loss 0.02072532 - samples/sec: 180.25 - lr: 0.050000\n",
            "2022-10-04 05:48:14,061 epoch 20 - iter 40/209 - loss 0.01947552 - samples/sec: 160.19 - lr: 0.050000\n",
            "2022-10-04 05:48:17,498 epoch 20 - iter 60/209 - loss 0.02158679 - samples/sec: 186.43 - lr: 0.050000\n",
            "2022-10-04 05:48:20,973 epoch 20 - iter 80/209 - loss 0.02216467 - samples/sec: 184.43 - lr: 0.050000\n",
            "2022-10-04 05:48:24,194 epoch 20 - iter 100/209 - loss 0.02130723 - samples/sec: 198.94 - lr: 0.050000\n",
            "2022-10-04 05:48:27,854 epoch 20 - iter 120/209 - loss 0.02234719 - samples/sec: 175.14 - lr: 0.050000\n",
            "2022-10-04 05:48:31,701 epoch 20 - iter 140/209 - loss 0.02191465 - samples/sec: 166.56 - lr: 0.050000\n",
            "2022-10-04 05:48:35,858 epoch 20 - iter 160/209 - loss 0.02197061 - samples/sec: 154.12 - lr: 0.050000\n",
            "2022-10-04 05:48:39,446 epoch 20 - iter 180/209 - loss 0.02129801 - samples/sec: 178.60 - lr: 0.050000\n",
            "2022-10-04 05:48:44,414 epoch 20 - iter 200/209 - loss 0.02088105 - samples/sec: 128.94 - lr: 0.050000\n",
            "2022-10-04 05:48:45,646 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:48:45,648 EPOCH 20 done: loss 0.0206 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:48:55,279 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:48:55,294 DEV : loss 0.03424276411533356 - f1-score (micro avg)  0.8741\n",
            "2022-10-04 05:48:55,384 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:48:55,389 saving best model\n",
            "2022-10-04 05:48:56,100 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:49:00,410 epoch 21 - iter 20/209 - loss 0.02000345 - samples/sec: 148.72 - lr: 0.050000\n",
            "2022-10-04 05:49:03,353 epoch 21 - iter 40/209 - loss 0.01988644 - samples/sec: 217.81 - lr: 0.050000\n",
            "2022-10-04 05:49:07,322 epoch 21 - iter 60/209 - loss 0.01749872 - samples/sec: 161.43 - lr: 0.050000\n",
            "2022-10-04 05:49:11,287 epoch 21 - iter 80/209 - loss 0.01635425 - samples/sec: 161.61 - lr: 0.050000\n",
            "2022-10-04 05:49:14,779 epoch 21 - iter 100/209 - loss 0.01716428 - samples/sec: 183.57 - lr: 0.050000\n",
            "2022-10-04 05:49:19,372 epoch 21 - iter 120/209 - loss 0.01668688 - samples/sec: 139.49 - lr: 0.050000\n",
            "2022-10-04 05:49:22,611 epoch 21 - iter 140/209 - loss 0.01686328 - samples/sec: 197.91 - lr: 0.050000\n",
            "2022-10-04 05:49:26,363 epoch 21 - iter 160/209 - loss 0.01739001 - samples/sec: 170.83 - lr: 0.050000\n",
            "2022-10-04 05:49:29,579 epoch 21 - iter 180/209 - loss 0.01747740 - samples/sec: 199.27 - lr: 0.050000\n",
            "2022-10-04 05:49:33,297 epoch 21 - iter 200/209 - loss 0.01759878 - samples/sec: 172.37 - lr: 0.050000\n",
            "2022-10-04 05:49:35,199 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:49:35,201 EPOCH 21 done: loss 0.0174 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:49:44,666 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:49:44,681 DEV : loss 0.03426947444677353 - f1-score (micro avg)  0.8881\n",
            "2022-10-04 05:49:44,774 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:49:44,779 saving best model\n",
            "2022-10-04 05:49:45,487 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:49:50,354 epoch 22 - iter 20/209 - loss 0.02030395 - samples/sec: 131.71 - lr: 0.050000\n",
            "2022-10-04 05:49:54,108 epoch 22 - iter 40/209 - loss 0.01579204 - samples/sec: 170.75 - lr: 0.050000\n",
            "2022-10-04 05:49:57,850 epoch 22 - iter 60/209 - loss 0.01481956 - samples/sec: 171.33 - lr: 0.050000\n",
            "2022-10-04 05:50:01,161 epoch 22 - iter 80/209 - loss 0.01532455 - samples/sec: 193.60 - lr: 0.050000\n",
            "2022-10-04 05:50:05,046 epoch 22 - iter 100/209 - loss 0.01842723 - samples/sec: 164.93 - lr: 0.050000\n",
            "2022-10-04 05:50:09,146 epoch 22 - iter 120/209 - loss 0.01686300 - samples/sec: 156.29 - lr: 0.050000\n",
            "2022-10-04 05:50:12,855 epoch 22 - iter 140/209 - loss 0.01750032 - samples/sec: 172.78 - lr: 0.050000\n",
            "2022-10-04 05:50:16,476 epoch 22 - iter 160/209 - loss 0.01738387 - samples/sec: 176.96 - lr: 0.050000\n",
            "2022-10-04 05:50:19,918 epoch 22 - iter 180/209 - loss 0.01737593 - samples/sec: 186.18 - lr: 0.050000\n",
            "2022-10-04 05:50:23,107 epoch 22 - iter 200/209 - loss 0.01700482 - samples/sec: 201.03 - lr: 0.050000\n",
            "2022-10-04 05:50:24,564 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:50:24,567 EPOCH 22 done: loss 0.0168 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:50:34,468 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:50:34,483 DEV : loss 0.03882388770580292 - f1-score (micro avg)  0.8726\n",
            "2022-10-04 05:50:34,576 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 05:50:34,585 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:50:37,749 epoch 23 - iter 20/209 - loss 0.01449184 - samples/sec: 202.61 - lr: 0.050000\n",
            "2022-10-04 05:50:42,093 epoch 23 - iter 40/209 - loss 0.01550535 - samples/sec: 147.51 - lr: 0.050000\n",
            "2022-10-04 05:50:46,674 epoch 23 - iter 60/209 - loss 0.01751384 - samples/sec: 139.84 - lr: 0.050000\n",
            "2022-10-04 05:50:50,366 epoch 23 - iter 80/209 - loss 0.01744938 - samples/sec: 173.57 - lr: 0.050000\n",
            "2022-10-04 05:50:53,712 epoch 23 - iter 100/209 - loss 0.01735984 - samples/sec: 191.59 - lr: 0.050000\n",
            "2022-10-04 05:50:57,119 epoch 23 - iter 120/209 - loss 0.01697531 - samples/sec: 188.11 - lr: 0.050000\n",
            "2022-10-04 05:51:01,039 epoch 23 - iter 140/209 - loss 0.01668240 - samples/sec: 163.46 - lr: 0.050000\n",
            "2022-10-04 05:51:04,819 epoch 23 - iter 160/209 - loss 0.01726318 - samples/sec: 169.58 - lr: 0.050000\n",
            "2022-10-04 05:51:08,128 epoch 23 - iter 180/209 - loss 0.01818698 - samples/sec: 193.70 - lr: 0.050000\n",
            "2022-10-04 05:51:11,827 epoch 23 - iter 200/209 - loss 0.01741258 - samples/sec: 173.23 - lr: 0.050000\n",
            "2022-10-04 05:51:13,855 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:51:13,856 EPOCH 23 done: loss 0.0176 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:51:22,945 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:51:22,960 DEV : loss 0.041657477617263794 - f1-score (micro avg)  0.8528\n",
            "2022-10-04 05:51:23,052 BAD EPOCHS (no improvement): 2\n",
            "2022-10-04 05:51:23,057 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:51:26,779 epoch 24 - iter 20/209 - loss 0.01655219 - samples/sec: 172.19 - lr: 0.050000\n",
            "2022-10-04 05:51:30,340 epoch 24 - iter 40/209 - loss 0.02004088 - samples/sec: 179.98 - lr: 0.050000\n",
            "2022-10-04 05:51:33,889 epoch 24 - iter 60/209 - loss 0.01968991 - samples/sec: 180.58 - lr: 0.050000\n",
            "2022-10-04 05:51:38,097 epoch 24 - iter 80/209 - loss 0.01905586 - samples/sec: 152.24 - lr: 0.050000\n",
            "2022-10-04 05:51:41,078 epoch 24 - iter 100/209 - loss 0.01956661 - samples/sec: 215.07 - lr: 0.050000\n",
            "2022-10-04 05:51:44,968 epoch 24 - iter 120/209 - loss 0.01836147 - samples/sec: 164.70 - lr: 0.050000\n",
            "2022-10-04 05:51:48,370 epoch 24 - iter 140/209 - loss 0.01791639 - samples/sec: 188.38 - lr: 0.050000\n",
            "2022-10-04 05:51:52,046 epoch 24 - iter 160/209 - loss 0.01739429 - samples/sec: 174.29 - lr: 0.050000\n",
            "2022-10-04 05:51:55,881 epoch 24 - iter 180/209 - loss 0.01659935 - samples/sec: 167.10 - lr: 0.050000\n",
            "2022-10-04 05:52:00,091 epoch 24 - iter 200/209 - loss 0.01643591 - samples/sec: 152.18 - lr: 0.050000\n",
            "2022-10-04 05:52:01,724 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:52:01,726 EPOCH 24 done: loss 0.0163 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:52:11,713 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:52:11,728 DEV : loss 0.03571942076086998 - f1-score (micro avg)  0.8854\n",
            "2022-10-04 05:52:11,818 BAD EPOCHS (no improvement): 3\n",
            "2022-10-04 05:52:11,824 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:52:15,465 epoch 25 - iter 20/209 - loss 0.01993831 - samples/sec: 176.08 - lr: 0.050000\n",
            "2022-10-04 05:52:18,967 epoch 25 - iter 40/209 - loss 0.01650090 - samples/sec: 182.98 - lr: 0.050000\n",
            "2022-10-04 05:52:22,666 epoch 25 - iter 60/209 - loss 0.01470098 - samples/sec: 173.32 - lr: 0.050000\n",
            "2022-10-04 05:52:26,845 epoch 25 - iter 80/209 - loss 0.01561499 - samples/sec: 153.31 - lr: 0.050000\n",
            "2022-10-04 05:52:30,292 epoch 25 - iter 100/209 - loss 0.01538331 - samples/sec: 185.96 - lr: 0.050000\n",
            "2022-10-04 05:52:34,244 epoch 25 - iter 120/209 - loss 0.01586565 - samples/sec: 162.14 - lr: 0.050000\n",
            "2022-10-04 05:52:37,802 epoch 25 - iter 140/209 - loss 0.01554579 - samples/sec: 180.09 - lr: 0.050000\n",
            "2022-10-04 05:52:41,752 epoch 25 - iter 160/209 - loss 0.01558129 - samples/sec: 162.20 - lr: 0.050000\n",
            "2022-10-04 05:52:45,594 epoch 25 - iter 180/209 - loss 0.01539162 - samples/sec: 166.80 - lr: 0.050000\n",
            "2022-10-04 05:52:49,179 epoch 25 - iter 200/209 - loss 0.01534383 - samples/sec: 178.76 - lr: 0.050000\n",
            "2022-10-04 05:52:50,566 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:52:50,569 EPOCH 25 done: loss 0.0152 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:52:59,780 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:52:59,795 DEV : loss 0.03778481110930443 - f1-score (micro avg)  0.8821\n",
            "2022-10-04 05:52:59,886 Epoch    25: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2022-10-04 05:52:59,889 BAD EPOCHS (no improvement): 4\n",
            "2022-10-04 05:52:59,894 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:53:03,399 epoch 26 - iter 20/209 - loss 0.01967255 - samples/sec: 182.95 - lr: 0.025000\n",
            "2022-10-04 05:53:06,934 epoch 26 - iter 40/209 - loss 0.01463242 - samples/sec: 181.26 - lr: 0.025000\n",
            "2022-10-04 05:53:10,288 epoch 26 - iter 60/209 - loss 0.01412666 - samples/sec: 191.11 - lr: 0.025000\n",
            "2022-10-04 05:53:13,930 epoch 26 - iter 80/209 - loss 0.01378679 - samples/sec: 175.94 - lr: 0.025000\n",
            "2022-10-04 05:53:18,273 epoch 26 - iter 100/209 - loss 0.01434530 - samples/sec: 147.53 - lr: 0.025000\n",
            "2022-10-04 05:53:22,319 epoch 26 - iter 120/209 - loss 0.01344290 - samples/sec: 158.36 - lr: 0.025000\n",
            "2022-10-04 05:53:25,992 epoch 26 - iter 140/209 - loss 0.01340357 - samples/sec: 174.52 - lr: 0.025000\n",
            "2022-10-04 05:53:30,217 epoch 26 - iter 160/209 - loss 0.01362597 - samples/sec: 151.63 - lr: 0.025000\n",
            "2022-10-04 05:53:33,512 epoch 26 - iter 180/209 - loss 0.01330793 - samples/sec: 194.47 - lr: 0.025000\n",
            "2022-10-04 05:53:37,548 epoch 26 - iter 200/209 - loss 0.01357656 - samples/sec: 158.75 - lr: 0.025000\n",
            "2022-10-04 05:53:38,778 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:53:38,780 EPOCH 26 done: loss 0.0133 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:53:48,435 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:53:48,451 DEV : loss 0.03459864482283592 - f1-score (micro avg)  0.8825\n",
            "2022-10-04 05:53:48,541 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 05:53:48,546 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:53:52,578 epoch 27 - iter 20/209 - loss 0.01175891 - samples/sec: 158.99 - lr: 0.025000\n",
            "2022-10-04 05:53:56,133 epoch 27 - iter 40/209 - loss 0.01106545 - samples/sec: 180.22 - lr: 0.025000\n",
            "2022-10-04 05:53:59,489 epoch 27 - iter 60/209 - loss 0.01069050 - samples/sec: 190.98 - lr: 0.025000\n",
            "2022-10-04 05:54:02,958 epoch 27 - iter 80/209 - loss 0.01132348 - samples/sec: 184.69 - lr: 0.025000\n",
            "2022-10-04 05:54:07,106 epoch 27 - iter 100/209 - loss 0.01228738 - samples/sec: 154.49 - lr: 0.025000\n",
            "2022-10-04 05:54:11,024 epoch 27 - iter 120/209 - loss 0.01309411 - samples/sec: 163.58 - lr: 0.025000\n",
            "2022-10-04 05:54:14,470 epoch 27 - iter 140/209 - loss 0.01345793 - samples/sec: 185.95 - lr: 0.025000\n",
            "2022-10-04 05:54:18,162 epoch 27 - iter 160/209 - loss 0.01393774 - samples/sec: 173.55 - lr: 0.025000\n",
            "2022-10-04 05:54:21,934 epoch 27 - iter 180/209 - loss 0.01335527 - samples/sec: 169.92 - lr: 0.025000\n",
            "2022-10-04 05:54:25,135 epoch 27 - iter 200/209 - loss 0.01298843 - samples/sec: 200.22 - lr: 0.025000\n",
            "2022-10-04 05:54:27,332 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:54:27,334 EPOCH 27 done: loss 0.0130 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:54:36,554 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:54:36,571 DEV : loss 0.034660086035728455 - f1-score (micro avg)  0.8906\n",
            "2022-10-04 05:54:36,661 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:54:36,668 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:54:37,393 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:54:41,040 epoch 28 - iter 20/209 - loss 0.01054552 - samples/sec: 176.07 - lr: 0.025000\n",
            "2022-10-04 05:54:44,946 epoch 28 - iter 40/209 - loss 0.01374067 - samples/sec: 164.04 - lr: 0.025000\n",
            "2022-10-04 05:54:48,599 epoch 28 - iter 60/209 - loss 0.01201335 - samples/sec: 175.56 - lr: 0.025000\n",
            "2022-10-04 05:54:52,494 epoch 28 - iter 80/209 - loss 0.01254415 - samples/sec: 164.49 - lr: 0.025000\n",
            "2022-10-04 05:54:56,144 epoch 28 - iter 100/209 - loss 0.01342201 - samples/sec: 175.59 - lr: 0.025000\n",
            "2022-10-04 05:55:00,062 epoch 28 - iter 120/209 - loss 0.01298945 - samples/sec: 163.55 - lr: 0.025000\n",
            "2022-10-04 05:55:03,336 epoch 28 - iter 140/209 - loss 0.01266880 - samples/sec: 195.80 - lr: 0.025000\n",
            "2022-10-04 05:55:07,579 epoch 28 - iter 160/209 - loss 0.01261674 - samples/sec: 151.04 - lr: 0.025000\n",
            "2022-10-04 05:55:11,633 epoch 28 - iter 180/209 - loss 0.01288221 - samples/sec: 158.02 - lr: 0.025000\n",
            "2022-10-04 05:55:14,903 epoch 28 - iter 200/209 - loss 0.01308371 - samples/sec: 196.00 - lr: 0.025000\n",
            "2022-10-04 05:55:16,399 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:55:16,401 EPOCH 28 done: loss 0.0129 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:55:26,249 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:55:26,265 DEV : loss 0.03398394212126732 - f1-score (micro avg)  0.8971\n",
            "2022-10-04 05:55:26,355 BAD EPOCHS (no improvement): 0\n",
            "2022-10-04 05:55:26,361 saving best model\n",
            "2022-10-04 05:55:27,089 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:55:30,894 epoch 29 - iter 20/209 - loss 0.00919966 - samples/sec: 168.46 - lr: 0.025000\n",
            "2022-10-04 05:55:34,135 epoch 29 - iter 40/209 - loss 0.01038876 - samples/sec: 197.78 - lr: 0.025000\n",
            "2022-10-04 05:55:37,525 epoch 29 - iter 60/209 - loss 0.01092163 - samples/sec: 189.20 - lr: 0.025000\n",
            "2022-10-04 05:55:41,740 epoch 29 - iter 80/209 - loss 0.01215935 - samples/sec: 151.98 - lr: 0.025000\n",
            "2022-10-04 05:55:44,830 epoch 29 - iter 100/209 - loss 0.01162038 - samples/sec: 207.46 - lr: 0.025000\n",
            "2022-10-04 05:55:49,004 epoch 29 - iter 120/209 - loss 0.01227539 - samples/sec: 153.48 - lr: 0.025000\n",
            "2022-10-04 05:55:52,653 epoch 29 - iter 140/209 - loss 0.01126877 - samples/sec: 175.63 - lr: 0.025000\n",
            "2022-10-04 05:55:55,941 epoch 29 - iter 160/209 - loss 0.01106722 - samples/sec: 194.98 - lr: 0.025000\n",
            "2022-10-04 05:56:00,077 epoch 29 - iter 180/209 - loss 0.01167747 - samples/sec: 154.91 - lr: 0.025000\n",
            "2022-10-04 05:56:04,500 epoch 29 - iter 200/209 - loss 0.01247597 - samples/sec: 144.84 - lr: 0.025000\n",
            "2022-10-04 05:56:05,890 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:56:05,892 EPOCH 29 done: loss 0.0124 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:56:15,160 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:56:15,176 DEV : loss 0.03598839417099953 - f1-score (micro avg)  0.8789\n",
            "2022-10-04 05:56:15,271 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 05:56:15,276 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:56:18,776 epoch 30 - iter 20/209 - loss 0.00953641 - samples/sec: 183.19 - lr: 0.025000\n",
            "2022-10-04 05:56:22,014 epoch 30 - iter 40/209 - loss 0.01216349 - samples/sec: 197.94 - lr: 0.025000\n",
            "2022-10-04 05:56:26,038 epoch 30 - iter 60/209 - loss 0.01165593 - samples/sec: 159.23 - lr: 0.025000\n",
            "2022-10-04 05:56:30,644 epoch 30 - iter 80/209 - loss 0.01036310 - samples/sec: 139.08 - lr: 0.025000\n",
            "2022-10-04 05:56:33,663 epoch 30 - iter 100/209 - loss 0.01120701 - samples/sec: 212.30 - lr: 0.025000\n",
            "2022-10-04 05:56:37,577 epoch 30 - iter 120/209 - loss 0.01146768 - samples/sec: 163.71 - lr: 0.025000\n",
            "2022-10-04 05:56:41,816 epoch 30 - iter 140/209 - loss 0.01178776 - samples/sec: 151.14 - lr: 0.025000\n",
            "2022-10-04 05:56:45,427 epoch 30 - iter 160/209 - loss 0.01273598 - samples/sec: 177.49 - lr: 0.025000\n",
            "2022-10-04 05:56:48,825 epoch 30 - iter 180/209 - loss 0.01269582 - samples/sec: 188.58 - lr: 0.025000\n",
            "2022-10-04 05:56:52,339 epoch 30 - iter 200/209 - loss 0.01244290 - samples/sec: 182.34 - lr: 0.025000\n",
            "2022-10-04 05:56:53,666 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:56:53,669 EPOCH 30 done: loss 0.0122 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:57:03,513 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:57:03,528 DEV : loss 0.03772483393549919 - f1-score (micro avg)  0.8811\n",
            "2022-10-04 05:57:03,620 BAD EPOCHS (no improvement): 2\n",
            "2022-10-04 05:57:03,627 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:57:07,449 epoch 31 - iter 20/209 - loss 0.01236270 - samples/sec: 167.76 - lr: 0.025000\n",
            "2022-10-04 05:57:11,367 epoch 31 - iter 40/209 - loss 0.01118533 - samples/sec: 163.53 - lr: 0.025000\n",
            "2022-10-04 05:57:14,790 epoch 31 - iter 60/209 - loss 0.01042194 - samples/sec: 187.17 - lr: 0.025000\n",
            "2022-10-04 05:57:19,446 epoch 31 - iter 80/209 - loss 0.01320989 - samples/sec: 137.62 - lr: 0.025000\n",
            "2022-10-04 05:57:22,882 epoch 31 - iter 100/209 - loss 0.01219673 - samples/sec: 186.52 - lr: 0.025000\n",
            "2022-10-04 05:57:26,509 epoch 31 - iter 120/209 - loss 0.01278864 - samples/sec: 176.67 - lr: 0.025000\n",
            "2022-10-04 05:57:30,388 epoch 31 - iter 140/209 - loss 0.01253886 - samples/sec: 165.18 - lr: 0.025000\n",
            "2022-10-04 05:57:34,133 epoch 31 - iter 160/209 - loss 0.01239262 - samples/sec: 171.14 - lr: 0.025000\n",
            "2022-10-04 05:57:37,378 epoch 31 - iter 180/209 - loss 0.01249081 - samples/sec: 197.55 - lr: 0.025000\n",
            "2022-10-04 05:57:41,007 epoch 31 - iter 200/209 - loss 0.01198677 - samples/sec: 176.56 - lr: 0.025000\n",
            "2022-10-04 05:57:42,380 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:57:42,382 EPOCH 31 done: loss 0.0122 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:57:51,807 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:57:51,821 DEV : loss 0.03528624773025513 - f1-score (micro avg)  0.8964\n",
            "2022-10-04 05:57:51,912 BAD EPOCHS (no improvement): 3\n",
            "2022-10-04 05:57:51,918 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:57:55,838 epoch 32 - iter 20/209 - loss 0.01122096 - samples/sec: 163.58 - lr: 0.025000\n",
            "2022-10-04 05:57:59,540 epoch 32 - iter 40/209 - loss 0.01012146 - samples/sec: 173.08 - lr: 0.025000\n",
            "2022-10-04 05:58:03,139 epoch 32 - iter 60/209 - loss 0.01366236 - samples/sec: 178.08 - lr: 0.025000\n",
            "2022-10-04 05:58:06,884 epoch 32 - iter 80/209 - loss 0.01366934 - samples/sec: 171.14 - lr: 0.025000\n",
            "2022-10-04 05:58:10,587 epoch 32 - iter 100/209 - loss 0.01296765 - samples/sec: 173.01 - lr: 0.025000\n",
            "2022-10-04 05:58:14,579 epoch 32 - iter 120/209 - loss 0.01263353 - samples/sec: 160.51 - lr: 0.025000\n",
            "2022-10-04 05:58:18,061 epoch 32 - iter 140/209 - loss 0.01264715 - samples/sec: 184.05 - lr: 0.025000\n",
            "2022-10-04 05:58:22,270 epoch 32 - iter 160/209 - loss 0.01300515 - samples/sec: 152.25 - lr: 0.025000\n",
            "2022-10-04 05:58:26,101 epoch 32 - iter 180/209 - loss 0.01246446 - samples/sec: 167.22 - lr: 0.025000\n",
            "2022-10-04 05:58:29,405 epoch 32 - iter 200/209 - loss 0.01215041 - samples/sec: 193.92 - lr: 0.025000\n",
            "2022-10-04 05:58:30,734 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:58:30,736 EPOCH 32 done: loss 0.0123 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:58:40,419 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:58:40,433 DEV : loss 0.03627915680408478 - f1-score (micro avg)  0.8889\n",
            "2022-10-04 05:58:40,524 Epoch    32: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2022-10-04 05:58:40,526 BAD EPOCHS (no improvement): 4\n",
            "2022-10-04 05:58:40,533 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:58:43,778 epoch 33 - iter 20/209 - loss 0.01074466 - samples/sec: 197.52 - lr: 0.012500\n",
            "2022-10-04 05:58:47,008 epoch 33 - iter 40/209 - loss 0.01381590 - samples/sec: 198.46 - lr: 0.012500\n",
            "2022-10-04 05:58:51,226 epoch 33 - iter 60/209 - loss 0.01455667 - samples/sec: 151.91 - lr: 0.012500\n",
            "2022-10-04 05:58:54,488 epoch 33 - iter 80/209 - loss 0.01295653 - samples/sec: 196.46 - lr: 0.012500\n",
            "2022-10-04 05:58:57,940 epoch 33 - iter 100/209 - loss 0.01344330 - samples/sec: 185.65 - lr: 0.012500\n",
            "2022-10-04 05:59:01,149 epoch 33 - iter 120/209 - loss 0.01279400 - samples/sec: 199.70 - lr: 0.012500\n",
            "2022-10-04 05:59:04,909 epoch 33 - iter 140/209 - loss 0.01211552 - samples/sec: 170.45 - lr: 0.012500\n",
            "2022-10-04 05:59:08,887 epoch 33 - iter 160/209 - loss 0.01174626 - samples/sec: 161.07 - lr: 0.012500\n",
            "2022-10-04 05:59:13,148 epoch 33 - iter 180/209 - loss 0.01122590 - samples/sec: 150.37 - lr: 0.012500\n",
            "2022-10-04 05:59:17,577 epoch 33 - iter 200/209 - loss 0.01065755 - samples/sec: 144.67 - lr: 0.012500\n",
            "2022-10-04 05:59:19,312 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:59:19,315 EPOCH 33 done: loss 0.0104 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 05:59:28,561 Evaluating as a multi-label problem: False\n",
            "2022-10-04 05:59:28,576 DEV : loss 0.03610891103744507 - f1-score (micro avg)  0.8934\n",
            "2022-10-04 05:59:28,669 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 05:59:28,675 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 05:59:32,917 epoch 34 - iter 20/209 - loss 0.01028631 - samples/sec: 151.08 - lr: 0.012500\n",
            "2022-10-04 05:59:36,770 epoch 34 - iter 40/209 - loss 0.00992648 - samples/sec: 166.32 - lr: 0.012500\n",
            "2022-10-04 05:59:40,047 epoch 34 - iter 60/209 - loss 0.01073276 - samples/sec: 195.63 - lr: 0.012500\n",
            "2022-10-04 05:59:43,797 epoch 34 - iter 80/209 - loss 0.01046705 - samples/sec: 170.85 - lr: 0.012500\n",
            "2022-10-04 05:59:47,162 epoch 34 - iter 100/209 - loss 0.01014213 - samples/sec: 190.47 - lr: 0.012500\n",
            "2022-10-04 05:59:50,771 epoch 34 - iter 120/209 - loss 0.01068458 - samples/sec: 177.58 - lr: 0.012500\n",
            "2022-10-04 05:59:55,250 epoch 34 - iter 140/209 - loss 0.01078379 - samples/sec: 143.03 - lr: 0.012500\n",
            "2022-10-04 05:59:58,549 epoch 34 - iter 160/209 - loss 0.01057927 - samples/sec: 194.27 - lr: 0.012500\n",
            "2022-10-04 06:00:02,415 epoch 34 - iter 180/209 - loss 0.01104997 - samples/sec: 165.74 - lr: 0.012500\n",
            "2022-10-04 06:00:05,771 epoch 34 - iter 200/209 - loss 0.01097820 - samples/sec: 190.99 - lr: 0.012500\n",
            "2022-10-04 06:00:07,457 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:00:07,460 EPOCH 34 done: loss 0.0111 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:00:16,840 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:00:16,856 DEV : loss 0.036554399877786636 - f1-score (micro avg)  0.8891\n",
            "2022-10-04 06:00:16,948 BAD EPOCHS (no improvement): 2\n",
            "2022-10-04 06:00:16,955 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:00:21,844 epoch 35 - iter 20/209 - loss 0.00938407 - samples/sec: 131.06 - lr: 0.012500\n",
            "2022-10-04 06:00:25,356 epoch 35 - iter 40/209 - loss 0.00914864 - samples/sec: 182.48 - lr: 0.012500\n",
            "2022-10-04 06:00:28,610 epoch 35 - iter 60/209 - loss 0.01067397 - samples/sec: 196.93 - lr: 0.012500\n",
            "2022-10-04 06:00:32,449 epoch 35 - iter 80/209 - loss 0.01079024 - samples/sec: 166.92 - lr: 0.012500\n",
            "2022-10-04 06:00:35,817 epoch 35 - iter 100/209 - loss 0.01088875 - samples/sec: 190.28 - lr: 0.012500\n",
            "2022-10-04 06:00:40,277 epoch 35 - iter 120/209 - loss 0.01040033 - samples/sec: 143.62 - lr: 0.012500\n",
            "2022-10-04 06:00:43,450 epoch 35 - iter 140/209 - loss 0.01006489 - samples/sec: 202.02 - lr: 0.012500\n",
            "2022-10-04 06:00:47,084 epoch 35 - iter 160/209 - loss 0.01019271 - samples/sec: 176.32 - lr: 0.012500\n",
            "2022-10-04 06:00:51,224 epoch 35 - iter 180/209 - loss 0.00980946 - samples/sec: 154.74 - lr: 0.012500\n",
            "2022-10-04 06:00:54,446 epoch 35 - iter 200/209 - loss 0.01023801 - samples/sec: 198.95 - lr: 0.012500\n",
            "2022-10-04 06:00:55,857 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:00:55,860 EPOCH 35 done: loss 0.0101 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:01:05,238 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:01:05,253 DEV : loss 0.03681835159659386 - f1-score (micro avg)  0.8914\n",
            "2022-10-04 06:01:05,345 BAD EPOCHS (no improvement): 3\n",
            "2022-10-04 06:01:05,350 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:01:09,109 epoch 36 - iter 20/209 - loss 0.00585385 - samples/sec: 170.53 - lr: 0.012500\n",
            "2022-10-04 06:01:13,124 epoch 36 - iter 40/209 - loss 0.00785727 - samples/sec: 159.60 - lr: 0.012500\n",
            "2022-10-04 06:01:16,944 epoch 36 - iter 60/209 - loss 0.00979658 - samples/sec: 167.77 - lr: 0.012500\n",
            "2022-10-04 06:01:21,225 epoch 36 - iter 80/209 - loss 0.00966733 - samples/sec: 149.63 - lr: 0.012500\n",
            "2022-10-04 06:01:24,573 epoch 36 - iter 100/209 - loss 0.01037219 - samples/sec: 191.44 - lr: 0.012500\n",
            "2022-10-04 06:01:27,993 epoch 36 - iter 120/209 - loss 0.01038273 - samples/sec: 187.36 - lr: 0.012500\n",
            "2022-10-04 06:01:31,770 epoch 36 - iter 140/209 - loss 0.00956070 - samples/sec: 169.68 - lr: 0.012500\n",
            "2022-10-04 06:01:34,894 epoch 36 - iter 160/209 - loss 0.00951557 - samples/sec: 205.13 - lr: 0.012500\n",
            "2022-10-04 06:01:38,132 epoch 36 - iter 180/209 - loss 0.00983683 - samples/sec: 197.96 - lr: 0.012500\n",
            "2022-10-04 06:01:42,393 epoch 36 - iter 200/209 - loss 0.01005551 - samples/sec: 150.36 - lr: 0.012500\n",
            "2022-10-04 06:01:43,869 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:01:43,871 EPOCH 36 done: loss 0.0101 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:01:53,132 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:01:53,148 DEV : loss 0.0368008092045784 - f1-score (micro avg)  0.8935\n",
            "2022-10-04 06:01:53,240 Epoch    36: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2022-10-04 06:01:53,242 BAD EPOCHS (no improvement): 4\n",
            "2022-10-04 06:01:53,247 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:01:56,892 epoch 37 - iter 20/209 - loss 0.00911506 - samples/sec: 175.83 - lr: 0.006250\n",
            "2022-10-04 06:02:00,950 epoch 37 - iter 40/209 - loss 0.00799043 - samples/sec: 157.91 - lr: 0.006250\n",
            "2022-10-04 06:02:05,123 epoch 37 - iter 60/209 - loss 0.01042876 - samples/sec: 153.53 - lr: 0.006250\n",
            "2022-10-04 06:02:08,688 epoch 37 - iter 80/209 - loss 0.00950002 - samples/sec: 179.78 - lr: 0.006250\n",
            "2022-10-04 06:02:11,782 epoch 37 - iter 100/209 - loss 0.00904592 - samples/sec: 207.13 - lr: 0.006250\n",
            "2022-10-04 06:02:15,689 epoch 37 - iter 120/209 - loss 0.00981121 - samples/sec: 164.02 - lr: 0.006250\n",
            "2022-10-04 06:02:19,668 epoch 37 - iter 140/209 - loss 0.00974833 - samples/sec: 160.98 - lr: 0.006250\n",
            "2022-10-04 06:02:23,602 epoch 37 - iter 160/209 - loss 0.01028125 - samples/sec: 162.91 - lr: 0.006250\n",
            "2022-10-04 06:02:27,003 epoch 37 - iter 180/209 - loss 0.01055163 - samples/sec: 188.45 - lr: 0.006250\n",
            "2022-10-04 06:02:30,692 epoch 37 - iter 200/209 - loss 0.01023426 - samples/sec: 173.67 - lr: 0.006250\n",
            "2022-10-04 06:02:32,071 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:02:32,072 EPOCH 37 done: loss 0.0104 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:02:41,323 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:02:41,338 DEV : loss 0.037444423884153366 - f1-score (micro avg)  0.8879\n",
            "2022-10-04 06:02:41,431 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 06:02:41,436 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:02:44,998 epoch 38 - iter 20/209 - loss 0.01032092 - samples/sec: 179.99 - lr: 0.006250\n",
            "2022-10-04 06:02:49,023 epoch 38 - iter 40/209 - loss 0.00817445 - samples/sec: 159.19 - lr: 0.006250\n",
            "2022-10-04 06:02:52,260 epoch 38 - iter 60/209 - loss 0.00819486 - samples/sec: 198.01 - lr: 0.006250\n",
            "2022-10-04 06:02:56,357 epoch 38 - iter 80/209 - loss 0.00841288 - samples/sec: 156.39 - lr: 0.006250\n",
            "2022-10-04 06:03:00,254 epoch 38 - iter 100/209 - loss 0.00869600 - samples/sec: 164.44 - lr: 0.006250\n",
            "2022-10-04 06:03:03,040 epoch 38 - iter 120/209 - loss 0.00875049 - samples/sec: 230.10 - lr: 0.006250\n",
            "2022-10-04 06:03:06,134 epoch 38 - iter 140/209 - loss 0.00877342 - samples/sec: 207.17 - lr: 0.006250\n",
            "2022-10-04 06:03:10,484 epoch 38 - iter 160/209 - loss 0.00843609 - samples/sec: 147.31 - lr: 0.006250\n",
            "2022-10-04 06:03:13,959 epoch 38 - iter 180/209 - loss 0.00869098 - samples/sec: 184.40 - lr: 0.006250\n",
            "2022-10-04 06:03:18,829 epoch 38 - iter 200/209 - loss 0.00896940 - samples/sec: 131.54 - lr: 0.006250\n",
            "2022-10-04 06:03:20,240 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:03:20,242 EPOCH 38 done: loss 0.0092 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:03:29,557 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:03:29,572 DEV : loss 0.036882925778627396 - f1-score (micro avg)  0.8897\n",
            "2022-10-04 06:03:29,663 BAD EPOCHS (no improvement): 2\n",
            "2022-10-04 06:03:29,668 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:03:33,651 epoch 39 - iter 20/209 - loss 0.00720484 - samples/sec: 160.95 - lr: 0.006250\n",
            "2022-10-04 06:03:37,117 epoch 39 - iter 40/209 - loss 0.00866009 - samples/sec: 184.90 - lr: 0.006250\n",
            "2022-10-04 06:03:41,509 epoch 39 - iter 60/209 - loss 0.00984890 - samples/sec: 145.85 - lr: 0.006250\n",
            "2022-10-04 06:03:44,962 epoch 39 - iter 80/209 - loss 0.01017707 - samples/sec: 185.60 - lr: 0.006250\n",
            "2022-10-04 06:03:48,922 epoch 39 - iter 100/209 - loss 0.00927738 - samples/sec: 161.78 - lr: 0.006250\n",
            "2022-10-04 06:03:52,515 epoch 39 - iter 120/209 - loss 0.00969488 - samples/sec: 178.45 - lr: 0.006250\n",
            "2022-10-04 06:03:56,930 epoch 39 - iter 140/209 - loss 0.00930524 - samples/sec: 145.12 - lr: 0.006250\n",
            "2022-10-04 06:04:00,466 epoch 39 - iter 160/209 - loss 0.00895152 - samples/sec: 181.24 - lr: 0.006250\n",
            "2022-10-04 06:04:03,663 epoch 39 - iter 180/209 - loss 0.00871912 - samples/sec: 200.47 - lr: 0.006250\n",
            "2022-10-04 06:04:07,065 epoch 39 - iter 200/209 - loss 0.00849781 - samples/sec: 188.40 - lr: 0.006250\n",
            "2022-10-04 06:04:08,842 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:04:08,844 EPOCH 39 done: loss 0.0084 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:04:18,295 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:04:18,309 DEV : loss 0.03780832514166832 - f1-score (micro avg)  0.8858\n",
            "2022-10-04 06:04:18,399 BAD EPOCHS (no improvement): 3\n",
            "2022-10-04 06:04:18,404 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:04:23,159 epoch 40 - iter 20/209 - loss 0.01454504 - samples/sec: 134.77 - lr: 0.006250\n",
            "2022-10-04 06:04:27,018 epoch 40 - iter 40/209 - loss 0.01110806 - samples/sec: 166.03 - lr: 0.006250\n",
            "2022-10-04 06:04:30,576 epoch 40 - iter 60/209 - loss 0.01105876 - samples/sec: 180.16 - lr: 0.006250\n",
            "2022-10-04 06:04:34,139 epoch 40 - iter 80/209 - loss 0.01046653 - samples/sec: 179.85 - lr: 0.006250\n",
            "2022-10-04 06:04:37,332 epoch 40 - iter 100/209 - loss 0.00982467 - samples/sec: 200.72 - lr: 0.006250\n",
            "2022-10-04 06:04:40,735 epoch 40 - iter 120/209 - loss 0.01021223 - samples/sec: 188.35 - lr: 0.006250\n",
            "2022-10-04 06:04:44,260 epoch 40 - iter 140/209 - loss 0.01030779 - samples/sec: 181.77 - lr: 0.006250\n",
            "2022-10-04 06:04:47,824 epoch 40 - iter 160/209 - loss 0.00970592 - samples/sec: 179.85 - lr: 0.006250\n",
            "2022-10-04 06:04:51,542 epoch 40 - iter 180/209 - loss 0.00961284 - samples/sec: 172.36 - lr: 0.006250\n",
            "2022-10-04 06:04:55,273 epoch 40 - iter 200/209 - loss 0.00954269 - samples/sec: 171.69 - lr: 0.006250\n",
            "2022-10-04 06:04:56,767 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:04:56,770 EPOCH 40 done: loss 0.0096 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:05:06,126 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:05:06,141 DEV : loss 0.0374482125043869 - f1-score (micro avg)  0.8922\n",
            "2022-10-04 06:05:06,232 Epoch    40: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2022-10-04 06:05:06,234 BAD EPOCHS (no improvement): 4\n",
            "2022-10-04 06:05:06,240 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:05:09,864 epoch 41 - iter 20/209 - loss 0.00966414 - samples/sec: 176.90 - lr: 0.003125\n",
            "2022-10-04 06:05:13,416 epoch 41 - iter 40/209 - loss 0.00893676 - samples/sec: 180.39 - lr: 0.003125\n",
            "2022-10-04 06:05:16,711 epoch 41 - iter 60/209 - loss 0.00844606 - samples/sec: 194.55 - lr: 0.003125\n",
            "2022-10-04 06:05:20,687 epoch 41 - iter 80/209 - loss 0.00852052 - samples/sec: 161.13 - lr: 0.003125\n",
            "2022-10-04 06:05:24,453 epoch 41 - iter 100/209 - loss 0.00821224 - samples/sec: 170.18 - lr: 0.003125\n",
            "2022-10-04 06:05:28,956 epoch 41 - iter 120/209 - loss 0.00852039 - samples/sec: 142.27 - lr: 0.003125\n",
            "2022-10-04 06:05:32,623 epoch 41 - iter 140/209 - loss 0.00851900 - samples/sec: 174.72 - lr: 0.003125\n",
            "2022-10-04 06:05:36,536 epoch 41 - iter 160/209 - loss 0.00807858 - samples/sec: 163.72 - lr: 0.003125\n",
            "2022-10-04 06:05:40,029 epoch 41 - iter 180/209 - loss 0.00778218 - samples/sec: 183.53 - lr: 0.003125\n",
            "2022-10-04 06:05:43,475 epoch 41 - iter 200/209 - loss 0.00782003 - samples/sec: 185.97 - lr: 0.003125\n",
            "2022-10-04 06:05:45,638 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:05:45,640 EPOCH 41 done: loss 0.0078 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:05:54,820 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:05:54,835 DEV : loss 0.037678979337215424 - f1-score (micro avg)  0.893\n",
            "2022-10-04 06:05:54,930 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 06:05:54,936 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:05:58,071 epoch 42 - iter 20/209 - loss 0.00721139 - samples/sec: 204.51 - lr: 0.003125\n",
            "2022-10-04 06:06:01,349 epoch 42 - iter 40/209 - loss 0.00857131 - samples/sec: 195.56 - lr: 0.003125\n",
            "2022-10-04 06:06:04,532 epoch 42 - iter 60/209 - loss 0.00867251 - samples/sec: 201.36 - lr: 0.003125\n",
            "2022-10-04 06:06:08,553 epoch 42 - iter 80/209 - loss 0.00922860 - samples/sec: 159.33 - lr: 0.003125\n",
            "2022-10-04 06:06:13,092 epoch 42 - iter 100/209 - loss 0.00961675 - samples/sec: 141.17 - lr: 0.003125\n",
            "2022-10-04 06:06:17,012 epoch 42 - iter 120/209 - loss 0.00909729 - samples/sec: 163.41 - lr: 0.003125\n",
            "2022-10-04 06:06:21,018 epoch 42 - iter 140/209 - loss 0.00923968 - samples/sec: 159.94 - lr: 0.003125\n",
            "2022-10-04 06:06:24,726 epoch 42 - iter 160/209 - loss 0.00964753 - samples/sec: 172.85 - lr: 0.003125\n",
            "2022-10-04 06:06:28,374 epoch 42 - iter 180/209 - loss 0.00937081 - samples/sec: 175.70 - lr: 0.003125\n",
            "2022-10-04 06:06:32,318 epoch 42 - iter 200/209 - loss 0.00903052 - samples/sec: 162.46 - lr: 0.003125\n",
            "2022-10-04 06:06:33,484 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:06:33,486 EPOCH 42 done: loss 0.0089 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:06:42,725 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:06:42,740 DEV : loss 0.03834991157054901 - f1-score (micro avg)  0.8899\n",
            "2022-10-04 06:06:42,832 BAD EPOCHS (no improvement): 2\n",
            "2022-10-04 06:06:42,839 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:06:48,127 epoch 43 - iter 20/209 - loss 0.00778794 - samples/sec: 121.17 - lr: 0.003125\n",
            "2022-10-04 06:06:51,489 epoch 43 - iter 40/209 - loss 0.00902505 - samples/sec: 190.63 - lr: 0.003125\n",
            "2022-10-04 06:06:55,140 epoch 43 - iter 60/209 - loss 0.00810162 - samples/sec: 175.54 - lr: 0.003125\n",
            "2022-10-04 06:06:58,744 epoch 43 - iter 80/209 - loss 0.00844783 - samples/sec: 177.84 - lr: 0.003125\n",
            "2022-10-04 06:07:02,708 epoch 43 - iter 100/209 - loss 0.00798762 - samples/sec: 161.63 - lr: 0.003125\n",
            "2022-10-04 06:07:06,436 epoch 43 - iter 120/209 - loss 0.00881416 - samples/sec: 171.92 - lr: 0.003125\n",
            "2022-10-04 06:07:09,996 epoch 43 - iter 140/209 - loss 0.00932053 - samples/sec: 179.99 - lr: 0.003125\n",
            "2022-10-04 06:07:13,376 epoch 43 - iter 160/209 - loss 0.00904417 - samples/sec: 189.61 - lr: 0.003125\n",
            "2022-10-04 06:07:17,180 epoch 43 - iter 180/209 - loss 0.00885551 - samples/sec: 168.47 - lr: 0.003125\n",
            "2022-10-04 06:07:20,012 epoch 43 - iter 200/209 - loss 0.00874426 - samples/sec: 226.33 - lr: 0.003125\n",
            "2022-10-04 06:07:21,684 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:07:21,687 EPOCH 43 done: loss 0.0089 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:07:31,658 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:07:31,673 DEV : loss 0.038088683038949966 - f1-score (micro avg)  0.8879\n",
            "2022-10-04 06:07:31,767 BAD EPOCHS (no improvement): 3\n",
            "2022-10-04 06:07:31,772 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:07:35,183 epoch 44 - iter 20/209 - loss 0.00868002 - samples/sec: 188.05 - lr: 0.003125\n",
            "2022-10-04 06:07:38,643 epoch 44 - iter 40/209 - loss 0.01136547 - samples/sec: 185.21 - lr: 0.003125\n",
            "2022-10-04 06:07:42,288 epoch 44 - iter 60/209 - loss 0.00900600 - samples/sec: 175.80 - lr: 0.003125\n",
            "2022-10-04 06:07:46,399 epoch 44 - iter 80/209 - loss 0.00955548 - samples/sec: 155.84 - lr: 0.003125\n",
            "2022-10-04 06:07:49,535 epoch 44 - iter 100/209 - loss 0.00944047 - samples/sec: 204.44 - lr: 0.003125\n",
            "2022-10-04 06:07:53,019 epoch 44 - iter 120/209 - loss 0.00907744 - samples/sec: 183.92 - lr: 0.003125\n",
            "2022-10-04 06:07:57,480 epoch 44 - iter 140/209 - loss 0.00918135 - samples/sec: 143.62 - lr: 0.003125\n",
            "2022-10-04 06:08:02,051 epoch 44 - iter 160/209 - loss 0.00934953 - samples/sec: 140.17 - lr: 0.003125\n",
            "2022-10-04 06:08:05,620 epoch 44 - iter 180/209 - loss 0.00884861 - samples/sec: 179.52 - lr: 0.003125\n",
            "2022-10-04 06:08:08,880 epoch 44 - iter 200/209 - loss 0.00859749 - samples/sec: 196.58 - lr: 0.003125\n",
            "2022-10-04 06:08:10,687 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:08:10,690 EPOCH 44 done: loss 0.0084 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:08:19,957 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:08:19,971 DEV : loss 0.037843670696020126 - f1-score (micro avg)  0.8914\n",
            "2022-10-04 06:08:20,062 Epoch    44: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2022-10-04 06:08:20,065 BAD EPOCHS (no improvement): 4\n",
            "2022-10-04 06:08:20,070 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:08:23,467 epoch 45 - iter 20/209 - loss 0.00915057 - samples/sec: 188.75 - lr: 0.001563\n",
            "2022-10-04 06:08:27,390 epoch 45 - iter 40/209 - loss 0.00806987 - samples/sec: 163.33 - lr: 0.001563\n",
            "2022-10-04 06:08:30,808 epoch 45 - iter 60/209 - loss 0.00765503 - samples/sec: 187.53 - lr: 0.001563\n",
            "2022-10-04 06:08:35,751 epoch 45 - iter 80/209 - loss 0.00841716 - samples/sec: 129.60 - lr: 0.001563\n",
            "2022-10-04 06:08:39,710 epoch 45 - iter 100/209 - loss 0.00798017 - samples/sec: 161.81 - lr: 0.001563\n",
            "2022-10-04 06:08:43,587 epoch 45 - iter 120/209 - loss 0.00809475 - samples/sec: 165.32 - lr: 0.001563\n",
            "2022-10-04 06:08:46,622 epoch 45 - iter 140/209 - loss 0.00830406 - samples/sec: 211.16 - lr: 0.001563\n",
            "2022-10-04 06:08:50,778 epoch 45 - iter 160/209 - loss 0.00868140 - samples/sec: 154.19 - lr: 0.001563\n",
            "2022-10-04 06:08:54,372 epoch 45 - iter 180/209 - loss 0.00824181 - samples/sec: 178.31 - lr: 0.001563\n",
            "2022-10-04 06:08:57,745 epoch 45 - iter 200/209 - loss 0.00861409 - samples/sec: 189.98 - lr: 0.001563\n",
            "2022-10-04 06:08:59,212 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:08:59,214 EPOCH 45 done: loss 0.0088 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:09:09,026 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:09:09,041 DEV : loss 0.03789843991398811 - f1-score (micro avg)  0.8899\n",
            "2022-10-04 06:09:09,132 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 06:09:09,138 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:09:12,415 epoch 46 - iter 20/209 - loss 0.00825654 - samples/sec: 195.68 - lr: 0.001563\n",
            "2022-10-04 06:09:15,533 epoch 46 - iter 40/209 - loss 0.00960911 - samples/sec: 205.61 - lr: 0.001563\n",
            "2022-10-04 06:09:20,083 epoch 46 - iter 60/209 - loss 0.01020414 - samples/sec: 140.78 - lr: 0.001563\n",
            "2022-10-04 06:09:23,546 epoch 46 - iter 80/209 - loss 0.00987878 - samples/sec: 185.09 - lr: 0.001563\n",
            "2022-10-04 06:09:27,190 epoch 46 - iter 100/209 - loss 0.00951879 - samples/sec: 175.84 - lr: 0.001563\n",
            "2022-10-04 06:09:30,430 epoch 46 - iter 120/209 - loss 0.00904749 - samples/sec: 197.78 - lr: 0.001563\n",
            "2022-10-04 06:09:34,636 epoch 46 - iter 140/209 - loss 0.00866594 - samples/sec: 152.35 - lr: 0.001563\n",
            "2022-10-04 06:09:38,222 epoch 46 - iter 160/209 - loss 0.00858736 - samples/sec: 178.64 - lr: 0.001563\n",
            "2022-10-04 06:09:42,402 epoch 46 - iter 180/209 - loss 0.00896224 - samples/sec: 153.29 - lr: 0.001563\n",
            "2022-10-04 06:09:46,033 epoch 46 - iter 200/209 - loss 0.00870595 - samples/sec: 176.53 - lr: 0.001563\n",
            "2022-10-04 06:09:47,465 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:09:47,467 EPOCH 46 done: loss 0.0086 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:09:56,792 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:09:56,807 DEV : loss 0.03774372115731239 - f1-score (micro avg)  0.8906\n",
            "2022-10-04 06:09:56,899 BAD EPOCHS (no improvement): 2\n",
            "2022-10-04 06:09:56,908 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:10:00,630 epoch 47 - iter 20/209 - loss 0.00921869 - samples/sec: 172.17 - lr: 0.001563\n",
            "2022-10-04 06:10:04,153 epoch 47 - iter 40/209 - loss 0.00960107 - samples/sec: 181.89 - lr: 0.001563\n",
            "2022-10-04 06:10:07,512 epoch 47 - iter 60/209 - loss 0.00868945 - samples/sec: 190.76 - lr: 0.001563\n",
            "2022-10-04 06:10:11,139 epoch 47 - iter 80/209 - loss 0.00895019 - samples/sec: 176.67 - lr: 0.001563\n",
            "2022-10-04 06:10:15,956 epoch 47 - iter 100/209 - loss 0.00940435 - samples/sec: 132.98 - lr: 0.001563\n",
            "2022-10-04 06:10:19,644 epoch 47 - iter 120/209 - loss 0.00895410 - samples/sec: 173.78 - lr: 0.001563\n",
            "2022-10-04 06:10:23,462 epoch 47 - iter 140/209 - loss 0.00851100 - samples/sec: 167.84 - lr: 0.001563\n",
            "2022-10-04 06:10:27,772 epoch 47 - iter 160/209 - loss 0.00875492 - samples/sec: 148.68 - lr: 0.001563\n",
            "2022-10-04 06:10:31,011 epoch 47 - iter 180/209 - loss 0.00890603 - samples/sec: 197.82 - lr: 0.001563\n",
            "2022-10-04 06:10:33,937 epoch 47 - iter 200/209 - loss 0.00859730 - samples/sec: 219.12 - lr: 0.001563\n",
            "2022-10-04 06:10:35,189 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:10:35,191 EPOCH 47 done: loss 0.0085 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:10:45,072 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:10:45,087 DEV : loss 0.037846531718969345 - f1-score (micro avg)  0.8906\n",
            "2022-10-04 06:10:45,181 BAD EPOCHS (no improvement): 3\n",
            "2022-10-04 06:10:45,187 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:10:49,212 epoch 48 - iter 20/209 - loss 0.00885887 - samples/sec: 159.30 - lr: 0.001563\n",
            "2022-10-04 06:10:53,223 epoch 48 - iter 40/209 - loss 0.00982232 - samples/sec: 159.73 - lr: 0.001563\n",
            "2022-10-04 06:10:56,692 epoch 48 - iter 60/209 - loss 0.00891986 - samples/sec: 184.72 - lr: 0.001563\n",
            "2022-10-04 06:11:00,584 epoch 48 - iter 80/209 - loss 0.00822634 - samples/sec: 164.73 - lr: 0.001563\n",
            "2022-10-04 06:11:03,921 epoch 48 - iter 100/209 - loss 0.00815458 - samples/sec: 192.05 - lr: 0.001563\n",
            "2022-10-04 06:11:06,774 epoch 48 - iter 120/209 - loss 0.00823428 - samples/sec: 224.74 - lr: 0.001563\n",
            "2022-10-04 06:11:10,599 epoch 48 - iter 140/209 - loss 0.00813609 - samples/sec: 167.55 - lr: 0.001563\n",
            "2022-10-04 06:11:14,957 epoch 48 - iter 160/209 - loss 0.00819137 - samples/sec: 147.01 - lr: 0.001563\n",
            "2022-10-04 06:11:18,395 epoch 48 - iter 180/209 - loss 0.00806218 - samples/sec: 186.43 - lr: 0.001563\n",
            "2022-10-04 06:11:23,248 epoch 48 - iter 200/209 - loss 0.00788857 - samples/sec: 131.99 - lr: 0.001563\n",
            "2022-10-04 06:11:24,926 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:11:24,928 EPOCH 48 done: loss 0.0078 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:11:34,120 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:11:34,136 DEV : loss 0.03800590708851814 - f1-score (micro avg)  0.8906\n",
            "2022-10-04 06:11:34,229 Epoch    48: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2022-10-04 06:11:34,232 BAD EPOCHS (no improvement): 4\n",
            "2022-10-04 06:11:34,239 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:11:38,276 epoch 49 - iter 20/209 - loss 0.00723680 - samples/sec: 158.75 - lr: 0.000781\n",
            "2022-10-04 06:11:41,882 epoch 49 - iter 40/209 - loss 0.00742433 - samples/sec: 177.72 - lr: 0.000781\n",
            "2022-10-04 06:11:45,918 epoch 49 - iter 60/209 - loss 0.00735570 - samples/sec: 158.78 - lr: 0.000781\n",
            "2022-10-04 06:11:49,769 epoch 49 - iter 80/209 - loss 0.00758143 - samples/sec: 166.43 - lr: 0.000781\n",
            "2022-10-04 06:11:53,118 epoch 49 - iter 100/209 - loss 0.00723109 - samples/sec: 191.39 - lr: 0.000781\n",
            "2022-10-04 06:11:56,679 epoch 49 - iter 120/209 - loss 0.00795437 - samples/sec: 179.95 - lr: 0.000781\n",
            "2022-10-04 06:11:59,628 epoch 49 - iter 140/209 - loss 0.00884515 - samples/sec: 217.34 - lr: 0.000781\n",
            "2022-10-04 06:12:04,317 epoch 49 - iter 160/209 - loss 0.00883326 - samples/sec: 136.62 - lr: 0.000781\n",
            "2022-10-04 06:12:07,840 epoch 49 - iter 180/209 - loss 0.00913840 - samples/sec: 181.90 - lr: 0.000781\n",
            "2022-10-04 06:12:11,334 epoch 49 - iter 200/209 - loss 0.00899281 - samples/sec: 183.41 - lr: 0.000781\n",
            "2022-10-04 06:12:12,825 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:12:12,827 EPOCH 49 done: loss 0.0092 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:12:22,660 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:12:22,675 DEV : loss 0.038007382303476334 - f1-score (micro avg)  0.8906\n",
            "2022-10-04 06:12:22,769 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 06:12:22,773 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:12:27,153 epoch 50 - iter 20/209 - loss 0.00575047 - samples/sec: 146.31 - lr: 0.000781\n",
            "2022-10-04 06:12:30,634 epoch 50 - iter 40/209 - loss 0.00608610 - samples/sec: 184.13 - lr: 0.000781\n",
            "2022-10-04 06:12:34,190 epoch 50 - iter 60/209 - loss 0.00799629 - samples/sec: 180.22 - lr: 0.000781\n",
            "2022-10-04 06:12:37,501 epoch 50 - iter 80/209 - loss 0.00825067 - samples/sec: 193.60 - lr: 0.000781\n",
            "2022-10-04 06:12:41,826 epoch 50 - iter 100/209 - loss 0.00924510 - samples/sec: 148.13 - lr: 0.000781\n",
            "2022-10-04 06:12:45,715 epoch 50 - iter 120/209 - loss 0.00867024 - samples/sec: 164.76 - lr: 0.000781\n",
            "2022-10-04 06:12:49,134 epoch 50 - iter 140/209 - loss 0.00844992 - samples/sec: 187.50 - lr: 0.000781\n",
            "2022-10-04 06:12:52,677 epoch 50 - iter 160/209 - loss 0.00834193 - samples/sec: 180.85 - lr: 0.000781\n",
            "2022-10-04 06:12:56,422 epoch 50 - iter 180/209 - loss 0.00861522 - samples/sec: 171.10 - lr: 0.000781\n",
            "2022-10-04 06:13:00,110 epoch 50 - iter 200/209 - loss 0.00874079 - samples/sec: 173.74 - lr: 0.000781\n",
            "2022-10-04 06:13:01,853 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:13:01,855 EPOCH 50 done: loss 0.0087 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:13:11,116 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:13:11,133 DEV : loss 0.038025226444005966 - f1-score (micro avg)  0.8906\n",
            "2022-10-04 06:13:11,225 BAD EPOCHS (no improvement): 2\n",
            "2022-10-04 06:13:11,231 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:13:14,963 epoch 51 - iter 20/209 - loss 0.00907028 - samples/sec: 171.74 - lr: 0.000781\n",
            "2022-10-04 06:13:18,617 epoch 51 - iter 40/209 - loss 0.00816937 - samples/sec: 175.42 - lr: 0.000781\n",
            "2022-10-04 06:13:21,897 epoch 51 - iter 60/209 - loss 0.00762472 - samples/sec: 195.42 - lr: 0.000781\n",
            "2022-10-04 06:13:26,133 epoch 51 - iter 80/209 - loss 0.00841463 - samples/sec: 151.23 - lr: 0.000781\n",
            "2022-10-04 06:13:29,964 epoch 51 - iter 100/209 - loss 0.00775230 - samples/sec: 167.28 - lr: 0.000781\n",
            "2022-10-04 06:13:33,045 epoch 51 - iter 120/209 - loss 0.00766789 - samples/sec: 207.99 - lr: 0.000781\n",
            "2022-10-04 06:13:36,902 epoch 51 - iter 140/209 - loss 0.00748351 - samples/sec: 166.15 - lr: 0.000781\n",
            "2022-10-04 06:13:40,916 epoch 51 - iter 160/209 - loss 0.00780402 - samples/sec: 159.64 - lr: 0.000781\n",
            "2022-10-04 06:13:44,277 epoch 51 - iter 180/209 - loss 0.00758937 - samples/sec: 190.65 - lr: 0.000781\n",
            "2022-10-04 06:13:48,452 epoch 51 - iter 200/209 - loss 0.00747814 - samples/sec: 153.47 - lr: 0.000781\n",
            "2022-10-04 06:13:50,370 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:13:50,372 EPOCH 51 done: loss 0.0076 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:14:00,254 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:14:00,270 DEV : loss 0.038149621337652206 - f1-score (micro avg)  0.8914\n",
            "2022-10-04 06:14:00,369 BAD EPOCHS (no improvement): 3\n",
            "2022-10-04 06:14:00,374 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:14:03,993 epoch 52 - iter 20/209 - loss 0.00807312 - samples/sec: 177.12 - lr: 0.000781\n",
            "2022-10-04 06:14:07,964 epoch 52 - iter 40/209 - loss 0.00746013 - samples/sec: 161.39 - lr: 0.000781\n",
            "2022-10-04 06:14:11,841 epoch 52 - iter 60/209 - loss 0.00917152 - samples/sec: 165.28 - lr: 0.000781\n",
            "2022-10-04 06:14:15,376 epoch 52 - iter 80/209 - loss 0.00875250 - samples/sec: 181.22 - lr: 0.000781\n",
            "2022-10-04 06:14:18,841 epoch 52 - iter 100/209 - loss 0.00891767 - samples/sec: 184.99 - lr: 0.000781\n",
            "2022-10-04 06:14:21,969 epoch 52 - iter 120/209 - loss 0.00851070 - samples/sec: 204.84 - lr: 0.000781\n",
            "2022-10-04 06:14:25,567 epoch 52 - iter 140/209 - loss 0.00824121 - samples/sec: 178.13 - lr: 0.000781\n",
            "2022-10-04 06:14:29,382 epoch 52 - iter 160/209 - loss 0.00843917 - samples/sec: 167.93 - lr: 0.000781\n",
            "2022-10-04 06:14:32,880 epoch 52 - iter 180/209 - loss 0.00830659 - samples/sec: 183.19 - lr: 0.000781\n",
            "2022-10-04 06:14:37,207 epoch 52 - iter 200/209 - loss 0.00837678 - samples/sec: 148.09 - lr: 0.000781\n",
            "2022-10-04 06:14:38,821 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:14:38,823 EPOCH 52 done: loss 0.0083 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:14:48,136 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:14:48,151 DEV : loss 0.038144659250974655 - f1-score (micro avg)  0.8922\n",
            "2022-10-04 06:14:48,248 Epoch    52: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2022-10-04 06:14:48,250 BAD EPOCHS (no improvement): 4\n",
            "2022-10-04 06:14:48,256 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:14:52,196 epoch 53 - iter 20/209 - loss 0.01103940 - samples/sec: 162.68 - lr: 0.000391\n",
            "2022-10-04 06:14:57,029 epoch 53 - iter 40/209 - loss 0.01270246 - samples/sec: 132.56 - lr: 0.000391\n",
            "2022-10-04 06:15:00,835 epoch 53 - iter 60/209 - loss 0.01043549 - samples/sec: 168.39 - lr: 0.000391\n",
            "2022-10-04 06:15:04,543 epoch 53 - iter 80/209 - loss 0.01143983 - samples/sec: 172.84 - lr: 0.000391\n",
            "2022-10-04 06:15:07,817 epoch 53 - iter 100/209 - loss 0.01024308 - samples/sec: 195.77 - lr: 0.000391\n",
            "2022-10-04 06:15:11,062 epoch 53 - iter 120/209 - loss 0.00957503 - samples/sec: 197.54 - lr: 0.000391\n",
            "2022-10-04 06:15:14,567 epoch 53 - iter 140/209 - loss 0.00952799 - samples/sec: 182.81 - lr: 0.000391\n",
            "2022-10-04 06:15:18,493 epoch 53 - iter 160/209 - loss 0.00972760 - samples/sec: 163.20 - lr: 0.000391\n",
            "2022-10-04 06:15:21,689 epoch 53 - iter 180/209 - loss 0.00973548 - samples/sec: 200.62 - lr: 0.000391\n",
            "2022-10-04 06:15:25,295 epoch 53 - iter 200/209 - loss 0.00951458 - samples/sec: 177.69 - lr: 0.000391\n",
            "2022-10-04 06:15:26,667 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:15:26,670 EPOCH 53 done: loss 0.0097 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:15:36,365 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:15:36,381 DEV : loss 0.03815596550703049 - f1-score (micro avg)  0.8906\n",
            "2022-10-04 06:15:36,471 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 06:15:36,476 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:15:40,090 epoch 54 - iter 20/209 - loss 0.00581222 - samples/sec: 177.39 - lr: 0.000391\n",
            "2022-10-04 06:15:43,332 epoch 54 - iter 40/209 - loss 0.00700413 - samples/sec: 197.73 - lr: 0.000391\n",
            "2022-10-04 06:15:46,986 epoch 54 - iter 60/209 - loss 0.00758364 - samples/sec: 175.35 - lr: 0.000391\n",
            "2022-10-04 06:15:51,398 epoch 54 - iter 80/209 - loss 0.00845202 - samples/sec: 145.18 - lr: 0.000391\n",
            "2022-10-04 06:15:55,427 epoch 54 - iter 100/209 - loss 0.00857451 - samples/sec: 159.04 - lr: 0.000391\n",
            "2022-10-04 06:15:59,161 epoch 54 - iter 120/209 - loss 0.00889105 - samples/sec: 171.61 - lr: 0.000391\n",
            "2022-10-04 06:16:02,473 epoch 54 - iter 140/209 - loss 0.00867399 - samples/sec: 193.50 - lr: 0.000391\n",
            "2022-10-04 06:16:06,255 epoch 54 - iter 160/209 - loss 0.00832112 - samples/sec: 169.43 - lr: 0.000391\n",
            "2022-10-04 06:16:10,135 epoch 54 - iter 180/209 - loss 0.00851003 - samples/sec: 165.12 - lr: 0.000391\n",
            "2022-10-04 06:16:13,715 epoch 54 - iter 200/209 - loss 0.00869914 - samples/sec: 178.97 - lr: 0.000391\n",
            "2022-10-04 06:16:15,006 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:16:15,008 EPOCH 54 done: loss 0.0086 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:16:24,477 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:16:24,492 DEV : loss 0.03805556148290634 - f1-score (micro avg)  0.8906\n",
            "2022-10-04 06:16:24,585 BAD EPOCHS (no improvement): 2\n",
            "2022-10-04 06:16:24,592 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:16:28,601 epoch 55 - iter 20/209 - loss 0.01075096 - samples/sec: 159.90 - lr: 0.000391\n",
            "2022-10-04 06:16:32,071 epoch 55 - iter 40/209 - loss 0.01310031 - samples/sec: 184.66 - lr: 0.000391\n",
            "2022-10-04 06:16:36,509 epoch 55 - iter 60/209 - loss 0.01258739 - samples/sec: 144.32 - lr: 0.000391\n",
            "2022-10-04 06:16:40,007 epoch 55 - iter 80/209 - loss 0.01135015 - samples/sec: 183.19 - lr: 0.000391\n",
            "2022-10-04 06:16:43,881 epoch 55 - iter 100/209 - loss 0.01041704 - samples/sec: 165.43 - lr: 0.000391\n",
            "2022-10-04 06:16:47,367 epoch 55 - iter 120/209 - loss 0.00984000 - samples/sec: 183.86 - lr: 0.000391\n",
            "2022-10-04 06:16:50,812 epoch 55 - iter 140/209 - loss 0.00931392 - samples/sec: 186.03 - lr: 0.000391\n",
            "2022-10-04 06:16:54,599 epoch 55 - iter 160/209 - loss 0.00913260 - samples/sec: 169.21 - lr: 0.000391\n",
            "2022-10-04 06:16:58,407 epoch 55 - iter 180/209 - loss 0.00877388 - samples/sec: 168.29 - lr: 0.000391\n",
            "2022-10-04 06:17:02,041 epoch 55 - iter 200/209 - loss 0.00878236 - samples/sec: 176.31 - lr: 0.000391\n",
            "2022-10-04 06:17:03,254 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:17:03,256 EPOCH 55 done: loss 0.0088 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:17:13,091 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:17:13,106 DEV : loss 0.038078758865594864 - f1-score (micro avg)  0.8914\n",
            "2022-10-04 06:17:13,196 BAD EPOCHS (no improvement): 3\n",
            "2022-10-04 06:17:13,201 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:17:17,914 epoch 56 - iter 20/209 - loss 0.00893760 - samples/sec: 136.01 - lr: 0.000391\n",
            "2022-10-04 06:17:21,453 epoch 56 - iter 40/209 - loss 0.00915405 - samples/sec: 181.09 - lr: 0.000391\n",
            "2022-10-04 06:17:25,476 epoch 56 - iter 60/209 - loss 0.00785992 - samples/sec: 159.26 - lr: 0.000391\n",
            "2022-10-04 06:17:28,931 epoch 56 - iter 80/209 - loss 0.00830929 - samples/sec: 185.51 - lr: 0.000391\n",
            "2022-10-04 06:17:32,134 epoch 56 - iter 100/209 - loss 0.00872877 - samples/sec: 200.10 - lr: 0.000391\n",
            "2022-10-04 06:17:35,722 epoch 56 - iter 120/209 - loss 0.00869752 - samples/sec: 178.64 - lr: 0.000391\n",
            "2022-10-04 06:17:39,032 epoch 56 - iter 140/209 - loss 0.00876022 - samples/sec: 193.66 - lr: 0.000391\n",
            "2022-10-04 06:17:42,459 epoch 56 - iter 160/209 - loss 0.00876339 - samples/sec: 186.97 - lr: 0.000391\n",
            "2022-10-04 06:17:46,280 epoch 56 - iter 180/209 - loss 0.00847649 - samples/sec: 167.72 - lr: 0.000391\n",
            "2022-10-04 06:17:49,408 epoch 56 - iter 200/209 - loss 0.00861680 - samples/sec: 204.92 - lr: 0.000391\n",
            "2022-10-04 06:17:51,635 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:17:51,637 EPOCH 56 done: loss 0.0089 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:18:00,830 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:18:00,844 DEV : loss 0.038082562386989594 - f1-score (micro avg)  0.8899\n",
            "2022-10-04 06:18:00,937 Epoch    56: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2022-10-04 06:18:00,939 BAD EPOCHS (no improvement): 4\n",
            "2022-10-04 06:18:00,945 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:18:04,368 epoch 57 - iter 20/209 - loss 0.00799015 - samples/sec: 187.34 - lr: 0.000195\n",
            "2022-10-04 06:18:08,384 epoch 57 - iter 40/209 - loss 0.00766520 - samples/sec: 159.55 - lr: 0.000195\n",
            "2022-10-04 06:18:11,744 epoch 57 - iter 60/209 - loss 0.00751153 - samples/sec: 190.73 - lr: 0.000195\n",
            "2022-10-04 06:18:15,132 epoch 57 - iter 80/209 - loss 0.00926397 - samples/sec: 189.16 - lr: 0.000195\n",
            "2022-10-04 06:18:18,822 epoch 57 - iter 100/209 - loss 0.00874149 - samples/sec: 173.63 - lr: 0.000195\n",
            "2022-10-04 06:18:22,704 epoch 57 - iter 120/209 - loss 0.00914877 - samples/sec: 165.07 - lr: 0.000195\n",
            "2022-10-04 06:18:27,051 epoch 57 - iter 140/209 - loss 0.00854662 - samples/sec: 147.38 - lr: 0.000195\n",
            "2022-10-04 06:18:31,258 epoch 57 - iter 160/209 - loss 0.00937500 - samples/sec: 152.27 - lr: 0.000195\n",
            "2022-10-04 06:18:35,206 epoch 57 - iter 180/209 - loss 0.00910348 - samples/sec: 162.30 - lr: 0.000195\n",
            "2022-10-04 06:18:38,205 epoch 57 - iter 200/209 - loss 0.00886491 - samples/sec: 213.74 - lr: 0.000195\n",
            "2022-10-04 06:18:39,658 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:18:39,660 EPOCH 57 done: loss 0.0087 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:18:48,752 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:18:48,768 DEV : loss 0.03809021785855293 - f1-score (micro avg)  0.8908\n",
            "2022-10-04 06:18:48,860 BAD EPOCHS (no improvement): 1\n",
            "2022-10-04 06:18:48,865 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:18:53,029 epoch 58 - iter 20/209 - loss 0.01286258 - samples/sec: 153.90 - lr: 0.000195\n",
            "2022-10-04 06:18:56,466 epoch 58 - iter 40/209 - loss 0.00981505 - samples/sec: 186.45 - lr: 0.000195\n",
            "2022-10-04 06:18:59,814 epoch 58 - iter 60/209 - loss 0.00900506 - samples/sec: 191.46 - lr: 0.000195\n",
            "2022-10-04 06:19:03,675 epoch 58 - iter 80/209 - loss 0.00766555 - samples/sec: 165.92 - lr: 0.000195\n",
            "2022-10-04 06:19:07,896 epoch 58 - iter 100/209 - loss 0.00685628 - samples/sec: 151.80 - lr: 0.000195\n",
            "2022-10-04 06:19:12,001 epoch 58 - iter 120/209 - loss 0.00711517 - samples/sec: 156.09 - lr: 0.000195\n",
            "2022-10-04 06:19:15,103 epoch 58 - iter 140/209 - loss 0.00776291 - samples/sec: 206.63 - lr: 0.000195\n",
            "2022-10-04 06:19:18,252 epoch 58 - iter 160/209 - loss 0.00809358 - samples/sec: 203.60 - lr: 0.000195\n",
            "2022-10-04 06:19:21,858 epoch 58 - iter 180/209 - loss 0.00828458 - samples/sec: 177.69 - lr: 0.000195\n",
            "2022-10-04 06:19:25,923 epoch 58 - iter 200/209 - loss 0.00841895 - samples/sec: 157.61 - lr: 0.000195\n",
            "2022-10-04 06:19:27,150 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:19:27,152 EPOCH 58 done: loss 0.0084 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:19:36,496 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:19:36,517 DEV : loss 0.03806339576840401 - f1-score (micro avg)  0.8899\n",
            "2022-10-04 06:19:36,631 BAD EPOCHS (no improvement): 2\n",
            "2022-10-04 06:19:36,638 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:19:39,793 epoch 59 - iter 20/209 - loss 0.01022128 - samples/sec: 203.28 - lr: 0.000195\n",
            "2022-10-04 06:19:43,329 epoch 59 - iter 40/209 - loss 0.00782568 - samples/sec: 181.25 - lr: 0.000195\n",
            "2022-10-04 06:19:46,719 epoch 59 - iter 60/209 - loss 0.00760278 - samples/sec: 189.01 - lr: 0.000195\n",
            "2022-10-04 06:19:50,312 epoch 59 - iter 80/209 - loss 0.00807451 - samples/sec: 178.35 - lr: 0.000195\n",
            "2022-10-04 06:19:53,955 epoch 59 - iter 100/209 - loss 0.00851865 - samples/sec: 175.92 - lr: 0.000195\n",
            "2022-10-04 06:19:57,877 epoch 59 - iter 120/209 - loss 0.00909560 - samples/sec: 163.38 - lr: 0.000195\n",
            "2022-10-04 06:20:01,264 epoch 59 - iter 140/209 - loss 0.00911432 - samples/sec: 189.28 - lr: 0.000195\n",
            "2022-10-04 06:20:06,748 epoch 59 - iter 160/209 - loss 0.00927495 - samples/sec: 116.81 - lr: 0.000195\n",
            "2022-10-04 06:20:11,298 epoch 59 - iter 180/209 - loss 0.00907668 - samples/sec: 140.79 - lr: 0.000195\n",
            "2022-10-04 06:20:15,017 epoch 59 - iter 200/209 - loss 0.00907362 - samples/sec: 172.31 - lr: 0.000195\n",
            "2022-10-04 06:20:16,403 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:20:16,405 EPOCH 59 done: loss 0.0089 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:20:25,874 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:20:25,889 DEV : loss 0.03805448114871979 - f1-score (micro avg)  0.8899\n",
            "2022-10-04 06:20:25,983 BAD EPOCHS (no improvement): 3\n",
            "2022-10-04 06:20:25,988 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:20:29,327 epoch 60 - iter 20/209 - loss 0.00549876 - samples/sec: 192.05 - lr: 0.000195\n",
            "2022-10-04 06:20:33,106 epoch 60 - iter 40/209 - loss 0.00827131 - samples/sec: 169.58 - lr: 0.000195\n",
            "2022-10-04 06:20:36,786 epoch 60 - iter 60/209 - loss 0.00767564 - samples/sec: 174.14 - lr: 0.000195\n",
            "2022-10-04 06:20:40,275 epoch 60 - iter 80/209 - loss 0.00754839 - samples/sec: 183.63 - lr: 0.000195\n",
            "2022-10-04 06:20:44,259 epoch 60 - iter 100/209 - loss 0.00754319 - samples/sec: 160.85 - lr: 0.000195\n",
            "2022-10-04 06:20:47,773 epoch 60 - iter 120/209 - loss 0.00785504 - samples/sec: 182.36 - lr: 0.000195\n",
            "2022-10-04 06:20:51,116 epoch 60 - iter 140/209 - loss 0.00783770 - samples/sec: 191.74 - lr: 0.000195\n",
            "2022-10-04 06:20:55,087 epoch 60 - iter 160/209 - loss 0.00792624 - samples/sec: 161.33 - lr: 0.000195\n",
            "2022-10-04 06:20:58,478 epoch 60 - iter 180/209 - loss 0.00799376 - samples/sec: 188.98 - lr: 0.000195\n",
            "2022-10-04 06:21:02,632 epoch 60 - iter 200/209 - loss 0.00845501 - samples/sec: 154.25 - lr: 0.000195\n",
            "2022-10-04 06:21:04,248 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:21:04,253 EPOCH 60 done: loss 0.0083 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:09<00:00,  4.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:21:13,523 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:21:13,539 DEV : loss 0.038046371191740036 - f1-score (micro avg)  0.8906\n",
            "2022-10-04 06:21:13,634 Epoch    60: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2022-10-04 06:21:13,637 BAD EPOCHS (no improvement): 4\n",
            "2022-10-04 06:21:13,643 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:21:13,645 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:21:13,647 learning rate too small - quitting training!\n",
            "2022-10-04 06:21:13,648 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:21:14,329 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-04 06:21:14,334 loading file /content/drive/MyDrive/Flair_NLP/sota-ner-flair/best-model.pt\n",
            "2022-10-04 06:21:15,156 SequenceTagger predicts: Dictionary with 31 tags: O, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-FUNDAMENTO, B-FUNDAMENTO, E-FUNDAMENTO, I-FUNDAMENTO, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-DATA, B-DATA, E-DATA, I-DATA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL, S-PRODUTODELEI, B-PRODUTODELEI, E-PRODUTODELEI, I-PRODUTODELEI, S-EVENTO, B-EVENTO, E-EVENTO, I-EVENTO, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:38<00:00,  1.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-04 06:21:53,861 Evaluating as a multi-label problem: False\n",
            "2022-10-04 06:21:53,877 0.8961\t0.8932\t0.8946\t0.8193\n",
            "2022-10-04 06:21:53,878 \n",
            "Results:\n",
            "- F-score (micro) 0.8946\n",
            "- F-score (macro) 0.856\n",
            "- Accuracy 0.8193\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  FUNDAMENTO     0.9431    0.9355    0.9393       124\n",
            "      PESSOA     0.9167    0.9244    0.9205       119\n",
            "       LOCAL     0.8173    0.8416    0.8293       101\n",
            "        DATA     0.9600    0.9796    0.9697        98\n",
            " ORGANIZACAO     0.8710    0.8617    0.8663        94\n",
            "PRODUTODELEI     0.8235    0.7778    0.8000        54\n",
            "      EVENTO     0.8333    0.5556    0.6667         9\n",
            "\n",
            "   micro avg     0.8961    0.8932    0.8946       599\n",
            "   macro avg     0.8807    0.8394    0.8560       599\n",
            "weighted avg     0.8957    0.8932    0.8939       599\n",
            "\n",
            "2022-10-04 06:21:53,880 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_score': 0.8946488294314382,\n",
              " 'dev_score_history': [0.5040916530278232,\n",
              "  0.618213660245184,\n",
              "  0.7527472527472527,\n",
              "  0.7420000000000001,\n",
              "  0.7791519434628975,\n",
              "  0.7723292469352013,\n",
              "  0.8042895442359249,\n",
              "  0.8197945845004668,\n",
              "  0.82842287694974,\n",
              "  0.8449682683590208,\n",
              "  0.8388746803069055,\n",
              "  0.8444055944055944,\n",
              "  0.8363309352517986,\n",
              "  0.8506151142355008,\n",
              "  0.8683522231909329,\n",
              "  0.8566463944396178,\n",
              "  0.8631211857018308,\n",
              "  0.8612354521038496,\n",
              "  0.8603256212510711,\n",
              "  0.8741258741258741,\n",
              "  0.8881057268722466,\n",
              "  0.8726003490401397,\n",
              "  0.8528174936921783,\n",
              "  0.8853893263342082,\n",
              "  0.8821490467937607,\n",
              "  0.8825065274151437,\n",
              "  0.8906386701662291,\n",
              "  0.8970976253298153,\n",
              "  0.8788927335640138,\n",
              "  0.881118881118881,\n",
              "  0.896431679721497,\n",
              "  0.8888888888888888,\n",
              "  0.8933566433566434,\n",
              "  0.8890845070422535,\n",
              "  0.8913987836663771,\n",
              "  0.8935427574171029,\n",
              "  0.8879159369527145,\n",
              "  0.8896672504378285,\n",
              "  0.8857644991212653,\n",
              "  0.8921739130434783,\n",
              "  0.8929824561403509,\n",
              "  0.8898601398601399,\n",
              "  0.8879159369527145,\n",
              "  0.8914185639229423,\n",
              "  0.8898601398601399,\n",
              "  0.8906386701662291,\n",
              "  0.8906386701662291,\n",
              "  0.8906386701662291,\n",
              "  0.8906386701662291,\n",
              "  0.8906386701662291,\n",
              "  0.8914185639229423,\n",
              "  0.8921998247151621,\n",
              "  0.8906386701662291,\n",
              "  0.8906386701662291,\n",
              "  0.8914185639229423,\n",
              "  0.8898601398601399,\n",
              "  0.8908296943231442,\n",
              "  0.8898601398601399,\n",
              "  0.8898601398601399,\n",
              "  0.8906386701662291],\n",
              " 'train_loss_history': [0.324166766694639,\n",
              "  0.13905455491622426,\n",
              "  0.10240539725794269,\n",
              "  0.08001536761418682,\n",
              "  0.074007477580883,\n",
              "  0.06277379899065882,\n",
              "  0.05745753377578789,\n",
              "  0.051874964693025744,\n",
              "  0.04835534635248925,\n",
              "  0.04212120887305657,\n",
              "  0.0407063668498517,\n",
              "  0.038666686498093586,\n",
              "  0.03598583453755818,\n",
              "  0.03299440929281186,\n",
              "  0.029906381934452074,\n",
              "  0.02916487460099061,\n",
              "  0.027526485151347608,\n",
              "  0.027225395543626758,\n",
              "  0.026458288117409405,\n",
              "  0.020601076684150788,\n",
              "  0.017381500409642068,\n",
              "  0.01675255561619517,\n",
              "  0.017622322128333628,\n",
              "  0.0163399243777369,\n",
              "  0.01520006839001496,\n",
              "  0.013307246788932149,\n",
              "  0.013042163573437533,\n",
              "  0.012864945770922507,\n",
              "  0.012442899339329405,\n",
              "  0.01223339417124061,\n",
              "  0.012171747103529463,\n",
              "  0.012251560649427557,\n",
              "  0.010395169656910362,\n",
              "  0.011096153867225648,\n",
              "  0.0100566462862907,\n",
              "  0.010121317401419682,\n",
              "  0.010381944760087893,\n",
              "  0.009195143432350863,\n",
              "  0.008364313512295593,\n",
              "  0.009576966038424378,\n",
              "  0.007812264112887516,\n",
              "  0.008932088402150007,\n",
              "  0.008925780641259064,\n",
              "  0.008423041794042326,\n",
              "  0.008775864235593456,\n",
              "  0.008554798696677541,\n",
              "  0.008506122249627289,\n",
              "  0.007784866966161796,\n",
              "  0.00922090205139202,\n",
              "  0.008674777730422242,\n",
              "  0.007618631230585223,\n",
              "  0.008330143488557942,\n",
              "  0.009685674487391433,\n",
              "  0.00862009377126535,\n",
              "  0.008778997983200698,\n",
              "  0.008933230108456532,\n",
              "  0.008673756821145096,\n",
              "  0.008408433279802008,\n",
              "  0.008858703097119665,\n",
              "  0.008292043281155848],\n",
              " 'dev_loss_history': [0.16018033027648926,\n",
              "  0.08979383111000061,\n",
              "  0.06800028681755066,\n",
              "  0.07237409800291061,\n",
              "  0.06755087524652481,\n",
              "  0.05483702942728996,\n",
              "  0.05141553282737732,\n",
              "  0.05836400017142296,\n",
              "  0.04702908545732498,\n",
              "  0.04637054726481438,\n",
              "  0.04224751144647598,\n",
              "  0.038745809346437454,\n",
              "  0.04167303070425987,\n",
              "  0.041958753019571304,\n",
              "  0.03923148289322853,\n",
              "  0.04206893965601921,\n",
              "  0.03701391816139221,\n",
              "  0.04064689949154854,\n",
              "  0.03446009382605553,\n",
              "  0.03424276411533356,\n",
              "  0.03426947444677353,\n",
              "  0.03882388770580292,\n",
              "  0.041657477617263794,\n",
              "  0.03571942076086998,\n",
              "  0.03778481110930443,\n",
              "  0.03459864482283592,\n",
              "  0.034660086035728455,\n",
              "  0.03398394212126732,\n",
              "  0.03598839417099953,\n",
              "  0.03772483393549919,\n",
              "  0.03528624773025513,\n",
              "  0.03627915680408478,\n",
              "  0.03610891103744507,\n",
              "  0.036554399877786636,\n",
              "  0.03681835159659386,\n",
              "  0.0368008092045784,\n",
              "  0.037444423884153366,\n",
              "  0.036882925778627396,\n",
              "  0.03780832514166832,\n",
              "  0.0374482125043869,\n",
              "  0.037678979337215424,\n",
              "  0.03834991157054901,\n",
              "  0.038088683038949966,\n",
              "  0.037843670696020126,\n",
              "  0.03789843991398811,\n",
              "  0.03774372115731239,\n",
              "  0.037846531718969345,\n",
              "  0.03800590708851814,\n",
              "  0.038007382303476334,\n",
              "  0.038025226444005966,\n",
              "  0.038149621337652206,\n",
              "  0.038144659250974655,\n",
              "  0.03815596550703049,\n",
              "  0.03805556148290634,\n",
              "  0.038078758865594864,\n",
              "  0.038082562386989594,\n",
              "  0.03809021785855293,\n",
              "  0.03806339576840401,\n",
              "  0.03805448114871979,\n",
              "  0.038046371191740036]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# Initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "path = '/content/drive/MyDrive/Flair_NLP/sota-ner-flair'\n",
        "\n",
        "# Start training\n",
        "trainer.train(path,\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqkZzDs7XvWU"
      },
      "source": [
        "## Teste 4.3 NER Flair Stacked Embeddings (Word e Flair Embeddings) com Corpus Ulysses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9koheW1XvWU"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGPYMEVVXvWV"
      },
      "outputs": [],
      "source": [
        "## Importes\n",
        "## datasets\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxlUtHXUXvWV"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjdHxpqJXvWV",
        "outputId": "0abfdcf2-35d1-4df5-bb4f-31cc40f35497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogKkyEOFXvWV",
        "outputId": "9b2ef798-a0ed-45ee-94e5-32c3a8de35fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:18:46,495 Reading data from /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria\n",
            "2022-10-05 21:18:46,497 Train: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/train.txt\n",
            "2022-10-05 21:18:46,498 Dev: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/valid.txt\n",
            "2022-10-05 21:18:46,499 Test: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/test.txt\n"
          ]
        }
      ],
      "source": [
        "## carregando um corpus e definindo as colunas\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='valid.txt')\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgk0iC1HXvWV",
        "outputId": "508ded7a-f348-4fb1-a467-89a0decfab7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:18:54,409 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6667it [00:00, 53636.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:18:54,582 Dictionary created for label 'ner' with 8 values: PESSOA (seen 628 times), FUNDAMENTO (seen 490 times), ORGANIZACAO (seen 435 times), DATA (seen 433 times), LOCAL (seen 369 times), PRODUTODELEI (seen 230 times), EVENTO (seen 9 times)\n",
            "Dictionary with 8 tags: <unk>, PESSOA, FUNDAMENTO, ORGANIZACAO, DATA, LOCAL, PRODUTODELEI, EVENTO\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-t7lTzYXvWV"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPOc2pQCXvWV",
        "outputId": "6807c953-57ec-4db5-fa11-83ec6870eaca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:18:55,258 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmp4kfa13pe\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 710528528/710528528 [00:53<00:00, 13262686.27B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:19:49,803 copying /tmp/tmp4kfa13pe to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M.vectors.npy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:19:51,766 removing temp file /tmp/tmp4kfa13pe\n",
            "2022-10-05 21:19:52,816 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmpdxhnahfl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23541010/23541010 [00:03<00:00, 6577452.98B/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:19:57,086 copying /tmp/tmpdxhnahfl to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M\n",
            "2022-10-05 21:19:57,112 removing temp file /tmp/tmpdxhnahfl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:20:00,427 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-forward.pt not found in cache, downloading to /tmp/tmpa5j19a4h\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:06<00:00, 10789816.41B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:20:07,819 copying /tmp/tmpa5j19a4h to cache at /root/.flair/embeddings/lm-pt-forward.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:20:07,911 removing temp file /tmp/tmpa5j19a4h\n",
            "2022-10-05 21:20:18,702 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-pt-backward.pt not found in cache, downloading to /tmp/tmpcritzwjg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 72819080/72819080 [00:41<00:00, 1754470.60B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:21:00,910 copying /tmp/tmpcritzwjg to cache at /root/.flair/embeddings/lm-pt-backward.pt\n",
            "2022-10-05 21:21:00,979 removing temp file /tmp/tmpcritzwjg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Stacked Embeddings\n",
        "# Initialize embedding stack with \n",
        "embedding_types = [\n",
        "    WordEmbeddings('pt'),\n",
        "    FlairEmbeddings('pt-forward'),\n",
        "    FlairEmbeddings('pt-backward')\n",
        "]\n",
        "\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4Zo4q0dXvWV"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1NAYNS3XvWW",
        "outputId": "de77e505-19a5-40cb-bb3b-5555b9e9b567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:21:01,190 SequenceTagger predicts: Dictionary with 29 tags: O, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-FUNDAMENTO, B-FUNDAMENTO, E-FUNDAMENTO, I-FUNDAMENTO, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-DATA, B-DATA, E-DATA, I-DATA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL, S-PRODUTODELEI, B-PRODUTODELEI, E-PRODUTODELEI, I-PRODUTODELEI, S-EVENTO, B-EVENTO, E-EVENTO, I-EVENTO\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUKVmeVAXvWW",
        "outputId": "91da02a9-470f-4e07-8c79-9238c1d8eac8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/flair/trainers/trainer.py:65: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
            "  \"There should be no best model saved at epoch 1 except there \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:21:02,612 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:21:02,614 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'pt'\n",
            "      (embedding): Embedding(592108, 300)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.5, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4396, out_features=4396, bias=True)\n",
            "  (rnn): LSTM(4396, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=31, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-10-05 21:21:02,615 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:21:02,617 Corpus: \"Corpus: 6667 train + 1429 dev + 1430 test sentences\"\n",
            "2022-10-05 21:21:02,618 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:21:02,619 Parameters:\n",
            "2022-10-05 21:21:02,620  - learning_rate: \"0.100000\"\n",
            "2022-10-05 21:21:02,622  - mini_batch_size: \"32\"\n",
            "2022-10-05 21:21:02,623  - patience: \"3\"\n",
            "2022-10-05 21:21:02,628  - anneal_factor: \"0.5\"\n",
            "2022-10-05 21:21:02,630  - max_epochs: \"40\"\n",
            "2022-10-05 21:21:02,631  - shuffle: \"True\"\n",
            "2022-10-05 21:21:02,634  - train_with_dev: \"False\"\n",
            "2022-10-05 21:21:02,636  - batch_growth_annealing: \"False\"\n",
            "2022-10-05 21:21:02,638 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:21:02,639 Model training base path: \"/content/drive/MyDrive/Flair_NLP/sota-ner-flair\"\n",
            "2022-10-05 21:21:02,641 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:21:02,645 Device: cuda:0\n",
            "2022-10-05 21:21:02,647 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:21:02,648 Embeddings storage mode: cpu\n",
            "2022-10-05 21:21:02,649 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:21:13,925 epoch 1 - iter 20/209 - loss 1.25777442 - samples/sec: 56.78 - lr: 0.100000\n",
            "2022-10-05 21:21:31,978 epoch 1 - iter 40/209 - loss 0.80316787 - samples/sec: 35.46 - lr: 0.100000\n",
            "2022-10-05 21:21:45,329 epoch 1 - iter 60/209 - loss 0.67689762 - samples/sec: 47.95 - lr: 0.100000\n",
            "2022-10-05 21:21:59,208 epoch 1 - iter 80/209 - loss 0.58461340 - samples/sec: 46.12 - lr: 0.100000\n",
            "2022-10-05 21:22:14,330 epoch 1 - iter 100/209 - loss 0.50958686 - samples/sec: 42.33 - lr: 0.100000\n",
            "2022-10-05 21:22:29,082 epoch 1 - iter 120/209 - loss 0.47264126 - samples/sec: 43.40 - lr: 0.100000\n",
            "2022-10-05 21:22:43,126 epoch 1 - iter 140/209 - loss 0.44360391 - samples/sec: 45.59 - lr: 0.100000\n",
            "2022-10-05 21:22:57,884 epoch 1 - iter 160/209 - loss 0.42197810 - samples/sec: 43.38 - lr: 0.100000\n",
            "2022-10-05 21:23:14,866 epoch 1 - iter 180/209 - loss 0.40091394 - samples/sec: 37.69 - lr: 0.100000\n",
            "2022-10-05 21:23:30,122 epoch 1 - iter 200/209 - loss 0.37993950 - samples/sec: 41.96 - lr: 0.100000\n",
            "2022-10-05 21:23:36,536 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:23:36,537 EPOCH 1 done: loss 0.3750 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:33<00:00,  1.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:24:10,466 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:24:10,483 DEV : loss 0.1848800778388977 - f1-score (micro avg)  0.3554\n",
            "2022-10-05 21:24:10,587 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:24:10,592 saving best model\n",
            "2022-10-05 21:24:14,967 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:24:18,778 epoch 2 - iter 20/209 - loss 0.20290499 - samples/sec: 168.59 - lr: 0.100000\n",
            "2022-10-05 21:24:23,038 epoch 2 - iter 40/209 - loss 0.17775158 - samples/sec: 150.35 - lr: 0.100000\n",
            "2022-10-05 21:24:26,554 epoch 2 - iter 60/209 - loss 0.17685361 - samples/sec: 182.28 - lr: 0.100000\n",
            "2022-10-05 21:24:29,969 epoch 2 - iter 80/209 - loss 0.16575493 - samples/sec: 187.67 - lr: 0.100000\n",
            "2022-10-05 21:24:34,706 epoch 2 - iter 100/209 - loss 0.16704786 - samples/sec: 135.23 - lr: 0.100000\n",
            "2022-10-05 21:24:39,112 epoch 2 - iter 120/209 - loss 0.15990150 - samples/sec: 145.40 - lr: 0.100000\n",
            "2022-10-05 21:24:42,984 epoch 2 - iter 140/209 - loss 0.15841900 - samples/sec: 165.59 - lr: 0.100000\n",
            "2022-10-05 21:24:46,928 epoch 2 - iter 160/209 - loss 0.15631276 - samples/sec: 162.45 - lr: 0.100000\n",
            "2022-10-05 21:24:50,160 epoch 2 - iter 180/209 - loss 0.15472775 - samples/sec: 198.28 - lr: 0.100000\n",
            "2022-10-05 21:24:53,421 epoch 2 - iter 200/209 - loss 0.15114723 - samples/sec: 196.48 - lr: 0.100000\n",
            "2022-10-05 21:24:55,051 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:24:55,053 EPOCH 2 done: loss 0.1498 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:25:03,591 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:25:03,606 DEV : loss 0.10556729137897491 - f1-score (micro avg)  0.6008\n",
            "2022-10-05 21:25:03,705 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:25:03,709 saving best model\n",
            "2022-10-05 21:25:07,946 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:25:11,409 epoch 3 - iter 20/209 - loss 0.11541722 - samples/sec: 185.13 - lr: 0.100000\n",
            "2022-10-05 21:25:16,403 epoch 3 - iter 40/209 - loss 0.11182255 - samples/sec: 128.26 - lr: 0.100000\n",
            "2022-10-05 21:25:20,328 epoch 3 - iter 60/209 - loss 0.12935928 - samples/sec: 163.21 - lr: 0.100000\n",
            "2022-10-05 21:25:24,428 epoch 3 - iter 80/209 - loss 0.12186519 - samples/sec: 156.29 - lr: 0.100000\n",
            "2022-10-05 21:25:28,325 epoch 3 - iter 100/209 - loss 0.11785908 - samples/sec: 164.40 - lr: 0.100000\n",
            "2022-10-05 21:25:32,210 epoch 3 - iter 120/209 - loss 0.11635322 - samples/sec: 164.92 - lr: 0.100000\n",
            "2022-10-05 21:25:36,208 epoch 3 - iter 140/209 - loss 0.11446433 - samples/sec: 160.28 - lr: 0.100000\n",
            "2022-10-05 21:25:40,085 epoch 3 - iter 160/209 - loss 0.11365239 - samples/sec: 165.24 - lr: 0.100000\n",
            "2022-10-05 21:25:44,012 epoch 3 - iter 180/209 - loss 0.11240089 - samples/sec: 163.16 - lr: 0.100000\n",
            "2022-10-05 21:25:47,372 epoch 3 - iter 200/209 - loss 0.11233121 - samples/sec: 190.71 - lr: 0.100000\n",
            "2022-10-05 21:25:49,046 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:25:49,048 EPOCH 3 done: loss 0.1104 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:25:57,727 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:25:57,741 DEV : loss 0.10561355203390121 - f1-score (micro avg)  0.6265\n",
            "2022-10-05 21:25:57,844 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:25:57,849 saving best model\n",
            "2022-10-05 21:26:02,054 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:26:07,352 epoch 4 - iter 20/209 - loss 0.08648542 - samples/sec: 120.93 - lr: 0.100000\n",
            "2022-10-05 21:26:11,116 epoch 4 - iter 40/209 - loss 0.09000425 - samples/sec: 170.22 - lr: 0.100000\n",
            "2022-10-05 21:26:15,110 epoch 4 - iter 60/209 - loss 0.08596960 - samples/sec: 160.38 - lr: 0.100000\n",
            "2022-10-05 21:26:19,234 epoch 4 - iter 80/209 - loss 0.08908865 - samples/sec: 155.38 - lr: 0.100000\n",
            "2022-10-05 21:26:22,871 epoch 4 - iter 100/209 - loss 0.09743297 - samples/sec: 176.18 - lr: 0.100000\n",
            "2022-10-05 21:26:26,414 epoch 4 - iter 120/209 - loss 0.09350501 - samples/sec: 180.82 - lr: 0.100000\n",
            "2022-10-05 21:26:30,291 epoch 4 - iter 140/209 - loss 0.09225635 - samples/sec: 165.28 - lr: 0.100000\n",
            "2022-10-05 21:26:33,716 epoch 4 - iter 160/209 - loss 0.09066095 - samples/sec: 187.10 - lr: 0.100000\n",
            "2022-10-05 21:26:37,314 epoch 4 - iter 180/209 - loss 0.08923384 - samples/sec: 178.05 - lr: 0.100000\n",
            "2022-10-05 21:26:40,854 epoch 4 - iter 200/209 - loss 0.08771683 - samples/sec: 180.98 - lr: 0.100000\n",
            "2022-10-05 21:26:42,550 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:26:42,552 EPOCH 4 done: loss 0.0874 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:26:51,054 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:26:51,070 DEV : loss 0.06625504791736603 - f1-score (micro avg)  0.7642\n",
            "2022-10-05 21:26:51,184 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:26:51,189 saving best model\n",
            "2022-10-05 21:26:55,281 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:26:58,715 epoch 5 - iter 20/209 - loss 0.07382398 - samples/sec: 186.66 - lr: 0.100000\n",
            "2022-10-05 21:27:02,542 epoch 5 - iter 40/209 - loss 0.07442300 - samples/sec: 167.39 - lr: 0.100000\n",
            "2022-10-05 21:27:06,147 epoch 5 - iter 60/209 - loss 0.07241555 - samples/sec: 177.78 - lr: 0.100000\n",
            "2022-10-05 21:27:10,762 epoch 5 - iter 80/209 - loss 0.07524735 - samples/sec: 138.83 - lr: 0.100000\n",
            "2022-10-05 21:27:15,334 epoch 5 - iter 100/209 - loss 0.07657167 - samples/sec: 140.13 - lr: 0.100000\n",
            "2022-10-05 21:27:18,434 epoch 5 - iter 120/209 - loss 0.07292674 - samples/sec: 206.70 - lr: 0.100000\n",
            "2022-10-05 21:27:22,923 epoch 5 - iter 140/209 - loss 0.07319745 - samples/sec: 142.76 - lr: 0.100000\n",
            "2022-10-05 21:27:26,663 epoch 5 - iter 160/209 - loss 0.07137934 - samples/sec: 171.32 - lr: 0.100000\n",
            "2022-10-05 21:27:29,622 epoch 5 - iter 180/209 - loss 0.07033773 - samples/sec: 216.61 - lr: 0.100000\n",
            "2022-10-05 21:27:33,532 epoch 5 - iter 200/209 - loss 0.06997024 - samples/sec: 163.82 - lr: 0.100000\n",
            "2022-10-05 21:27:35,050 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:27:35,052 EPOCH 5 done: loss 0.0700 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:27:43,763 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:27:43,778 DEV : loss 0.0641130656003952 - f1-score (micro avg)  0.7273\n",
            "2022-10-05 21:27:43,881 BAD EPOCHS (no improvement): 1\n",
            "2022-10-05 21:27:43,886 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:27:48,346 epoch 6 - iter 20/209 - loss 0.07178041 - samples/sec: 143.65 - lr: 0.100000\n",
            "2022-10-05 21:27:51,428 epoch 6 - iter 40/209 - loss 0.07102524 - samples/sec: 207.89 - lr: 0.100000\n",
            "2022-10-05 21:27:55,330 epoch 6 - iter 60/209 - loss 0.06735485 - samples/sec: 164.15 - lr: 0.100000\n",
            "2022-10-05 21:27:58,659 epoch 6 - iter 80/209 - loss 0.06497303 - samples/sec: 192.48 - lr: 0.100000\n",
            "2022-10-05 21:28:01,894 epoch 6 - iter 100/209 - loss 0.06898219 - samples/sec: 198.10 - lr: 0.100000\n",
            "2022-10-05 21:28:06,344 epoch 6 - iter 120/209 - loss 0.06644753 - samples/sec: 143.96 - lr: 0.100000\n",
            "2022-10-05 21:28:10,132 epoch 6 - iter 140/209 - loss 0.06407983 - samples/sec: 169.15 - lr: 0.100000\n",
            "2022-10-05 21:28:15,237 epoch 6 - iter 160/209 - loss 0.06256828 - samples/sec: 125.48 - lr: 0.100000\n",
            "2022-10-05 21:28:19,011 epoch 6 - iter 180/209 - loss 0.06213842 - samples/sec: 169.78 - lr: 0.100000\n",
            "2022-10-05 21:28:21,892 epoch 6 - iter 200/209 - loss 0.06194981 - samples/sec: 222.48 - lr: 0.100000\n",
            "2022-10-05 21:28:23,953 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:28:23,955 EPOCH 6 done: loss 0.0614 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:28:32,724 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:28:32,739 DEV : loss 0.053595658391714096 - f1-score (micro avg)  0.8236\n",
            "2022-10-05 21:28:32,843 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:28:32,847 saving best model\n",
            "2022-10-05 21:28:37,029 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:28:40,755 epoch 7 - iter 20/209 - loss 0.04414143 - samples/sec: 172.11 - lr: 0.100000\n",
            "2022-10-05 21:28:44,641 epoch 7 - iter 40/209 - loss 0.05017447 - samples/sec: 164.89 - lr: 0.100000\n",
            "2022-10-05 21:28:48,272 epoch 7 - iter 60/209 - loss 0.05605570 - samples/sec: 176.44 - lr: 0.100000\n",
            "2022-10-05 21:28:52,497 epoch 7 - iter 80/209 - loss 0.05949845 - samples/sec: 151.61 - lr: 0.100000\n",
            "2022-10-05 21:28:56,123 epoch 7 - iter 100/209 - loss 0.05599440 - samples/sec: 176.71 - lr: 0.100000\n",
            "2022-10-05 21:29:00,661 epoch 7 - iter 120/209 - loss 0.05359963 - samples/sec: 141.13 - lr: 0.100000\n",
            "2022-10-05 21:29:05,266 epoch 7 - iter 140/209 - loss 0.05388439 - samples/sec: 139.14 - lr: 0.100000\n",
            "2022-10-05 21:29:09,053 epoch 7 - iter 160/209 - loss 0.05433543 - samples/sec: 169.16 - lr: 0.100000\n",
            "2022-10-05 21:29:12,543 epoch 7 - iter 180/209 - loss 0.05279126 - samples/sec: 183.61 - lr: 0.100000\n",
            "2022-10-05 21:29:16,172 epoch 7 - iter 200/209 - loss 0.05325638 - samples/sec: 176.52 - lr: 0.100000\n",
            "2022-10-05 21:29:17,764 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:29:17,766 EPOCH 7 done: loss 0.0528 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:29:26,500 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:29:26,514 DEV : loss 0.04733815789222717 - f1-score (micro avg)  0.8326\n",
            "2022-10-05 21:29:26,613 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:29:26,617 saving best model\n",
            "2022-10-05 21:29:30,762 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:29:36,049 epoch 8 - iter 20/209 - loss 0.04569936 - samples/sec: 121.22 - lr: 0.100000\n",
            "2022-10-05 21:29:39,284 epoch 8 - iter 40/209 - loss 0.05077859 - samples/sec: 198.04 - lr: 0.100000\n",
            "2022-10-05 21:29:43,534 epoch 8 - iter 60/209 - loss 0.04905524 - samples/sec: 150.73 - lr: 0.100000\n",
            "2022-10-05 21:29:47,673 epoch 8 - iter 80/209 - loss 0.04949787 - samples/sec: 154.81 - lr: 0.100000\n",
            "2022-10-05 21:29:51,841 epoch 8 - iter 100/209 - loss 0.04512084 - samples/sec: 153.69 - lr: 0.100000\n",
            "2022-10-05 21:29:55,378 epoch 8 - iter 120/209 - loss 0.04542671 - samples/sec: 181.17 - lr: 0.100000\n",
            "2022-10-05 21:30:00,029 epoch 8 - iter 140/209 - loss 0.04681635 - samples/sec: 137.76 - lr: 0.100000\n",
            "2022-10-05 21:30:03,244 epoch 8 - iter 160/209 - loss 0.04650454 - samples/sec: 199.24 - lr: 0.100000\n",
            "2022-10-05 21:30:07,064 epoch 8 - iter 180/209 - loss 0.04576327 - samples/sec: 167.74 - lr: 0.100000\n",
            "2022-10-05 21:30:10,833 epoch 8 - iter 200/209 - loss 0.04514502 - samples/sec: 170.00 - lr: 0.100000\n",
            "2022-10-05 21:30:12,463 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:30:12,466 EPOCH 8 done: loss 0.0453 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:30:21,083 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:30:21,100 DEV : loss 0.04674920812249184 - f1-score (micro avg)  0.8346\n",
            "2022-10-05 21:30:21,210 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:30:21,215 saving best model\n",
            "2022-10-05 21:30:25,358 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:30:29,194 epoch 9 - iter 20/209 - loss 0.03085014 - samples/sec: 167.11 - lr: 0.100000\n",
            "2022-10-05 21:30:33,631 epoch 9 - iter 40/209 - loss 0.03677123 - samples/sec: 144.34 - lr: 0.100000\n",
            "2022-10-05 21:30:37,387 epoch 9 - iter 60/209 - loss 0.03806133 - samples/sec: 170.60 - lr: 0.100000\n",
            "2022-10-05 21:30:41,768 epoch 9 - iter 80/209 - loss 0.03881291 - samples/sec: 146.21 - lr: 0.100000\n",
            "2022-10-05 21:30:44,895 epoch 9 - iter 100/209 - loss 0.03928512 - samples/sec: 204.98 - lr: 0.100000\n",
            "2022-10-05 21:30:48,238 epoch 9 - iter 120/209 - loss 0.03969840 - samples/sec: 191.70 - lr: 0.100000\n",
            "2022-10-05 21:30:52,730 epoch 9 - iter 140/209 - loss 0.03996324 - samples/sec: 142.64 - lr: 0.100000\n",
            "2022-10-05 21:30:56,564 epoch 9 - iter 160/209 - loss 0.04055610 - samples/sec: 167.07 - lr: 0.100000\n",
            "2022-10-05 21:31:01,052 epoch 9 - iter 180/209 - loss 0.04152104 - samples/sec: 142.72 - lr: 0.100000\n",
            "2022-10-05 21:31:03,998 epoch 9 - iter 200/209 - loss 0.04214951 - samples/sec: 217.57 - lr: 0.100000\n",
            "2022-10-05 21:31:05,784 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:31:05,786 EPOCH 9 done: loss 0.0425 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:31:14,594 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:31:14,608 DEV : loss 0.04545168578624725 - f1-score (micro avg)  0.8434\n",
            "2022-10-05 21:31:14,708 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:31:14,713 saving best model\n",
            "2022-10-05 21:31:18,878 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:31:23,917 epoch 10 - iter 20/209 - loss 0.03383951 - samples/sec: 127.13 - lr: 0.100000\n",
            "2022-10-05 21:31:28,117 epoch 10 - iter 40/209 - loss 0.03514448 - samples/sec: 152.57 - lr: 0.100000\n",
            "2022-10-05 21:31:31,723 epoch 10 - iter 60/209 - loss 0.03327105 - samples/sec: 177.70 - lr: 0.100000\n",
            "2022-10-05 21:31:36,083 epoch 10 - iter 80/209 - loss 0.03435673 - samples/sec: 146.94 - lr: 0.100000\n",
            "2022-10-05 21:31:39,629 epoch 10 - iter 100/209 - loss 0.03522639 - samples/sec: 180.65 - lr: 0.100000\n",
            "2022-10-05 21:31:43,819 epoch 10 - iter 120/209 - loss 0.03621806 - samples/sec: 152.90 - lr: 0.100000\n",
            "2022-10-05 21:31:47,296 epoch 10 - iter 140/209 - loss 0.03742392 - samples/sec: 184.27 - lr: 0.100000\n",
            "2022-10-05 21:31:50,816 epoch 10 - iter 160/209 - loss 0.03820705 - samples/sec: 182.01 - lr: 0.100000\n",
            "2022-10-05 21:31:54,492 epoch 10 - iter 180/209 - loss 0.04007602 - samples/sec: 174.26 - lr: 0.100000\n",
            "2022-10-05 21:31:58,114 epoch 10 - iter 200/209 - loss 0.03982949 - samples/sec: 176.91 - lr: 0.100000\n",
            "2022-10-05 21:32:00,121 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:32:00,123 EPOCH 10 done: loss 0.0401 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:32:08,965 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:32:08,986 DEV : loss 0.04424387961626053 - f1-score (micro avg)  0.8622\n",
            "2022-10-05 21:32:09,090 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:32:09,094 saving best model\n",
            "2022-10-05 21:32:13,127 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:32:17,122 epoch 11 - iter 20/209 - loss 0.03257700 - samples/sec: 160.40 - lr: 0.100000\n",
            "2022-10-05 21:32:21,086 epoch 11 - iter 40/209 - loss 0.03352178 - samples/sec: 161.64 - lr: 0.100000\n",
            "2022-10-05 21:32:24,932 epoch 11 - iter 60/209 - loss 0.03510874 - samples/sec: 166.59 - lr: 0.100000\n",
            "2022-10-05 21:32:28,739 epoch 11 - iter 80/209 - loss 0.03390923 - samples/sec: 168.31 - lr: 0.100000\n",
            "2022-10-05 21:32:32,470 epoch 11 - iter 100/209 - loss 0.03517851 - samples/sec: 171.77 - lr: 0.100000\n",
            "2022-10-05 21:32:36,650 epoch 11 - iter 120/209 - loss 0.03514172 - samples/sec: 153.29 - lr: 0.100000\n",
            "2022-10-05 21:32:40,707 epoch 11 - iter 140/209 - loss 0.03323607 - samples/sec: 157.95 - lr: 0.100000\n",
            "2022-10-05 21:32:43,971 epoch 11 - iter 160/209 - loss 0.03483922 - samples/sec: 196.38 - lr: 0.100000\n",
            "2022-10-05 21:32:47,747 epoch 11 - iter 180/209 - loss 0.03504728 - samples/sec: 169.68 - lr: 0.100000\n",
            "2022-10-05 21:32:52,529 epoch 11 - iter 200/209 - loss 0.03644593 - samples/sec: 133.96 - lr: 0.100000\n",
            "2022-10-05 21:32:53,934 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:32:53,936 EPOCH 11 done: loss 0.0368 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:33:02,525 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:33:02,539 DEV : loss 0.04265153035521507 - f1-score (micro avg)  0.8579\n",
            "2022-10-05 21:33:02,639 BAD EPOCHS (no improvement): 1\n",
            "2022-10-05 21:33:02,643 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:33:06,662 epoch 12 - iter 20/209 - loss 0.03155935 - samples/sec: 159.44 - lr: 0.100000\n",
            "2022-10-05 21:33:10,075 epoch 12 - iter 40/209 - loss 0.03468160 - samples/sec: 187.73 - lr: 0.100000\n",
            "2022-10-05 21:33:14,369 epoch 12 - iter 60/209 - loss 0.03069837 - samples/sec: 149.19 - lr: 0.100000\n",
            "2022-10-05 21:33:18,599 epoch 12 - iter 80/209 - loss 0.03005796 - samples/sec: 151.44 - lr: 0.100000\n",
            "2022-10-05 21:33:22,344 epoch 12 - iter 100/209 - loss 0.03097189 - samples/sec: 171.06 - lr: 0.100000\n",
            "2022-10-05 21:33:25,843 epoch 12 - iter 120/209 - loss 0.03324901 - samples/sec: 183.16 - lr: 0.100000\n",
            "2022-10-05 21:33:29,472 epoch 12 - iter 140/209 - loss 0.03524909 - samples/sec: 176.52 - lr: 0.100000\n",
            "2022-10-05 21:33:33,176 epoch 12 - iter 160/209 - loss 0.03384007 - samples/sec: 172.98 - lr: 0.100000\n",
            "2022-10-05 21:33:36,984 epoch 12 - iter 180/209 - loss 0.03327405 - samples/sec: 168.27 - lr: 0.100000\n",
            "2022-10-05 21:33:40,918 epoch 12 - iter 200/209 - loss 0.03385853 - samples/sec: 162.89 - lr: 0.100000\n",
            "2022-10-05 21:33:42,537 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:33:42,539 EPOCH 12 done: loss 0.0343 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:33:51,380 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:33:51,398 DEV : loss 0.04187864810228348 - f1-score (micro avg)  0.8607\n",
            "2022-10-05 21:33:51,498 BAD EPOCHS (no improvement): 2\n",
            "2022-10-05 21:33:51,502 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:33:54,614 epoch 13 - iter 20/209 - loss 0.03408621 - samples/sec: 206.06 - lr: 0.100000\n",
            "2022-10-05 21:33:58,329 epoch 13 - iter 40/209 - loss 0.03399409 - samples/sec: 172.44 - lr: 0.100000\n",
            "2022-10-05 21:34:02,751 epoch 13 - iter 60/209 - loss 0.03419849 - samples/sec: 144.89 - lr: 0.100000\n",
            "2022-10-05 21:34:06,369 epoch 13 - iter 80/209 - loss 0.03294558 - samples/sec: 177.04 - lr: 0.100000\n",
            "2022-10-05 21:34:10,190 epoch 13 - iter 100/209 - loss 0.03109294 - samples/sec: 167.71 - lr: 0.100000\n",
            "2022-10-05 21:34:13,707 epoch 13 - iter 120/209 - loss 0.03091515 - samples/sec: 182.20 - lr: 0.100000\n",
            "2022-10-05 21:34:17,424 epoch 13 - iter 140/209 - loss 0.03142319 - samples/sec: 172.38 - lr: 0.100000\n",
            "2022-10-05 21:34:21,027 epoch 13 - iter 160/209 - loss 0.03096344 - samples/sec: 177.83 - lr: 0.100000\n",
            "2022-10-05 21:34:24,954 epoch 13 - iter 180/209 - loss 0.03052709 - samples/sec: 163.13 - lr: 0.100000\n",
            "2022-10-05 21:34:29,078 epoch 13 - iter 200/209 - loss 0.03098197 - samples/sec: 155.34 - lr: 0.100000\n",
            "2022-10-05 21:34:30,758 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:34:30,759 EPOCH 13 done: loss 0.0310 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:34:39,346 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:34:39,360 DEV : loss 0.03841810300946236 - f1-score (micro avg)  0.8818\n",
            "2022-10-05 21:34:39,460 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:34:39,463 saving best model\n",
            "2022-10-05 21:34:43,571 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:34:47,883 epoch 14 - iter 20/209 - loss 0.02195948 - samples/sec: 148.62 - lr: 0.100000\n",
            "2022-10-05 21:34:51,565 epoch 14 - iter 40/209 - loss 0.02317068 - samples/sec: 174.01 - lr: 0.100000\n",
            "2022-10-05 21:34:55,464 epoch 14 - iter 60/209 - loss 0.02174408 - samples/sec: 164.35 - lr: 0.100000\n",
            "2022-10-05 21:34:59,431 epoch 14 - iter 80/209 - loss 0.02539978 - samples/sec: 161.51 - lr: 0.100000\n",
            "2022-10-05 21:35:04,574 epoch 14 - iter 100/209 - loss 0.02694561 - samples/sec: 124.57 - lr: 0.100000\n",
            "2022-10-05 21:35:08,458 epoch 14 - iter 120/209 - loss 0.02681864 - samples/sec: 164.95 - lr: 0.100000\n",
            "2022-10-05 21:35:12,846 epoch 14 - iter 140/209 - loss 0.02573051 - samples/sec: 146.00 - lr: 0.100000\n",
            "2022-10-05 21:35:15,991 epoch 14 - iter 160/209 - loss 0.02714955 - samples/sec: 203.79 - lr: 0.100000\n",
            "2022-10-05 21:35:20,286 epoch 14 - iter 180/209 - loss 0.02706318 - samples/sec: 149.14 - lr: 0.100000\n",
            "2022-10-05 21:35:23,442 epoch 14 - iter 200/209 - loss 0.02762156 - samples/sec: 203.00 - lr: 0.100000\n",
            "2022-10-05 21:35:25,130 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:35:25,132 EPOCH 14 done: loss 0.0282 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:35:33,919 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:35:33,932 DEV : loss 0.04374944046139717 - f1-score (micro avg)  0.8445\n",
            "2022-10-05 21:35:34,033 BAD EPOCHS (no improvement): 1\n",
            "2022-10-05 21:35:34,038 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:35:37,743 epoch 15 - iter 20/209 - loss 0.02351027 - samples/sec: 172.97 - lr: 0.100000\n",
            "2022-10-05 21:35:42,481 epoch 15 - iter 40/209 - loss 0.02376470 - samples/sec: 135.21 - lr: 0.100000\n",
            "2022-10-05 21:35:46,564 epoch 15 - iter 60/209 - loss 0.02417537 - samples/sec: 156.88 - lr: 0.100000\n",
            "2022-10-05 21:35:50,730 epoch 15 - iter 80/209 - loss 0.02424160 - samples/sec: 153.79 - lr: 0.100000\n",
            "2022-10-05 21:35:54,673 epoch 15 - iter 100/209 - loss 0.02404251 - samples/sec: 162.48 - lr: 0.100000\n",
            "2022-10-05 21:35:58,269 epoch 15 - iter 120/209 - loss 0.02405063 - samples/sec: 178.22 - lr: 0.100000\n",
            "2022-10-05 21:36:01,505 epoch 15 - iter 140/209 - loss 0.02491102 - samples/sec: 198.00 - lr: 0.100000\n",
            "2022-10-05 21:36:04,895 epoch 15 - iter 160/209 - loss 0.02663132 - samples/sec: 189.10 - lr: 0.100000\n",
            "2022-10-05 21:36:08,821 epoch 15 - iter 180/209 - loss 0.02657392 - samples/sec: 163.18 - lr: 0.100000\n",
            "2022-10-05 21:36:11,847 epoch 15 - iter 200/209 - loss 0.02742681 - samples/sec: 211.79 - lr: 0.100000\n",
            "2022-10-05 21:36:13,441 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:36:13,443 EPOCH 15 done: loss 0.0271 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:36:22,224 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:36:22,239 DEV : loss 0.04772869125008583 - f1-score (micro avg)  0.8637\n",
            "2022-10-05 21:36:22,341 BAD EPOCHS (no improvement): 2\n",
            "2022-10-05 21:36:22,345 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:36:25,883 epoch 16 - iter 20/209 - loss 0.01926824 - samples/sec: 181.16 - lr: 0.100000\n",
            "2022-10-05 21:36:29,906 epoch 16 - iter 40/209 - loss 0.02653799 - samples/sec: 159.27 - lr: 0.100000\n",
            "2022-10-05 21:36:33,716 epoch 16 - iter 60/209 - loss 0.02486661 - samples/sec: 168.14 - lr: 0.100000\n",
            "2022-10-05 21:36:36,950 epoch 16 - iter 80/209 - loss 0.02407938 - samples/sec: 198.14 - lr: 0.100000\n",
            "2022-10-05 21:36:40,413 epoch 16 - iter 100/209 - loss 0.02526230 - samples/sec: 185.08 - lr: 0.100000\n",
            "2022-10-05 21:36:44,403 epoch 16 - iter 120/209 - loss 0.02407721 - samples/sec: 160.55 - lr: 0.100000\n",
            "2022-10-05 21:36:48,319 epoch 16 - iter 140/209 - loss 0.02429720 - samples/sec: 163.62 - lr: 0.100000\n",
            "2022-10-05 21:36:51,964 epoch 16 - iter 160/209 - loss 0.02517173 - samples/sec: 175.79 - lr: 0.100000\n",
            "2022-10-05 21:36:56,490 epoch 16 - iter 180/209 - loss 0.02637966 - samples/sec: 141.53 - lr: 0.100000\n",
            "2022-10-05 21:37:00,649 epoch 16 - iter 200/209 - loss 0.02581683 - samples/sec: 154.03 - lr: 0.100000\n",
            "2022-10-05 21:37:01,962 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:37:01,963 EPOCH 16 done: loss 0.0257 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:37:10,691 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:37:10,705 DEV : loss 0.04398127645254135 - f1-score (micro avg)  0.8621\n",
            "2022-10-05 21:37:10,808 BAD EPOCHS (no improvement): 3\n",
            "2022-10-05 21:37:10,812 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:37:14,339 epoch 17 - iter 20/209 - loss 0.02031844 - samples/sec: 181.71 - lr: 0.100000\n",
            "2022-10-05 21:37:17,409 epoch 17 - iter 40/209 - loss 0.02325208 - samples/sec: 208.75 - lr: 0.100000\n",
            "2022-10-05 21:37:22,055 epoch 17 - iter 60/209 - loss 0.02726224 - samples/sec: 137.91 - lr: 0.100000\n",
            "2022-10-05 21:37:25,625 epoch 17 - iter 80/209 - loss 0.02616710 - samples/sec: 179.48 - lr: 0.100000\n",
            "2022-10-05 21:37:29,351 epoch 17 - iter 100/209 - loss 0.02663420 - samples/sec: 171.91 - lr: 0.100000\n",
            "2022-10-05 21:37:33,062 epoch 17 - iter 120/209 - loss 0.02624300 - samples/sec: 172.63 - lr: 0.100000\n",
            "2022-10-05 21:37:37,218 epoch 17 - iter 140/209 - loss 0.02598901 - samples/sec: 154.16 - lr: 0.100000\n",
            "2022-10-05 21:37:40,787 epoch 17 - iter 160/209 - loss 0.02585009 - samples/sec: 179.52 - lr: 0.100000\n",
            "2022-10-05 21:37:44,145 epoch 17 - iter 180/209 - loss 0.02553335 - samples/sec: 190.81 - lr: 0.100000\n",
            "2022-10-05 21:37:48,625 epoch 17 - iter 200/209 - loss 0.02517070 - samples/sec: 142.99 - lr: 0.100000\n",
            "2022-10-05 21:37:50,248 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:37:50,251 EPOCH 17 done: loss 0.0253 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:37:59,071 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:37:59,085 DEV : loss 0.0367460660636425 - f1-score (micro avg)  0.8754\n",
            "2022-10-05 21:37:59,187 Epoch    17: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2022-10-05 21:37:59,189 BAD EPOCHS (no improvement): 4\n",
            "2022-10-05 21:37:59,193 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:38:03,376 epoch 18 - iter 20/209 - loss 0.01589900 - samples/sec: 153.19 - lr: 0.050000\n",
            "2022-10-05 21:38:07,760 epoch 18 - iter 40/209 - loss 0.01636240 - samples/sec: 146.12 - lr: 0.050000\n",
            "2022-10-05 21:38:10,961 epoch 18 - iter 60/209 - loss 0.01623631 - samples/sec: 200.20 - lr: 0.050000\n",
            "2022-10-05 21:38:15,519 epoch 18 - iter 80/209 - loss 0.01857460 - samples/sec: 140.52 - lr: 0.050000\n",
            "2022-10-05 21:38:19,262 epoch 18 - iter 100/209 - loss 0.01845181 - samples/sec: 171.20 - lr: 0.050000\n",
            "2022-10-05 21:38:23,174 epoch 18 - iter 120/209 - loss 0.01829115 - samples/sec: 163.74 - lr: 0.050000\n",
            "2022-10-05 21:38:27,054 epoch 18 - iter 140/209 - loss 0.01853521 - samples/sec: 165.12 - lr: 0.050000\n",
            "2022-10-05 21:38:30,607 epoch 18 - iter 160/209 - loss 0.01858244 - samples/sec: 180.36 - lr: 0.050000\n",
            "2022-10-05 21:38:34,853 epoch 18 - iter 180/209 - loss 0.01843820 - samples/sec: 150.86 - lr: 0.050000\n",
            "2022-10-05 21:38:38,022 epoch 18 - iter 200/209 - loss 0.01913909 - samples/sec: 202.24 - lr: 0.050000\n",
            "2022-10-05 21:38:39,078 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:38:39,080 EPOCH 18 done: loss 0.0195 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:38:47,782 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:38:47,797 DEV : loss 0.041797056794166565 - f1-score (micro avg)  0.8797\n",
            "2022-10-05 21:38:47,901 BAD EPOCHS (no improvement): 1\n",
            "2022-10-05 21:38:47,906 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:38:52,111 epoch 19 - iter 20/209 - loss 0.01687931 - samples/sec: 152.37 - lr: 0.050000\n",
            "2022-10-05 21:38:55,825 epoch 19 - iter 40/209 - loss 0.01821464 - samples/sec: 172.52 - lr: 0.050000\n",
            "2022-10-05 21:38:59,055 epoch 19 - iter 60/209 - loss 0.01724672 - samples/sec: 198.46 - lr: 0.050000\n",
            "2022-10-05 21:39:02,551 epoch 19 - iter 80/209 - loss 0.01668321 - samples/sec: 183.23 - lr: 0.050000\n",
            "2022-10-05 21:39:06,801 epoch 19 - iter 100/209 - loss 0.01839335 - samples/sec: 150.75 - lr: 0.050000\n",
            "2022-10-05 21:39:10,485 epoch 19 - iter 120/209 - loss 0.01732240 - samples/sec: 173.87 - lr: 0.050000\n",
            "2022-10-05 21:39:15,106 epoch 19 - iter 140/209 - loss 0.01673944 - samples/sec: 138.63 - lr: 0.050000\n",
            "2022-10-05 21:39:19,011 epoch 19 - iter 160/209 - loss 0.01791802 - samples/sec: 164.07 - lr: 0.050000\n",
            "2022-10-05 21:39:22,267 epoch 19 - iter 180/209 - loss 0.01730830 - samples/sec: 196.78 - lr: 0.050000\n",
            "2022-10-05 21:39:25,470 epoch 19 - iter 200/209 - loss 0.01723802 - samples/sec: 200.13 - lr: 0.050000\n",
            "2022-10-05 21:39:26,683 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:39:26,685 EPOCH 19 done: loss 0.0172 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:39:35,257 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:39:35,272 DEV : loss 0.0396113283932209 - f1-score (micro avg)  0.8806\n",
            "2022-10-05 21:39:35,372 BAD EPOCHS (no improvement): 2\n",
            "2022-10-05 21:39:35,376 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:39:39,487 epoch 20 - iter 20/209 - loss 0.01300777 - samples/sec: 155.87 - lr: 0.050000\n",
            "2022-10-05 21:39:43,108 epoch 20 - iter 40/209 - loss 0.01113714 - samples/sec: 176.99 - lr: 0.050000\n",
            "2022-10-05 21:39:46,728 epoch 20 - iter 60/209 - loss 0.01352605 - samples/sec: 177.00 - lr: 0.050000\n",
            "2022-10-05 21:39:50,748 epoch 20 - iter 80/209 - loss 0.01432690 - samples/sec: 159.37 - lr: 0.050000\n",
            "2022-10-05 21:39:54,557 epoch 20 - iter 100/209 - loss 0.01359308 - samples/sec: 168.25 - lr: 0.050000\n",
            "2022-10-05 21:39:58,185 epoch 20 - iter 120/209 - loss 0.01347934 - samples/sec: 176.60 - lr: 0.050000\n",
            "2022-10-05 21:40:01,908 epoch 20 - iter 140/209 - loss 0.01329447 - samples/sec: 172.09 - lr: 0.050000\n",
            "2022-10-05 21:40:05,427 epoch 20 - iter 160/209 - loss 0.01364284 - samples/sec: 182.07 - lr: 0.050000\n",
            "2022-10-05 21:40:08,590 epoch 20 - iter 180/209 - loss 0.01368065 - samples/sec: 202.59 - lr: 0.050000\n",
            "2022-10-05 21:40:12,423 epoch 20 - iter 200/209 - loss 0.01479059 - samples/sec: 167.15 - lr: 0.050000\n",
            "2022-10-05 21:40:14,719 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:40:14,721 EPOCH 20 done: loss 0.0154 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:40:23,549 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:40:23,565 DEV : loss 0.04213029518723488 - f1-score (micro avg)  0.8846\n",
            "2022-10-05 21:40:23,666 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:40:23,671 saving best model\n",
            "2022-10-05 21:40:27,755 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:40:31,723 epoch 21 - iter 20/209 - loss 0.00371124 - samples/sec: 161.53 - lr: 0.050000\n",
            "2022-10-05 21:40:35,305 epoch 21 - iter 40/209 - loss 0.00980371 - samples/sec: 178.86 - lr: 0.050000\n",
            "2022-10-05 21:40:39,545 epoch 21 - iter 60/209 - loss 0.01403910 - samples/sec: 151.18 - lr: 0.050000\n",
            "2022-10-05 21:40:43,052 epoch 21 - iter 80/209 - loss 0.01371703 - samples/sec: 182.72 - lr: 0.050000\n",
            "2022-10-05 21:40:47,045 epoch 21 - iter 100/209 - loss 0.01472907 - samples/sec: 160.43 - lr: 0.050000\n",
            "2022-10-05 21:40:51,240 epoch 21 - iter 120/209 - loss 0.01510171 - samples/sec: 152.70 - lr: 0.050000\n",
            "2022-10-05 21:40:55,579 epoch 21 - iter 140/209 - loss 0.01595048 - samples/sec: 147.63 - lr: 0.050000\n",
            "2022-10-05 21:40:58,631 epoch 21 - iter 160/209 - loss 0.01628172 - samples/sec: 209.98 - lr: 0.050000\n",
            "2022-10-05 21:41:02,720 epoch 21 - iter 180/209 - loss 0.01566918 - samples/sec: 156.67 - lr: 0.050000\n",
            "2022-10-05 21:41:06,903 epoch 21 - iter 200/209 - loss 0.01554977 - samples/sec: 153.17 - lr: 0.050000\n",
            "2022-10-05 21:41:08,373 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:41:08,375 EPOCH 21 done: loss 0.0156 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:41:17,095 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:41:17,111 DEV : loss 0.04122639447450638 - f1-score (micro avg)  0.8935\n",
            "2022-10-05 21:41:17,215 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:41:17,219 saving best model\n",
            "2022-10-05 21:41:21,313 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:41:24,749 epoch 22 - iter 20/209 - loss 0.02159565 - samples/sec: 186.60 - lr: 0.050000\n",
            "2022-10-05 21:41:28,929 epoch 22 - iter 40/209 - loss 0.01633133 - samples/sec: 153.26 - lr: 0.050000\n",
            "2022-10-05 21:41:32,274 epoch 22 - iter 60/209 - loss 0.01381400 - samples/sec: 191.55 - lr: 0.050000\n",
            "2022-10-05 21:41:35,733 epoch 22 - iter 80/209 - loss 0.01360445 - samples/sec: 185.26 - lr: 0.050000\n",
            "2022-10-05 21:41:39,476 epoch 22 - iter 100/209 - loss 0.01258573 - samples/sec: 171.15 - lr: 0.050000\n",
            "2022-10-05 21:41:43,201 epoch 22 - iter 120/209 - loss 0.01258263 - samples/sec: 172.04 - lr: 0.050000\n",
            "2022-10-05 21:41:47,787 epoch 22 - iter 140/209 - loss 0.01326233 - samples/sec: 139.68 - lr: 0.050000\n",
            "2022-10-05 21:41:51,853 epoch 22 - iter 160/209 - loss 0.01394250 - samples/sec: 157.59 - lr: 0.050000\n",
            "2022-10-05 21:41:56,139 epoch 22 - iter 180/209 - loss 0.01357372 - samples/sec: 149.45 - lr: 0.050000\n",
            "2022-10-05 21:42:00,482 epoch 22 - iter 200/209 - loss 0.01360376 - samples/sec: 147.50 - lr: 0.050000\n",
            "2022-10-05 21:42:01,959 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:42:01,961 EPOCH 22 done: loss 0.0142 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:42:10,582 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:42:10,596 DEV : loss 0.0426638089120388 - f1-score (micro avg)  0.8797\n",
            "2022-10-05 21:42:10,698 BAD EPOCHS (no improvement): 1\n",
            "2022-10-05 21:42:10,704 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:42:15,188 epoch 23 - iter 20/209 - loss 0.01521899 - samples/sec: 142.89 - lr: 0.050000\n",
            "2022-10-05 21:42:18,341 epoch 23 - iter 40/209 - loss 0.01296490 - samples/sec: 203.21 - lr: 0.050000\n",
            "2022-10-05 21:42:22,000 epoch 23 - iter 60/209 - loss 0.01339334 - samples/sec: 175.11 - lr: 0.050000\n",
            "2022-10-05 21:42:26,856 epoch 23 - iter 80/209 - loss 0.01191753 - samples/sec: 131.90 - lr: 0.050000\n",
            "2022-10-05 21:42:30,215 epoch 23 - iter 100/209 - loss 0.01157915 - samples/sec: 190.75 - lr: 0.050000\n",
            "2022-10-05 21:42:33,829 epoch 23 - iter 120/209 - loss 0.01163532 - samples/sec: 177.29 - lr: 0.050000\n",
            "2022-10-05 21:42:37,496 epoch 23 - iter 140/209 - loss 0.01139401 - samples/sec: 174.69 - lr: 0.050000\n",
            "2022-10-05 21:42:41,344 epoch 23 - iter 160/209 - loss 0.01195319 - samples/sec: 166.51 - lr: 0.050000\n",
            "2022-10-05 21:42:44,714 epoch 23 - iter 180/209 - loss 0.01262390 - samples/sec: 190.11 - lr: 0.050000\n",
            "2022-10-05 21:42:48,523 epoch 23 - iter 200/209 - loss 0.01282980 - samples/sec: 168.20 - lr: 0.050000\n",
            "2022-10-05 21:42:49,984 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:42:49,986 EPOCH 23 done: loss 0.0129 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:42:58,846 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:42:58,860 DEV : loss 0.041186459362506866 - f1-score (micro avg)  0.886\n",
            "2022-10-05 21:42:58,961 BAD EPOCHS (no improvement): 2\n",
            "2022-10-05 21:42:58,965 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:43:02,872 epoch 24 - iter 20/209 - loss 0.01441993 - samples/sec: 164.04 - lr: 0.050000\n",
            "2022-10-05 21:43:06,447 epoch 24 - iter 40/209 - loss 0.01325895 - samples/sec: 179.19 - lr: 0.050000\n",
            "2022-10-05 21:43:11,706 epoch 24 - iter 60/209 - loss 0.01324376 - samples/sec: 121.81 - lr: 0.050000\n",
            "2022-10-05 21:43:15,686 epoch 24 - iter 80/209 - loss 0.01326353 - samples/sec: 160.97 - lr: 0.050000\n",
            "2022-10-05 21:43:19,263 epoch 24 - iter 100/209 - loss 0.01236676 - samples/sec: 179.15 - lr: 0.050000\n",
            "2022-10-05 21:43:22,426 epoch 24 - iter 120/209 - loss 0.01247524 - samples/sec: 202.64 - lr: 0.050000\n",
            "2022-10-05 21:43:25,758 epoch 24 - iter 140/209 - loss 0.01220494 - samples/sec: 192.28 - lr: 0.050000\n",
            "2022-10-05 21:43:29,863 epoch 24 - iter 160/209 - loss 0.01256383 - samples/sec: 156.07 - lr: 0.050000\n",
            "2022-10-05 21:43:33,260 epoch 24 - iter 180/209 - loss 0.01307530 - samples/sec: 188.63 - lr: 0.050000\n",
            "2022-10-05 21:43:36,997 epoch 24 - iter 200/209 - loss 0.01378474 - samples/sec: 171.44 - lr: 0.050000\n",
            "2022-10-05 21:43:38,508 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:43:38,510 EPOCH 24 done: loss 0.0142 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:43:47,072 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:43:47,087 DEV : loss 0.039838846772909164 - f1-score (micro avg)  0.8885\n",
            "2022-10-05 21:43:47,189 BAD EPOCHS (no improvement): 3\n",
            "2022-10-05 21:43:47,193 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:43:50,905 epoch 25 - iter 20/209 - loss 0.01756077 - samples/sec: 172.65 - lr: 0.050000\n",
            "2022-10-05 21:43:54,767 epoch 25 - iter 40/209 - loss 0.01404397 - samples/sec: 165.90 - lr: 0.050000\n",
            "2022-10-05 21:43:57,935 epoch 25 - iter 60/209 - loss 0.01368055 - samples/sec: 202.26 - lr: 0.050000\n",
            "2022-10-05 21:44:01,282 epoch 25 - iter 80/209 - loss 0.01328832 - samples/sec: 191.48 - lr: 0.050000\n",
            "2022-10-05 21:44:05,046 epoch 25 - iter 100/209 - loss 0.01241484 - samples/sec: 170.21 - lr: 0.050000\n",
            "2022-10-05 21:44:09,397 epoch 25 - iter 120/209 - loss 0.01314229 - samples/sec: 147.25 - lr: 0.050000\n",
            "2022-10-05 21:44:13,203 epoch 25 - iter 140/209 - loss 0.01241984 - samples/sec: 168.31 - lr: 0.050000\n",
            "2022-10-05 21:44:17,002 epoch 25 - iter 160/209 - loss 0.01225026 - samples/sec: 168.67 - lr: 0.050000\n",
            "2022-10-05 21:44:20,879 epoch 25 - iter 180/209 - loss 0.01258982 - samples/sec: 165.26 - lr: 0.050000\n",
            "2022-10-05 21:44:24,924 epoch 25 - iter 200/209 - loss 0.01305574 - samples/sec: 158.38 - lr: 0.050000\n",
            "2022-10-05 21:44:26,354 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:44:26,356 EPOCH 25 done: loss 0.0132 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:44:35,015 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:44:35,029 DEV : loss 0.043526165187358856 - f1-score (micro avg)  0.8897\n",
            "2022-10-05 21:44:35,131 Epoch    25: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2022-10-05 21:44:35,133 BAD EPOCHS (no improvement): 4\n",
            "2022-10-05 21:44:35,138 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:44:39,131 epoch 26 - iter 20/209 - loss 0.00972412 - samples/sec: 160.43 - lr: 0.025000\n",
            "2022-10-05 21:44:43,122 epoch 26 - iter 40/209 - loss 0.01112099 - samples/sec: 160.51 - lr: 0.025000\n",
            "2022-10-05 21:44:46,916 epoch 26 - iter 60/209 - loss 0.01039840 - samples/sec: 168.87 - lr: 0.025000\n",
            "2022-10-05 21:44:50,956 epoch 26 - iter 80/209 - loss 0.01176128 - samples/sec: 158.58 - lr: 0.025000\n",
            "2022-10-05 21:44:54,668 epoch 26 - iter 100/209 - loss 0.01129144 - samples/sec: 172.62 - lr: 0.025000\n",
            "2022-10-05 21:44:58,508 epoch 26 - iter 120/209 - loss 0.01102369 - samples/sec: 166.83 - lr: 0.025000\n",
            "2022-10-05 21:45:01,982 epoch 26 - iter 140/209 - loss 0.01075925 - samples/sec: 184.46 - lr: 0.025000\n",
            "2022-10-05 21:45:05,273 epoch 26 - iter 160/209 - loss 0.01120098 - samples/sec: 194.69 - lr: 0.025000\n",
            "2022-10-05 21:45:09,273 epoch 26 - iter 180/209 - loss 0.01094624 - samples/sec: 160.16 - lr: 0.025000\n",
            "2022-10-05 21:45:13,433 epoch 26 - iter 200/209 - loss 0.01067943 - samples/sec: 154.00 - lr: 0.025000\n",
            "2022-10-05 21:45:14,887 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:45:14,889 EPOCH 26 done: loss 0.0106 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:45:23,754 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:45:23,769 DEV : loss 0.04127642512321472 - f1-score (micro avg)  0.8914\n",
            "2022-10-05 21:45:23,885 BAD EPOCHS (no improvement): 1\n",
            "2022-10-05 21:45:23,890 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:45:27,378 epoch 27 - iter 20/209 - loss 0.01392249 - samples/sec: 183.80 - lr: 0.025000\n",
            "2022-10-05 21:45:30,931 epoch 27 - iter 40/209 - loss 0.01211990 - samples/sec: 180.32 - lr: 0.025000\n",
            "2022-10-05 21:45:34,673 epoch 27 - iter 60/209 - loss 0.01059058 - samples/sec: 171.20 - lr: 0.025000\n",
            "2022-10-05 21:45:38,181 epoch 27 - iter 80/209 - loss 0.00973524 - samples/sec: 182.66 - lr: 0.025000\n",
            "2022-10-05 21:45:41,878 epoch 27 - iter 100/209 - loss 0.00975362 - samples/sec: 173.31 - lr: 0.025000\n",
            "2022-10-05 21:45:45,633 epoch 27 - iter 120/209 - loss 0.01002076 - samples/sec: 170.64 - lr: 0.025000\n",
            "2022-10-05 21:45:49,587 epoch 27 - iter 140/209 - loss 0.00990182 - samples/sec: 162.06 - lr: 0.025000\n",
            "2022-10-05 21:45:54,393 epoch 27 - iter 160/209 - loss 0.01027883 - samples/sec: 133.27 - lr: 0.025000\n",
            "2022-10-05 21:45:58,428 epoch 27 - iter 180/209 - loss 0.01067035 - samples/sec: 158.74 - lr: 0.025000\n",
            "2022-10-05 21:46:01,907 epoch 27 - iter 200/209 - loss 0.01080438 - samples/sec: 184.15 - lr: 0.025000\n",
            "2022-10-05 21:46:03,205 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:46:03,207 EPOCH 27 done: loss 0.0107 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:46:11,898 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:46:11,911 DEV : loss 0.04112984240055084 - f1-score (micro avg)  0.8856\n",
            "2022-10-05 21:46:12,010 BAD EPOCHS (no improvement): 2\n",
            "2022-10-05 21:46:12,014 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:46:15,677 epoch 28 - iter 20/209 - loss 0.00988743 - samples/sec: 175.01 - lr: 0.025000\n",
            "2022-10-05 21:46:20,417 epoch 28 - iter 40/209 - loss 0.00989922 - samples/sec: 135.15 - lr: 0.025000\n",
            "2022-10-05 21:46:24,500 epoch 28 - iter 60/209 - loss 0.00933759 - samples/sec: 156.90 - lr: 0.025000\n",
            "2022-10-05 21:46:28,285 epoch 28 - iter 80/209 - loss 0.00892438 - samples/sec: 169.27 - lr: 0.025000\n",
            "2022-10-05 21:46:31,363 epoch 28 - iter 100/209 - loss 0.00961709 - samples/sec: 208.22 - lr: 0.025000\n",
            "2022-10-05 21:46:35,196 epoch 28 - iter 120/209 - loss 0.00924728 - samples/sec: 167.12 - lr: 0.025000\n",
            "2022-10-05 21:46:38,907 epoch 28 - iter 140/209 - loss 0.00927528 - samples/sec: 172.68 - lr: 0.025000\n",
            "2022-10-05 21:46:42,453 epoch 28 - iter 160/209 - loss 0.00962406 - samples/sec: 180.65 - lr: 0.025000\n",
            "2022-10-05 21:46:46,218 epoch 28 - iter 180/209 - loss 0.01008547 - samples/sec: 170.18 - lr: 0.025000\n",
            "2022-10-05 21:46:50,111 epoch 28 - iter 200/209 - loss 0.01082382 - samples/sec: 164.56 - lr: 0.025000\n",
            "2022-10-05 21:46:51,972 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:46:51,974 EPOCH 28 done: loss 0.0106 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:47:00,729 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:47:00,743 DEV : loss 0.04193611070513725 - f1-score (micro avg)  0.892\n",
            "2022-10-05 21:47:00,852 BAD EPOCHS (no improvement): 3\n",
            "2022-10-05 21:47:00,857 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:47:04,946 epoch 29 - iter 20/209 - loss 0.01232944 - samples/sec: 156.72 - lr: 0.025000\n",
            "2022-10-05 21:47:07,896 epoch 29 - iter 40/209 - loss 0.01164638 - samples/sec: 217.21 - lr: 0.025000\n",
            "2022-10-05 21:47:11,585 epoch 29 - iter 60/209 - loss 0.00926472 - samples/sec: 173.67 - lr: 0.025000\n",
            "2022-10-05 21:47:15,230 epoch 29 - iter 80/209 - loss 0.01005147 - samples/sec: 175.79 - lr: 0.025000\n",
            "2022-10-05 21:47:18,848 epoch 29 - iter 100/209 - loss 0.00973328 - samples/sec: 177.09 - lr: 0.025000\n",
            "2022-10-05 21:47:22,173 epoch 29 - iter 120/209 - loss 0.00959216 - samples/sec: 192.73 - lr: 0.025000\n",
            "2022-10-05 21:47:26,028 epoch 29 - iter 140/209 - loss 0.00972614 - samples/sec: 166.18 - lr: 0.025000\n",
            "2022-10-05 21:47:30,402 epoch 29 - iter 160/209 - loss 0.01041004 - samples/sec: 146.50 - lr: 0.025000\n",
            "2022-10-05 21:47:33,642 epoch 29 - iter 180/209 - loss 0.01085476 - samples/sec: 197.75 - lr: 0.025000\n",
            "2022-10-05 21:47:38,627 epoch 29 - iter 200/209 - loss 0.01115439 - samples/sec: 128.48 - lr: 0.025000\n",
            "2022-10-05 21:47:40,065 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:47:40,067 EPOCH 29 done: loss 0.0110 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:47:48,719 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:47:48,733 DEV : loss 0.04304569214582443 - f1-score (micro avg)  0.8929\n",
            "2022-10-05 21:47:48,833 Epoch    29: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2022-10-05 21:47:48,834 BAD EPOCHS (no improvement): 4\n",
            "2022-10-05 21:47:48,841 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:47:51,979 epoch 30 - iter 20/209 - loss 0.00900415 - samples/sec: 204.26 - lr: 0.012500\n",
            "2022-10-05 21:47:56,100 epoch 30 - iter 40/209 - loss 0.00930958 - samples/sec: 155.48 - lr: 0.012500\n",
            "2022-10-05 21:48:00,595 epoch 30 - iter 60/209 - loss 0.00918096 - samples/sec: 142.48 - lr: 0.012500\n",
            "2022-10-05 21:48:04,216 epoch 30 - iter 80/209 - loss 0.00951263 - samples/sec: 176.94 - lr: 0.012500\n",
            "2022-10-05 21:48:07,869 epoch 30 - iter 100/209 - loss 0.00919009 - samples/sec: 175.40 - lr: 0.012500\n",
            "2022-10-05 21:48:10,912 epoch 30 - iter 120/209 - loss 0.00882923 - samples/sec: 210.59 - lr: 0.012500\n",
            "2022-10-05 21:48:14,514 epoch 30 - iter 140/209 - loss 0.00905244 - samples/sec: 177.87 - lr: 0.012500\n",
            "2022-10-05 21:48:18,145 epoch 30 - iter 160/209 - loss 0.00892860 - samples/sec: 176.47 - lr: 0.012500\n",
            "2022-10-05 21:48:22,691 epoch 30 - iter 180/209 - loss 0.00901825 - samples/sec: 140.88 - lr: 0.012500\n",
            "2022-10-05 21:48:26,303 epoch 30 - iter 200/209 - loss 0.00884002 - samples/sec: 177.38 - lr: 0.012500\n",
            "2022-10-05 21:48:27,962 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:48:27,964 EPOCH 30 done: loss 0.0088 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:48:36,782 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:48:36,797 DEV : loss 0.043189745396375656 - f1-score (micro avg)  0.8987\n",
            "2022-10-05 21:48:36,901 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:48:36,905 saving best model\n",
            "2022-10-05 21:48:41,005 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:48:44,992 epoch 31 - iter 20/209 - loss 0.01111741 - samples/sec: 160.73 - lr: 0.012500\n",
            "2022-10-05 21:48:49,145 epoch 31 - iter 40/209 - loss 0.01065424 - samples/sec: 154.26 - lr: 0.012500\n",
            "2022-10-05 21:48:53,016 epoch 31 - iter 60/209 - loss 0.00924915 - samples/sec: 165.50 - lr: 0.012500\n",
            "2022-10-05 21:48:56,662 epoch 31 - iter 80/209 - loss 0.00945991 - samples/sec: 175.73 - lr: 0.012500\n",
            "2022-10-05 21:49:00,834 epoch 31 - iter 100/209 - loss 0.00867199 - samples/sec: 153.62 - lr: 0.012500\n",
            "2022-10-05 21:49:04,744 epoch 31 - iter 120/209 - loss 0.00863448 - samples/sec: 163.81 - lr: 0.012500\n",
            "2022-10-05 21:49:09,283 epoch 31 - iter 140/209 - loss 0.00915948 - samples/sec: 141.15 - lr: 0.012500\n",
            "2022-10-05 21:49:13,069 epoch 31 - iter 160/209 - loss 0.00917087 - samples/sec: 169.20 - lr: 0.012500\n",
            "2022-10-05 21:49:16,594 epoch 31 - iter 180/209 - loss 0.00930423 - samples/sec: 181.75 - lr: 0.012500\n",
            "2022-10-05 21:49:20,055 epoch 31 - iter 200/209 - loss 0.00939658 - samples/sec: 185.13 - lr: 0.012500\n",
            "2022-10-05 21:49:21,331 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:49:21,333 EPOCH 31 done: loss 0.0091 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:49:29,894 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:49:29,908 DEV : loss 0.04211299121379852 - f1-score (micro avg)  0.8972\n",
            "2022-10-05 21:49:30,009 BAD EPOCHS (no improvement): 1\n",
            "2022-10-05 21:49:30,013 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:49:33,682 epoch 32 - iter 20/209 - loss 0.00678333 - samples/sec: 174.68 - lr: 0.012500\n",
            "2022-10-05 21:49:38,029 epoch 32 - iter 40/209 - loss 0.00725025 - samples/sec: 147.39 - lr: 0.012500\n",
            "2022-10-05 21:49:41,469 epoch 32 - iter 60/209 - loss 0.00685618 - samples/sec: 186.24 - lr: 0.012500\n",
            "2022-10-05 21:49:45,511 epoch 32 - iter 80/209 - loss 0.00881562 - samples/sec: 158.47 - lr: 0.012500\n",
            "2022-10-05 21:49:48,498 epoch 32 - iter 100/209 - loss 0.00954683 - samples/sec: 214.51 - lr: 0.012500\n",
            "2022-10-05 21:49:51,768 epoch 32 - iter 120/209 - loss 0.00926375 - samples/sec: 195.93 - lr: 0.012500\n",
            "2022-10-05 21:49:55,634 epoch 32 - iter 140/209 - loss 0.00898170 - samples/sec: 165.76 - lr: 0.012500\n",
            "2022-10-05 21:49:59,522 epoch 32 - iter 160/209 - loss 0.00909969 - samples/sec: 164.75 - lr: 0.012500\n",
            "2022-10-05 21:50:03,032 epoch 32 - iter 180/209 - loss 0.00860483 - samples/sec: 182.53 - lr: 0.012500\n",
            "2022-10-05 21:50:07,091 epoch 32 - iter 200/209 - loss 0.00877940 - samples/sec: 157.80 - lr: 0.012500\n",
            "2022-10-05 21:50:08,520 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:50:08,521 EPOCH 32 done: loss 0.0087 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:50:17,423 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:50:17,436 DEV : loss 0.042406294494867325 - f1-score (micro avg)  0.8945\n",
            "2022-10-05 21:50:17,537 BAD EPOCHS (no improvement): 2\n",
            "2022-10-05 21:50:17,543 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:50:21,044 epoch 33 - iter 20/209 - loss 0.01397413 - samples/sec: 182.99 - lr: 0.012500\n",
            "2022-10-05 21:50:24,261 epoch 33 - iter 40/209 - loss 0.00987107 - samples/sec: 199.21 - lr: 0.012500\n",
            "2022-10-05 21:50:27,939 epoch 33 - iter 60/209 - loss 0.01083281 - samples/sec: 174.19 - lr: 0.012500\n",
            "2022-10-05 21:50:32,133 epoch 33 - iter 80/209 - loss 0.00992414 - samples/sec: 152.75 - lr: 0.012500\n",
            "2022-10-05 21:50:37,101 epoch 33 - iter 100/209 - loss 0.01058709 - samples/sec: 128.92 - lr: 0.012500\n",
            "2022-10-05 21:50:40,321 epoch 33 - iter 120/209 - loss 0.00999387 - samples/sec: 199.00 - lr: 0.012500\n",
            "2022-10-05 21:50:43,540 epoch 33 - iter 140/209 - loss 0.00997776 - samples/sec: 199.09 - lr: 0.012500\n",
            "2022-10-05 21:50:47,722 epoch 33 - iter 160/209 - loss 0.00981450 - samples/sec: 153.16 - lr: 0.012500\n",
            "2022-10-05 21:50:51,373 epoch 33 - iter 180/209 - loss 0.00950359 - samples/sec: 175.51 - lr: 0.012500\n",
            "2022-10-05 21:50:54,577 epoch 33 - iter 200/209 - loss 0.00923735 - samples/sec: 199.97 - lr: 0.012500\n",
            "2022-10-05 21:50:56,367 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:50:56,369 EPOCH 33 done: loss 0.0094 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:51:05,092 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:51:05,108 DEV : loss 0.042864881455898285 - f1-score (micro avg)  0.8968\n",
            "2022-10-05 21:51:05,210 BAD EPOCHS (no improvement): 3\n",
            "2022-10-05 21:51:05,215 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:51:08,666 epoch 34 - iter 20/209 - loss 0.00942216 - samples/sec: 185.79 - lr: 0.012500\n",
            "2022-10-05 21:51:12,734 epoch 34 - iter 40/209 - loss 0.00929236 - samples/sec: 157.44 - lr: 0.012500\n",
            "2022-10-05 21:51:17,409 epoch 34 - iter 60/209 - loss 0.00933935 - samples/sec: 137.03 - lr: 0.012500\n",
            "2022-10-05 21:51:21,556 epoch 34 - iter 80/209 - loss 0.00886663 - samples/sec: 154.47 - lr: 0.012500\n",
            "2022-10-05 21:51:24,563 epoch 34 - iter 100/209 - loss 0.00867597 - samples/sec: 213.14 - lr: 0.012500\n",
            "2022-10-05 21:51:28,275 epoch 34 - iter 120/209 - loss 0.00867409 - samples/sec: 172.58 - lr: 0.012500\n",
            "2022-10-05 21:51:32,453 epoch 34 - iter 140/209 - loss 0.00887532 - samples/sec: 153.32 - lr: 0.012500\n",
            "2022-10-05 21:51:36,402 epoch 34 - iter 160/209 - loss 0.00829177 - samples/sec: 162.22 - lr: 0.012500\n",
            "2022-10-05 21:51:39,704 epoch 34 - iter 180/209 - loss 0.00816300 - samples/sec: 194.02 - lr: 0.012500\n",
            "2022-10-05 21:51:42,766 epoch 34 - iter 200/209 - loss 0.00834139 - samples/sec: 209.36 - lr: 0.012500\n",
            "2022-10-05 21:51:44,155 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:51:44,157 EPOCH 34 done: loss 0.0083 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:51:52,664 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:51:52,678 DEV : loss 0.04302244633436203 - f1-score (micro avg)  0.8985\n",
            "2022-10-05 21:51:52,779 Epoch    34: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2022-10-05 21:51:52,780 BAD EPOCHS (no improvement): 4\n",
            "2022-10-05 21:51:52,784 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:51:56,714 epoch 35 - iter 20/209 - loss 0.01065642 - samples/sec: 163.10 - lr: 0.006250\n",
            "2022-10-05 21:52:00,834 epoch 35 - iter 40/209 - loss 0.00976164 - samples/sec: 155.51 - lr: 0.006250\n",
            "2022-10-05 21:52:04,506 epoch 35 - iter 60/209 - loss 0.00823052 - samples/sec: 174.48 - lr: 0.006250\n",
            "2022-10-05 21:52:08,601 epoch 35 - iter 80/209 - loss 0.00869985 - samples/sec: 156.43 - lr: 0.006250\n",
            "2022-10-05 21:52:12,091 epoch 35 - iter 100/209 - loss 0.00803104 - samples/sec: 183.57 - lr: 0.006250\n",
            "2022-10-05 21:52:15,602 epoch 35 - iter 120/209 - loss 0.00810181 - samples/sec: 182.45 - lr: 0.006250\n",
            "2022-10-05 21:52:19,064 epoch 35 - iter 140/209 - loss 0.00800772 - samples/sec: 185.08 - lr: 0.006250\n",
            "2022-10-05 21:52:22,770 epoch 35 - iter 160/209 - loss 0.00804806 - samples/sec: 172.86 - lr: 0.006250\n",
            "2022-10-05 21:52:26,808 epoch 35 - iter 180/209 - loss 0.00796190 - samples/sec: 158.67 - lr: 0.006250\n",
            "2022-10-05 21:52:30,323 epoch 35 - iter 200/209 - loss 0.00780016 - samples/sec: 182.26 - lr: 0.006250\n",
            "2022-10-05 21:52:32,010 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:52:32,011 EPOCH 35 done: loss 0.0079 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:52:40,786 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:52:40,801 DEV : loss 0.0440131239593029 - f1-score (micro avg)  0.8977\n",
            "2022-10-05 21:52:40,918 BAD EPOCHS (no improvement): 1\n",
            "2022-10-05 21:52:40,922 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:52:44,901 epoch 36 - iter 20/209 - loss 0.01148051 - samples/sec: 161.06 - lr: 0.006250\n",
            "2022-10-05 21:52:48,902 epoch 36 - iter 40/209 - loss 0.00975667 - samples/sec: 160.11 - lr: 0.006250\n",
            "2022-10-05 21:52:53,074 epoch 36 - iter 60/209 - loss 0.00880615 - samples/sec: 153.57 - lr: 0.006250\n",
            "2022-10-05 21:52:56,618 epoch 36 - iter 80/209 - loss 0.00809481 - samples/sec: 180.77 - lr: 0.006250\n",
            "2022-10-05 21:53:00,044 epoch 36 - iter 100/209 - loss 0.00777736 - samples/sec: 186.99 - lr: 0.006250\n",
            "2022-10-05 21:53:04,398 epoch 36 - iter 120/209 - loss 0.00788669 - samples/sec: 147.12 - lr: 0.006250\n",
            "2022-10-05 21:53:08,369 epoch 36 - iter 140/209 - loss 0.00779768 - samples/sec: 161.35 - lr: 0.006250\n",
            "2022-10-05 21:53:11,901 epoch 36 - iter 160/209 - loss 0.00785073 - samples/sec: 181.38 - lr: 0.006250\n",
            "2022-10-05 21:53:15,803 epoch 36 - iter 180/209 - loss 0.00756697 - samples/sec: 164.19 - lr: 0.006250\n",
            "2022-10-05 21:53:19,460 epoch 36 - iter 200/209 - loss 0.00767034 - samples/sec: 175.19 - lr: 0.006250\n",
            "2022-10-05 21:53:20,948 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:53:20,950 EPOCH 36 done: loss 0.0081 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:53:29,474 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:53:29,489 DEV : loss 0.0434238463640213 - f1-score (micro avg)  0.8989\n",
            "2022-10-05 21:53:29,589 BAD EPOCHS (no improvement): 0\n",
            "2022-10-05 21:53:29,594 saving best model\n",
            "2022-10-05 21:53:34,335 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:53:38,732 epoch 37 - iter 20/209 - loss 0.00775726 - samples/sec: 145.73 - lr: 0.006250\n",
            "2022-10-05 21:53:42,823 epoch 37 - iter 40/209 - loss 0.00624281 - samples/sec: 156.59 - lr: 0.006250\n",
            "2022-10-05 21:53:46,547 epoch 37 - iter 60/209 - loss 0.00650477 - samples/sec: 172.05 - lr: 0.006250\n",
            "2022-10-05 21:53:50,000 epoch 37 - iter 80/209 - loss 0.00736840 - samples/sec: 185.55 - lr: 0.006250\n",
            "2022-10-05 21:53:54,004 epoch 37 - iter 100/209 - loss 0.00780496 - samples/sec: 159.97 - lr: 0.006250\n",
            "2022-10-05 21:53:57,170 epoch 37 - iter 120/209 - loss 0.00727453 - samples/sec: 202.39 - lr: 0.006250\n",
            "2022-10-05 21:54:01,689 epoch 37 - iter 140/209 - loss 0.00776301 - samples/sec: 141.76 - lr: 0.006250\n",
            "2022-10-05 21:54:05,133 epoch 37 - iter 160/209 - loss 0.00766717 - samples/sec: 186.06 - lr: 0.006250\n",
            "2022-10-05 21:54:08,834 epoch 37 - iter 180/209 - loss 0.00800417 - samples/sec: 173.10 - lr: 0.006250\n",
            "2022-10-05 21:54:12,286 epoch 37 - iter 200/209 - loss 0.00824807 - samples/sec: 185.62 - lr: 0.006250\n",
            "2022-10-05 21:54:14,149 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:54:14,152 EPOCH 37 done: loss 0.0081 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:54:22,653 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:54:22,668 DEV : loss 0.043052833527326584 - f1-score (micro avg)  0.8954\n",
            "2022-10-05 21:54:22,769 BAD EPOCHS (no improvement): 1\n",
            "2022-10-05 21:54:22,773 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:54:26,454 epoch 38 - iter 20/209 - loss 0.00253162 - samples/sec: 174.10 - lr: 0.006250\n",
            "2022-10-05 21:54:30,802 epoch 38 - iter 40/209 - loss 0.00448836 - samples/sec: 147.37 - lr: 0.006250\n",
            "2022-10-05 21:54:34,672 epoch 38 - iter 60/209 - loss 0.00542029 - samples/sec: 165.52 - lr: 0.006250\n",
            "2022-10-05 21:54:39,000 epoch 38 - iter 80/209 - loss 0.00624532 - samples/sec: 148.02 - lr: 0.006250\n",
            "2022-10-05 21:54:42,693 epoch 38 - iter 100/209 - loss 0.00665653 - samples/sec: 173.49 - lr: 0.006250\n",
            "2022-10-05 21:54:46,071 epoch 38 - iter 120/209 - loss 0.00628900 - samples/sec: 189.64 - lr: 0.006250\n",
            "2022-10-05 21:54:49,305 epoch 38 - iter 140/209 - loss 0.00668611 - samples/sec: 198.14 - lr: 0.006250\n",
            "2022-10-05 21:54:53,814 epoch 38 - iter 160/209 - loss 0.00714442 - samples/sec: 142.08 - lr: 0.006250\n",
            "2022-10-05 21:54:57,988 epoch 38 - iter 180/209 - loss 0.00748548 - samples/sec: 153.48 - lr: 0.006250\n",
            "2022-10-05 21:55:01,814 epoch 38 - iter 200/209 - loss 0.00751523 - samples/sec: 167.43 - lr: 0.006250\n",
            "2022-10-05 21:55:03,184 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:55:03,186 EPOCH 38 done: loss 0.0074 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:55:11,833 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:55:11,850 DEV : loss 0.044001515954732895 - f1-score (micro avg)  0.8931\n",
            "2022-10-05 21:55:11,953 BAD EPOCHS (no improvement): 2\n",
            "2022-10-05 21:55:11,957 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:55:16,430 epoch 39 - iter 20/209 - loss 0.00961082 - samples/sec: 143.24 - lr: 0.006250\n",
            "2022-10-05 21:55:20,353 epoch 39 - iter 40/209 - loss 0.00901881 - samples/sec: 163.33 - lr: 0.006250\n",
            "2022-10-05 21:55:24,674 epoch 39 - iter 60/209 - loss 0.00789886 - samples/sec: 148.26 - lr: 0.006250\n",
            "2022-10-05 21:55:28,578 epoch 39 - iter 80/209 - loss 0.00775143 - samples/sec: 164.09 - lr: 0.006250\n",
            "2022-10-05 21:55:32,360 epoch 39 - iter 100/209 - loss 0.00720805 - samples/sec: 169.40 - lr: 0.006250\n",
            "2022-10-05 21:55:35,384 epoch 39 - iter 120/209 - loss 0.00781003 - samples/sec: 211.90 - lr: 0.006250\n",
            "2022-10-05 21:55:39,154 epoch 39 - iter 140/209 - loss 0.00766624 - samples/sec: 169.92 - lr: 0.006250\n",
            "2022-10-05 21:55:42,471 epoch 39 - iter 160/209 - loss 0.00736136 - samples/sec: 193.14 - lr: 0.006250\n",
            "2022-10-05 21:55:45,618 epoch 39 - iter 180/209 - loss 0.00695830 - samples/sec: 203.66 - lr: 0.006250\n",
            "2022-10-05 21:55:49,597 epoch 39 - iter 200/209 - loss 0.00714343 - samples/sec: 160.99 - lr: 0.006250\n",
            "2022-10-05 21:55:50,753 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:55:50,755 EPOCH 39 done: loss 0.0073 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:55:59,523 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:55:59,536 DEV : loss 0.04349417984485626 - f1-score (micro avg)  0.8943\n",
            "2022-10-05 21:55:59,637 BAD EPOCHS (no improvement): 3\n",
            "2022-10-05 21:55:59,641 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:56:04,154 epoch 40 - iter 20/209 - loss 0.00492850 - samples/sec: 141.98 - lr: 0.006250\n",
            "2022-10-05 21:56:07,492 epoch 40 - iter 40/209 - loss 0.00820768 - samples/sec: 191.95 - lr: 0.006250\n",
            "2022-10-05 21:56:11,218 epoch 40 - iter 60/209 - loss 0.00792448 - samples/sec: 171.96 - lr: 0.006250\n",
            "2022-10-05 21:56:15,399 epoch 40 - iter 80/209 - loss 0.00716753 - samples/sec: 153.22 - lr: 0.006250\n",
            "2022-10-05 21:56:19,689 epoch 40 - iter 100/209 - loss 0.00836589 - samples/sec: 149.32 - lr: 0.006250\n",
            "2022-10-05 21:56:23,723 epoch 40 - iter 120/209 - loss 0.00816008 - samples/sec: 158.81 - lr: 0.006250\n",
            "2022-10-05 21:56:28,041 epoch 40 - iter 140/209 - loss 0.00745399 - samples/sec: 148.36 - lr: 0.006250\n",
            "2022-10-05 21:56:31,369 epoch 40 - iter 160/209 - loss 0.00724750 - samples/sec: 192.54 - lr: 0.006250\n",
            "2022-10-05 21:56:34,993 epoch 40 - iter 180/209 - loss 0.00716943 - samples/sec: 176.82 - lr: 0.006250\n",
            "2022-10-05 21:56:38,103 epoch 40 - iter 200/209 - loss 0.00749715 - samples/sec: 206.01 - lr: 0.006250\n",
            "2022-10-05 21:56:39,451 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:56:39,452 EPOCH 40 done: loss 0.0076 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:08<00:00,  5.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:56:48,041 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:56:48,056 DEV : loss 0.04413469880819321 - f1-score (micro avg)  0.8954\n",
            "2022-10-05 21:56:48,155 Epoch    40: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2022-10-05 21:56:48,158 BAD EPOCHS (no improvement): 4\n",
            "2022-10-05 21:56:57,847 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-05 21:56:57,850 loading file /content/drive/MyDrive/Flair_NLP/sota-ner-flair/best-model.pt\n",
            "2022-10-05 21:57:00,436 SequenceTagger predicts: Dictionary with 31 tags: O, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-FUNDAMENTO, B-FUNDAMENTO, E-FUNDAMENTO, I-FUNDAMENTO, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-DATA, B-DATA, E-DATA, I-DATA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL, S-PRODUTODELEI, B-PRODUTODELEI, E-PRODUTODELEI, I-PRODUTODELEI, S-EVENTO, B-EVENTO, E-EVENTO, I-EVENTO, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:38<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-05 21:57:39,697 Evaluating as a multi-label problem: False\n",
            "2022-10-05 21:57:39,710 0.8842\t0.9048\t0.8944\t0.8138\n",
            "2022-10-05 21:57:39,712 \n",
            "Results:\n",
            "- F-score (micro) 0.8944\n",
            "- F-score (macro) 0.8532\n",
            "- Accuracy 0.8138\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  FUNDAMENTO     0.9200    0.9274    0.9237       124\n",
            "      PESSOA     0.9256    0.9412    0.9333       119\n",
            "       LOCAL     0.8037    0.8515    0.8269       101\n",
            "        DATA     0.9697    0.9796    0.9746        98\n",
            " ORGANIZACAO     0.8300    0.8830    0.8557        94\n",
            "PRODUTODELEI     0.8333    0.8333    0.8333        54\n",
            "      EVENTO     0.7143    0.5556    0.6250         9\n",
            "\n",
            "   micro avg     0.8842    0.9048    0.8944       599\n",
            "   macro avg     0.8567    0.8531    0.8532       599\n",
            "weighted avg     0.8846    0.9048    0.8943       599\n",
            "\n",
            "2022-10-05 21:57:39,714 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_score': 0.8943894389438943,\n",
              " 'dev_score_history': [0.35537742150968604,\n",
              "  0.6008163265306123,\n",
              "  0.6264840182648402,\n",
              "  0.7641996557659209,\n",
              "  0.7272727272727273,\n",
              "  0.8236331569664904,\n",
              "  0.8326105810928013,\n",
              "  0.8346186803770351,\n",
              "  0.8434163701067615,\n",
              "  0.8622222222222221,\n",
              "  0.8579040852575489,\n",
              "  0.8606921029281278,\n",
              "  0.8818342151675485,\n",
              "  0.8445199660152931,\n",
              "  0.8637137989778535,\n",
              "  0.8620988725065047,\n",
              "  0.8754325259515572,\n",
              "  0.8796536796536796,\n",
              "  0.8806228373702423,\n",
              "  0.8846487424111016,\n",
              "  0.8934707903780069,\n",
              "  0.8796536796536796,\n",
              "  0.8859878154917319,\n",
              "  0.8885017421602787,\n",
              "  0.889661164205039,\n",
              "  0.8913793103448276,\n",
              "  0.885640584694755,\n",
              "  0.89198606271777,\n",
              "  0.8929188255613126,\n",
              "  0.8987012987012988,\n",
              "  0.897212543554007,\n",
              "  0.8944636678200691,\n",
              "  0.8967909800520383,\n",
              "  0.8985255854293148,\n",
              "  0.8977469670710572,\n",
              "  0.898876404494382,\n",
              "  0.8954191875540191,\n",
              "  0.8931034482758621,\n",
              "  0.8942807625649914,\n",
              "  0.8954191875540191],\n",
              " 'train_loss_history': [0.37498423234156175,\n",
              "  0.1498252156393744,\n",
              "  0.11043878112573569,\n",
              "  0.08737651094065733,\n",
              "  0.07001841979050871,\n",
              "  0.06138459383830802,\n",
              "  0.052751063379103076,\n",
              "  0.04529202119400558,\n",
              "  0.042499616188840204,\n",
              "  0.040119912173698626,\n",
              "  0.03679763940106547,\n",
              "  0.03431254520916014,\n",
              "  0.030984216098324486,\n",
              "  0.02817829197155118,\n",
              "  0.0271004628805199,\n",
              "  0.025747547565393387,\n",
              "  0.02534697098271971,\n",
              "  0.019451562006919842,\n",
              "  0.017230262528862436,\n",
              "  0.015371757429804865,\n",
              "  0.015621846595133384,\n",
              "  0.014211830746157303,\n",
              "  0.012865324331691736,\n",
              "  0.014152907160027116,\n",
              "  0.013163564905013688,\n",
              "  0.010578573155076673,\n",
              "  0.010651880782227232,\n",
              "  0.010562730672231803,\n",
              "  0.011002141439008378,\n",
              "  0.008772443872462444,\n",
              "  0.009129782410828381,\n",
              "  0.00868288159412531,\n",
              "  0.009350012199168346,\n",
              "  0.008302159794576719,\n",
              "  0.007894186692484859,\n",
              "  0.008073078532572348,\n",
              "  0.00807037407414562,\n",
              "  0.007432120617227596,\n",
              "  0.007297259769926769,\n",
              "  0.007631249922892815],\n",
              " 'dev_loss_history': [0.1848800778388977,\n",
              "  0.10556729137897491,\n",
              "  0.10561355203390121,\n",
              "  0.06625504791736603,\n",
              "  0.0641130656003952,\n",
              "  0.053595658391714096,\n",
              "  0.04733815789222717,\n",
              "  0.04674920812249184,\n",
              "  0.04545168578624725,\n",
              "  0.04424387961626053,\n",
              "  0.04265153035521507,\n",
              "  0.04187864810228348,\n",
              "  0.03841810300946236,\n",
              "  0.04374944046139717,\n",
              "  0.04772869125008583,\n",
              "  0.04398127645254135,\n",
              "  0.0367460660636425,\n",
              "  0.041797056794166565,\n",
              "  0.0396113283932209,\n",
              "  0.04213029518723488,\n",
              "  0.04122639447450638,\n",
              "  0.0426638089120388,\n",
              "  0.041186459362506866,\n",
              "  0.039838846772909164,\n",
              "  0.043526165187358856,\n",
              "  0.04127642512321472,\n",
              "  0.04112984240055084,\n",
              "  0.04193611070513725,\n",
              "  0.04304569214582443,\n",
              "  0.043189745396375656,\n",
              "  0.04211299121379852,\n",
              "  0.042406294494867325,\n",
              "  0.042864881455898285,\n",
              "  0.04302244633436203,\n",
              "  0.0440131239593029,\n",
              "  0.0434238463640213,\n",
              "  0.043052833527326584,\n",
              "  0.044001515954732895,\n",
              "  0.04349417984485626,\n",
              "  0.04413469880819321]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# Initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "path = '/content/drive/MyDrive/Flair_NLP/sota-ner-flair'\n",
        "\n",
        "# Start training\n",
        "trainer.train(path,\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YG7XlyNBrUH"
      },
      "source": [
        "## Teste 4.4 NER Flair Bert Embeddings com Corpus Ulysses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsOJoJLQBrUI"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7stWCeO_BrUI"
      },
      "outputs": [],
      "source": [
        "## Importes\n",
        "## datasets\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOTNDFWuBrUI"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww2OHv6DBrUI",
        "outputId": "4877d485-b400-4169-b881-ab922d5788f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aelsgGQeBrUJ",
        "outputId": "bffc148d-3d37-4e26-e92c-29fc4297d6ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-19 17:32:33,235 Reading data from /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria\n",
            "2022-10-19 17:32:33,237 Train: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/train.txt\n",
            "2022-10-19 17:32:33,239 Dev: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/valid.txt\n",
            "2022-10-19 17:32:33,242 Test: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/test.txt\n"
          ]
        }
      ],
      "source": [
        "## carregando um corpus e definindo as colunas\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='valid.txt')\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncDJx_oyBrUJ",
        "outputId": "dd77582a-2450-4665-a2bf-531ab3d51067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-19 17:32:36,603 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6667it [00:00, 50300.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-19 17:32:36,792 Dictionary created for label 'ner' with 8 values: PESSOA (seen 628 times), FUNDAMENTO (seen 490 times), ORGANIZACAO (seen 435 times), DATA (seen 433 times), LOCAL (seen 369 times), PRODUTODELEI (seen 230 times), EVENTO (seen 9 times)\n",
            "Dictionary with 8 tags: <unk>, PESSOA, FUNDAMENTO, ORGANIZACAO, DATA, LOCAL, PRODUTODELEI, EVENTO\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i59fNDc3BrUJ"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "59d661be1e0343049f24f10128873e23",
            "fafa44bb6ca44c7f8dd74a3317b258f7",
            "b82288dcdc1044d4a0ee2bf66137c76e",
            "ce25e0dc810e41db9cdd8aed83c5d94a",
            "42067333bf194d11a98894eaa31e13ff",
            "f4a645dfd391490884160d4fd7a2ea35",
            "960452461ae84c11aecf4c715911ca59",
            "a12c2dc4a85f4c6c862ae08b324a58fd",
            "93612f6ea1134e50930d9bda8abf794a",
            "010a04542c0f4f819a04272f631112a0",
            "81a277303e0c45ab8e86b8235c52ee1b",
            "516e0ec4927b449f9d202cdbd2f2aecc",
            "dff6ac8758a94f40a0acaaa074ea6421",
            "4d3405eb60dc4b2e9a283039f270d6be",
            "95c09ca2b072458d84808cc04539b567",
            "3ca5b857fc0e469eb8d46139fe516704",
            "0fe1862fc8af42939b3f1d41569cc22e",
            "3b7abfa087e24e539e65421c6c32d59b",
            "79dd73fa24214684b6239043727e73f2",
            "65921150cada46db9b7cca43f6d3bc1b",
            "ae29de0a658042afb862a8dbeaa5cc0f",
            "c9b4dbfd465d44aa925f69ad804739ac",
            "ef1fdecd44f1470ca257685acc6031ea",
            "55b10fb79447425883d253902281daef",
            "b5195c58a3534f95b9cfb1482c5a27b1",
            "db1f7f3f4e6c41eaaa3b7922ea36d98e",
            "77fda6a857994a04aa94313a954ad5e5",
            "351870153f5e4843be8856534ed53874",
            "c49d6058e87f47a6a5d5bfddd6420fe6",
            "3392cc69ffa34776a4c7e9c5e87dda3f",
            "24151aaaea0e46d39ff91cb6b49bf6d1",
            "f664954a7ecb4a16ad1968a08d7b99c6",
            "4206e3a39ec1491faa788b49b59fff2b",
            "a632e721554f4e109fca460118021840",
            "9853062dfbe343c1bb2aebeaafa812bb",
            "3cfce413eeb349f5a98b149b45567bc7",
            "2f1672b8004c486899cdfa66a6e9f879",
            "51d969e767ca4477b4340033b526c949",
            "0f833d8142fd4f20a4ec0456934445a4",
            "83aa54c3eff04a28a50369e8f0aa5d0d",
            "0fb4769941754222a671bb8386cdbee1",
            "9c0d15d34aa34a56aaf28e8780ef89f1",
            "adae77b1992f4e89a0d5360f37c617b9",
            "a1a705c2a8a141af845adc77e557c6c9",
            "f22a5125e1c0405db2323f6461376b16",
            "47cb1247e6084a70b85e34bb078e3c83",
            "2c9d300451dc4a4c9721898871dfe168",
            "6a3d132cdae340f49689ef9852cae89c",
            "beaebecce77544689ebefb53ce47b3c7",
            "41f2ca0255454b41ac03d011637967df",
            "ff22171ecc6949b7b3495e7cc911ab21",
            "138094cb1c2b43b5b5bb6b95b0d8a7fd",
            "f537ac0e44164a1cae9b1bafe06d98a2",
            "5807265c72814dc98d3d0752e30bdb14",
            "4268b55c1f644241a22c00334bd3bc0c",
            "2eea50aad688406f90d4fd2cf41ac565",
            "81c9328246d548f7b0ace61d89cca748",
            "cb7989b1fb98474c9cccbe1c330a01a1",
            "f01102409f8e4573834cc09abed0feb1",
            "ef7cd9acb42045b2a5eb519dfbf7839e",
            "6ef14d94c3f44ba384c34633abbf9ddb",
            "73bd87fce839498498598cc01f4c4131",
            "7429c024545f4eafb934caeab63ad803",
            "f87e5ef6ced947fd82e87728192884c3",
            "f2fe39a2f370482f8ee9bce4f0518a7e",
            "8e2034fe53a048edb5f347adafdb8c33"
          ]
        },
        "id": "cnwSaHs2BrUJ",
        "outputId": "5289ae9f-c078-43f1-a64c-8e628e5d6e5b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59d661be1e0343049f24f10128873e23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/155 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "516e0ec4927b449f9d202cdbd2f2aecc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/648 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef1fdecd44f1470ca257685acc6031ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/210k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a632e721554f4e109fca460118021840",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f22a5125e1c0405db2323f6461376b16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2eea50aad688406f90d4fd2cf41ac565",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Apenas Bert\n",
        "embeddings = TransformerWordEmbeddings('neuralmind/bert-large-portuguese-cased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr50Gg0fBrUJ"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDQk-6ZHBrUJ",
        "outputId": "1c089724-0c6f-4f67-c237-67ad342a370e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-19 17:33:09,976 SequenceTagger predicts: Dictionary with 29 tags: O, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-FUNDAMENTO, B-FUNDAMENTO, E-FUNDAMENTO, I-FUNDAMENTO, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-DATA, B-DATA, E-DATA, I-DATA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL, S-PRODUTODELEI, B-PRODUTODELEI, E-PRODUTODELEI, I-PRODUTODELEI, S-EVENTO, B-EVENTO, E-EVENTO, I-EVENTO\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "tagger = SequenceTagger(hidden_size=128,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7Q7j8fGqBrUJ",
        "outputId": "5cb9aacb-8045-4c28-c7ab-9b774fac99d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-19 17:33:13,368 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-19 17:33:13,374 Model: \"SequenceTagger(\n",
            "  (embeddings): TransformerWordEmbeddings(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(29794, 1024, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 1024)\n",
            "        (token_type_embeddings): Embedding(2, 1024)\n",
            "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (12): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (13): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (14): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (15): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (16): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (17): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (18): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (19): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (20): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (21): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (22): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (23): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (rnn): LSTM(1024, 128, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=256, out_features=31, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-10-19 17:33:13,376 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-19 17:33:13,378 Corpus: \"Corpus: 6667 train + 1429 dev + 1430 test sentences\"\n",
            "2022-10-19 17:33:13,382 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-19 17:33:13,384 Parameters:\n",
            "2022-10-19 17:33:13,388  - learning_rate: \"0.100000\"\n",
            "2022-10-19 17:33:13,390  - mini_batch_size: \"32\"\n",
            "2022-10-19 17:33:13,391  - patience: \"3\"\n",
            "2022-10-19 17:33:13,395  - anneal_factor: \"0.5\"\n",
            "2022-10-19 17:33:13,396  - max_epochs: \"1\"\n",
            "2022-10-19 17:33:13,397  - shuffle: \"True\"\n",
            "2022-10-19 17:33:13,400  - train_with_dev: \"False\"\n",
            "2022-10-19 17:33:13,401  - batch_growth_annealing: \"False\"\n",
            "2022-10-19 17:33:13,403 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-19 17:33:13,405 Model training base path: \"/content/drive/MyDrive/Flair_NLP/sota-ner-flair\"\n",
            "2022-10-19 17:33:13,407 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-19 17:33:13,409 Device: cuda:0\n",
            "2022-10-19 17:33:13,411 ----------------------------------------------------------------------------------------------------\n",
            "2022-10-19 17:33:13,412 Embeddings storage mode: cpu\n",
            "2022-10-19 17:33:13,416 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b2d16af6604b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m               \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m               checkpoint=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, learning_rate, mini_batch_size, eval_batch_size, mini_batch_chunk_size, max_epochs, train_with_dev, train_with_test, monitor_train, monitor_test, main_evaluation_metric, scheduler, anneal_factor, patience, min_learning_rate, initial_extra_patience, optimizer, cycle_momentum, warmup_fraction, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, anneal_with_prestarts, anneal_against_dev_loss, batch_growth_annealing, shuffle, param_selection_mode, write_weights, num_workers, sampler, use_amp, amp_opt_level, eval_on_train_fraction, eval_on_train_shuffle, save_model_each_k_epochs, tensorboard_comment, use_swa, use_final_model_for_eval, gold_label_dictionary_for_eval, exclude_labels, create_file_logs, create_loss_file, epoch, use_tensorboard, tensorboard_log_dir, metrics_for_tensorboard, optimizer_state_dict, scheduler_state_dict, save_optimizer_state, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m                                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 454.00 MiB (GPU 0; 14.76 GiB total capacity; 12.21 GiB already allocated; 349.75 MiB free; 13.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# 6. initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "path = '/content/drive/MyDrive/Flair_NLP/sota-ner-flair'\n",
        "\n",
        "# 7. start training\n",
        "trainer.train(path,\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=1,\n",
        "              checkpoint=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyqUJfUyYUrV"
      },
      "source": [
        "## Teste 4.6 NER Flair Stacked Embeddings (Word, Bert e Flair Embeddings) com Corpus Ulysses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QnWADUOYUrV"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_tdoYLlYUrV",
        "outputId": "13fa8eac-8b3e-45b2-bb20-5242af04408c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83df3f10f75f4cf1a1b1d43eab2f5d4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Importes\n",
        "## datasets\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "## Embeddings\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings, TransformerWordEmbeddings\n",
        "\n",
        "## Modelo/Treino\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj34vXLhYUrV"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im0dSzsrYUrV",
        "outputId": "fa5f9b79-ee01-4411-ce22-7b67c4a9ecff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Montando o Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE2L7c8qYUrW",
        "outputId": "384f2d0b-4744-4dab-bbcb-2c93649e2226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-22 00:02:15,148 Reading data from /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria\n",
            "2022-09-22 00:02:15,150 Train: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/train.txt\n",
            "2022-09-22 00:02:15,152 Dev: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/valid.txt\n",
            "2022-09-22 00:02:15,154 Test: /content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria/test.txt\n"
          ]
        }
      ],
      "source": [
        "## carregando um corpus e definindo as colunas\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/Flair_NLP/Corpus/pl_corpus_categoria'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='valid.txt')\n",
        "\n",
        "## Tarefa\n",
        "label_type = 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCDHcSSXYUrW",
        "outputId": "df59ed41-54f3-405e-ef4a-604b8179fd14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-22 00:02:19,476 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6667it [00:00, 27377.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-22 00:02:19,784 Dictionary created for label 'ner' with 8 values: PESSOA (seen 628 times), FUNDAMENTO (seen 490 times), ORGANIZACAO (seen 435 times), DATA (seen 433 times), LOCAL (seen 369 times), PRODUTODELEI (seen 230 times), EVENTO (seen 9 times)\n",
            "Dictionary with 8 tags: <unk>, PESSOA, FUNDAMENTO, ORGANIZACAO, DATA, LOCAL, PRODUTODELEI, EVENTO\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Dicionário de rótulos\n",
        "# Make the label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LR1slGcYUrW"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qplbO-vYUrW",
        "outputId": "1d4eabb9-f84c-44ea-9f3e-c417a8163221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-22 00:06:27,559 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpc8149ee7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 710528528/710528528 [00:39<00:00, 17833913.65B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-22 00:07:07,885 copying /tmp/tmpc8149ee7 to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M.vectors.npy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-22 00:07:10,016 removing temp file /tmp/tmpc8149ee7\n",
            "2022-09-22 00:07:10,936 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmpkvubojdm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23541010/23541010 [00:02<00:00, 9310860.15B/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-22 00:07:13,950 copying /tmp/tmpkvubojdm to cache at /root/.flair/embeddings/pt-wiki-fasttext-300d-1M\n",
            "2022-09-22 00:07:13,986 removing temp file /tmp/tmpkvubojdm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Stacked Embeddings\n",
        "# Initialize embedding stack with \n",
        "embedding_types = [\n",
        "    WordEmbeddings('pt'),\n",
        "    TransformerWordEmbeddings('neuralmind/bert-base-portuguese-cased')\n",
        "]\n",
        "\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nksIebfAYUrW"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEubp--ZYUrW",
        "outputId": "66ec2149-b72b-4f04-8d72-84229a5490e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-22 00:07:31,863 SequenceTagger predicts: Dictionary with 29 tags: O, S-PESSOA, B-PESSOA, E-PESSOA, I-PESSOA, S-FUNDAMENTO, B-FUNDAMENTO, E-FUNDAMENTO, I-FUNDAMENTO, S-ORGANIZACAO, B-ORGANIZACAO, E-ORGANIZACAO, I-ORGANIZACAO, S-DATA, B-DATA, E-DATA, I-DATA, S-LOCAL, B-LOCAL, E-LOCAL, I-LOCAL, S-PRODUTODELEI, B-PRODUTODELEI, E-PRODUTODELEI, I-PRODUTODELEI, S-EVENTO, B-EVENTO, E-EVENTO, I-EVENTO\n"
          ]
        }
      ],
      "source": [
        "## Inicializando o modelo\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fHsDGuMVYUrW",
        "outputId": "5a63cd61-70bc-49fc-aa16-d2204947892c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-22 00:07:36,412 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-22 00:07:36,416 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'pt'\n",
            "      (embedding): Embedding(592108, 300)\n",
            "    )\n",
            "    (list_embedding_1): TransformerWordEmbeddings(\n",
            "      (model): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=1068, out_features=1068, bias=True)\n",
            "  (rnn): LSTM(1068, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=31, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-09-22 00:07:36,418 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-22 00:07:36,420 Corpus: \"Corpus: 6667 train + 1429 dev + 1430 test sentences\"\n",
            "2022-09-22 00:07:36,422 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-22 00:07:36,424 Parameters:\n",
            "2022-09-22 00:07:36,432  - learning_rate: \"0.100000\"\n",
            "2022-09-22 00:07:36,434  - mini_batch_size: \"12\"\n",
            "2022-09-22 00:07:36,435  - patience: \"3\"\n",
            "2022-09-22 00:07:36,438  - anneal_factor: \"0.5\"\n",
            "2022-09-22 00:07:36,440  - max_epochs: \"5\"\n",
            "2022-09-22 00:07:36,442  - shuffle: \"True\"\n",
            "2022-09-22 00:07:36,444  - train_with_dev: \"False\"\n",
            "2022-09-22 00:07:36,446  - batch_growth_annealing: \"False\"\n",
            "2022-09-22 00:07:36,448 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-22 00:07:36,450 Model training base path: \"resources/taggers/sota-ner-flair\"\n",
            "2022-09-22 00:07:36,452 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-22 00:07:36,453 Device: cuda:0\n",
            "2022-09-22 00:07:36,456 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-22 00:07:36,459 Embeddings storage mode: cpu\n",
            "2022-09-22 00:07:36,466 ----------------------------------------------------------------------------------------------------\n",
            "2022-09-22 00:07:49,926 epoch 1 - iter 55/556 - loss 0.91045696 - samples/sec: 49.08 - lr: 0.100000\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5c5251bf930c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m               \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m               \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m               max_epochs=5)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, learning_rate, mini_batch_size, eval_batch_size, mini_batch_chunk_size, max_epochs, train_with_dev, train_with_test, monitor_train, monitor_test, main_evaluation_metric, scheduler, anneal_factor, patience, min_learning_rate, initial_extra_patience, optimizer, cycle_momentum, warmup_fraction, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, anneal_with_prestarts, anneal_against_dev_loss, batch_growth_annealing, shuffle, param_selection_mode, write_weights, num_workers, sampler, use_amp, amp_opt_level, eval_on_train_fraction, eval_on_train_shuffle, save_model_each_k_epochs, tensorboard_comment, use_swa, use_final_model_for_eval, gold_label_dictionary_for_eval, exclude_labels, create_file_logs, create_loss_file, epoch, use_tensorboard, tensorboard_log_dir, metrics_for_tensorboard, optimizer_state_dict, scheduler_state_dict, save_optimizer_state, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward_loss\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# forward pass to get scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# calculate loss given scores and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# make a zero-padded tensor for the whole sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/embeddings/token.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/embeddings/base.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, data_points)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_everything_embedded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/embeddings/base.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mexpanded_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_to_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;31m# move embeddings from context back to original sentence (if using context)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/embeddings/base.py\u001b[0m in \u001b[0;36m_add_embeddings_to_sentences\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgradient_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;31m# make the tuple a tensor; makes working with it easier.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0mbuffered_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m                 \u001b[0mbuffered_token_type_ids_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids_expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (855) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [12, 855].  Tensor sizes: [1, 512]"
          ]
        }
      ],
      "source": [
        "## Treinando o modelo\n",
        "# Initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# Start training\n",
        "trainer.train('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=12,\n",
        "              max_epochs=5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "zEAuBQUjA0bl",
        "ecLSL6v1A0bq",
        "Tb2KbJ6LA0br",
        "fa8JGdIZA0br",
        "o_Pwv28MA0br",
        "s3krh2xB7vtX",
        "xvzF9y-17vte",
        "6nmlv9Di7vte",
        "oomnwDAA7vtf",
        "KwbeFKLl7vtf",
        "OW7c_AtGp5KS",
        "tT07DOE1nVIj",
        "m4koyc4JnYod",
        "LE4G2c3MncbG",
        "rmAx0fh0nhhJ",
        "_uFWjSmHdZdT",
        "-M8CvTbxdZdT",
        "e0yYFk_KdZdU",
        "v_ZS-BeDDPbJ",
        "pYPiToDIDPbT",
        "DUPLWIxwDPbU",
        "EwYHKBgMDPbU",
        "PDFAQblGDPbU",
        "9FEh-XFYJwPz",
        "vGiL58J7JwP6",
        "tMgco6pAJwP7",
        "Yf4gF5CvJwP7",
        "mofnzuW1JwP7",
        "8kCAsXVDL2cl",
        "C87p0ahbL2cr",
        "U763QiM7L2cs",
        "rrNaYl5VL2cs",
        "Xph3wVUvL2cs",
        "qTcj9YXEf5HQ",
        "KLzcp2Rff5HV",
        "ljmFfYgSf5HV",
        "qCyAXFcqf5HW",
        "tMiKWbCFf5HW",
        "knRAUHLJn2ze",
        "irBiiaDkn2zm",
        "4bJPzMJEn2zm",
        "Ha3l1o97n2zn",
        "_C7591KDn2zn",
        "c5m1lHNkbDIh",
        "lw1iuzGfbDIh",
        "GgRc9E3UbDIi",
        "EZ4y9dIzbDIi",
        "bOq8J_9VbDIi",
        "OHhtWpYeaa2q",
        "woNuyNwxaa2x",
        "XSlgwCNaaa2y",
        "PBRuD12Caa2y",
        "tncSoOGCaa2y",
        "GSvIPgvRDpN8",
        "xNL0hdTlDpN9",
        "R9ICFtkWDpN-",
        "9ulqqiJHDpN-",
        "7EegwNYeDpN-",
        "kI4cHv1z0PrD",
        "G0GrkbPf0PrD",
        "3X_eM36m0PrE",
        "9iHTmWVq0PrE",
        "AkP_b5NT0PrE",
        "vbXtQ7rhqGqD",
        "p-1DOm4xqGqJ",
        "ZJaVvL1oqGqJ",
        "SATvGxbBqGqJ",
        "MIzOGdLeqGqK",
        "7MTdmN9sXiue",
        "d7PKxStLvY2j",
        "8BFtUmgOvY2k",
        "4ayg1NWNvY2k",
        "GyqUJfUyYUrV",
        "0QnWADUOYUrV",
        "Pj34vXLhYUrV",
        "_LR1slGcYUrW",
        "nksIebfAYUrW"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "010a04542c0f4f819a04272f631112a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f833d8142fd4f20a4ec0456934445a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fb4769941754222a671bb8386cdbee1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe1862fc8af42939b3f1d41569cc22e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "138094cb1c2b43b5b5bb6b95b0d8a7fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24151aaaea0e46d39ff91cb6b49bf6d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c9d300451dc4a4c9721898871dfe168": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_138094cb1c2b43b5b5bb6b95b0d8a7fd",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f537ac0e44164a1cae9b1bafe06d98a2",
            "value": 112
          }
        },
        "2eea50aad688406f90d4fd2cf41ac565": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81c9328246d548f7b0ace61d89cca748",
              "IPY_MODEL_cb7989b1fb98474c9cccbe1c330a01a1",
              "IPY_MODEL_f01102409f8e4573834cc09abed0feb1"
            ],
            "layout": "IPY_MODEL_ef7cd9acb42045b2a5eb519dfbf7839e"
          }
        },
        "2f1672b8004c486899cdfa66a6e9f879": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adae77b1992f4e89a0d5360f37c617b9",
            "placeholder": "​",
            "style": "IPY_MODEL_a1a705c2a8a141af845adc77e557c6c9",
            "value": " 2.00/2.00 [00:00&lt;00:00, 79.3B/s]"
          }
        },
        "3392cc69ffa34776a4c7e9c5e87dda3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "351870153f5e4843be8856534ed53874": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b7abfa087e24e539e65421c6c32d59b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ca5b857fc0e469eb8d46139fe516704": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cfce413eeb349f5a98b149b45567bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fb4769941754222a671bb8386cdbee1",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c0d15d34aa34a56aaf28e8780ef89f1",
            "value": 2
          }
        },
        "41f2ca0255454b41ac03d011637967df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42067333bf194d11a98894eaa31e13ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4206e3a39ec1491faa788b49b59fff2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4268b55c1f644241a22c00334bd3bc0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47cb1247e6084a70b85e34bb078e3c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41f2ca0255454b41ac03d011637967df",
            "placeholder": "​",
            "style": "IPY_MODEL_ff22171ecc6949b7b3495e7cc911ab21",
            "value": "Downloading: 100%"
          }
        },
        "4d3405eb60dc4b2e9a283039f270d6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79dd73fa24214684b6239043727e73f2",
            "max": 648,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65921150cada46db9b7cca43f6d3bc1b",
            "value": 648
          }
        },
        "516e0ec4927b449f9d202cdbd2f2aecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dff6ac8758a94f40a0acaaa074ea6421",
              "IPY_MODEL_4d3405eb60dc4b2e9a283039f270d6be",
              "IPY_MODEL_95c09ca2b072458d84808cc04539b567"
            ],
            "layout": "IPY_MODEL_3ca5b857fc0e469eb8d46139fe516704"
          }
        },
        "51d969e767ca4477b4340033b526c949": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55b10fb79447425883d253902281daef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_351870153f5e4843be8856534ed53874",
            "placeholder": "​",
            "style": "IPY_MODEL_c49d6058e87f47a6a5d5bfddd6420fe6",
            "value": "Downloading: 100%"
          }
        },
        "5807265c72814dc98d3d0752e30bdb14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59d661be1e0343049f24f10128873e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fafa44bb6ca44c7f8dd74a3317b258f7",
              "IPY_MODEL_b82288dcdc1044d4a0ee2bf66137c76e",
              "IPY_MODEL_ce25e0dc810e41db9cdd8aed83c5d94a"
            ],
            "layout": "IPY_MODEL_42067333bf194d11a98894eaa31e13ff"
          }
        },
        "65921150cada46db9b7cca43f6d3bc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a3d132cdae340f49689ef9852cae89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5807265c72814dc98d3d0752e30bdb14",
            "placeholder": "​",
            "style": "IPY_MODEL_4268b55c1f644241a22c00334bd3bc0c",
            "value": " 112/112 [00:00&lt;00:00, 4.82kB/s]"
          }
        },
        "6ef14d94c3f44ba384c34633abbf9ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73bd87fce839498498598cc01f4c4131": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7429c024545f4eafb934caeab63ad803": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77fda6a857994a04aa94313a954ad5e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79dd73fa24214684b6239043727e73f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81a277303e0c45ab8e86b8235c52ee1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81c9328246d548f7b0ace61d89cca748": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef14d94c3f44ba384c34633abbf9ddb",
            "placeholder": "​",
            "style": "IPY_MODEL_73bd87fce839498498598cc01f4c4131",
            "value": "Downloading: 100%"
          }
        },
        "83aa54c3eff04a28a50369e8f0aa5d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e2034fe53a048edb5f347adafdb8c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93612f6ea1134e50930d9bda8abf794a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95c09ca2b072458d84808cc04539b567": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae29de0a658042afb862a8dbeaa5cc0f",
            "placeholder": "​",
            "style": "IPY_MODEL_c9b4dbfd465d44aa925f69ad804739ac",
            "value": " 648/648 [00:00&lt;00:00, 23.1kB/s]"
          }
        },
        "960452461ae84c11aecf4c715911ca59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9853062dfbe343c1bb2aebeaafa812bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f833d8142fd4f20a4ec0456934445a4",
            "placeholder": "​",
            "style": "IPY_MODEL_83aa54c3eff04a28a50369e8f0aa5d0d",
            "value": "Downloading: 100%"
          }
        },
        "9c0d15d34aa34a56aaf28e8780ef89f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a12c2dc4a85f4c6c862ae08b324a58fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1a705c2a8a141af845adc77e557c6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a632e721554f4e109fca460118021840": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9853062dfbe343c1bb2aebeaafa812bb",
              "IPY_MODEL_3cfce413eeb349f5a98b149b45567bc7",
              "IPY_MODEL_2f1672b8004c486899cdfa66a6e9f879"
            ],
            "layout": "IPY_MODEL_51d969e767ca4477b4340033b526c949"
          }
        },
        "adae77b1992f4e89a0d5360f37c617b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae29de0a658042afb862a8dbeaa5cc0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5195c58a3534f95b9cfb1482c5a27b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3392cc69ffa34776a4c7e9c5e87dda3f",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24151aaaea0e46d39ff91cb6b49bf6d1",
            "value": 209528
          }
        },
        "b82288dcdc1044d4a0ee2bf66137c76e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a12c2dc4a85f4c6c862ae08b324a58fd",
            "max": 155,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93612f6ea1134e50930d9bda8abf794a",
            "value": 155
          }
        },
        "beaebecce77544689ebefb53ce47b3c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c49d6058e87f47a6a5d5bfddd6420fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9b4dbfd465d44aa925f69ad804739ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb7989b1fb98474c9cccbe1c330a01a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7429c024545f4eafb934caeab63ad803",
            "max": 1342014951,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f87e5ef6ced947fd82e87728192884c3",
            "value": 1342014951
          }
        },
        "ce25e0dc810e41db9cdd8aed83c5d94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_010a04542c0f4f819a04272f631112a0",
            "placeholder": "​",
            "style": "IPY_MODEL_81a277303e0c45ab8e86b8235c52ee1b",
            "value": " 155/155 [00:00&lt;00:00, 5.68kB/s]"
          }
        },
        "db1f7f3f4e6c41eaaa3b7922ea36d98e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f664954a7ecb4a16ad1968a08d7b99c6",
            "placeholder": "​",
            "style": "IPY_MODEL_4206e3a39ec1491faa788b49b59fff2b",
            "value": " 210k/210k [00:00&lt;00:00, 2.67MB/s]"
          }
        },
        "dff6ac8758a94f40a0acaaa074ea6421": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fe1862fc8af42939b3f1d41569cc22e",
            "placeholder": "​",
            "style": "IPY_MODEL_3b7abfa087e24e539e65421c6c32d59b",
            "value": "Downloading: 100%"
          }
        },
        "ef1fdecd44f1470ca257685acc6031ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55b10fb79447425883d253902281daef",
              "IPY_MODEL_b5195c58a3534f95b9cfb1482c5a27b1",
              "IPY_MODEL_db1f7f3f4e6c41eaaa3b7922ea36d98e"
            ],
            "layout": "IPY_MODEL_77fda6a857994a04aa94313a954ad5e5"
          }
        },
        "ef7cd9acb42045b2a5eb519dfbf7839e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f01102409f8e4573834cc09abed0feb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2fe39a2f370482f8ee9bce4f0518a7e",
            "placeholder": "​",
            "style": "IPY_MODEL_8e2034fe53a048edb5f347adafdb8c33",
            "value": " 1.34G/1.34G [00:21&lt;00:00, 65.6MB/s]"
          }
        },
        "f22a5125e1c0405db2323f6461376b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47cb1247e6084a70b85e34bb078e3c83",
              "IPY_MODEL_2c9d300451dc4a4c9721898871dfe168",
              "IPY_MODEL_6a3d132cdae340f49689ef9852cae89c"
            ],
            "layout": "IPY_MODEL_beaebecce77544689ebefb53ce47b3c7"
          }
        },
        "f2fe39a2f370482f8ee9bce4f0518a7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4a645dfd391490884160d4fd7a2ea35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f537ac0e44164a1cae9b1bafe06d98a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f664954a7ecb4a16ad1968a08d7b99c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f87e5ef6ced947fd82e87728192884c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fafa44bb6ca44c7f8dd74a3317b258f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4a645dfd391490884160d4fd7a2ea35",
            "placeholder": "​",
            "style": "IPY_MODEL_960452461ae84c11aecf4c715911ca59",
            "value": "Downloading: 100%"
          }
        },
        "ff22171ecc6949b7b3495e7cc911ab21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}